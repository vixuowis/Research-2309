{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5943b92c-7c7c-459a-a996-185e499ebef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的是跑分，需要把 llama predict 出来的算个分\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "model_name = \"codellama-34b-python\"\n",
    "\n",
    "valid_path = \"output/hf-eval-data-v4-valid\"\n",
    "folder_path = f\"output/hf-eval-data-v4-valid-result/{model_name}\"\n",
    "eval_path = f\"output/hf-eval-data-v4-valid-result/{model_name}-eval\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(eval_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def iter_files(folder_path):\n",
    "    # 遍历文件列表\n",
    "    for file in os.listdir(folder_path):\n",
    "        # 获取文件的完整路径\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "\n",
    "        # 判断是否为文件（而不是文件夹）\n",
    "        if os.path.isfile(file_path):\n",
    "            yield file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24df63b2-d94c-4dbe-b661-01912f83bdb4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49,\n",
       " {'path': 'output/hf-eval-data-v4-valid/f00055_translate_french_to_english.py',\n",
       "  'content': '# requirements_file --------------------\\n\\nimport subprocess\\n\\nrequirements = [\"transformers\"]\\n\\nfor package in requirements:\\n    subprocess.run([\\'pip\\', \\'install\\', \\'-U\\', package])\\n\\n# function_import --------------------\\n\\nfrom transformers import pipeline\\n\\n# function_code --------------------\\n\\ndef translate_french_to_english(text):\\n    \"\"\"\\n    Translates a given text from French to English using Hugging Face\\'s Transformers library.\\n\\n    Args:\\n        text (str): The text in French to be translated.\\n\\n    Returns:\\n        str: The translated text in English.\\n\\n    Raises:\\n        ValueError: If the input text is not a string or if it\\'s empty.\\n    \"\"\"\\n    if not isinstance(text, str) or not text:\\n        raise ValueError(\\'Input text must be a non-empty string.\\')\\n    \\n    translation_pipeline = pipeline(\\'translation_fr_to_en\\', model=\\'Helsinki-NLP/opus-mt-fr-en\\')\\n    translated_text = translation_pipeline(text)\\n    return translated_text[0][\\'translation_text\\']\\n\\n# test_function_code --------------------\\n\\ndef test_translate_french_to_english():\\n    print(\"Testing started.\")\\n    # Test case 1: Valid French text\\n    print(\"Testing case [1/2] started.\")\\n    french_text = \\'Bonjour, comment ça va?\\'\\n    assert translate_french_to_english(french_text) == \\'Hello, how are you?\\', \"Test case [1/2] failed: French text was not translated correctly.\"\\n\\n    # Test case 2: Invalid input (empty string)\\n    print(\"Testing case [2/2] started.\")\\n    try:\\n        translate_french_to_english(\\'\\')\\n        assert False, \"Test case [2/2] failed: Empty string did not raise ValueError.\"\\n    except ValueError:\\n        assert True\\n\\n    print(\"Testing finished.\")\\n\\n# call_test_function_line --------------------\\n\\ntest_translate_french_to_english()',\n",
       "  'function_import': '# function_import --------------------\\n\\nfrom transformers import pipeline\\n\\n',\n",
       "  'function_code': '# function_code --------------------\\n\\ndef translate_french_to_english(text):\\n    \"\"\"\\n    Translates a given text from French to English using Hugging Face\\'s Transformers library.\\n\\n    Args:\\n        text (str): The text in French to be translated.\\n\\n    Returns:\\n        str: The translated text in English.\\n\\n    Raises:\\n        ValueError: If the input text is not a string or if it\\'s empty.\\n    \"\"\"\\n    if not isinstance(text, str) or not text:\\n        raise ValueError(\\'Input text must be a non-empty string.\\')\\n    \\n    translation_pipeline = pipeline(\\'translation_fr_to_en\\', model=\\'Helsinki-NLP/opus-mt-fr-en\\')\\n    translated_text = translation_pipeline(text)\\n    return translated_text[0][\\'translation_text\\']\\n\\n',\n",
       "  'test_function_code': '# test_function_code --------------------\\n\\ndef test_translate_french_to_english():\\n    print(\"Testing started.\")\\n    # Test case 1: Valid French text\\n    print(\"Testing case [1/2] started.\")\\n    french_text = \\'Bonjour, comment ça va?\\'\\n    assert translate_french_to_english(french_text) == \\'Hello, how are you?\\', \"Test case [1/2] failed: French text was not translated correctly.\"\\n\\n    # Test case 2: Invalid input (empty string)\\n    print(\"Testing case [2/2] started.\")\\n    try:\\n        translate_french_to_english(\\'\\')\\n        assert False, \"Test case [2/2] failed: Empty string did not raise ValueError.\"\\n    except ValueError:\\n        assert True\\n\\n    print(\"Testing finished.\")\\n\\n',\n",
       "  'call_test_function_line': '# call_test_function_line --------------------\\n\\ntest_translate_french_to_english()',\n",
       "  'function_req': '# requirements_file --------------------\\n\\nimport subprocess\\n\\nrequirements = [\"transformers\"]\\n\\nfor package in requirements:\\n    subprocess.run([\\'pip\\', \\'install\\', \\'-U\\', package])\\n\\n',\n",
       "  'instruct': '# requirements_file --------------------\\n\\nimport subprocess\\n\\nrequirements = [\"transformers\"]\\n\\nfor package in requirements:\\n    subprocess.run([\\'pip\\', \\'install\\', \\'-U\\', package])\\n\\n# function_import --------------------\\n\\nfrom transformers import pipeline\\n\\n# function_code --------------------\\n\\ndef translate_french_to_english(text):\\n    \"\"\"\\n    Translates a given text from French to English using Hugging Face\\'s Transformers library.\\n\\n    Args:\\n        text (str): The text in French to be translated.\\n\\n    Returns:\\n        str: The translated text in English.\\n\\n    Raises:\\n        ValueError: If the input text is not a string or if it\\'s empty.\\n    \"\"\"',\n",
       "  'answer': \"\\n    if not isinstance(text, str) or not text:\\n        raise ValueError('Input text must be a non-empty string.')\\n    \\n    translation_pipeline = pipeline('translation_fr_to_en', model='Helsinki-NLP/opus-mt-fr-en')\\n    translated_text = translation_pipeline(text)\\n    return translated_text[0]['translation_text']\\n\\n\",\n",
       "  'prediction': '\\n    \\n    if type(text) != str: raise ValueError(\"Input must be of type string.\")\\n    if not text: raise ValueError(\"Cannot pass an empty value.\")\\n    \\n    model = pipeline(\\'translation_fr_to_en\\', model=\"t5-small\") # you can also use t5-base\\n    result = model([text])[0][\\'translation_text\\']\\n    return result'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predict_result = []\n",
    "\n",
    "for file in iter_files(folder_path):\n",
    "    with open(file) as f:\n",
    "        try:\n",
    "            d = json.loads(f.read())\n",
    "            all_predict_result.append(d)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "len(all_predict_result), all_predict_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e282fe3-644d-4d4e-a465-c45db91a06b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/hf-eval-data-v4-valid/f00055_translate_french_to_english.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00055_translate_french_to_english.py\n",
      "output/hf-eval-data-v4-valid/f00064_generate_story_start.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00064_generate_story_start.py\n",
      "output/hf-eval-data-v4-valid/f00065_predict_missing_text.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00065_predict_missing_text.py\n",
      "output/hf-eval-data-v4-valid/f00066_fill_in_the_blank_chinese_sentence.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00066_fill_in_the_blank_chinese_sentence.py\n",
      "output/hf-eval-data-v4-valid/f00070_calculate_sentence_similarity.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00070_calculate_sentence_similarity.py\n",
      "output/hf-eval-data-v4-valid/f00085_predict_vehicle_co2_emissions.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00085_predict_vehicle_co2_emissions.py\n",
      "output/hf-eval-data-v4-valid/f00111_detect_objects_in_image.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00111_detect_objects_in_image.py\n",
      "output/hf-eval-data-v4-valid/f00126_find_most_relevant_passage.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00126_find_most_relevant_passage.py\n",
      "output/hf-eval-data-v4-valid/f00156_transcribe_audio.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00156_transcribe_audio.py\n",
      "output/hf-eval-data-v4-valid/f00169_predict_prosthetic_leg_actions.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00169_predict_prosthetic_leg_actions.py\n",
      "output/hf-eval-data-v4-valid/f00184_estimate_depth_from_footage.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00184_estimate_depth_from_footage.py\n",
      "output/hf-eval-data-v4-valid/f00189_classify_image.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00189_classify_image.py\n",
      "output/hf-eval-data-v4-valid/f00232_convert_chinese_text_to_speech.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00232_convert_chinese_text_to_speech.py\n",
      "output/hf-eval-data-v4-valid/f00261_load_text_to_image_model.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00261_load_text_to_image_model.py\n",
      "output/hf-eval-data-v4-valid/f00278_extract_table_from_image.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00278_extract_table_from_image.py\n",
      "output/hf-eval-data-v4-valid/f00280_generate_book_cover.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00280_generate_book_cover.py\n",
      "output/hf-eval-data-v4-valid/f00300_summarize_executive_meeting_notes.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00300_summarize_executive_meeting_notes.py\n",
      "output/hf-eval-data-v4-valid/f00307_create_loading_spinner.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00307_create_loading_spinner.py\n",
      "output/hf-eval-data-v4-valid/f00313_generate_fill_in_the_blank.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00313_generate_fill_in_the_blank.py\n",
      "output/hf-eval-data-v4-valid/f00368_generate_luxury_living_room_image.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00368_generate_luxury_living_room_image.py\n",
      "output/hf-eval-data-v4-valid/f00373_generate_cat_character_image.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00373_generate_cat_character_image.py\n",
      "output/hf-eval-data-v4-valid/f00411_complete_slogan.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00411_complete_slogan.py\n",
      "output/hf-eval-data-v4-valid/f00435_perform_speaker_diarization.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00435_perform_speaker_diarization.py\n",
      "output/hf-eval-data-v4-valid/f00441_predict_carbon_emissions.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00441_predict_carbon_emissions.py\n",
      "output/hf-eval-data-v4-valid/f00444_estimate_co2_emissions.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00444_estimate_co2_emissions.py\n",
      "output/hf-eval-data-v4-valid/f00464_classify_image.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00464_classify_image.py\n",
      "output/hf-eval-data-v4-valid/f00475_generate_car_image.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00475_generate_car_image.py\n",
      "output/hf-eval-data-v4-valid/f00525_calculate_sentence_similarity.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00525_calculate_sentence_similarity.py\n",
      "output/hf-eval-data-v4-valid/f00533_classify_voice_command.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00533_classify_voice_command.py\n",
      "output/hf-eval-data-v4-valid/f00546_extract_features.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00546_extract_features.py\n",
      "output/hf-eval-data-v4-valid/f00551_extract_text_from_manga.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00551_extract_text_from_manga.py\n",
      "output/hf-eval-data-v4-valid/f00563_classify_image.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00563_classify_image.py\n",
      "output/hf-eval-data-v4-valid/f00570_generate_eco_friendly_slogan.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00570_generate_eco_friendly_slogan.py\n",
      "output/hf-eval-data-v4-valid/f00626_classify_caller_demographics.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00626_classify_caller_demographics.py\n",
      "output/hf-eval-data-v4-valid/f00639_generate_image_from_text.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00639_generate_image_from_text.py\n",
      "output/hf-eval-data-v4-valid/f00672_find_relevant_passage.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00672_find_relevant_passage.py\n",
      "output/hf-eval-data-v4-valid/f00704_find_most_related_faq.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00704_find_most_related_faq.py\n",
      "output/hf-eval-data-v4-valid/f00721_analyze_wine_quality.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00721_analyze_wine_quality.py\n",
      "output/hf-eval-data-v4-valid/f00758_generate_cute_butterfly_images.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00758_generate_cute_butterfly_images.py\n",
      "output/hf-eval-data-v4-valid/f00781_classify_news_article.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00781_classify_news_article.py\n",
      "output/hf-eval-data-v4-valid/f00801_calculate_sentence_similarity.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00801_calculate_sentence_similarity.py\n",
      "output/hf-eval-data-v4-valid/f00803_find_most_relevant_answer.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00803_find_most_relevant_answer.py\n",
      "output/hf-eval-data-v4-valid/f00823_generate_contextual_representation.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00823_generate_contextual_representation.py\n",
      "output/hf-eval-data-v4-valid/f00842_predict_car_brand.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00842_predict_car_brand.py\n",
      "output/hf-eval-data-v4-valid/f00851_simplify_floor_plan.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00851_simplify_floor_plan.py\n",
      "output/hf-eval-data-v4-valid/f00861_analyze_movie_review_sentiment.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00861_analyze_movie_review_sentiment.py\n",
      "output/hf-eval-data-v4-valid/f00862_rank_search_results.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00862_rank_search_results.py\n",
      "output/hf-eval-data-v4-valid/f00895_convert_text_to_speech.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00895_convert_text_to_speech.py\n",
      "output/hf-eval-data-v4-valid/f00909_diarize_audio.py\n",
      "output/hf-eval-data-v4-valid-result/codellama-34b-python-eval/f00909_diarize_audio.py\n"
     ]
    }
   ],
   "source": [
    "# pip file + predict file => eval file\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    os.mkdir(eval_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for d in all_predict_result:\n",
    "    print(d['path'])\n",
    "    \n",
    "    predict_file = d['path']\n",
    "    \n",
    "    # pip file\n",
    "    pip_file = predict_file.split(\".\")[0] + \".txt\"\n",
    "    file_name = pip_file.split(\"/\")[-1]\n",
    "    \n",
    "    try:\n",
    "        shutil.copy(pip_file, eval_path + \"/\" + file_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # eval python file\n",
    "    eval_file = d['instruct'] + d['prediction'].split(\"\\ndef\")[0] + \"\\n\\n\" + d['test_function_code'] + \"\\n\" + d['call_test_function_line']\n",
    "    \n",
    "    eval_file_path = eval_path + \"/\" + predict_file.split(\"/\")[-1]\n",
    "    \n",
    "    print(eval_file_path)\n",
    "    \n",
    "    with open(eval_file_path, 'w') as fw:\n",
    "        fw.write(eval_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69a5077a-ac53-4b69-86a1-ce5a9db897d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_eval_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mhf_eval_data\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     formatted_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hf_eval_data' is not defined"
     ]
    }
   ],
   "source": [
    "for idx, d in enumerate(hf_eval_data):\n",
    "    print(idx + 1, end=\"...\")\n",
    "    formatted_number = str(idx + 1).zfill(5)\n",
    "\n",
    "    # check err\n",
    "    matching_files_err = glob.glob(f\"{output_dir}/f{formatted_number}_*.err\")\n",
    "    if not matching_files_err:\n",
    "        continue\n",
    "    \n",
    "    matched += 1\n",
    "        \n",
    "    with open(matching_files_err[0]) as f:\n",
    "        content = f.read()\n",
    "        if 'Error' in content:\n",
    "            continue\n",
    "\n",
    "    # check out\n",
    "    matching_files_out = glob.glob(f\"{output_dir}/f{formatted_number}_*.out\")\n",
    "    if not matching_files_out:\n",
    "        continue\n",
    "        \n",
    "    with open(matching_files_out[0]) as f:\n",
    "        content = f.read()\n",
    "        if 'failed' in content:\n",
    "            continue\n",
    "            \n",
    "    # copy files\n",
    "    matching_files = glob.glob(f\"{output_dir}/f{formatted_number}_*\")\n",
    "    for source_file in matching_files:\n",
    "        dest_file = valid_dir + source_file.split(f\"{output_dir}\")[-1]\n",
    "        shutil.copy(source_file, dest_file)\n",
    "        \n",
    "    valid += 1\n",
    "    \n",
    "valid, matched, valid/matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2846970c-5094-4845-85c6-56a985773890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7b 44 241 0.1825726141078838\n",
      "13b 51 239 0.21338912133891214\n",
      "34b 51 241 0.21161825726141079\n"
     ]
    }
   ],
   "source": [
    "# get eval pass rate\n",
    "import os\n",
    "\n",
    "for i in [7, 13, 34]:\n",
    "    eval_dir = f\"output/hf-eval-data-v3-reuslt-{i}b-eval/\"\n",
    "    total_case = 0\n",
    "    pass_case = 0\n",
    "\n",
    "    for file in os.listdir(eval_dir):\n",
    "        if file.endswith(\".err\"):\n",
    "            # print(file)\n",
    "\n",
    "            total_case += 1\n",
    "\n",
    "            # check err file\n",
    "            err_file = file\n",
    "            with open(eval_dir + err_file) as f:\n",
    "                content = f.read()\n",
    "                if 'Error' in content:\n",
    "                    continue\n",
    "\n",
    "            # check out file\n",
    "            out_file = file.split(\".\")[0] + \".out\"\n",
    "            with open(eval_dir + out_file) as f:\n",
    "                content = f.read()\n",
    "                if 'failed' in content:\n",
    "                    continue\n",
    "            \n",
    "            # print(file)\n",
    "            pass_case += 1\n",
    "\n",
    "    print(f\"{i}b\", pass_case, total_case, pass_case / total_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66afcb62-b945-4c3e-9b0b-5fc28a81822a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
