{'code': "###Instruction: I have a website text about technology and I want to know if it represents a positive sentiment or a negative one.\n###Output: <<<domain>>>: Natural Language Processing Zero-Shot Classification\n<<<api_call>>>: pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-6')\n<<<api_provider>>>: Transformers\n<<<explanation>>>: 1. Import the pipeline function from the transformers library.\n2. Use the pipeline function to create an instance of the zero-shot classification model by specifying the model 'valhalla/distilbart-mnli-12-6'.\n3. This model is designed to perform zero-shoot classification tasks, which allows it to classify text into categories it hasn't explicitly been trained on.\n4. Once the model is loaded, pass the text into the model with a list of candidate labels ('positive' and 'negative') to get the sentiment classification.\n<<<code>>>: from transformers import pipeline\nnlp = pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-6')\nresult = nlp('The website text about technology', ['positive', 'negative'])", 'api_call': "pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-6')", 'provider': 'Transformers', 'api_data': {'domain': 'Natural Language Processing Zero-Shot Classification', 'framework': 'Transformers', 'functionality': 'Zero-Shot Classification', 'api_name': 'valhalla/distilbart-mnli-12-6', 'api_call': "pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-6')", 'api_arguments': 'text, candidate_labels', 'python_environment_requirements': 'transformers', 'example_code': "from transformers import pipeline\nnlp = pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-6')\nresult = nlp('The movie was great!', ['positive', 'negative'])\nprint(result)", 'performance': {'dataset': 'MNLI', 'accuracy': {'matched_acc': '89.19', 'mismatched_acc': '89.01'}}, 'description': 'distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks.'}}

