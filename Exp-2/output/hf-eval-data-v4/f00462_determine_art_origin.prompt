{'code': '###Instruction: Our team has built a Japanese language learning app for students. We want to make sure that the user-submitted image is an anime art created by humans and not AI-generated.\n###Output: <<<domain>>>: Computer Vision Image Classification\n<<<api_call>>>: pipeline(\'image-classification\', model=\'saltacc/anime-ai-detect\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the necessary library functions, including the \'pipeline\' from the transformers library.\n2. Use the \'pipeline\' function to create an image classification model with the pre-trained model \'saltacc/anime-ai-detect\'. This model is trained to classify whether the provided anime art is created by a human or generated through AI.\n3. Load the user-submitted image from the app with a suitable image-loading library, such as PIL.\n4. Pass the image to the image classification model, which will return a classification result indicating whether the provided image is created by a human or AI-generated.\n<<<code>>>: from transformers import pipeline\nfrom PIL import Image\n\nimage = Image.open("image_path.jpg")\n# replace "image_path.jpg" with path to your image\n\nanime_detector = pipeline("image-classification", model="saltacc/anime-ai-detect")\nclassification_result = anime_detector(image)', 'api_call': "pipeline('image-classification', model='saltacc/anime-ai-detect')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Computer Vision Image Classification', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'saltacc/anime-ai-detect', 'api_call': "pipeline('image-classification', model='saltacc/anime-ai-detect')", 'api_arguments': ['image'], 'python_environment_requirements': ['transformers'], 'example_code': '', 'performance': {'dataset': 'aibooru and imageboard sites', 'accuracy': '96%'}, 'description': 'A BEiT classifier to see if anime art was made by an AI or a human.'}}

