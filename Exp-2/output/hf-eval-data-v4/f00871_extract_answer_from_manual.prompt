{'code': '###Instruction: You are the head of the QA department and you want to create an application that extracts answers from large product manuals. Explain how you can use this API for the project.\n###Output: <<<domain>>>: Natural Language Processing Question Answering\n<<<api_call>>>: pipeline(\'question-answering\', model=\'deepset/bert-large-uncased-whole-word-masking-squad2\')\n<<<api_provider>>>: Transformers\n<<<explanation>>>: 1. Import the necessary libraries, which are \'pipeline\', \'AutoModel\', and \'AutoTokenizer\' from transformers.\n2. Use the \'pipeline\' function from transformers to create a question-answering model with the pre-trained model \'deepset/bert-large-uncased-whole-word-masking-squad2\'.\n3. For the tokenizer, use \'deepset/bert-large-uncased-whole-word-masking-squad2\' as well.\n4. With the created pipeline, you can now provide the context (e.g., product manual content) and the question you want to ask about the manual.\n5. The model will then process the input and return the extracted answer from the given context.\n<<<code>>>: from transformers import pipeline, AutoModel, AutoTokenizer\nqa_pipeline = pipeline(\n    \'question-answering\',\n    model=AutoModel.from_pretrained(\'deepset/bert-large-uncased-whole-word-masking-squad2\'),\n    tokenizer=AutoTokenizer.from_pretrained(\'deepset/bert-large-uncased-whole-word-masking-squad2\')\n)\n\nmanual_content = "<large product manual content here>"\nquestion = "How to perform a factory reset on the product?"\n\ninput_data = {\'question\': question, \'context\': manual_content}\nanswer = qa_pipeline(input_data)\n', 'api_call': "pipeline('question-answering', model=AutoModel.from_pretrained('deepset/bert-large-uncased-whole-word-masking-squad2'), tokenizer=AutoTokenizer.from_pretrained('deepset/bert-large-uncased-whole-word-masking-squad2'))", 'provider': 'Transformers', 'api_data': {'domain': 'Natural Language Processing Question Answering', 'framework': 'Transformers', 'functionality': 'Question Answering', 'api_name': 'bert-large-uncased-whole-word-masking-squad2', 'api_call': "pipeline('question-answering', model=AutoModel.from_pretrained('deepset/bert-large-uncased-whole-word-masking-squad2'), tokenizer=AutoTokenizer.from_pretrained('deepset/bert-large-uncased-whole-word-masking-squad2'))", 'api_arguments': {'model_name': 'deepset/bert-large-uncased-whole-word-masking-squad2', 'tokenizer': 'deepset/bert-large-uncased-whole-word-masking-squad2'}, 'python_environment_requirements': ['transformers'], 'example_code': "QA_input = {\n 'question': 'Why is model conversion important?',\n 'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n}\nres = nlp(QA_input)", 'performance': {'dataset': 'squad_v2', 'accuracy': {'Exact Match': 80.885, 'F1': 83.876}}, 'description': 'This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language.'}}

