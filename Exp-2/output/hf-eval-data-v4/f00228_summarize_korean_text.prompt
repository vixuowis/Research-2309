{'code': '###Instruction: A customer wants to convert an input Korean text into a summary. Provide a solution for it.\n###Output: <<<domain>>>: Natural Language Processing Text2Text Generation\n<<<api_call>>>: EncoderDecoderModel.from_pretrained(\'kykim/bertshared-kor-base\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. First, we import the BertTokenizerFast and EncoderDecoderModel classes from the transformers package.\n2. Then, we create a tokenizer instance for the Korean language using the BertTokenizerFast.from_pretrained() method and specifying the model name \'kykim/bertshared-kor-base\'.\n3. We create a model instance for Text2Text Generation tasks using the EncoderDecoderModel.from_pretrained() method and specifying the model name \'kykim/bertshared-kor-base\'.\n4. Use the tokenizer to convert the input Korean text into input tokens.\n5. Use the model to generate a summarized version of the input tokens.\n6. Decode the generated tokens back into text.\n<<<code>>>: from transformers import BertTokenizerFast, EncoderDecoderModel\ntokenizer = BertTokenizerFast.from_pretrained(\'kykim/bertshared-kor-base\')\nmodel = EncoderDecoderModel.from_pretrained(\'kykim/bertshared-kor-base\')\ninput_text = "고객이 입력한 한국어 텍스트를 요약으로 변환하려고 합니다."\ninput_tokens = tokenizer.encode(input_text, return_tensors=\'pt\')\nsummary_tokens = model.generate(input_tokens)\nsummary_text = tokenizer.decode(summary_tokens[0], skip_special_tokens=True)', 'api_call': "EncoderDecoderModel.from_pretrained('kykim/bertshared-kor-base')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Text2Text Generation', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'kykim/bertshared-kor-base', 'api_call': "EncoderDecoderModel.from_pretrained('kykim/bertshared-kor-base')", 'api_arguments': {'tokenizer': 'BertTokenizerFast.from_pretrained(kykim/bertshared-kor-base)'}, 'python_environment_requirements': 'transformers', 'example_code': 'from transformers import BertTokenizerFast, EncoderDecoderModel\ntokenizer = BertTokenizerFast.from_pretrained(kykim/bertshared-kor-base)\nmodel = EncoderDecoderModel.from_pretrained(kykim/bertshared-kor-base)', 'performance': {'dataset': '70GB Korean text dataset', 'accuracy': '42000 lower-cased subwords'}, 'description': 'Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks.'}}

