{'code': '###Instruction: Create a machine learning-based image recognition tool that can identify whether an animal in an image is a cat or a dog.\n###Output: <<<domain>>>: Computer Vision Zero-Shot Image Classification\n<<<api_call>>>: pipeline(\'image-classification\', model=\'laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft\')\n<<<api_provider>>>: Hugging Face\n<<<explanation>>>: 1. First, import the pipeline function from the transformers library provided by Hugging Face.\n2. Utilize the pipeline function to create an image classification model that is based on the zero-shot learning paradigm â€“ this means the model can classify images into categories it has not been explicitly trained on.\n3. Specify the model as \'laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft\', which is pre-trained on a diverse set of images.\n4. Apply the classifier to an image file to determine if the depicted animal is a cat or a dog by providing a list containing the two relevant categories: \'cat\' and \'dog\'.\n<<<code>>>: from transformers import pipeline\nimage_classifier = pipeline(\'image-classification\', model=\'laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft\')\nresult = image_classifier("path/to/animal_image.jpg", ["cat", "dog"])', 'api_call': "pipeline('image-classification', model='laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft')", 'provider': 'Hugging Face', 'api_data': {'domain': 'Computer Vision Zero-Shot Image Classification', 'framework': 'Hugging Face', 'functionality': 'Zero-Shot Image Classification', 'api_name': 'laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft', 'api_call': "pipeline('image-classification', model='laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft')", 'api_arguments': {'image_path': 'Path to the image file', 'class_names': 'List of comma-separated class names'}, 'python_environment_requirements': ['transformers'], 'example_code': "from transformers import pipeline; classifier = pipeline('image-classification', model='laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft'); classifier('path/to/image.jpg', ['class1', 'class2'])", 'performance': {'dataset': 'ImageNet-1k', 'accuracy': '75.9-76.9%'}, 'description': 'A series of CLIP ConvNeXt-Large models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models achieve between 75.9 and 76.9 top-1 zero-shot accuracy on ImageNet-1k.'}}

