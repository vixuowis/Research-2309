{'code': "###Instruction: We are working on an AI chatbot for customer support and we need our chatbot to generate human-like responses to customers' questions.\n###Output: <<<domain>>>: Natural Language Processing Text Generation\n<<<api_call>>>: pipeline('text-generation', model='facebook/opt-350m')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. First, import the transformer's library `pipeline` function.\n2. Use the pipeline function to create a text generation model with the specified pre-trained model, `facebook/opt-350m`.\n3. The loaded text generation model is designed to create human-like responses to a given input text.\n4. Finally, use the created generator to generate responses to customers' questions.\n<<<code>>>: from transformers import pipeline\ngenerator = pipeline('text-generation', model='facebook/opt-350m')\nresponse = generator('What is your return policy?')\n", 'api_call': "pipeline('text-generation', model='facebook/opt-350m')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Text Generation', 'framework': 'Hugging Face Transformers', 'functionality': 'Text Generation', 'api_name': 'facebook/opt-350m', 'api_call': "pipeline('text-generation', model='facebook/opt-350m')", 'api_arguments': {'model': 'facebook/opt-350m', 'do_sample': 'True', 'num_return_sequences': 5}, 'python_environment_requirements': {'transformers': '4.3.0'}, 'example_code': "from transformers import pipeline, set_seed\nset_seed(32)\ngenerator = pipeline('text-generation', model='facebook/opt-350m', do_sample=True, num_return_sequences=5)\ngenerator('The man worked as a')", 'performance': {'dataset': 'BookCorpus, CC-Stories, The Pile, Pushshift.io Reddit, CCNewsV2', 'accuracy': 'Roughly matches GPT-3 performance'}, 'description': 'OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example.'}}

