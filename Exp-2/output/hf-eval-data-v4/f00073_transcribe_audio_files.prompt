{'code': "###Instruction: We are working on a transcription service for our customers. We need a way to convert audio files into text.\n###Output: <<<domain>>>: Audio Automatic Speech Recognition\n<<<api_call>>>: Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-english')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import SpeechRecognitionModel from huggingsound package, which is using Hugging Face Transformers in the background.\n2. Create an instance of the SpeechRecognitionModel by specifying the pre-trained ASR model 'jonatasgrosman/wav2vec2-large-xlsr-53-english'. This model is fine-tuned on a large-scale English dataset that can convert spoken language into text.\n3. The model can then be used to transcribe audio files into text.\n4. By loading audio files with the specified path, the transcribe function generates transcriptions for each audio file.\n<<<code>>>: from huggingsound import SpeechRecognitionModel\nmodel = SpeechRecognitionModel('jonatasgrosman/wav2vec2-large-xlsr-53-english')\naudio_paths = ['path/to/first_audio.mp3', 'path/to/second_audio.wav']\n# Replace the paths above with the actual paths to the audio files \ntranscriptions = model.transcribe(audio_paths)\n", 'api_call': "Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-english')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Audio Automatic Speech Recognition', 'framework': 'Hugging Face Transformers', 'functionality': 'Speech Recognition', 'api_name': 'jonatasgrosman/wav2vec2-large-xlsr-53-english', 'api_call': "Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-english')", 'api_arguments': ['audio_paths'], 'python_environment_requirements': ['huggingsound', 'torch', 'librosa', 'datasets', 'transformers'], 'example_code': "from huggingsound import SpeechRecognitionModel\nmodel = SpeechRecognitionModel('jonatasgrosman/wav2vec2-large-xlsr-53-english')\naudio_paths = ['/path/to/file.mp3', '/path/to/another_file.wav']\ntranscriptions = model.transcribe(audio_paths)", 'performance': {'dataset': 'mozilla-foundation/common_voice_6_0', 'accuracy': {'Test WER': 19.06, 'Test CER': 7.69, 'Test WER (+LM)': 14.81, 'Test CER (+LM)': 6.84}}, 'description': 'Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz.'}}

