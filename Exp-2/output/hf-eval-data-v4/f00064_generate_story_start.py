# requirements_file --------------------

!pip install -U transformers

# function_import --------------------

from transformers import pipeline

# function_code --------------------



def generate_story_start(prompt):
    """
    Generate the beginning of a story given a story prompt using the GPT-2 model.

    Parameters:
        prompt (str): The initial text to start the story.

    Returns:
        str: The starting passage of the story generated by the model.
    """
    text_generator = pipeline('text-generation', model='sshleifer/tiny-gpt2')
    story_start = text_generator(prompt, max_length=100, num_return_sequences=1)[0]['generated_text']
    return story_start


# test_function_code --------------------


def test_generate_story_start():
    print("Testing started.")
    prompt = "A brave knight sets out on a quest"

    # Test case 1: Check if the output is a string
    print("Testing case [1/3] started.")
    story_start = generate_story_start(prompt)
    assert isinstance(story_start, str), f"Test case [1/3] failed: Output is not a string"

    # Test case 2: Check if the output starts with the prompt
    print("Testing case [2/3] started.")
    assert story_start.startswith(prompt), f"Test case [2/3] failed: Output does not start with the prompt"

    # Test case 3: Check if the length of the output is reasonable
    print("Testing case [3/3] started.")
    assert 50 < len(story_start) <= 100, f"Test case [3/3] failed: Output length is not within the expected range"
    print("Testing finished.")

test_generate_story_start()
