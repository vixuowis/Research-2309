{'code': "###Instruction: Bob is designing an app for his city. He needs to quickly identify if the provided image has a bike or a car. Design a model that recognizes a bike or car and provides classification output for the given image.\n###Output: <<<domain>>>: Natural Language Processing Zero-Shot Classification\n<<<api_call>>>: pipeline('zero-shot-classification', model='laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-rewind')\n<<<api_provider>>>: Hugging Face\n<<<explanation>>>: 1. Import the required package, which is 'pipeline' from transformers.\n2. Use the pipeline function to create a zero-shot classification model with the pretrained model: 'laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-rewind'.\n3. This model has been trained on a large dataset and is useful for tasks such as image classification.\n4. Utilize the model on the input image with the desired class names (in this case, ['bike', 'car']) to classify the image as either a bike or a car.\n<<<code>>>: from transformers import pipeline\nclip = pipeline('zero-shot-classification', model='laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-rewind')\nclass_names = ['bike', 'car']\nresult = clip(image, class_names)\n", 'api_call': "CLIPModel.from_pretrained('laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-rewind')", 'provider': 'Hugging Face', 'api_data': {'domain': 'Natural Language Processing Zero-Shot Classification', 'framework': 'Hugging Face', 'functionality': 'Zero-Shot Image Classification', 'api_name': 'laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-rewind', 'api_call': "CLIPModel.from_pretrained('laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-rewind')", 'api_arguments': 'image, class_names', 'python_environment_requirements': 'transformers', 'example_code': "from transformers import pipeline; clip = pipeline('zero-shot-classification', model='laion/CLIP-convnext_xxlarge-laion2B-s34B-b82K-augreg-rewind'); clip(image, class_names=['cat', 'dog', 'fish'])", 'performance': {'dataset': 'ImageNet-1k', 'accuracy': '79.1 - 79.4'}, 'description': 'A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks.'}}

