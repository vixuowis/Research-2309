{'code': '###Instruction: We have a coffee shop with different types of coffee on the menu. Determine the caffeine levels in each cup of coffee.\n###Output: <<<domain>>>: Natural Language Processing Table Question Answering\n<<<api_call>>>: pipeline(\'table-question-answering\', model=\'navteca/tapas-large-finetuned-wtq\', tokenizer=\'navteca/tapas-large-finetuned-wtq\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import Transformer\'s libraries, AutoModelForTableQuestionAnswering, and AutoTokenizer, and pipeline.\n2. Load the model \'navteca/tapas-large-finetuned-wtq\' which is a fine-tuned TAPAS model designed for table question answering tasks.\n3. Define the provided coffeeshop menu and its details as a table. For instance, you can include columns such as "Coffee Type," "Size," and "Caffeine Content."\n4. You can provide different queries related to caffeine levels in each type of coffee using the \'pipeline\' function. The model will provide the answers to these queries based on the provided table.\n<<<code>>>: from transformers import AutoModelForTableQuestionAnswering, AutoTokenizer, pipeline\n\ntapas_model = AutoModelForTableQuestionAnswering.from_pretrained(\'navteca/tapas-large-finetuned-wtq\')\ntapas_tokenizer = AutoTokenizer.from_pretrained(\'navteca/tapas-large-finetuned-wtq\')\n\nnlp = pipeline(\'table-question-answering\', model=tapas_model, tokenizer=tapas_tokenizer)\n\nmenu_table = {\n    \'Coffee Type\': [\'Espresso\', \'Cappuccino\', \'Latte\', \'Americano\', \'Mocha\'],\n    \'Size\': [\'Small\', \'Medium\', \'Large\'],\n    \'Caffeine Content\': [\'95 mg\', \'120 mg\', \'145 mg\', \'165 mg\', \'185 mg\']\n}\n\nquery = \'What are the caffeine levels in each cup of coffee?\'\nresult = nlp({\'table\': menu_table, \'query\': query})\nprint(result)', 'api_call': "AutoModelForTableQuestionAnswering.from_pretrained('navteca/tapas-large-finetuned-wtq')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Table Question Answering', 'framework': 'Hugging Face Transformers', 'functionality': 'Table Question Answering', 'api_name': 'navteca/tapas-large-finetuned-wtq', 'api_call': "AutoModelForTableQuestionAnswering.from_pretrained('navteca/tapas-large-finetuned-wtq')", 'api_arguments': {'table': 'table_data', 'query': 'query'}, 'python_environment_requirements': {'transformers': 'AutoModelForTableQuestionAnswering, AutoTokenizer, pipeline'}, 'example_code': "from transformers import AutoModelForTableQuestionAnswering, AutoTokenizer, pipeline\n\n# Load model & tokenizer\ntapas_model = AutoModelForTableQuestionAnswering.from_pretrained('navteca/tapas-large-finetuned-wtq')\ntapas_tokenizer = AutoTokenizer.from_pretrained('navteca/tapas-large-finetuned-wtq')\n\n# Get predictions\nnlp = pipeline('table-question-answering', model=tapas_model, tokenizer=tapas_tokenizer)\nresult = nlp({'table': {'Repository': ['Transformers', 'Datasets', 'Tokenizers'], 'Stars': ['36542', '4512', '3934'], 'Contributors': ['651', '77', '34'], 'Programming language': ['Python', 'Python', 'Rust, Python and NodeJS']}, 'query': 'How many stars does the transformers repository have?'})\nprint(result)", 'performance': {'dataset': 'wikisql', 'accuracy': 'Not provided'}, 'description': 'TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table.'}}

