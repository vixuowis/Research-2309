{'code': '###Instruction: Translate the following English sentence to German: "I have a doctor\'s appointment tomorrow morning."\n###Input: "I have a doctor\'s appointment tomorrow morning."\n###Output: "Ich habe morgen fr√ºh einen Arzttermin."\n\n###Instruction: We are trying to summarize the following paragraph: "Machine learning is a subset of artificial intelligence that focuses on developing algorithms that can learn patterns from data without being explicitly programmed. The field has seen tremendous growth in recent years, driven by advances in computational power, the abundance of data, and improvements in algorithms. There are many types of machine learning algorithms, including supervised learning, unsupervised learning, reinforcement learning, and deep learning. Applications of machine learning are diverse, ranging from image and speech recognition to financial trading and recommendation systems."\n###Input: "Machine learning is a subset of artificial intelligence that focuses on developing algorithms that can learn patterns from data without being explicitly programmed. The field has seen tremendous growth in recent years, driven by advances in computational power, the abundance of data, and improvements in algorithms. There are many types of machine learning algorithms, including supervised learning, unsupervised learning, reinforcement learning, and deep learning. Applications of machine learning are diverse, ranging from image and speech recognition to financial trading and recommendation systems."\n###Output: "Machine learning, a subset of artificial intelligence, develops algorithms to learn patterns without explicit programming. Driven by computational advancement, abundant data, and algorithmic improvements, it includes supervised, unsupervised, reinforcement, and deep learning algorithms. Applications span from image and speech recognition to financial trading and recommendation systems."', 'api_call': "T5ForConditionalGeneration.from_pretrained('google/flan-t5-large')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Text2Text Generation', 'framework': 'Hugging Face Transformers', 'functionality': 'Language model', 'api_name': 'google/flan-t5-large', 'api_call': "T5ForConditionalGeneration.from_pretrained('google/flan-t5-large')", 'api_arguments': ['input_text', 'input_ids', 'outputs'], 'python_environment_requirements': ['transformers', 'torch'], 'example_code': 'from transformers import T5Tokenizer, T5ForConditionalGeneration\ntokenizer = T5Tokenizer.from_pretrained(google/flan-t5-large)\nmodel = T5ForConditionalGeneration.from_pretrained(google/flan-t5-large)\ninput_text = translate English to German: How old are you?\ninput_ids = tokenizer(input_text, return_tensors=pt).input_ids\noutputs = model.generate(input_ids)\nprint(tokenizer.decode(outputs[0]))', 'performance': {'dataset': [{'name': 'MMLU', 'accuracy': '75.2%'}]}, 'description': 'FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research.'}}

