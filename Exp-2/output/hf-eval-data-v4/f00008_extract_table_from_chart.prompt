{'code': '###Instruction: I am a financial analyst, and I receive report after report filled with charts helping to explain trends and data in my field. However, I also need to have this information in tabular format. Please help me extract a linearized table from this chart.\n###Output: <<<domain>>>: Multimodal Image-to-Text\n<<<api_call>>>: Pix2StructForConditionalGeneration.from_pretrained(\'google/deplot\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. We will import the necessary classes from the transformers library, which include Pix2StructForConditionalGeneration and Pix2StructProcessor. We also need the \'requests\' library for downloading images and \'Image\' from PIL for image handling.\n2. We\'ll then load the pre-trained model \'google/deplot\' using the from_pretrained method of Pix2StructForConditionalGeneration. The model is used for translating images of plots or charts into linearized tables.\n3. We will also load the processor using the from_pretrained method of Pix2StructProcessor.\n4. We will open the image file that contains the chart, and use the processor to convert the image into the required format.\n5. The model will then process the image and generate the underlying data table as a linearized text.\n<<<code>>>: from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\nimport requests\nfrom PIL import Image\n\nmodel = Pix2StructForConditionalGeneration.from_pretrained(\'google/deplot\')\nprocessor = Pix2StructProcessor.from_pretrained(\'google/deplot\')\n\nchart_url = "https://example.com/chart_image.png"\nimage = Image.open(requests.get(chart_url, stream=True).raw)\n\ninputs = processor(images=image, text="Generate underlying data table of the figure below:", return_tensors=\'pt\')\npredictions = model.generate(**inputs, max_new_tokens=512)\n\ntable = processor.decode(predictions[0], skip_special_tokens=True)\n', 'api_call': "Pix2StructForConditionalGeneration.from_pretrained('google/deplot')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Multimodal Image-to-Text', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'google/deplot', 'api_call': "Pix2StructForConditionalGeneration.from_pretrained('google/deplot')", 'api_arguments': {'images': 'image', 'text': 'question', 'return_tensors': 'pt', 'max_new_tokens': 512}, 'python_environment_requirements': {'transformers': 'Pix2StructForConditionalGeneration, Pix2StructProcessor', 'requests': 'requests', 'PIL': 'Image'}, 'example_code': "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\nimport requests\nfrom PIL import Image\nmodel = Pix2StructForConditionalGeneration.from_pretrained('google/deplot')\nprocessor = Pix2StructProcessor.from_pretrained('google/deplot')\nurl = https://raw.githubusercontent.com/vis-nlp/ChartQA/main/ChartQA%20Dataset/val/png/5090.png\nimage = Image.open(requests.get(url, stream=True).raw)\ninputs = processor(images=image, text=Generate underlying data table of the figure below:, return_tensors=pt)\npredictions = model.generate(**inputs, max_new_tokens=512)\nprint(processor.decode(predictions[0], skip_special_tokens=True))", 'performance': {'dataset': 'ChartQA', 'accuracy': '24.0% improvement over finetuned SOTA'}, 'description': 'DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs.'}}

