{'code': '###Instruction: Our company needs a versatile NLP model to build a social media manager to generate summaries of lengthy articles for sharing on social media.\n###Output: <<<domain>>>: Natural Language Processing Text2Text Generation\n<<<api_call>>>: T5Model.from_pretrained(\'t5-large\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. First, import the required T5Tokenizer and T5Model from the transformers package.\n2. We will use the \'t5-large\' model, which is a powerful NLP model capable of performing a variety of tasks, including summarization.\n3. Tokenize the lengthy article using the tokenizer, and store the resulting tokens as input_ids.\n4. Create a prompt for the model, such as "summarize:", to guide it to perform summarization. Tokenize the prompt and store it as decoder_input_ids.\n5. Pass the input_ids and decoder_input_ids into the T5 model for summarization.\n6. Output the summarized text.\n<<<code>>>:from transformers import T5Tokenizer, T5Model\ntokenizer = T5Tokenizer.from_pretrained(\'t5-large\')\nmodel = T5Model.from_pretrained(\'t5-large\')\narticle = "Lengthy article text here..."\ninput_ids = tokenizer("summarize: " + article, return_tensors=\'pt\').input_ids\ndecoder_input_ids = tokenizer("summarize: ", return_tensors=\'pt\').input_ids\noutputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n', 'api_call': "T5Model.from_pretrained('t5-large')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Text2Text Generation', 'framework': 'Hugging Face Transformers', 'functionality': 'Translation, Summarization, Question Answering, Sentiment Analysis, Regression', 'api_name': 't5-large', 'api_call': "T5Model.from_pretrained('t5-large')", 'api_arguments': {'input_ids': "tokenizer(..., return_tensors='pt').input_ids", 'decoder_input_ids': "tokenizer(..., return_tensors='pt').input_ids"}, 'python_environment_requirements': {'transformers': 'from transformers import T5Tokenizer, T5Model'}, 'example_code': "tokenizer = T5Tokenizer.from_pretrained('t5-large')\nmodel = T5Model.from_pretrained('t5-large')\ninput_ids = tokenizer('Studies have been shown that owning a dog is good for you', return_tensors='pt').input_ids\ndecoder_input_ids = tokenizer('Studies show that', return_tensors='pt').input_ids\noutputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\nlast_hidden_states = outputs.last_hidden_state", 'performance': {'dataset': 'c4', 'accuracy': 'See research paper, Table 14'}, 'description': 'T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks.'}}

