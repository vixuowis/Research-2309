{'code': '###Instruction: We have a dataset related to coffee and tea prices. We need to answer a question on who sells hot chocolate and their prices.\n###Input: {"table": [["Shop", "Drink", "Price"], ["Cafe A", "Coffee", "3.00"], ["Cafe B", "Tea", "2.50"], ["Cafe C", "Hot Chocolate", "4.50"], ["Cafe D", "Hot Chocolate", "3.75"]], "queries": ["Which shops sell hot chocolate and what are their prices?"]}\n###Output: <<<domain>>>: Natural Language Processing Table Question Answering\n<<<api_call>>>: TapasForQuestionAnswering.from_pretrained(\'google/tapas-mini-finetuned-sqa\')\n<<<api_provider>>>: Transformers\n<<<explanation>>>: 1. Load the TapasForQuestionAnswering model from the transformers library provided by Hugging Face. Use the \'google/tapas-mini-finetuned-sqa\' model, which is pretrained for sequential question answering.\n2. Convert the input table into the Pandas dataframe format.\n3. Use the model to ask the given query.\n4. Parse the model\'s output and format the answer accordingly.\n5. Return the shops that sell Hot Chocolate along with their prices.\n<<<code>>>: from transformers import TapasTokenizer, TapasForQuestionAnswering\nimport pandas as pd\n\nmodel = TapasForQuestionAnswering.from_pretrained(\'google/tapas-mini-finetuned-sqa\')\ntokenizer = TapasTokenizer.from_pretrained(\'google/tapas-mini-finetuned-sqa\')\n\ntable = [["Shop", "Drink", "Price"], ["Cafe A", "Coffee", "3.00"], ["Cafe B", "Tea", "2.50"], ["Cafe C", "Hot Chocolate", "4.50"], ["Cafe D", "Hot Chocolate", "3.75"]]\nqueries = ["Which shops sell hot chocolate and what are their prices?"]\n\ndataframe = pd.DataFrame(table[1:], columns=table[0])\ninputs = tokenizer(table=dataframe, queries=queries, padding=True, truncation=True, return_tensors="pt")\noutputs = model(**inputs)\n\nanswered_shops = [table[row_idx][0] for row_idx in outputs[\'answer_coordinates\'][0][:, 0]]\nhot_chocolate_prices = [table[row_idx][2] for row_idx in outputs[\'answer_coordinates\'][0][:, 0]]\n\nanswer = {shop: price for shop, price in zip(answered_shops, hot_chocolate_prices)}\n', 'api_call': "TapasForQuestionAnswering.from_pretrained('google/tapas-mini-finetuned-sqa')", 'provider': 'Transformers', 'api_data': {'domain': 'Natural Language Processing Table Question Answering', 'framework': 'Transformers', 'functionality': 'Table Question Answering', 'api_name': 'google/tapas-mini-finetuned-sqa', 'api_call': "TapasForQuestionAnswering.from_pretrained('google/tapas-mini-finetuned-sqa')", 'api_arguments': ['model_name', 'table', 'queries'], 'python_environment_requirements': ['transformers'], 'example_code': 'N/A', 'performance': {'dataset': 'msr_sqa', 'accuracy': 0.5148}, 'description': 'TAPAS mini model fine-tuned on Sequential Question Answering (SQA)'}}

