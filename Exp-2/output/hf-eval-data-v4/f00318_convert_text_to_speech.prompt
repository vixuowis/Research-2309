{'code': '###Instruction: We are a company specializing in building automation systems for homes. We\'d like to convert our written rules into an audio format for user interaction purposes.\n###Output: <<<domain>>>: Audio Text-to-Speech\n<<<api_call>>>: Tacotron2.from_hparams(source=\'speechbrain/tts-tacotron2-ljspeech\')\n<<<api_provider>>>: SpeechBrain\n<<<explanation>>>: 1. We first import the necessary libraries, which include \'Tacotron2\' and \'HIFIGAN\' from SpeechBrain, and \'torchaudio\' for saving the generated audio.\n2. We then load the pre-trained TTS model \'speechbrain/tts-tacotron2-ljspeech\' using Tacotron2 from_hparams and the vocoder \'speechbrain/tts-hifigan-ljspeech\'.\n3. The loaded model will be used for text-to-speech generation, converting the provided text containing the rule into a waveform.\n4. We then save the generated waveform into a file \'example_TTS.wav\' with the help of torchaudio.\n<<<code>>>: from speechbrain.pretrained import Tacotron2, HIFIGAN\nimport torchaudio\ntacotron2 = Tacotron2.from_hparams(source=\'speechbrain/tts-tacotron2-ljspeech\')\nhifi_gan = HIFIGAN.from_hparams(source=\'speechbrain/tts-hifigan-ljspeech\')\ntext = "Mary had a little lamb"\nmel_output, mel_length, alignment = tacotron2.encode_text(text)\nwaveforms = hifi_gan.decode_batch(mel_output)\ntorchaudio.save(\'example_TTS.wav\', waveforms.squeeze(1), 22050)', 'api_call': "Tacotron2.from_hparams(source='speechbrain/tts-tacotron2-ljspeech')", 'provider': 'SpeechBrain', 'api_data': {'domain': 'Audio Text-to-Speech', 'framework': 'SpeechBrain', 'functionality': 'Text-to-Speech', 'api_name': 'speechbrain/tts-tacotron2-ljspeech', 'api_call': "Tacotron2.from_hparams(source='speechbrain/tts-tacotron2-ljspeech')", 'api_arguments': ['text'], 'python_environment_requirements': ['speechbrain'], 'example_code': ['import torchaudio', 'from speechbrain.pretrained import Tacotron2', 'from speechbrain.pretrained import HIFIGAN', 'tacotron2 = Tacotron2.from_hparams(source=speechbrain/tts-tacotron2-ljspeech, savedir=tmpdir_tts)', 'hifi_gan = HIFIGAN.from_hparams(source=speechbrain/tts-hifigan-ljspeech, savedir=tmpdir_vocoder)', 'mel_output, mel_length, alignment = tacotron2.encode_text(Mary had a little lamb)', 'waveforms = hifi_gan.decode_batch(mel_output)', "torchaudio.save('example_TTS.wav',waveforms.squeeze(1), 22050)"], 'performance': {'dataset': 'LJSpeech', 'accuracy': 'Not specified'}, 'description': 'This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram.'}}

