{'code': '###Instruction: Create a tool to determine the logical relationship between two given sentences.\n\n###Output: <<<domain>>>: Natural Language Processing Zero-Shot Classification\n<<<api_call>>>: AutoModelForSequenceClassification.from_pretrained(\'cointegrated/rubert-base-cased-nli-threeway\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the necessary libraries: AutoTokenizer and AutoModelForSequenceClassification from the transformers library, and torch for GPU inference if available.\n2. Specify the model checkpoint \'cointegrated/rubert-base-cased-nli-threeway\', which is a fine-tuned model for predicting the logical relationship between two short texts: entailment, contradiction, or neutral.\n3. Instantiate the tokenizer using the AutoTokenizer.from_pretrained method with the selected checkpoint.\n4. Instantiate the model using the AutoModelForSequenceClassification.from_pretrained method with the selected checkpoint.\n5. Run the model on the given sentences (text1 and text2) to determine their logical relationship.\n6. Print the result, which will be a dictionary containing the probabilities of each logical relationship (entailment, contradiction, or neutral).\n<<<code>>>: import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodel_checkpoint = \'cointegrated/rubert-base-cased-nli-threeway\'\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\nif torch.cuda.is_available():\n    model.cuda()\n\ntext1 = "The first sentence here."\ntext2 = "The second sentence here."\n\nwith torch.inference_mode():\n    out = model(**tokenizer(text1, text2, return_tensors=\'pt\').to(model.device))\n    proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n\nresult = {v: proba[k] for k, v in model.config.id2label.items()}\nprint(result)', 'api_call': "AutoModelForSequenceClassification.from_pretrained('cointegrated/rubert-base-cased-nli-threeway')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Zero-Shot Classification', 'framework': 'Hugging Face Transformers', 'functionality': 'Natural Language Inference', 'api_name': 'cointegrated/rubert-base-cased-nli-threeway', 'api_call': "AutoModelForSequenceClassification.from_pretrained('cointegrated/rubert-base-cased-nli-threeway')", 'api_arguments': ['text1', 'text2'], 'python_environment_requirements': ['transformers', 'sentencepiece'], 'example_code': "import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nmodel_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\nif torch.cuda.is_available():\n model.cuda()\ntext1 = '.'\ntext2 = '.'\nwith torch.inference_mode():\n out = model(**tokenizer(text1, text2, return_tensors='pt').to(model.device))\n proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\nprint({v: proba[k] for k, v in model.config.id2label.items()})", 'performance': {'dataset': ['JOCI', 'MNLI', 'MPE', 'SICK', 'SNLI', 'ANLI', 'NLI-style FEVER', 'IMPPRES'], 'accuracy': {'ROC AUC': {'entailment': 0.91, 'contradiction': 0.71, 'neutral': 0.79}}}, 'description': 'This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral.'}}

