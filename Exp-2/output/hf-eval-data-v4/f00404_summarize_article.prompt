{'code': '###Instruction: We have a long article, and we want to generate a summary to understand the main points of the article.\n###Output: <<<domain>>>: Natural Language Processing Summarization\n<<<api_call>>>: PegasusForConditionalGeneration.from_pretrained("tuner007/pegasus_summarizer")\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import necessary libraries: PegasusForConditionalGeneration, PegasusTokenizer from transformers\n2. Initialize the tokenizer and the model, both by calling .from_pretrained method with the model name "tuner007/pegasus_summarizer"\n3. Tokenize the input text using the tokenizer by calling the .encode method with the text and truncation=True\n4. Feed the tokenized input into the model to generate the summary by calling model.generate() method\n5. Decode the generated summary with the tokenizer using the .decode method\n<<<code>>>: from transformers import PegasusForConditionalGeneration, PegasusTokenizer\ntokenizer = PegasusTokenizer.from_pretrained("tuner007/pegasus_summarizer")\nmodel = PegasusForConditionalGeneration.from_pretrained("tuner007/pegasus_summarizer")\narticle_text = """<Your long article text here>"""\ninputs = tokenizer.encode(article_text, return_tensors="pt", truncation=True)\nsummary_ids = model.generate(inputs)\nsummary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n', 'api_call': "PegasusForConditionalGeneration.from_pretrained('tuner007/pegasus_summarizer')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Summarization', 'framework': 'Hugging Face Transformers', 'functionality': 'text2text-generation', 'api_name': 'tuner007/pegasus_summarizer', 'api_call': "PegasusForConditionalGeneration.from_pretrained('tuner007/pegasus_summarizer')", 'api_arguments': ['input_text'], 'python_environment_requirements': ['pip install sentencepiece'], 'example_code': "context = \nIndia wicket-keeper batsman Rishabh Pant has said someone from the crowd threw a ball on pacer Mohammed Siraj while he was fielding in the ongoing third Test against England on Wednesday. Pant revealed the incident made India skipper Virat Kohli upset. I think, somebody threw a ball inside, at Siraj, so he [Kohli] was upset, said Pant in a virtual press conference after the close of the first day's play.You can say whatever you want to chant, but don't throw things at the fielders and all those things. It is not good for cricket, I guess, he added.In the third session of the opening day of the third Test, a section of spectators seemed to have asked Siraj the score of the match to tease the pacer. The India pacer however came with a brilliant reply as he gestured 1-0 (India leading the Test series) towards the crowd.Earlier this month, during the second Test match, there was some bad crowd behaviour on a show as some unruly fans threw champagne corks at India batsman KL Rahul.Kohli also intervened and he was seen gesturing towards the opening batsman to know more about the incident. An over later, the TV visuals showed that many champagne corks were thrown inside the playing field, and the Indian players were visibly left frustrated.Coming back to the game, after bundling out India for 78, openers Rory Burns and Haseeb Hameed ensured that England took the honours on the opening day of the ongoing third Test.At stumps, England's score reads 120/0 and the hosts have extended their lead to 42 runs. For the Three Lions, Burns (52) and Hameed (60) are currently unbeaten at the crease.Talking about the pitch on opening day, Pant said, They took the heavy roller, the wicket was much more settled down, and they batted nicely also, he said. But when we batted, the wicket was slightly soft, and they bowled in good areas, but we could have applied [ourselves] much better.Both England batsmen managed to see off the final session and the hosts concluded the opening day with all ten wickets intact, extending the lead to 42.(ANI)\n\nget_response(context)", 'performance': {'dataset': 'cnn_dailymail', 'accuracy': {'ROUGE-1': 36.604, 'ROUGE-2': 14.64, 'ROUGE-L': 23.884, 'ROUGE-LSUM': 32.902, 'loss': 2.576, 'gen_len': 76.398}}, 'description': 'PEGASUS fine-tuned for summarization'}}

