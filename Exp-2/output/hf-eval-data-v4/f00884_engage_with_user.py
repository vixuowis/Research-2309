# requirements_file --------------------

!pip install -U transformers

# function_import --------------------

from transformers import BlenderbotForConditionalGeneration, BlenderbotTokenizer

# function_code --------------------

def engage_with_user(user_message):
    '''
    This function takes a user message as input and returns an engaging reply.

    Parameters:
    user_message (str): Input message from a user.

    Returns:
    reply (str): Reply generated by the Blenderbot-3B model.
    '''
    model = BlenderbotForConditionalGeneration.from_pretrained('facebook/blenderbot-3B')
    tokenizer = BlenderbotTokenizer.from_pretrained('facebook/blenderbot-3B')
    inputs = tokenizer([user_message], return_tensors='pt')
    outputs = model.generate(**inputs)
    reply = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]
    return reply


# test_function_code --------------------

def test_engage_with_user():
    print("Testing started.")
    user_inputs = ['Hello!', 'What are the benefits of regular exercise?', 'Tell me a joke.']

    for i, input_message in enumerate(user_inputs):
        print(f"Testing case [{i+1}/{len(user_inputs)}] started.")
        reply = engage_with_user(input_message)
        assert reply, f"Test case [{i+1}/{len(user_inputs)}] failed: No reply received."
        print("Testing case [{i+1}/{len(user_inputs)}] successful.")

    print("Testing finished.")

# Run the test function
test_engage_with_user()
