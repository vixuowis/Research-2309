{'code': "###Instruction: Our company needs to analyze customer phone call recordings and identify specific numbers mentioned by customers during the call.\n###Output: <<<domain>>>: Audio Classification\n<<<api_call>>>: pipeline('audio-classification', model='mazkooleg/0-9up-data2vec-audio-base-960h-ft')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import the pipeline function from the transformers library.\n2. Load the 'mazkooleg/0-9up-data2vec-audio-base-960h-ft' model using the pipeline function. This model is trained on spoken digit recognition tasks and can classify individual spoken digits from 0 to 9.\n3. Use the created digit classifier to analyze the audio from the customer phone call recordings to identify and classify spoken numbers.\n4. The classifier should be applied sequentially to the audio recordings, extracting the spoken numbers mentioned by customers during the call.\n<<<code>>>: from transformers import pipeline\ndigit_classifier = pipeline('audio-classification', model='mazkooleg/0-9up-data2vec-audio-base-960h-ft')\ndigits_detected = digit_classifier(phone_call_audio_file)\n", 'api_call': "pipeline('audio-classification', model='mazkooleg/0-9up-data2vec-audio-base-960h-ft')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Audio Classification', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'mazkooleg/0-9up-data2vec-audio-base-960h-ft', 'api_call': "pipeline('audio-classification', model='mazkooleg/0-9up-data2vec-audio-base-960h-ft')", 'api_arguments': '', 'python_environment_requirements': 'Transformers 4.26.1, Pytorch 1.11.0+cpu, Datasets 2.10.1, Tokenizers 0.12.1', 'example_code': '', 'performance': {'dataset': 'None', 'accuracy': 0.9967}, 'description': 'This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset.'}}

