{'code': '###Instruction: I need to extract tables from a set of scanned document images to simplify data analysis.\n###Output: <<<domain>>>: Computer Vision Object Detection\n<<<api_call>>>: DetrForObjectDetection.from_pretrained(\'TahaDouaji/detr-doc-table-detection\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the necessary libraries, including DetrForObjectDetection from transformers, torch, PIL, and requests.\n2. Load the image using the PIL.Image.open function.\n3. Create the image processor using DetrImageProcessor.from_pretrained with the model \'TahaDouaji/detr-doc-table-detection\'.\n4. Load the DetrForObjectDetection model using the from_pretrained function and the model \'TahaDouaji/detr-doc-table-detection\'.\n5. Process the input image using the image processor and return_tensors as \'pt\'.\n6. Use the model to process the input and generate outputs.\n7. Calculate target sizes using the image size.\n8. Process the object detection outputs using the image processor and set an appropriate threshold (e.g., 0.9).\n9. Iterate through the results and print the detected tables information including the label, confidence score, and location.\n<<<code>>>: from transformers import DetrForObjectDetection, DetrImageProcessor\nimport torch\nfrom PIL import Image\n\nimage = Image.open(IMAGE_PATH)\nprocessor = DetrImageProcessor.from_pretrained(\'TahaDouaji/detr-doc-table-detection\')\nmodel = DetrForObjectDetection.from_pretrained(\'TahaDouaji/detr-doc-table-detection\')\n\ninputs = processor(images=image, return_tensors=\'pt\')\noutputs = model(**inputs)\ntarget_sizes = torch.tensor([image.size[::-1]])\nresults = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n\nfor score, label, box in zip(results[\'scores\'], results[\'labels\'], results[\'boxes\']):\n    box = [round(i, 2) for i in box.tolist()]\n    print(f"Detected {model.config.id2label[label.item()]} with confidence {round(score.item(), 3)} at location {box}")', 'api_call': "DetrForObjectDetection.from_pretrained('TahaDouaji/detr-doc-table-detection')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Computer Vision Object Detection', 'framework': 'Hugging Face Transformers', 'functionality': 'Detect Bordered and Borderless tables in documents', 'api_name': 'TahaDouaji/detr-doc-table-detection', 'api_call': "DetrForObjectDetection.from_pretrained('TahaDouaji/detr-doc-table-detection')", 'api_arguments': ['images', 'return_tensors', 'threshold'], 'python_environment_requirements': ['transformers', 'torch', 'PIL', 'requests'], 'example_code': 'from transformers import DetrImageProcessor, DetrForObjectDetection\nimport torch\nfrom PIL import Image\nimport requests\nimage = Image.open(IMAGE_PATH)\nprocessor = DetrImageProcessor.from_pretrained(TahaDouaji/detr-doc-table-detection)\nmodel = DetrForObjectDetection.from_pretrained(TahaDouaji/detr-doc-table-detection)\ninputs = processor(images=image, return_tensors=pt)\noutputs = model(**inputs)\ntarget_sizes = torch.tensor([image.size[::-1]])\nresults = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\nfor score, label, box in zip(results[scores], results[labels], results[boxes]):\n box = [round(i, 2) for i in box.tolist()]\n print(\n fDetected {model.config.id2label[label.item()]} with confidence \n f{round(score.item(), 3)} at location {box}\n )', 'performance': {'dataset': 'ICDAR2019 Table Dataset', 'accuracy': 'Not provided'}, 'description': 'detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50.'}}

