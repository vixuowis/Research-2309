{'code': "###Instruction: We want to utilize the machine learning model for predicting molecular properties in the drug discovery domain.\n###Output: <<<domain>>>: Multimodal Graph Machine Learning\n<<<api_call>>>: AutoModel.from_pretrained('graphormer-base-pcqm4mv1')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the AutoModel class from the transformers library provided by Hugging Face.\n2. Load the pretrained Graphormer model called 'graphormer-base-pcqm4mv1'. This model has been developed by Microsoft and has won 1st place in the KDD CUP 2021 (quantum prediction track) for predicting molecular properties in the drug discovery domain.\n3. The loaded Graphormer model can be used for graph classification tasks, graph representation tasks or fine-tuned on specific downstream tasks in the molecule modeling domain.\n4. Once you have processed your molecular graph data, you can pass it to the Graphormer model for prediction.\n<<<code>>>: from transformers import AutoModel\nmodel = AutoModel.from_pretrained('graphormer-base-pcqm4mv1')\n", 'api_call': "AutoModel.from_pretrained('graphormer-base-pcqm4mv1')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Multimodal Graph Machine Learning', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'graphormer-base-pcqm4mv1', 'api_call': "AutoModel.from_pretrained('graphormer-base-pcqm4mv1')", 'api_arguments': ['model_name'], 'python_environment_requirements': ['transformers'], 'example_code': 'See the Graph Classification with Transformers tutorial', 'performance': {'dataset': 'PCQM4M-LSC', 'accuracy': '1st place on the KDD CUP 2021 (quantum prediction track)'}, 'description': 'The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks.'}}

