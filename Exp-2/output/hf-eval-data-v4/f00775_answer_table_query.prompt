{'code': '###Instruction: I have a table in CSV format and a query related to it. Could you obtain an answer for my query?\n###Output: <<<domain>>>: Natural Language Processing Table Question Answering\n<<<api_call>>>: AutoModelForSeq2SeqLM.from_pretrained(\'neulab/omnitab-large-1024shot\')\n<<<api_provider>>>: PyTorch Transformers\n<<<explanation>>>:1. Import the necessary classes and packages from the transformers and pandas libraries.\n2. Load the AutoModelForSeq2SeqLM model using the from_pretrained() method, with \'neulab/omnitab-large-1024shot\' as the pre-trained model.\n3. Load and store the table from the CSV using pandas\' read_csv method to create a DataFrame.\n4. Encode the table and the query using the tokenizer, to generate input tensors for the model.\n5. Run model.generate() with the encoded table and query tensors to get raw outputs, then use tokenizer.batch_decode() to convert the raw outputs to a human-readable answer.\n<<<code>>>: import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\ntokenizer = AutoTokenizer.from_pretrained(\'neulab/omnitab-large-1024shot\')\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\'neulab/omnitab-large-1024shot\')\ntable = pd.read_csv(\'your_table.csv\')\nquery = "your_query"\n\nencoding = tokenizer(table=table, query=query, return_tensors=\'pt\')\noutputs = model.generate(**encoding)\nanswer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]', 'api_call': "AutoModelForSeq2SeqLM.from_pretrained('neulab/omnitab-large-1024shot')", 'provider': 'PyTorch Transformers', 'api_data': {'domain': 'Natural Language Processing Table Question Answering', 'framework': 'PyTorch Transformers', 'functionality': 'Table-based QA', 'api_name': 'neulab/omnitab-large-1024shot', 'api_call': "AutoModelForSeq2SeqLM.from_pretrained('neulab/omnitab-large-1024shot')", 'api_arguments': {'table': 'pd.DataFrame.from_dict(data)', 'query': 'str'}, 'python_environment_requirements': ['transformers', 'pandas'], 'example_code': 'from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport pandas as pd\ntokenizer = AutoTokenizer.from_pretrained(neulab/omnitab-large-1024shot)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(neulab/omnitab-large-1024shot)\ndata = {\n year: [1896, 1900, 1904, 2004, 2008, 2012],\n city: [athens, paris, st. louis, athens, beijing, london]\n}\ntable = pd.DataFrame.from_dict(data)\nquery = In which year did beijing host the Olympic Games?\nencoding = tokenizer(table=table, query=query, return_tensors=pt)\noutputs = model.generate(**encoding)\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))', 'performance': {'dataset': 'wikitablequestions', 'accuracy': 'Not provided'}, 'description': 'OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting).'}}

