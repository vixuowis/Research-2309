WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'
  warnings.warn(
config.json:   0%|                                         | 0.00/893 [00:00<?, ?B/s]config.json: 100%|███████████████████████████████████| 893/893 [00:00<00:00, 205kB/s]
model.safetensors:   0%|                                  | 0.00/511M [00:00<?, ?B/s]model.safetensors:   2%|▌                        | 10.5M/511M [00:02<01:48, 4.61MB/s]model.safetensors:   4%|█                        | 21.0M/511M [00:03<01:09, 7.09MB/s]model.safetensors:   6%|█▌                       | 31.5M/511M [00:04<00:59, 8.03MB/s]model.safetensors:   8%|██                       | 41.9M/511M [00:05<00:55, 8.44MB/s]model.safetensors:  10%|██▌                      | 52.4M/511M [00:06<00:51, 8.92MB/s]model.safetensors:  12%|███                      | 62.9M/511M [00:07<00:43, 10.2MB/s]model.safetensors:  14%|███▌                     | 73.4M/511M [00:08<00:42, 10.3MB/s]model.safetensors:  16%|████                     | 83.9M/511M [00:09<00:41, 10.3MB/s]model.safetensors:  18%|████▌                    | 94.4M/511M [00:10<00:40, 10.3MB/s]model.safetensors:  21%|█████▎                    | 105M/511M [00:11<00:39, 10.2MB/s]model.safetensors:  23%|█████▊                    | 115M/511M [00:12<00:45, 8.75MB/s]model.safetensors:  25%|██████▍                   | 126M/511M [00:13<00:42, 9.05MB/s]model.safetensors:  27%|██████▉                   | 136M/511M [00:15<00:40, 9.37MB/s]model.safetensors:  29%|███████▍                  | 147M/511M [00:16<00:38, 9.55MB/s]model.safetensors:  31%|███████▉                  | 157M/511M [00:17<00:35, 9.90MB/s]model.safetensors:  33%|████████▌                 | 168M/511M [00:17<00:33, 10.1MB/s]model.safetensors:  35%|█████████                 | 178M/511M [00:18<00:31, 10.7MB/s]model.safetensors:  37%|█████████▌                | 189M/511M [00:19<00:31, 10.4MB/s]model.safetensors:  39%|██████████▏               | 199M/511M [00:20<00:28, 11.0MB/s]model.safetensors:  41%|██████████▋               | 210M/511M [00:21<00:27, 10.9MB/s]model.safetensors:  43%|███████████▏              | 220M/511M [00:22<00:26, 11.1MB/s]model.safetensors:  45%|███████████▋              | 231M/511M [00:23<00:28, 9.94MB/s]model.safetensors:  47%|████████████▎             | 241M/511M [00:24<00:26, 10.0MB/s]model.safetensors:  49%|████████████▊             | 252M/511M [00:26<00:27, 9.46MB/s]model.safetensors:  51%|█████████████▎            | 262M/511M [00:27<00:26, 9.50MB/s]model.safetensors:  53%|█████████████▊            | 273M/511M [00:28<00:27, 8.72MB/s]model.safetensors:  55%|██████████████▍           | 283M/511M [00:30<00:27, 8.40MB/s]model.safetensors:  57%|██████████████▉           | 294M/511M [00:31<00:27, 8.03MB/s]model.safetensors:  59%|███████████████▍          | 304M/511M [00:33<00:26, 7.74MB/s]model.safetensors:  62%|███████████████▉          | 315M/511M [00:34<00:28, 6.83MB/s]model.safetensors:  64%|████████████████▌         | 325M/511M [00:36<00:26, 7.03MB/s]model.safetensors:  66%|█████████████████         | 336M/511M [00:37<00:23, 7.62MB/s]model.safetensors:  68%|█████████████████▌        | 346M/511M [00:39<00:22, 7.24MB/s]model.safetensors:  70%|██████████████████▏       | 357M/511M [00:40<00:21, 7.04MB/s]model.safetensors:  72%|██████████████████▋       | 367M/511M [00:42<00:20, 6.97MB/s]model.safetensors:  74%|███████████████████▏      | 377M/511M [00:43<00:19, 6.82MB/s]model.safetensors:  76%|███████████████████▋      | 388M/511M [00:45<00:19, 6.41MB/s]model.safetensors:  78%|████████████████████▎     | 398M/511M [00:47<00:17, 6.42MB/s]model.safetensors:  80%|████████████████████▊     | 409M/511M [00:49<00:17, 5.74MB/s]model.safetensors:  82%|█████████████████████▎    | 419M/511M [00:50<00:13, 6.84MB/s]model.safetensors:  84%|█████████████████████▊    | 430M/511M [00:51<00:10, 8.05MB/s]model.safetensors:  86%|██████████████████████▍   | 440M/511M [00:51<00:07, 9.18MB/s]model.safetensors:  88%|██████████████████████▉   | 451M/511M [00:53<00:06, 9.07MB/s]model.safetensors:  90%|███████████████████████▍  | 461M/511M [00:54<00:05, 9.20MB/s]model.safetensors:  92%|███████████████████████▉  | 472M/511M [00:56<00:05, 7.68MB/s]model.safetensors:  94%|████████████████████████▌ | 482M/511M [00:57<00:03, 8.02MB/s]model.safetensors:  96%|█████████████████████████ | 493M/511M [00:58<00:02, 8.23MB/s]model.safetensors:  98%|█████████████████████████▌| 503M/511M [00:59<00:00, 8.16MB/s]model.safetensors: 100%|██████████████████████████| 511M/511M [01:00<00:00, 8.21MB/s]model.safetensors: 100%|██████████████████████████| 511M/511M [01:00<00:00, 8.41MB/s]
Some weights of the model checkpoint at impira/layoutlm-invoices were not used when initializing LayoutLMForQuestionAnswering: ['token_classifier_head.bias', 'token_classifier_head.weight']
- This IS expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
tokenizer_config.json:   0%|                               | 0.00/315 [00:00<?, ?B/s]tokenizer_config.json: 100%|████████████████████████| 315/315 [00:00<00:00, 31.2kB/s]
vocab.json:   0%|                                         | 0.00/798k [00:00<?, ?B/s]vocab.json: 100%|██████████████████████████████████| 798k/798k [00:00<00:00, 924kB/s]vocab.json: 100%|██████████████████████████████████| 798k/798k [00:00<00:00, 923kB/s]
merges.txt:   0%|                                         | 0.00/456k [00:00<?, ?B/s]merges.txt: 100%|█████████████████████████████████| 456k/456k [00:00<00:00, 5.85MB/s]
tokenizer.json:   0%|                                    | 0.00/1.36M [00:00<?, ?B/s]tokenizer.json: 100%|███████████████████████████| 1.36M/1.36M [00:00<00:00, 3.29MB/s]tokenizer.json: 100%|███████████████████████████| 1.36M/1.36M [00:00<00:00, 3.28MB/s]
special_tokens_map.json:   0%|                             | 0.00/239 [00:00<?, ?B/s]special_tokens_map.json: 100%|███████████████████████| 239/239 [00:00<00:00, 271kB/s]2023-12-17 16:26:07.778378: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-17 16:26:09.818383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

Traceback (most recent call last):
  File "./f00014_extract_total_amount.py", line 59, in <module>
    test_extract_total_amount()
  File "./f00014_extract_total_amount.py", line 54, in test_extract_total_amount
    assert answer == expected_answer, f'Test case [1/1] failed: Expected {expected_answer} but got {answer}'
AssertionError: Test case [1/1] failed: Expected $81.38 but got <s>
