2023-11-11 23:30:35.440397: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-11 23:30:35.483484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-11 23:30:36.215591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)solve/main/vocab.txt:   0%|                                                                          | 0.00/262k [00:00<?, ?B/s]Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████████████████████████████| 262k/262k [00:00<00:00, 447kB/s]Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████████████████████████████| 262k/262k [00:00<00:00, 446kB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                           | 0.00/154 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 13.4kB/s]
Downloading (…)okenizer_config.json:   0%|                                                                           | 0.00/490 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████| 490/490 [00:00<00:00, 264kB/s]
Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/1.67k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 1.67k/1.67k [00:00<00:00, 915kB/s]
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/117M [00:00<?, ?B/s]Downloading pytorch_model.bin:   9%|██████▎                                                                | 10.5M/117M [00:07<01:15, 1.42MB/s]Downloading pytorch_model.bin:   9%|██████▎                                                                | 10.5M/117M [00:19<01:15, 1.42MB/s]Downloading pytorch_model.bin:  18%|████████████▉                                                           | 21.0M/117M [00:24<01:59, 807kB/s]Downloading pytorch_model.bin:  18%|████████████▉                                                           | 21.0M/117M [00:39<01:59, 807kB/s]Downloading pytorch_model.bin:  27%|███████████████████▎                                                    | 31.5M/117M [00:44<02:12, 650kB/s]Downloading pytorch_model.bin:  27%|███████████████████▎                                                    | 31.5M/117M [00:59<02:12, 650kB/s]Downloading pytorch_model.bin:  36%|█████████████████████████▊                                              | 41.9M/117M [01:04<02:07, 590kB/s]Downloading pytorch_model.bin:  36%|█████████████████████████▊                                              | 41.9M/117M [01:19<02:07, 590kB/s]Downloading pytorch_model.bin:  45%|████████████████████████████████▏                                       | 52.4M/117M [01:30<02:07, 509kB/s]Downloading pytorch_model.bin:  45%|████████████████████████████████▏                                       | 52.4M/117M [01:49<02:07, 509kB/s]Downloading pytorch_model.bin:  54%|██████████████████████████████████████▋                                 | 62.9M/117M [02:03<02:09, 420kB/s]Downloading pytorch_model.bin:  54%|██████████████████████████████████████▋                                 | 62.9M/117M [02:19<02:09, 420kB/s]Downloading pytorch_model.bin:  63%|█████████████████████████████████████████████                           | 73.4M/117M [02:28<01:44, 420kB/s]Downloading pytorch_model.bin:  63%|█████████████████████████████████████████████                           | 73.4M/117M [02:39<01:44, 420kB/s]Downloading pytorch_model.bin:  72%|███████████████████████████████████████████████████▌                    | 83.9M/117M [02:55<01:21, 407kB/s]Downloading pytorch_model.bin:  72%|███████████████████████████████████████████████████▌                    | 83.9M/117M [03:09<01:21, 407kB/s]Downloading pytorch_model.bin:  81%|█████████████████████████████████████████████████████████▉              | 94.4M/117M [03:27<00:59, 381kB/s]Downloading pytorch_model.bin:  81%|█████████████████████████████████████████████████████████▉              | 94.4M/117M [03:39<00:59, 381kB/s]Downloading pytorch_model.bin:  89%|█████████████████████████████████████████████████████████████████▎       | 105M/117M [03:57<00:33, 371kB/s]Downloading pytorch_model.bin:  89%|█████████████████████████████████████████████████████████████████▎       | 105M/117M [04:09<00:33, 371kB/s]Downloading pytorch_model.bin:  98%|███████████████████████████████████████████████████████████████████████▊ | 115M/117M [04:21<00:04, 387kB/s]Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████| 117M/117M [04:25<00:00, 390kB/s]Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████| 117M/117M [04:25<00:00, 441kB/s]
Traceback (most recent call last):
  File "./f00389_process_financial_transactions.py", line 38, in <module>
    test_process_financial_transactions()
  File "./f00389_process_financial_transactions.py", line 31, in test_process_financial_transactions
    results = process_financial_transactions(transaction_data, queries)
  File "./f00389_process_financial_transactions.py", line 21, in process_financial_transactions
    inputs = tokenizer(table=transaction_data, queries=queries, return_tensors='pt')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py", line 650, in __call__
    return self.batch_encode_plus(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py", line 768, in batch_encode_plus
    return self._batch_encode_plus(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py", line 827, in _batch_encode_plus
    table_tokens = self._tokenize_table(table)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py", line 1387, in _tokenize_table
    tokenized_row.append(self.tokenize(cell))
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils.py", line 515, in tokenize
    text = re.sub(pattern, lambda m: m.groups()[0] or m.groups()[1].lower(), text)
  File "/root/miniconda3/envs/py38/lib/python3.8/re.py", line 210, in sub
    return _compile(pattern, flags).sub(repl, string, count)
TypeError: expected string or bytes-like object
