2023-11-12 03:44:53.363251: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 03:44:53.406022: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 03:44:54.101450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Repo card metadata block was not found. Setting CardData to empty.
Generating session1 split: 0 examples [00:00, ? examples/s]Generating session1 split: 6 examples [00:00, 387.28 examples/s]
Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/2.15k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 2.15k/2.15k [00:00<00:00, 154kB/s]
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/378M [00:00<?, ?B/s]Downloading pytorch_model.bin:   3%|█▉                                                                     | 10.5M/378M [00:02<01:14, 4.96MB/s]Downloading pytorch_model.bin:   6%|███▉                                                                   | 21.0M/378M [00:02<00:41, 8.69MB/s]Downloading pytorch_model.bin:   8%|█████▉                                                                 | 31.5M/378M [00:03<00:30, 11.3MB/s]Downloading pytorch_model.bin:  11%|███████▊                                                               | 41.9M/378M [00:03<00:25, 13.3MB/s]Downloading pytorch_model.bin:  14%|█████████▊                                                             | 52.4M/378M [00:04<00:23, 13.9MB/s]Downloading pytorch_model.bin:  17%|███████████▊                                                           | 62.9M/378M [00:05<00:21, 14.7MB/s]Downloading pytorch_model.bin:  19%|█████████████▊                                                         | 73.4M/378M [00:05<00:20, 14.7MB/s]Downloading pytorch_model.bin:  22%|███████████████▋                                                       | 83.9M/378M [00:07<00:23, 12.5MB/s]Downloading pytorch_model.bin:  25%|█████████████████▋                                                     | 94.4M/378M [00:07<00:24, 11.8MB/s]Downloading pytorch_model.bin:  28%|███████████████████▉                                                    | 105M/378M [00:08<00:24, 11.4MB/s]Downloading pytorch_model.bin:  30%|█████████████████████▉                                                  | 115M/378M [00:10<00:25, 10.4MB/s]Downloading pytorch_model.bin:  33%|███████████████████████▉                                                | 126M/378M [00:10<00:22, 11.3MB/s]Downloading pytorch_model.bin:  36%|█████████████████████████▉                                              | 136M/378M [00:11<00:19, 12.2MB/s]Downloading pytorch_model.bin:  39%|███████████████████████████▉                                            | 147M/378M [00:12<00:18, 12.8MB/s]Downloading pytorch_model.bin:  42%|█████████████████████████████▉                                          | 157M/378M [00:13<00:16, 13.4MB/s]Downloading pytorch_model.bin:  44%|███████████████████████████████▉                                        | 168M/378M [00:13<00:15, 14.0MB/s]Downloading pytorch_model.bin:  47%|█████████████████████████████████▉                                      | 178M/378M [00:14<00:13, 14.6MB/s]Downloading pytorch_model.bin:  50%|███████████████████████████████████▉                                    | 189M/378M [00:15<00:12, 14.8MB/s]Downloading pytorch_model.bin:  53%|█████████████████████████████████████▉                                  | 199M/378M [00:15<00:11, 15.4MB/s]Downloading pytorch_model.bin:  55%|███████████████████████████████████████▉                                | 210M/378M [00:16<00:10, 15.7MB/s]Downloading pytorch_model.bin:  58%|█████████████████████████████████████████▉                              | 220M/378M [00:16<00:09, 16.0MB/s]Downloading pytorch_model.bin:  61%|███████████████████████████████████████████▉                            | 231M/378M [00:17<00:09, 15.5MB/s]Downloading pytorch_model.bin:  64%|█████████████████████████████████████████████▉                          | 241M/378M [00:18<00:08, 15.3MB/s]Downloading pytorch_model.bin:  67%|███████████████████████████████████████████████▉                        | 252M/378M [00:19<00:08, 15.4MB/s]Downloading pytorch_model.bin:  69%|█████████████████████████████████████████████████▉                      | 262M/378M [00:19<00:07, 15.0MB/s]Downloading pytorch_model.bin:  72%|███████████████████████████████████████████████████▉                    | 273M/378M [00:20<00:07, 14.3MB/s]Downloading pytorch_model.bin:  75%|█████████████████████████████████████████████████████▉                  | 283M/378M [00:21<00:06, 13.7MB/s]Downloading pytorch_model.bin:  78%|███████████████████████████████████████████████████████▊                | 294M/378M [00:22<00:06, 13.7MB/s]Downloading pytorch_model.bin:  80%|█████████████████████████████████████████████████████████▊              | 304M/378M [00:23<00:05, 13.5MB/s]Downloading pytorch_model.bin:  83%|███████████████████████████████████████████████████████████▊            | 315M/378M [00:24<00:06, 10.5MB/s]Downloading pytorch_model.bin:  86%|█████████████████████████████████████████████████████████████▊          | 325M/378M [00:26<00:05, 9.06MB/s]Downloading pytorch_model.bin:  89%|███████████████████████████████████████████████████████████████▊        | 336M/378M [00:27<00:04, 8.64MB/s]Downloading pytorch_model.bin:  91%|█████████████████████████████████████████████████████████████████▊      | 346M/378M [00:28<00:03, 8.16MB/s]Downloading pytorch_model.bin:  94%|███████████████████████████████████████████████████████████████████▊    | 357M/378M [00:30<00:02, 7.84MB/s]Downloading pytorch_model.bin:  97%|█████████████████████████████████████████████████████████████████████▊  | 367M/378M [00:31<00:01, 7.52MB/s]Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████▊| 377M/378M [00:33<00:00, 7.61MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████| 378M/378M [00:33<00:00, 7.58MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████| 378M/378M [00:33<00:00, 11.4MB/s]
Some weights of the model checkpoint at superb/wav2vec2-base-superb-er were not used when initializing Wav2Vec2ForSequenceClassification: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at superb/wav2vec2-base-superb-er and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Downloading (…)rocessor_config.json:   0%|                                                                           | 0.00/215 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|████████████████████████████████████████████████████████████████████| 215/215 [00:00<00:00, 88.5kB/s]
Traceback (most recent call last):
  File "./f00536_emotion_recognition.py", line 45, in <module>
    test_emotion_recognition()
  File "./f00536_emotion_recognition.py", line 35, in test_emotion_recognition
    result = emotion_recognition(test_audio_file)
  File "./f00536_emotion_recognition.py", line 25, in emotion_recognition
    labels = classifier(audio_file, top_k=top_k)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/audio_classification.py", line 136, in __call__
    return super().__call__(inputs, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1140, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1146, in run_single
    model_inputs = self.preprocess(inputs, **preprocess_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/audio_classification.py", line 154, in preprocess
    with open(inputs, "rb") as f:
FileNotFoundError: [Errno 2] No such file or directory: 'test_audio.wav'
