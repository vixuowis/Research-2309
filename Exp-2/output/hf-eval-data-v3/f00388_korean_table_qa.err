2023-11-11 23:26:39.595316: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-11 23:26:39.647508: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-11 23:26:40.364131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/1.37k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 1.37k/1.37k [00:00<00:00, 118kB/s]
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/447M [00:00<?, ?B/s]Downloading pytorch_model.bin:   2%|█▋                                                                      | 10.5M/447M [00:41<29:05, 250kB/s]Downloading pytorch_model.bin:   2%|█▋                                                                      | 10.5M/447M [00:56<29:05, 250kB/s]Downloading pytorch_model.bin:   4%|██▉                                                                     | 18.6M/447M [01:18<30:20, 236kB/s]Downloading pytorch_model.bin:   4%|██▉                                                                     | 18.6M/447M [01:18<30:02, 238kB/s]
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/447M [00:00<?, ?B/s]Downloading pytorch_model.bin:   2%|█▋                                                                      | 10.5M/447M [00:39<27:09, 268kB/s]Downloading pytorch_model.bin:   2%|█▋                                                                      | 10.5M/447M [00:50<27:09, 268kB/s]Downloading pytorch_model.bin:   5%|███▍                                                                    | 21.0M/447M [01:11<23:40, 300kB/s]Downloading pytorch_model.bin:   5%|███▍                                                                    | 21.0M/447M [01:30<23:40, 300kB/s]Downloading pytorch_model.bin:   7%|█████                                                                   | 31.5M/447M [01:52<25:06, 276kB/s]Downloading pytorch_model.bin:   8%|█████▊                                                                  | 35.9M/447M [02:06<23:56, 286kB/s]Downloading pytorch_model.bin:   8%|█████▊                                                                  | 35.9M/447M [02:06<24:06, 285kB/s]
Traceback (most recent call last):
  File "./f00388_korean_table_qa.py", line 38, in <module>
    test_korean_table_qa()
  File "./f00388_korean_table_qa.py", line 31, in test_korean_table_qa
    assert korean_table_qa(sample_table, sample_question) == '30'
  File "./f00388_korean_table_qa.py", line 19, in korean_table_qa
    table_qa = pipeline('table-question-answering', model='dsba-lab/koreapas-finetuned-korwikitq')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 824, in pipeline
    framework, model = infer_framework_load_model(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 282, in infer_framework_load_model
    raise ValueError(
ValueError: Could not load model dsba-lab/koreapas-finetuned-korwikitq with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForTableQuestionAnswering'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForTableQuestionAnswering'>, <class 'transformers.models.tapas.modeling_tapas.TapasForQuestionAnswering'>, <class 'transformers.models.tapas.modeling_tf_tapas.TFTapasForQuestionAnswering'>). See the original errors:

while loading with AutoModelForTableQuestionAnswering, an error is thrown:
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 269, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2793, in from_pretrained
    resolved_archive_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1429, in hf_hub_download
    http_get(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 557, in http_get
    raise EnvironmentError(
OSError: Consistency check failed: file should be of size 447317279 but has size 18596903 (pytorch_model.bin).
We are sorry for the inconvenience. Please retry download and pass `force_download=True, resume_download=False` as argument.
If the issue persists, please let us know by opening an issue on https://github.com/huggingface/huggingface_hub.

while loading with TFAutoModelForTableQuestionAnswering, an error is thrown:
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 269, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_tf_utils.py", line 2820, in from_pretrained
    raise EnvironmentError(
OSError: dsba-lab/koreapas-finetuned-korwikitq does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.

while loading with TapasForQuestionAnswering, an error is thrown:
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 269, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2793, in from_pretrained
    resolved_archive_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1429, in hf_hub_download
    http_get(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 557, in http_get
    raise EnvironmentError(
OSError: Consistency check failed: file should be of size 447317279 but has size 35917898 (pytorch_model.bin).
We are sorry for the inconvenience. Please retry download and pass `force_download=True, resume_download=False` as argument.
If the issue persists, please let us know by opening an issue on https://github.com/huggingface/huggingface_hub.

while loading with TFTapasForQuestionAnswering, an error is thrown:
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 269, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_tf_utils.py", line 2820, in from_pretrained
    raise EnvironmentError(
OSError: dsba-lab/koreapas-finetuned-korwikitq does not appear to have a file named tf_model.h5 but there is a file for PyTorch weights. Use `from_pt=True` to load this model from those weights.



