{'code': "###Instruction: I have a collection of audio recordings from different sources, and I want to convert them into text to make an archive.\n###Output: <<<domain>>>: Audio Automatic Speech Recognition\n<<<api_call>>>: WhisperForConditionalGeneration.from_pretrained('openai/whisper-small')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. The first step should be to import the necessary libraries, the WhisperProcessor, and the WhisperForConditionalGeneration model from the transformers library.\n2. Next, load the WhisperProcessor and the WhisperForConditionalGeneration model using the from_pretrained method.\n3. Iterate through your audio samples and process each audio sample with the WhisperProcessor to create the input features.\n4. For each input feature, use the WhisperForConditionalGeneration model to generate the predicted token IDs.\n5. Decode these token IDs using the processor and obtain the transcriptions. This will give you the transcribed text for each audio sample in your collection.\n6. Save these transcriptions in an organized manner for your archive.\n<<<code>>>: from transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom datasets import load_dataset\n\nprocessor = WhisperProcessor.from_pretrained('openai/whisper-small')\nmodel = WhisperForConditionalGeneration.from_pretrained('openai/whisper-small')\n\ntranscriptions = []\nfor audio_sample in audio_samples:\n    input_features = processor(audio_sample['array'], sampling_rate=audio_sample['sampling_rate'], return_tensors='pt').input_features\n    predicted_ids = model.generate(input_features)\n    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n    transcriptions.append(transcription)\n\narchive = create_archive(transcriptions)", 'api_call': "WhisperForConditionalGeneration.from_pretrained('openai/whisper-small')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Audio Automatic Speech Recognition', 'framework': 'Hugging Face Transformers', 'functionality': 'Transcription and Translation', 'api_name': 'openai/whisper-small', 'api_call': "WhisperForConditionalGeneration.from_pretrained('openai/whisper-small')", 'api_arguments': {'language': 'english', 'task': 'transcribe'}, 'python_environment_requirements': {'transformers': 'latest', 'datasets': 'latest'}, 'example_code': ['from transformers import WhisperProcessor, WhisperForConditionalGeneration', 'from datasets import load_dataset', 'processor = WhisperProcessor.from_pretrained(openai/whisper-small)', 'model = WhisperForConditionalGeneration.from_pretrained(openai/whisper-small)', 'model.config.forced_decoder_ids = None', 'ds = load_dataset(hf-internal-testing/librispeech_asr_dummy, clean, split=validation)', 'sample = ds[0][audio]', 'input_features = processor(sample[array], sampling_rate=sample[sampling_rate], return_tensors=pt).input_features', 'predicted_ids = model.generate(input_features)', 'transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)', 'print(transcription)'], 'performance': {'dataset': 'LibriSpeech (clean) test set', 'accuracy': '3.432 WER'}, 'description': 'Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages.'}}



Extracting data files:   0%|                                                   | 0/1 [00:00<?, ?it/s]
Extracting data files: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00, 1661.77it/s]

Generating validation split: 0 examples [00:00, ? examples/s]
Generating validation split: 0 examples [00:00, ? examples/s]
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/audio.py", line 91, in encode_example
    import soundfile as sf  # soundfile is a dependency of librosa, needed to decode audio files.
ModuleNotFoundError: No module named 'soundfile'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1693, in _prepare_split_single
    example = self.info.features.encode_example(record) if self.info.features is not None else record
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1852, in encode_example
    return encode_nested_example(self, example)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1229, in encode_nested_example
    {
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1230, in <dictcomp>
    k: encode_nested_example(sub_schema, sub_obj, level=level + 1)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1284, in encode_nested_example
    return schema.encode_example(obj) if obj is not None else None
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/audio.py", line 93, in encode_example
    raise ImportError("To support encoding audio data, please install 'soundfile'.") from err
ImportError: To support encoding audio data, please install 'soundfile'.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00709_transcribe_audio_samples.py", line 45, in <module>
    test_transcribe_audio_samples()
  File "output/hf-eval-data-v2/f00709_transcribe_audio_samples.py", line 36, in test_transcribe_audio_samples
    ds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split='validation')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/load.py", line 2153, in load_dataset
    builder_instance.download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 954, in download_and_prepare
    self._download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1717, in _download_and_prepare
    super()._download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1049, in _download_and_prepare
    self._prepare_split(split_generator, **prepare_split_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1555, in _prepare_split
    for job_id, done, content in self._prepare_split_single(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1712, in _prepare_split_single
    raise DatasetGenerationError("An error occurred while generating the dataset") from e
datasets.builder.DatasetGenerationError: An error occurred while generating the dataset
