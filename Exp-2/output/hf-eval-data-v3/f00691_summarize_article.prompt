{'code': '###Instruction: Our company needs a versatile NLP model to build a social media manager to generate summaries of lengthy articles for sharing on social media.\n###Output: <<<domain>>>: Natural Language Processing Text2Text Generation\n<<<api_call>>>: T5Model.from_pretrained(\'t5-large\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. First, import the required T5Tokenizer and T5Model from the transformers package.\n2. We will use the \'t5-large\' model, which is a powerful NLP model capable of performing a variety of tasks, including summarization.\n3. Tokenize the lengthy article using the tokenizer, and store the resulting tokens as input_ids.\n4. Create a prompt for the model, such as "summarize:", to guide it to perform summarization. Tokenize the prompt and store it as decoder_input_ids.\n5. Pass the input_ids and decoder_input_ids into the T5 model for summarization.\n6. Output the summarized text.\n<<<code>>>:from transformers import T5Tokenizer, T5Model\ntokenizer = T5Tokenizer.from_pretrained(\'t5-large\')\nmodel = T5Model.from_pretrained(\'t5-large\')\narticle = "Lengthy article text here..."\ninput_ids = tokenizer("summarize: " + article, return_tensors=\'pt\').input_ids\ndecoder_input_ids = tokenizer("summarize: ", return_tensors=\'pt\').input_ids\noutputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n', 'api_call': "T5Model.from_pretrained('t5-large')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Text2Text Generation', 'framework': 'Hugging Face Transformers', 'functionality': 'Translation, Summarization, Question Answering, Sentiment Analysis, Regression', 'api_name': 't5-large', 'api_call': "T5Model.from_pretrained('t5-large')", 'api_arguments': {'input_ids': "tokenizer(..., return_tensors='pt').input_ids", 'decoder_input_ids': "tokenizer(..., return_tensors='pt').input_ids"}, 'python_environment_requirements': {'transformers': 'from transformers import T5Tokenizer, T5Model'}, 'example_code': "tokenizer = T5Tokenizer.from_pretrained('t5-large')\nmodel = T5Model.from_pretrained('t5-large')\ninput_ids = tokenizer('Studies have been shown that owning a dog is good for you', return_tensors='pt').input_ids\ndecoder_input_ids = tokenizer('Studies show that', return_tensors='pt').input_ids\noutputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\nlast_hidden_states = outputs.last_hidden_state", 'performance': {'dataset': 'c4', 'accuracy': 'See research paper, Table 14'}, 'description': 'T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks.'}}

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00691_summarize_article.py", line 37, in <module>
    test_summarize_article()
  File "output/hf-eval-data-v2/f00691_summarize_article.py", line 31, in test_summarize_article
    summary = summarize_article(article)
  File "output/hf-eval-data-v2/f00691_summarize_article.py", line 17, in summarize_article
    tokenizer = T5Tokenizer.from_pretrained('t5-large')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 1813, in from_pretrained
    resolved_vocab_files[file_id] = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1193, in hf_hub_download
    os.makedirs(storage_folder, exist_ok=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/os.py", line 223, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/root/autodl-tmp/.cache/huggingface/hub/models--t5-large'
