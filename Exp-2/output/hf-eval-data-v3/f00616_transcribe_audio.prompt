{'code': "###Instruction: Our company has an audio archive of Chinese podcasts, and we want to create transcripts for them.\n###Output: <<<domain>>>: Audio Automatic Speech Recognition\n<<<api_call>>>: Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the SpeechRecognitionModel class from the huggingsound package.\n2. Create an instance of the SpeechRecognitionModel by specifying the pre-trained model 'jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn'. This model is designed to handle speech recognition tasks for the Chinese language.\n3. Use the 'transcribe' method of the SpeechRecognitionModel to create transcriptions for the provided audio files of Chinese podcasts.\n4. You can provide a list of paths to the audio files as input for the transcription process.\n5. The model will output a list of text transcriptions corresponding to the input audio files.\n<<<code>>>: from huggingsound import SpeechRecognitionModel\nmodel = SpeechRecognitionModel('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')\naudio_paths = ['/path/to/podcast1.mp3', '/path/to/podcast2.wav']\ntranscriptions = model.transcribe(audio_paths)\n", 'api_call': "Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Audio Automatic Speech Recognition', 'framework': 'Hugging Face Transformers', 'functionality': 'Speech Recognition', 'api_name': 'jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn', 'api_call': "Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')", 'api_arguments': ['audio_paths'], 'python_environment_requirements': ['huggingsound', 'torch', 'librosa', 'datasets', 'transformers'], 'example_code': "from huggingsound import SpeechRecognitionModel\nmodel = SpeechRecognitionModel('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')\naudio_paths = ['/path/to/file.mp3', '/path/to/another_file.wav']\ntranscriptions = model.transcribe(audio_paths)", 'performance': {'dataset': 'Common Voice zh-CN', 'accuracy': {'WER': 82.37, 'CER': 19.03}}, 'description': 'Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS.'}}

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00616_transcribe_audio.py", line 3, in <module>
    from huggingsound import SpeechRecognitionModel
ModuleNotFoundError: No module named 'huggingsound'
