{'code': "###Instruction: I have a picture of a room demonstrating a mixture of objects. The model needs to seperate the objects and label them accordingly.\n###Output: <<<domain>>>: Computer Vision Image Segmentation\n<<<api_call>>>: MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-large-ade')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the necessary packages, classes, and functions from the transformers, Pillow, and requests libraries.\n2. Load the image from a URL or a local path.\n3. Instantiate the MaskFormerImageProcessor to preprocess the image.\n4. Convert the image into a format suitable for the MaskFormer model using the processor.\n5. Instantiate the MaskFormerForInstanceSegmentation model with the pretrained weights.\n6. Perform instance segmentation on the image using the model.\n7. Post-process the output to obtain the labeled semantic map superimposed on the input image.\n<<<code>>>: from transformers import MaskFormerImageProcessor, MaskFormerForInstanceSegmentation\nfrom PIL import Image\nimport requests\n\nurl = 'your_image_url_here'\nimage = Image.open(requests.get(url, stream=True).raw)\nprocessor = MaskFormerImageProcessor.from_pretrained('facebook/maskformer-swin-large-ade')\ninputs = processor(images=image, return_tensors='pt')\nmodel = MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-large-ade')\noutputs = model(**inputs)\npredicted_semantic_map = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n", 'api_call': "MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-large-ade')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Computer Vision Image Segmentation', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'facebook/maskformer-swin-large-ade', 'api_call': "MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-large-ade')", 'api_arguments': {'from_pretrained': 'facebook/maskformer-swin-large-ade'}, 'python_environment_requirements': {'packages': ['transformers', 'PIL', 'requests']}, 'example_code': "from transformers import MaskFormerImageProcessor, MaskFormerForInstanceSegmentation\nfrom PIL import Image\nimport requests\nurl = 'https://huggingface.co/datasets/hf-internal-testing/fixtures_ade20k/resolve/main/ADE_val_00000001.jpg'\nimage = Image.open(requests.get(url, stream=True).raw)\nprocessor = MaskFormerImageProcessor.from_pretrained('facebook/maskformer-swin-large-ade')\ninputs = processor(images=image, return_tensors='pt')\nmodel = MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-large-ade')\noutputs = model(**inputs)\nclass_queries_logits = outputs.class_queries_logits\nmasks_queries_logits = outputs.masks_queries_logits\npredicted_semantic_map = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]", 'performance': {'dataset': 'ADE20k', 'accuracy': 'Not provided'}, 'description': 'MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation.'}}


/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/maskformer/image_processing_maskformer.py:411: FutureWarning: The `size_divisibility` argument is deprecated and will be removed in v4.27. Please use `size_divisor` instead.
  warnings.warn(
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/maskformer/image_processing_maskformer.py:418: FutureWarning: The `max_size` argument is deprecated and will be removed in v4.27. Please use size['longest_edge'] instead.
  warnings.warn(


