{'code': '###Instruction: We have received an invoice document, and would like to extract the total amount from it.\n###Input: {\'question\': \'What is the total amount?\', \'context\': \'Invoice information for order ABC_123\\nProduct: Widget A, Quantity: 10, Price: $5 each\\nProduct: Widget B, Quantity: 5, Price: $3 each\\nProduct: Widget C, Quantity: 15, Price: $2 each\\nSubtotal: $75, Tax: $6.38, Total Amount Due: $81.38\'}\n###Output: <<<domain>>>: Multimodal Document Question Answer\n<<<api_call>>>: AutoModelForDocumentQuestionAnswering.from_pretrained(\'impira/layoutlm-invoices\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import the necessary classes and functions from the transformers package, including the AutoModelForDocumentQuestionAnswering and AutoTokenizer.\n2. Load the pre-trained model \'impira/layoutlm-invoices\' using the from_pretrained method of the AutoModelForDocumentQuestionAnswering class.\n3. Load the tokenizer for the model using the from_pretrained method of the AutoTokenizer class.\n4. Use the tokenizer to encode the input question and context as a dictionary.\n5. Pass the encoded input to the model and obtain the answer by taking the highest scoring tokens using argmax.\n6. Decode the answer tokens back to a textual answer using the tokenizer\'s decode method.\n7. The resulting answer should be the total amount due from the invoice document.\n<<<code>>>:from transformers import AutoModelForDocumentQuestionAnswering, AutoTokenizer\nmodel = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-invoices")\ntokenizer = AutoTokenizer.from_pretrained("impira/layoutlm-invoices")\ninputs = tokenizer("What is the total amount?", "Invoice information for order ABC_123\\nProduct: Widget A, Quantity: 10, Price: $5 each\\nProduct: Widget B, Quantity: 5, Price: $3 each\\nProduct: Widget C, Quantity: 15, Price: $2 each\\nSubtotal: $75, Tax: $6.38, Total Amount Due: $81.38", return_tensors="pt")\noutputs = model(**inputs)\nanswer_start = outputs.start_logits.argmax().item()\nanswer_end = outputs.end_logits.argmax().item()\nanswer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs["input_ids"][0][answer_start: answer_end + 1].tolist()))\n', 'api_call': "AutoModelForDocumentQuestionAnswering.from_pretrained('impira/layoutlm-invoices')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Multimodal Document Question Answer', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'layoutlm-invoices', 'api_call': "AutoModelForDocumentQuestionAnswering.from_pretrained('impira/layoutlm-invoices')", 'api_arguments': 'question, context', 'python_environment_requirements': 'transformers', 'example_code': "nlp(question='What is the total amount?', context='your_invoice_text')", 'performance': {'dataset': 'proprietary dataset of invoices, SQuAD2.0, and DocVQA', 'accuracy': 'Not provided'}, 'description': 'A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head.'}}



Some weights of the model checkpoint at impira/layoutlm-invoices were not used when initializing LayoutLMForQuestionAnswering: ['token_classifier_head.weight', 'token_classifier_head.bias']
- This IS expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).





Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00014_extract_total_amount.py", line 40, in <module>
    test_extract_total_amount()
  File "output/hf-eval-data-v2/f00014_extract_total_amount.py", line 36, in test_extract_total_amount
    assert extract_total_amount(question, context) == expected_answer
AssertionError
