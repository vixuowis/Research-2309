# function_import --------------------

from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline

# function_code --------------------

def extract_locations(text):
    """
    Extracts location entities from a given multilingual text using a pre-trained model.

    Args:
        text (str): The multilingual text from which to extract location entities.

    Returns:
        list: A list of dictionaries, each containing information about a detected location entity.
    """
    tokenizer = AutoTokenizer.from_pretrained('Babelscape/wikineural-multilingual-ner')
    model = AutoModelForTokenClassification.from_pretrained('Babelscape/wikineural-multilingual-ner')
    nlp = pipeline('ner', model=model, tokenizer=tokenizer)
    ner_results = nlp(text)
    locations = [entity for entity in ner_results if entity['entity'] == 'LOC']
    return locations

# test_function_code --------------------

def test_extract_locations():
    """
    Tests the `extract_locations` function with some example texts.
    """
    # Test with English text
    english_text = 'My name is Wolfgang and I live in Berlin.'
    english_locations = extract_locations(english_text)
    assert len(english_locations) == 1 and english_locations[0]['word'] == 'Berlin', 'Test failed for English text.'

    # Test with German text
    german_text = 'Ich hei√üe Wolfgang und ich wohne in Berlin.'
    german_locations = extract_locations(german_text)
    assert len(german_locations) == 1 and german_locations[0]['word'] == 'Berlin', 'Test failed for German text.'

    # Test with no locations
    no_locations_text = 'My name is Wolfgang.'
    no_locations = extract_locations(no_locations_text)
    assert len(no_locations) == 0, 'Test failed for text with no locations.'

    return 'All tests passed.'

# call_test_function_code --------------------

test_extract_locations()