Downloading (…)lve/main/config.json:   0%|                                                                           | 0.00/570 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████████| 570/570 [00:00<00:00, 119kB/s]2023-11-11 20:26:52.305443: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-11 20:26:52.348204: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-11 20:26:52.987194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

Downloading model.safetensors:   0%|                                                                                | 0.00/440M [00:00<?, ?B/s]Downloading model.safetensors:   5%|███▍                                                                    | 21.0M/440M [00:00<00:02, 168MB/s]Downloading model.safetensors:  12%|████████▌                                                               | 52.4M/440M [00:00<00:01, 207MB/s]Downloading model.safetensors:  19%|█████████████▋                                                          | 83.9M/440M [00:00<00:01, 222MB/s]Downloading model.safetensors:  26%|███████████████████                                                      | 115M/440M [00:00<00:01, 231MB/s]Downloading model.safetensors:  33%|████████████████████████▎                                                | 147M/440M [00:00<00:01, 235MB/s]Downloading model.safetensors:  40%|█████████████████████████████▌                                           | 178M/440M [00:00<00:01, 240MB/s]Downloading model.safetensors:  48%|██████████████████████████████████▊                                      | 210M/440M [00:00<00:00, 243MB/s]Downloading model.safetensors:  55%|███████████████████████████████████████▉                                 | 241M/440M [00:01<00:00, 241MB/s]Downloading model.safetensors:  62%|█████████████████████████████████████████████▏                           | 273M/440M [00:01<00:00, 239MB/s]Downloading model.safetensors:  69%|██████████████████████████████████████████████████▍                      | 304M/440M [00:01<00:00, 239MB/s]Downloading model.safetensors:  76%|███████████████████████████████████████████████████████▌                 | 336M/440M [00:01<00:00, 241MB/s]Downloading model.safetensors:  83%|████████████████████████████████████████████████████████████▊            | 367M/440M [00:01<00:00, 243MB/s]Downloading model.safetensors:  90%|██████████████████████████████████████████████████████████████████       | 398M/440M [00:01<00:00, 239MB/s]Downloading model.safetensors:  98%|███████████████████████████████████████████████████████████████████████▎ | 430M/440M [00:01<00:00, 236MB/s]Downloading model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████| 440M/440M [00:01<00:00, 234MB/s]
Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "./f00356_load_question_answering_model.py", line 59, in <module>
    test_load_question_answering_model()
  File "./f00356_load_question_answering_model.py", line 37, in test_load_question_answering_model
    assert isinstance(model, AutoModelForQuestionAnswering), 'Model is not an instance of AutoModelForQuestionAnswering'
AssertionError: Model is not an instance of AutoModelForQuestionAnswering
