{'code': "###Instruction: Our company develops a city planning application. We need to segment streets, buildings, and trees in aerial photographs.\n###Output: <<<domain>>>: Computer Vision Image Segmentation\n<<<api_call>>>: OneFormerForUniversalSegmentation.from_pretrained('shi-labs/oneformer_ade20k_swin_large')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. We import the necessary classes such as OneFormerProcessor and OneFormerForUniversalSegmentation from the transformers library provided by Hugging Face.\n2. We load an image from the specified file path or URL. This image contains the aerial view of a city that needs to be segmented.\n3. Create an instance of the OneFormerProcessor with the ADE20k pre-trained model, which has been trained to perform multiple segmentation tasks including semantic, instance, and panoptic segmentation, which can be helpful for city planning.\n4. Create an instance of the OneFormerForUniversalSegmentation model by specifying the 'shi-labs/oneformer_ade20k_swin_large' pre-trained model.\n5. The model processes the input image and provides a semantic segmentation map for the different categories such as streets, buildings, and trees.\n<<<code>>>: from transformers import OneFormerProcessor, OneFormerForUniversalSegmentation\nfrom PIL import Image\n\nimage = Image.open('aerial_city_view.jpg')\nprocessor = OneFormerProcessor.from_pretrained('shi-labs/oneformer_ade20k_swin_large')\nmodel = OneFormerForUniversalSegmentation.from_pretrained('shi-labs/oneformer_ade20k_swin_large')\n\nsegmentation_inputs = processor(images=image, task_inputs=['semantic'], return_tensors='pt')\nsegmentation_outputs = model(**segmentation_inputs)\nsegmentation_map = processor.post_process_semantic_segmentation(segmentation_outputs, target_sizes=[image.size[::-1]])[0]", 'api_call': "OneFormerForUniversalSegmentation.from_pretrained('shi-labs/oneformer_ade20k_swin_large')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Computer Vision Image Segmentation', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'shi-labs/oneformer_ade20k_swin_large', 'api_call': "OneFormerForUniversalSegmentation.from_pretrained('shi-labs/oneformer_ade20k_swin_large')", 'api_arguments': ['images', 'task_inputs', 'return_tensors'], 'python_environment_requirements': ['transformers', 'PIL', 'requests'], 'example_code': 'from transformers import OneFormerProcessor, OneFormerForUniversalSegmentation\nfrom PIL import Image\nimport requests\nurl = https://huggingface.co/datasets/shi-labs/oneformer_demo/blob/main/ade20k.jpeg\nimage = Image.open(requests.get(url, stream=True).raw)\nprocessor = OneFormerProcessor.from_pretrained(shi-labs/oneformer_ade20k_swin_large)\nmodel = OneFormerForUniversalSegmentation.from_pretrained(shi-labs/oneformer_ade20k_swin_large)\nsemantic_inputs = processor(images=image, task_inputs=[semantic], return_tensors=pt)\nsemantic_outputs = model(**semantic_inputs)\npredicted_semantic_map = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]', 'performance': {'dataset': 'scene_parse_150', 'accuracy': None}, 'description': 'OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model.'}}

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00657_segment_aerial_image.py", line 38, in <module>
    test_segment_aerial_image()
  File "output/hf-eval-data-v2/f00657_segment_aerial_image.py", line 33, in test_segment_aerial_image
    segmentation_map = segment_aerial_image('sample_aerial_city_view.jpg')
  File "output/hf-eval-data-v2/f00657_segment_aerial_image.py", line 18, in segment_aerial_image
    image = Image.open(image_path)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/PIL/Image.py", line 3218, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: 'sample_aerial_city_view.jpg'
