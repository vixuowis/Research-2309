2023-11-12 06:27:37.031141: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 06:27:37.073299: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 06:27:37.685026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/2.11k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 2.11k/2.11k [00:00<00:00, 337kB/s]
Downloading pytorch_model.bin:   0%|                                                                               | 0.00/1.26G [00:00<?, ?B/s]Downloading pytorch_model.bin:   2%|█▏                                                                     | 21.0M/1.26G [00:00<00:06, 177MB/s]Downloading pytorch_model.bin:   4%|██▉                                                                    | 52.4M/1.26G [00:00<00:05, 209MB/s]Downloading pytorch_model.bin:   6%|████▏                                                                  | 73.4M/1.26G [00:00<00:05, 207MB/s]Downloading pytorch_model.bin:   8%|█████▉                                                                  | 105M/1.26G [00:00<00:05, 211MB/s]Downloading pytorch_model.bin:  11%|███████▊                                                                | 136M/1.26G [00:00<00:05, 212MB/s]Downloading pytorch_model.bin:  13%|█████████▌                                                              | 168M/1.26G [00:00<00:05, 214MB/s]Downloading pytorch_model.bin:  16%|███████████▎                                                            | 199M/1.26G [00:00<00:04, 219MB/s]Downloading pytorch_model.bin:  18%|█████████████▏                                                          | 231M/1.26G [00:01<00:04, 220MB/s]Downloading pytorch_model.bin:  21%|██████████████▉                                                         | 262M/1.26G [00:01<00:04, 219MB/s]Downloading pytorch_model.bin:  23%|████████████████▋                                                       | 294M/1.26G [00:01<00:04, 219MB/s]Downloading pytorch_model.bin:  26%|██████████████████▌                                                     | 325M/1.26G [00:01<00:04, 221MB/s]Downloading pytorch_model.bin:  28%|████████████████████▎                                                   | 357M/1.26G [00:01<00:04, 220MB/s]Downloading pytorch_model.bin:  31%|██████████████████████▏                                                 | 388M/1.26G [00:01<00:03, 219MB/s]Downloading pytorch_model.bin:  33%|███████████████████████▉                                                | 419M/1.26G [00:01<00:03, 220MB/s]Downloading pytorch_model.bin:  36%|█████████████████████████▋                                              | 451M/1.26G [00:02<00:03, 223MB/s]Downloading pytorch_model.bin:  38%|███████████████████████████▌                                            | 482M/1.26G [00:02<00:03, 219MB/s]Downloading pytorch_model.bin:  41%|█████████████████████████████▎                                          | 514M/1.26G [00:02<00:03, 212MB/s]Downloading pytorch_model.bin:  43%|███████████████████████████████                                         | 545M/1.26G [00:02<00:03, 210MB/s]Downloading pytorch_model.bin:  46%|████████████████████████████████▉                                       | 577M/1.26G [00:02<00:03, 211MB/s]Downloading pytorch_model.bin:  48%|██████████████████████████████████▋                                     | 608M/1.26G [00:02<00:03, 215MB/s]Downloading pytorch_model.bin:  51%|████████████████████████████████████▍                                   | 640M/1.26G [00:02<00:02, 217MB/s]Downloading pytorch_model.bin:  53%|██████████████████████████████████████▎                                 | 671M/1.26G [00:03<00:02, 217MB/s]Downloading pytorch_model.bin:  56%|████████████████████████████████████████                                | 703M/1.26G [00:03<00:02, 218MB/s]Downloading pytorch_model.bin:  58%|█████████████████████████████████████████▊                              | 734M/1.26G [00:03<00:02, 221MB/s]Downloading pytorch_model.bin:  61%|███████████████████████████████████████████▋                            | 765M/1.26G [00:03<00:02, 222MB/s]Downloading pytorch_model.bin:  63%|█████████████████████████████████████████████▍                          | 797M/1.26G [00:03<00:02, 219MB/s]Downloading pytorch_model.bin:  66%|███████████████████████████████████████████████▏                        | 828M/1.26G [00:03<00:01, 218MB/s]Downloading pytorch_model.bin:  68%|█████████████████████████████████████████████████                       | 860M/1.26G [00:03<00:01, 218MB/s]Downloading pytorch_model.bin:  71%|██████████████████████████████████████████████████▊                     | 891M/1.26G [00:04<00:01, 223MB/s]Downloading pytorch_model.bin:  73%|████████████████████████████████████████████████████▌                   | 923M/1.26G [00:04<00:01, 228MB/s]Downloading pytorch_model.bin:  76%|██████████████████████████████████████████████████████▍                 | 954M/1.26G [00:04<00:01, 230MB/s]Downloading pytorch_model.bin:  78%|████████████████████████████████████████████████████████▏               | 986M/1.26G [00:04<00:01, 229MB/s]Downloading pytorch_model.bin:  81%|█████████████████████████████████████████████████████████▏             | 1.02G/1.26G [00:04<00:01, 231MB/s]Downloading pytorch_model.bin:  83%|██████████████████████████████████████████████████████████▉            | 1.05G/1.26G [00:04<00:00, 227MB/s]Downloading pytorch_model.bin:  86%|████████████████████████████████████████████████████████████▋          | 1.08G/1.26G [00:04<00:00, 212MB/s]Downloading pytorch_model.bin:  88%|██████████████████████████████████████████████████████████████▌        | 1.11G/1.26G [00:05<00:00, 213MB/s]Downloading pytorch_model.bin:  91%|████████████████████████████████████████████████████████████████▎      | 1.14G/1.26G [00:05<00:00, 218MB/s]Downloading pytorch_model.bin:  93%|██████████████████████████████████████████████████████████████████     | 1.17G/1.26G [00:05<00:00, 221MB/s]Downloading pytorch_model.bin:  96%|███████████████████████████████████████████████████████████████████▊   | 1.21G/1.26G [00:05<00:00, 218MB/s]Downloading pytorch_model.bin:  98%|█████████████████████████████████████████████████████████████████████▌ | 1.24G/1.26G [00:05<00:00, 217MB/s]Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████| 1.26G/1.26G [00:05<00:00, 215MB/s]Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████| 1.26G/1.26G [00:05<00:00, 218MB/s]
Some weights of the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: 
  warnings.warn(
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py", line 261, in hf_raise_for_status
    response.raise_for_status()
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli/resolve/main/preprocessor_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1230, in hf_hub_download
    metadata = get_hf_file_metadata(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1606, in get_hf_file_metadata
    hf_raise_for_status(r)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py", line 271, in hf_raise_for_status
    raise EntryNotFoundError(message, response) from e
huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-654fffea-1569bbde6e3354ec2dbe24bc;991986d1-9b81-4502-8202-a91569fb9104)

Entry Not Found for url: https://huggingface.co/jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli/resolve/main/preprocessor_config.json.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 51, in from_pretrained
    return super().from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/processing_utils.py", line 226, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/processing_utils.py", line 270, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/feature_extraction_utils.py", line 365, in from_pretrained
    feature_extractor_dict, kwargs = cls.get_feature_extractor_dict(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/feature_extraction_utils.py", line 488, in get_feature_extractor_dict
    resolved_feature_extractor_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 480, in cached_file
    raise EnvironmentError(
OSError: jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli/main' for available files.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py", line 261, in hf_raise_for_status
    response.raise_for_status()
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli/resolve/main/preprocessor_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1230, in hf_hub_download
    metadata = get_hf_file_metadata(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1606, in get_hf_file_metadata
    hf_raise_for_status(r)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py", line 271, in hf_raise_for_status
    raise EntryNotFoundError(message, response) from e
huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-654fffeb-594ef4043f2c18da284c6fa2;36569d5e-a709-4186-bd1f-c6f1d0e84557)

Entry Not Found for url: https://huggingface.co/jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli/resolve/main/preprocessor_config.json.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "./f00615_transcribe_audio.py", line 62, in <module>
    test_transcribe_audio()
  File "./f00615_transcribe_audio.py", line 47, in test_transcribe_audio
    transcription = transcribe_audio('test_audio_short.wav')
  File "./f00615_transcribe_audio.py", line 24, in transcribe_audio
    processor = Wav2Vec2Processor.from_pretrained('jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 62, in from_pretrained
    feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/feature_extraction_utils.py", line 365, in from_pretrained
    feature_extractor_dict, kwargs = cls.get_feature_extractor_dict(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/feature_extraction_utils.py", line 488, in get_feature_extractor_dict
    resolved_feature_extractor_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 480, in cached_file
    raise EnvironmentError(
OSError: jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli/main' for available files.
