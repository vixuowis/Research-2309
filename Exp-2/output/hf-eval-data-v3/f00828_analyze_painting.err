Downloading (…)rocessor_config.json:   0%|                                                                                       | 0.00/432 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|████████████████████████████████████████████████████████████████████████████████| 432/432 [00:00<00:00, 69.9kB/s]
Downloading (…)okenizer_config.json:   0%|                                                                                       | 0.00/904 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████████████████████████████████████| 904/904 [00:00<00:00, 81.9kB/s]
Downloading (…)/main/tokenizer.json:   0%|                                                                                     | 0.00/2.11M [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████| 2.11M/2.11M [00:01<00:00, 1.93MB/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████| 2.11M/2.11M [00:01<00:00, 1.93MB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                                       | 0.00/548 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████████████████████| 548/548 [00:00<00:00, 297kB/s]
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. 
The class this function is called from is 'BertTokenizerFast'.
Traceback (most recent call last):
  File "./f00828_analyze_painting.py", line 24, in analyze_painting
    processor = BlipProcessor.from_pretrained('Salesforce/blip2-opt-2.7b')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/processing_utils.py", line 228, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/processing_utils.py", line 272, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2024, in from_pretrained
    return cls._from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2256, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert_fast.py", line 235, in __init__
    normalizer_state = json.loads(self.backend_tokenizer.normalizer.__getstate__())
AttributeError: 'NoneType' object has no attribute '__getstate__'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./f00828_analyze_painting.py", line 62, in <module>
    test_analyze_painting()
  File "./f00828_analyze_painting.py", line 42, in test_analyze_painting
    answer = analyze_painting(img_url, question)
  File "./f00828_analyze_painting.py", line 32, in analyze_painting
    raise Exception('Error in analyzing painting: ' + str(e))
Exception: Error in analyzing painting: 'NoneType' object has no attribute '__getstate__'
