Downloading (…)okenizer_config.json:   0%|                                                                         | 0.00/2.36k [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████| 2.36k/2.36k [00:00<00:00, 216kB/s]
Downloading (…)/main/tokenizer.json:   0%|                                                                         | 0.00/2.42M [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████████████████████████████| 2.42M/2.42M [00:01<00:00, 2.27MB/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████████████████████████████| 2.42M/2.42M [00:01<00:00, 2.27MB/s]
Downloading (…)in/added_tokens.json:   0%|                                                                          | 0.00/37.0 [00:00<?, ?B/s]Downloading (…)in/added_tokens.json: 100%|██████████████████████████████████████████████████████████████████| 37.0/37.0 [00:00<00:00, 15.7kB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                         | 0.00/2.20k [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████| 2.20k/2.20k [00:00<00:00, 1.00MB/s]
Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/1.49k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 1.49k/1.49k [00:00<00:00, 115kB/s]2023-11-12 03:13:25.983671: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 03:13:26.025674: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 03:13:26.634720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

Downloading pytorch_model.bin:   0%|                                                                                | 0.00/892M [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|▊                                                                      | 10.5M/892M [00:01<02:25, 6.06MB/s]Downloading pytorch_model.bin:   2%|█▋                                                                     | 21.0M/892M [00:02<01:28, 9.86MB/s]Downloading pytorch_model.bin:   4%|██▌                                                                    | 31.5M/892M [00:02<01:10, 12.2MB/s]Downloading pytorch_model.bin:   5%|███▎                                                                   | 41.9M/892M [00:03<01:02, 13.7MB/s]Downloading pytorch_model.bin:   6%|████▏                                                                  | 52.4M/892M [00:04<00:56, 14.8MB/s]Downloading pytorch_model.bin:   7%|█████                                                                  | 62.9M/892M [00:04<00:53, 15.4MB/s]Downloading pytorch_model.bin:   8%|█████▊                                                                 | 73.4M/892M [00:05<00:51, 16.0MB/s]Downloading pytorch_model.bin:   9%|██████▋                                                                | 83.9M/892M [00:06<00:49, 16.2MB/s]Downloading pytorch_model.bin:  11%|███████▌                                                               | 94.4M/892M [00:06<00:48, 16.4MB/s]Downloading pytorch_model.bin:  12%|████████▍                                                               | 105M/892M [00:07<00:46, 16.8MB/s]Downloading pytorch_model.bin:  13%|█████████▎                                                              | 115M/892M [00:07<00:47, 16.5MB/s]Downloading pytorch_model.bin:  14%|██████████▏                                                             | 126M/892M [00:08<00:45, 16.7MB/s]Downloading pytorch_model.bin:  15%|███████████                                                             | 136M/892M [00:09<00:45, 16.6MB/s]Downloading pytorch_model.bin:  16%|███████████▊                                                            | 147M/892M [00:10<00:51, 14.3MB/s]Downloading pytorch_model.bin:  18%|████████████▋                                                           | 157M/892M [00:10<00:50, 14.6MB/s]Downloading pytorch_model.bin:  19%|█████████████▌                                                          | 168M/892M [00:11<00:46, 15.5MB/s]Downloading pytorch_model.bin:  20%|██████████████▍                                                         | 178M/892M [00:12<00:45, 15.6MB/s]Downloading pytorch_model.bin:  21%|███████████████▏                                                        | 189M/892M [00:12<00:43, 16.1MB/s]Downloading pytorch_model.bin:  22%|████████████████                                                        | 199M/892M [00:13<00:42, 16.3MB/s]Downloading pytorch_model.bin:  24%|████████████████▉                                                       | 210M/892M [00:13<00:41, 16.6MB/s]Downloading pytorch_model.bin:  25%|█████████████████▊                                                      | 220M/892M [00:14<00:39, 16.8MB/s]Downloading pytorch_model.bin:  26%|██████████████████▋                                                     | 231M/892M [00:15<00:39, 16.9MB/s]Downloading pytorch_model.bin:  27%|███████████████████▍                                                    | 241M/892M [00:15<00:38, 16.8MB/s]Downloading pytorch_model.bin:  28%|████████████████████▎                                                   | 252M/892M [00:16<00:37, 17.0MB/s]Downloading pytorch_model.bin:  29%|█████████████████████▏                                                  | 262M/892M [00:16<00:36, 17.0MB/s]Downloading pytorch_model.bin:  31%|██████████████████████                                                  | 273M/892M [00:17<00:36, 17.0MB/s]Downloading pytorch_model.bin:  32%|██████████████████████▊                                                 | 283M/892M [00:18<00:36, 16.7MB/s]Downloading pytorch_model.bin:  33%|███████████████████████▋                                                | 294M/892M [00:18<00:35, 16.9MB/s]Downloading pytorch_model.bin:  34%|████████████████████████▌                                               | 304M/892M [00:19<00:34, 16.9MB/s]Downloading pytorch_model.bin:  35%|█████████████████████████▍                                              | 315M/892M [00:20<00:33, 17.1MB/s]Downloading pytorch_model.bin:  36%|██████████████████████████▏                                             | 325M/892M [00:20<00:33, 16.8MB/s]Downloading pytorch_model.bin:  38%|███████████████████████████                                             | 336M/892M [00:21<00:32, 17.1MB/s]Downloading pytorch_model.bin:  39%|███████████████████████████▉                                            | 346M/892M [00:21<00:32, 17.0MB/s]Downloading pytorch_model.bin:  40%|████████████████████████████▊                                           | 357M/892M [00:22<00:31, 17.1MB/s]Downloading pytorch_model.bin:  41%|█████████████████████████████▋                                          | 367M/892M [00:23<00:31, 16.8MB/s]Downloading pytorch_model.bin:  42%|██████████████████████████████▍                                         | 377M/892M [00:24<00:37, 13.8MB/s]Downloading pytorch_model.bin:  44%|███████████████████████████████▎                                        | 388M/892M [00:24<00:33, 15.0MB/s]Downloading pytorch_model.bin:  45%|████████████████████████████████▏                                       | 398M/892M [00:25<00:32, 15.3MB/s]Downloading pytorch_model.bin:  46%|█████████████████████████████████                                       | 409M/892M [00:26<00:30, 15.6MB/s]Downloading pytorch_model.bin:  47%|█████████████████████████████████▊                                      | 419M/892M [00:26<00:29, 16.0MB/s]Downloading pytorch_model.bin:  48%|██████████████████████████████████▋                                     | 430M/892M [00:27<00:33, 13.8MB/s]Downloading pytorch_model.bin:  49%|███████████████████████████████████▌                                    | 440M/892M [00:30<00:56, 8.05MB/s]Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 444, in _error_catcher
    yield
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 567, in read
    data = self._fp_read(amt) if not fp_closed else b""
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 533, in _fp_read
    return self._fp.read(amt) if amt is not None else self._fp.read()
  File "/root/miniconda3/envs/py38/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/root/miniconda3/envs/py38/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/root/miniconda3/envs/py38/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/root/miniconda3/envs/py38/lib/python3.8/ssl.py", line 1274, in recv_into
    return self.read(nbytes, buffer)
  File "/root/miniconda3/envs/py38/lib/python3.8/ssl.py", line 1132, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 628, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 593, in read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/root/miniconda3/envs/py38/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 449, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.")
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./f00511_generate_response.py", line 49, in <module>
    test_generate_response()
  File "./f00511_generate_response.py", line 42, in test_generate_response
    response = generate_response(instruction, knowledge, dialog)
  File "./f00511_generate_response.py", line 24, in generate_response
    model = AutoModelForSeq2SeqLM.from_pretrained('microsoft/GODEL-v1_1-base-seq2seq')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2793, in from_pretrained
    resolved_archive_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1429, in hf_hub_download
    http_get(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 551, in http_get
    for chunk in r.iter_content(chunk_size=10 * 1024 * 1024):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 822, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.
Downloading pytorch_model.bin:  49%|███████████████████████████████████▌                                    | 440M/892M [00:46<00:47, 9.51MB/s]