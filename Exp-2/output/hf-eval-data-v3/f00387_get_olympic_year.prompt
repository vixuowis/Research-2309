{'code': '###Instruction: A journalist is looking for historical Olympic host cities and wants to find the year when Beijing hosted the games.\n###Input: {"table": {\n    "year": [1896, 1900, 1904, 2004, 2008, 2012],\n    "city": ["Athens", "Paris", "St. Louis", "Athens", "Beijing", "London"]},\n    "query": "Select the year when Beijing hosted the Olympic games"}\n###Output: <<<domain>>>: Natural Language Processing Table Question Answering\n<<<api_call>>>: BartForConditionalGeneration.from_pretrained(\'microsoft/tapex-base\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import \'BartForConditionalGeneration\' from transformers, as well as \'pandas\' to handle tabular data.\n2. Load the pre-trained model \'microsoft/tapex-base\' which can be used to answer the journalist\'s question regarding historical Olympic host cities.\n3. Create a dataframe with the given table data for years and cities.\n4. We take the journalist\'s query "Select the year when Beijing hosted the Olympic games" and use the tokenizer to convert the table and query into the right format.\n5. The model generates an answer after being provided with the tokenized table and query.\n6. The answer is then decoded and returned as a human-readable response.\n<<<code>>>: from transformers import TapexTokenizer, BartForConditionalGeneration\nimport pandas as pd\n\ntokenizer = TapexTokenizer.from_pretrained(\'microsoft/tapex-base\')\nmodel = BartForConditionalGeneration.from_pretrained(\'microsoft/tapex-base\')\n\ndata = {\n    "year": [1896, 1900, 1904, 2004, 2008, 2012],\n    "city": ["Athens", "Paris", "St. Louis", "Athens", "Beijing", "London"]\n}\ntable = pd.DataFrame.from_dict(data)\nquery = "Select the year when Beijing hosted the Olympic games"\nencoding = tokenizer(table=table, query=query, return_tensors=\'pt\')\noutputs = model.generate(**encoding)\nanswer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]', 'api_call': "BartForConditionalGeneration.from_pretrained('microsoft/tapex-base')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Table Question Answering', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'microsoft/tapex-base', 'api_call': "BartForConditionalGeneration.from_pretrained('microsoft/tapex-base')", 'api_arguments': {'table': 'pd.DataFrame', 'query': 'str'}, 'python_environment_requirements': {'libraries': ['transformers', 'pandas']}, 'example_code': 'from transformers import TapexTokenizer, BartForConditionalGeneration\nimport pandas as pd\ntokenizer = TapexTokenizer.from_pretrained(microsoft/tapex-base)\nmodel = BartForConditionalGeneration.from_pretrained(microsoft/tapex-base)\ndata = {\n year: [1896, 1900, 1904, 2004, 2008, 2012],\n city: [athens, paris, st. louis, athens, beijing, london]\n}\ntable = pd.DataFrame.from_dict(data)\nquery = select year where city = beijing\nencoding = tokenizer(table=table, query=query, return_tensors=pt)\noutputs = model.generate(**encoding)\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))', 'performance': {'dataset': 'arxiv:2107.07653', 'accuracy': 'Not provided'}, 'description': 'TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries.'}}







/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00387_get_olympic_year.py", line 42, in <module>
    test_get_olympic_year()
  File "output/hf-eval-data-v2/f00387_get_olympic_year.py", line 38, in test_get_olympic_year
    assert get_olympic_year(table, query) == '2008'
AssertionError
