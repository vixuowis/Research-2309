{'code': "###Instruction: A product manager needs an explanation related to model conversion. They are confused why it is important. Can you please help them by providing an answer?\n\n###Input: \n{\n 'question': 'Why is model conversion important?',\n 'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n}\n\n###Output: Model conversion is important because it gives freedom to the user and allows people to easily switch between different frameworks.", 'api_call': "pipeline('question-answering', model=AutoModel.from_pretrained('deepset/bert-large-uncased-whole-word-masking-squad2'), tokenizer=AutoTokenizer.from_pretrained('deepset/bert-large-uncased-whole-word-masking-squad2'))", 'provider': 'Transformers', 'api_data': {'domain': 'Natural Language Processing Question Answering', 'framework': 'Transformers', 'functionality': 'Question Answering', 'api_name': 'bert-large-uncased-whole-word-masking-squad2', 'api_call': "pipeline('question-answering', model=AutoModel.from_pretrained('deepset/bert-large-uncased-whole-word-masking-squad2'), tokenizer=AutoTokenizer.from_pretrained('deepset/bert-large-uncased-whole-word-masking-squad2'))", 'api_arguments': {'model_name': 'deepset/bert-large-uncased-whole-word-masking-squad2', 'tokenizer': 'deepset/bert-large-uncased-whole-word-masking-squad2'}, 'python_environment_requirements': ['transformers'], 'example_code': "QA_input = {\n 'question': 'Why is model conversion important?',\n 'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n}\nres = nlp(QA_input)", 'performance': {'dataset': 'squad_v2', 'accuracy': {'Exact Match': 80.885, 'F1': 83.876}}, 'description': 'This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language.'}}

