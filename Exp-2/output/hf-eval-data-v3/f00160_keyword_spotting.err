Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/1.93k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 1.93k/1.93k [00:00<00:00, 218kB/s]
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/378M [00:00<?, ?B/s]Downloading pytorch_model.bin:   6%|███▉                                                                    | 21.0M/378M [00:00<00:02, 148MB/s]Downloading pytorch_model.bin:  14%|█████████▉                                                              | 52.4M/378M [00:00<00:01, 203MB/s]Downloading pytorch_model.bin:  22%|███████████████▉                                                        | 83.9M/378M [00:00<00:01, 218MB/s]Downloading pytorch_model.bin:  30%|██████████████████████▎                                                  | 115M/378M [00:00<00:01, 235MB/s]Downloading pytorch_model.bin:  39%|████████████████████████████▎                                            | 147M/378M [00:00<00:00, 243MB/s]Downloading pytorch_model.bin:  47%|██████████████████████████████████▍                                      | 178M/378M [00:00<00:00, 251MB/s]Downloading pytorch_model.bin:  55%|████████████████████████████████████████▍                                | 210M/378M [00:00<00:00, 252MB/s]Downloading pytorch_model.bin:  64%|██████████████████████████████████████████████▌                          | 241M/378M [00:01<00:00, 250MB/s]Downloading pytorch_model.bin:  72%|████████████████████████████████████████████████████▌                    | 273M/378M [00:01<00:00, 244MB/s]Downloading pytorch_model.bin:  80%|██████████████████████████████████████████████████████████▋              | 304M/378M [00:01<00:00, 243MB/s]Downloading pytorch_model.bin:  89%|████████████████████████████████████████████████████████████████▋        | 336M/378M [00:01<00:00, 241MB/s]Downloading pytorch_model.bin:  97%|██████████████████████████████████████████████████████████████████████▊  | 367M/378M [00:01<00:00, 247MB/s]Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████| 378M/378M [00:01<00:00, 239MB/s]
Some weights of the model checkpoint at superb/hubert-base-superb-ks were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at superb/hubert-base-superb-ks and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Downloading (…)rocessor_config.json:   0%|                                                                           | 0.00/213 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|█████████████████████████████████████████████████████████████████████| 213/213 [00:00<00:00, 115kB/s]
Some weights of the model checkpoint at superb/hubert-base-superb-ks were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']
- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at superb/hubert-base-superb-ks and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
