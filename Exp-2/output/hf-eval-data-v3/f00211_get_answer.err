Downloading (…)okenizer_config.json:   0%|                                                                          | 0.00/26.0 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████████████████████████████████████████████████████████████| 26.0/26.0 [00:00<00:00, 3.24kB/s]
Downloading (…)lve/main/config.json:   0%|                                                                           | 0.00/757 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████| 757/757 [00:00<00:00, 69.0kB/s]
Downloading (…)olve/main/vocab.json:   0%|                                                                          | 0.00/798k [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|███████████████████████████████████████████████████████████████████| 798k/798k [00:01<00:00, 682kB/s]Downloading (…)olve/main/vocab.json: 100%|███████████████████████████████████████████████████████████████████| 798k/798k [00:01<00:00, 681kB/s]
Downloading (…)olve/main/merges.txt:   0%|                                                                          | 0.00/456k [00:00<?, ?B/s]Downloading (…)olve/main/merges.txt: 100%|██████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 2.15MB/s]Downloading (…)olve/main/merges.txt: 100%|██████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 2.13MB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                           | 0.00/150 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 87.3kB/s]
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/595M [00:00<?, ?B/s]Downloading pytorch_model.bin:   4%|██▌                                                                     | 21.0M/595M [00:00<00:03, 168MB/s]Downloading pytorch_model.bin:   9%|██████▎                                                                 | 52.4M/595M [00:00<00:02, 207MB/s]Downloading pytorch_model.bin:  14%|██████████▏                                                             | 83.9M/595M [00:00<00:02, 209MB/s]Downloading pytorch_model.bin:  19%|██████████████▏                                                          | 115M/595M [00:00<00:02, 216MB/s]Downloading pytorch_model.bin:  25%|██████████████████                                                       | 147M/595M [00:00<00:02, 221MB/s]Downloading pytorch_model.bin:  30%|█████████████████████▉                                                   | 178M/595M [00:00<00:01, 233MB/s]Downloading pytorch_model.bin:  35%|█████████████████████████▋                                               | 210M/595M [00:00<00:01, 242MB/s]Downloading pytorch_model.bin:  41%|█████████████████████████████▌                                           | 241M/595M [00:01<00:01, 241MB/s]Downloading pytorch_model.bin:  46%|█████████████████████████████████▍                                       | 273M/595M [00:01<00:01, 237MB/s]Downloading pytorch_model.bin:  51%|█████████████████████████████████████▎                                   | 304M/595M [00:01<00:01, 238MB/s]Downloading pytorch_model.bin:  56%|█████████████████████████████████████████▏                               | 336M/595M [00:01<00:01, 245MB/s]Downloading pytorch_model.bin:  62%|█████████████████████████████████████████████                            | 367M/595M [00:01<00:00, 250MB/s]Downloading pytorch_model.bin:  67%|████████████████████████████████████████████████▉                        | 398M/595M [00:01<00:00, 245MB/s]Downloading pytorch_model.bin:  72%|████████████████████████████████████████████████████▊                    | 430M/595M [00:01<00:00, 240MB/s]Downloading pytorch_model.bin:  78%|████████████████████████████████████████████████████████▋                | 461M/595M [00:01<00:00, 238MB/s]Downloading pytorch_model.bin:  83%|████████████████████████████████████████████████████████████▍            | 493M/595M [00:02<00:00, 238MB/s]Downloading pytorch_model.bin:  88%|████████████████████████████████████████████████████████████████▎        | 524M/595M [00:02<00:00, 243MB/s]Downloading pytorch_model.bin:  93%|████████████████████████████████████████████████████████████████████▏    | 556M/595M [00:02<00:00, 247MB/s]Downloading pytorch_model.bin:  99%|████████████████████████████████████████████████████████████████████████ | 587M/595M [00:02<00:00, 245MB/s]Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████| 595M/595M [00:02<00:00, 237MB/s]
Some weights of the model checkpoint at valhalla/longformer-base-4096-finetuned-squadv1 were not used when initializing LongformerForQuestionAnswering: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']
- This IS expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Traceback (most recent call last):
  File "./f00211_get_answer.py", line 49, in <module>
    test_get_answer()
  File "./f00211_get_answer.py", line 38, in test_get_answer
    assert get_answer(question, text) == 'democratized NLP'
  File "./f00211_get_answer.py", line 26, in get_answer
    answer_tokens = all_tokens[torch.argmax(start_scores) :torch.argmax(end_scores)+1]
TypeError: argmax(): argument 'input' (position 1) must be Tensor, not str
