2023-11-12 03:39:24.745338: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 03:39:24.788129: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 03:39:25.405844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/2.28k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 2.28k/2.28k [00:00<00:00, 174kB/s]
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Downloading pytorch_model.bin:   0%|                                                                               | 0.00/1.27G [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|▌                                                                     | 10.5M/1.27G [00:01<03:31, 5.94MB/s]Downloading pytorch_model.bin:   2%|█▏                                                                    | 21.0M/1.27G [00:02<02:08, 9.73MB/s]Downloading pytorch_model.bin:   2%|█▋                                                                    | 31.5M/1.27G [00:02<01:42, 12.0MB/s]Downloading pytorch_model.bin:   3%|██▎                                                                   | 41.9M/1.27G [00:03<01:40, 12.2MB/s]Downloading pytorch_model.bin:   4%|██▉                                                                   | 52.4M/1.27G [00:07<03:40, 5.50MB/s]Downloading pytorch_model.bin:   5%|███▍                                                                  | 62.9M/1.27G [00:12<05:18, 3.78MB/s]Downloading pytorch_model.bin:   6%|████                                                                  | 73.4M/1.27G [00:14<04:49, 4.11MB/s]Downloading pytorch_model.bin:   7%|████▋                                                                 | 83.9M/1.27G [00:15<03:52, 5.09MB/s]Downloading pytorch_model.bin:   7%|█████▏                                                                | 94.4M/1.27G [00:15<03:04, 6.35MB/s]Downloading pytorch_model.bin:   8%|█████▉                                                                 | 105M/1.27G [00:16<02:29, 7.77MB/s]Downloading pytorch_model.bin:   9%|██████▍                                                                | 115M/1.27G [00:17<02:05, 9.17MB/s]Downloading pytorch_model.bin:  10%|███████                                                                | 126M/1.27G [00:17<01:51, 10.3MB/s]Downloading pytorch_model.bin:  11%|███████▋                                                               | 136M/1.27G [00:18<01:37, 11.6MB/s]Downloading pytorch_model.bin:  12%|████████▏                                                              | 147M/1.27G [00:21<02:52, 6.49MB/s]Downloading pytorch_model.bin:  12%|████████▊                                                              | 157M/1.27G [00:31<07:05, 2.60MB/s]Downloading pytorch_model.bin:  13%|█████████▍                                                             | 168M/1.27G [00:44<11:46, 1.55MB/s]Downloading pytorch_model.bin:  14%|█████████▉                                                             | 178M/1.27G [00:49<10:48, 1.68MB/s]Downloading pytorch_model.bin:  15%|██████████▌                                                            | 189M/1.27G [01:04<15:09, 1.18MB/s]Downloading pytorch_model.bin:  15%|██████████▌                                                            | 189M/1.27G [01:15<15:09, 1.18MB/s]Downloading pytorch_model.bin:  16%|███████████▎                                                            | 199M/1.27G [01:53<35:38, 499kB/s]Downloading pytorch_model.bin:  16%|███████████▎                                                            | 199M/1.27G [02:05<35:38, 499kB/s]Downloading pytorch_model.bin:  17%|███████████▉                                                            | 210M/1.27G [02:35<45:25, 388kB/s]Downloading pytorch_model.bin:  17%|███████████▉                                                            | 210M/1.27G [02:45<45:25, 388kB/s]Downloading pytorch_model.bin:  17%|████████████▏                                                         | 220M/1.27G [03:52<1:10:12, 248kB/s]Downloading pytorch_model.bin:  17%|████████████▏                                                         | 220M/1.27G [04:05<1:10:12, 248kB/s]Downloading pytorch_model.bin:  18%|████████████▊                                                         | 231M/1.27G [04:41<1:12:35, 238kB/s]Downloading pytorch_model.bin:  18%|████████████▊                                                         | 231M/1.27G [04:55<1:12:35, 238kB/s]Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 444, in _error_catcher
    yield
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 567, in read
    data = self._fp_read(amt) if not fp_closed else b""
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 533, in _fp_read
    return self._fp.read(amt) if amt is not None else self._fp.read()
  File "/root/miniconda3/envs/py38/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/root/miniconda3/envs/py38/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/root/miniconda3/envs/py38/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/root/miniconda3/envs/py38/lib/python3.8/ssl.py", line 1274, in recv_into
    return self.read(nbytes, buffer)
  File "/root/miniconda3/envs/py38/lib/python3.8/ssl.py", line 1132, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 628, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 593, in read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/root/miniconda3/envs/py38/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 449, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.")
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./f00534_analyze_emotion.py", line 44, in <module>
    test_analyze_emotion()
  File "./f00534_analyze_emotion.py", line 37, in test_analyze_emotion
    emotion = analyze_emotion(test_audio_path)
  File "./f00534_analyze_emotion.py", line 21, in analyze_emotion
    model = Wav2Vec2ForCTC.from_pretrained('ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2793, in from_pretrained
    resolved_archive_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1429, in hf_hub_download
    http_get(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 551, in http_get
    for chunk in r.iter_content(chunk_size=10 * 1024 * 1024):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 822, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.
Downloading pytorch_model.bin:  18%|█████████████                                                           | 231M/1.27G [05:06<22:55, 753kB/s]