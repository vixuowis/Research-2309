{'code': '###Instruction: Locate specific information from an invoice image, such as total amount due, invoice number, and due date.\n###Output: <<<domain>>>: Multimodal Document Question Answer\n<<<api_call>>>: AutoModelForDocumentQuestionAnswering.from_pretrained(\'L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. We import the necessary classes from the transformers library provided by Hugging Face, including AutoModelForDocumentQuestionAnswering.\n2. Use the from_pretrained method to load the pre-trained model \'L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023\'. This model is designed to answer questions from images containing text and layout information.\n3. Convert the invoice image to a text-based format that the model can process, including information about the layout and position of the text elements.\n4. Use the model to extract the desired information from the invoice by asking questions like "What is the total amount due?", "What is the invoice number?", and "What is the due date?".\n<<<code>>>: from transformers import AutoModelForDocumentQuestionAnswering\nimage = \'invoice_image.jpg\' # replace with path to your invoice image\nmodel = AutoModelForDocumentQuestionAnswering.from_pretrained(\'L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023\')\ninputs, layout = preprocess_image(image) # a custom function to preprocess the image \nquestions = [\'What is the total amount due?\', \'What is the invoice number?\', \'What is the due date?\']\nanswers = []\nfor question in questions:\n    answer = model(inputs, layout, question)\n    answers.append(answer)\n', 'api_call': "AutoModelForDocumentQuestionAnswering.from_pretrained('L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Multimodal Document Question Answer', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023', 'api_call': "AutoModelForDocumentQuestionAnswering.from_pretrained('L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023')", 'api_arguments': {}, 'python_environment_requirements': {'transformers': '>=4.11.0'}, 'example_code': {}, 'performance': {'dataset': {}, 'accuracy': {}}, 'description': 'A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information.'}}

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py", line 261, in hf_raise_for_status
    response.raise_for_status()
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1344, in hf_hub_download
    raise head_call_error
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1230, in hf_hub_download
    metadata = get_hf_file_metadata(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1606, in get_hf_file_metadata
    hf_raise_for_status(r)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py", line 293, in hf_raise_for_status
    raise RepositoryNotFoundError(message, response) from e
huggingface_hub.utils._errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-654da581-087e76872b64e2a11c7aa440;7863e2b9-fa05-42fa-97aa-b9982ed64684)

Repository Not Found for url: https://huggingface.co/L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023/resolve/main/config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00559_extract_invoice_info.py", line 42, in <module>
    test_extract_invoice_info()
  File "output/hf-eval-data-v2/f00559_extract_invoice_info.py", line 33, in test_extract_invoice_info
    answers = extract_invoice_info(image_path)
  File "output/hf-eval-data-v2/f00559_extract_invoice_info.py", line 17, in extract_invoice_info
    model = AutoModelForDocumentQuestionAnswering.from_pretrained('L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 494, in from_pretrained
    resolved_config_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 450, in cached_file
    raise EnvironmentError(
OSError: L-oenai/LayoutLMX_pt_question_answer_ocrazure_correct_V15_30_03_2023 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
