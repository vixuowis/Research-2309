2023-11-12 02:53:47.834722: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 02:53:47.895433: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 02:53:48.769475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/1.38k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 1.38k/1.38k [00:00<00:00, 121kB/s]
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/343M [00:00<?, ?B/s]Downloading pytorch_model.bin:   3%|██▏                                                                    | 10.5M/343M [00:08<04:33, 1.22MB/s]Downloading pytorch_model.bin:   6%|████▎                                                                  | 21.0M/343M [00:11<02:48, 1.92MB/s]Downloading pytorch_model.bin:   9%|██████▌                                                                | 31.5M/343M [00:14<01:59, 2.60MB/s]Downloading pytorch_model.bin:  12%|████████▋                                                              | 41.9M/343M [00:15<01:20, 3.73MB/s]Downloading pytorch_model.bin:  15%|██████████▊                                                            | 52.4M/343M [00:16<01:01, 4.74MB/s]Downloading pytorch_model.bin:  18%|█████████████                                                          | 62.9M/343M [00:17<00:47, 5.89MB/s]Downloading pytorch_model.bin:  21%|███████████████▏                                                       | 73.4M/343M [00:18<00:39, 6.89MB/s]Downloading pytorch_model.bin:  24%|█████████████████▎                                                     | 83.9M/343M [00:19<00:34, 7.46MB/s]Downloading pytorch_model.bin:  28%|███████████████████▌                                                   | 94.4M/343M [00:20<00:33, 7.46MB/s]Downloading pytorch_model.bin:  31%|██████████████████████                                                  | 105M/343M [00:21<00:27, 8.57MB/s]Downloading pytorch_model.bin:  34%|████████████████████████▏                                               | 115M/343M [00:22<00:27, 8.37MB/s]Downloading pytorch_model.bin:  37%|██████████████████████████▍                                             | 126M/343M [00:25<00:31, 6.91MB/s]Downloading pytorch_model.bin:  40%|████████████████████████████▌                                           | 136M/343M [00:27<00:37, 5.54MB/s]Downloading pytorch_model.bin:  40%|████████████████████████████▌                                           | 136M/343M [00:47<00:37, 5.54MB/s]Downloading pytorch_model.bin:  43%|███████████████████████████████▏                                         | 147M/343M [01:10<04:24, 742kB/s]Downloading pytorch_model.bin:  46%|█████████████████████████████████▍                                       | 157M/343M [01:20<03:48, 813kB/s]Downloading pytorch_model.bin:  49%|███████████████████████████████████▏                                    | 168M/343M [01:25<02:54, 1.00MB/s]Downloading pytorch_model.bin:  52%|█████████████████████████████████████▍                                  | 178M/343M [01:26<02:02, 1.35MB/s]Downloading pytorch_model.bin:  55%|███████████████████████████████████████▋                                | 189M/343M [01:27<01:25, 1.81MB/s]Downloading pytorch_model.bin:  58%|█████████████████████████████████████████▊                              | 199M/343M [01:28<00:59, 2.42MB/s]Downloading pytorch_model.bin:  61%|████████████████████████████████████████████                            | 210M/343M [01:32<00:53, 2.47MB/s]Downloading pytorch_model.bin:  64%|██████████████████████████████████████████████▏                         | 220M/343M [01:34<00:39, 3.10MB/s]Downloading pytorch_model.bin:  67%|████████████████████████████████████████████████▍                       | 231M/343M [01:34<00:27, 4.03MB/s]Downloading pytorch_model.bin:  70%|██████████████████████████████████████████████████▋                     | 241M/343M [01:35<00:19, 5.21MB/s]Downloading pytorch_model.bin:  73%|████████████████████████████████████████████████████▊                   | 252M/343M [01:36<00:14, 6.50MB/s]Downloading pytorch_model.bin:  76%|███████████████████████████████████████████████████████                 | 262M/343M [01:36<00:10, 7.82MB/s]Downloading pytorch_model.bin:  79%|█████████████████████████████████████████████████████████▏              | 273M/343M [01:38<00:08, 8.14MB/s]Downloading pytorch_model.bin:  83%|███████████████████████████████████████████████████████████▍            | 283M/343M [01:38<00:06, 9.19MB/s]Downloading pytorch_model.bin:  86%|█████████████████████████████████████████████████████████████▋          | 294M/343M [01:40<00:05, 8.70MB/s]Downloading pytorch_model.bin:  89%|███████████████████████████████████████████████████████████████▊        | 304M/343M [01:40<00:03, 10.1MB/s]Downloading pytorch_model.bin:  92%|██████████████████████████████████████████████████████████████████      | 315M/343M [01:41<00:02, 11.5MB/s]Downloading pytorch_model.bin:  95%|████████████████████████████████████████████████████████████████████▏   | 325M/343M [01:42<00:01, 12.5MB/s]Downloading pytorch_model.bin:  98%|██████████████████████████████████████████████████████████████████████▍ | 336M/343M [01:42<00:00, 12.6MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████| 343M/343M [01:43<00:00, 13.2MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████| 343M/343M [01:43<00:00, 3.31MB/s]
Downloading (…)neration_config.json:   0%|                                                                           | 0.00/293 [00:00<?, ?B/s]Downloading (…)neration_config.json: 100%|████████████████████████████████████████████████████████████████████| 293/293 [00:00<00:00, 26.4kB/s]
Downloading (…)okenizer_config.json:   0%|                                                                          | 0.00/42.0 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████████████████████████████████████████████████████████████| 42.0/42.0 [00:00<00:00, 17.7kB/s]
Downloading (…)olve/main/source.spm:   0%|                                                                          | 0.00/789k [00:00<?, ?B/s]Downloading (…)olve/main/source.spm: 100%|███████████████████████████████████████████████████████████████████| 789k/789k [00:00<00:00, 970kB/s]Downloading (…)olve/main/source.spm: 100%|███████████████████████████████████████████████████████████████████| 789k/789k [00:00<00:00, 968kB/s]
Downloading (…)olve/main/target.spm:   0%|                                                                          | 0.00/814k [00:00<?, ?B/s]Downloading (…)olve/main/target.spm: 100%|██████████████████████████████████████████████████████████████████| 814k/814k [00:00<00:00, 2.71MB/s]Downloading (…)olve/main/target.spm: 100%|██████████████████████████████████████████████████████████████████| 814k/814k [00:00<00:00, 2.69MB/s]
Downloading (…)olve/main/vocab.json:   0%|                                                                         | 0.00/2.35M [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|████████████████████████████████████████████████████████████████| 2.35M/2.35M [00:00<00:00, 9.28MB/s]Downloading (…)olve/main/vocab.json: 100%|████████████████████████████████████████████████████████████████| 2.35M/2.35M [00:00<00:00, 9.18MB/s]
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.
  warnings.warn("Recommended: pip install sacremoses.")
Token indices sequence length is longer than the specified maximum sequence length for this model (500002 > 512). Running this sequence through the model will result in indexing errors
Your input_length: 500002 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)
Traceback (most recent call last):
  File "./f00504_translate_english_to_italian.py", line 58, in <module>
    test_translate_english_to_italian()
  File "./f00504_translate_english_to_italian.py", line 50, in test_translate_english_to_italian
    translate_english_to_italian(large_text)
  File "./f00504_translate_english_to_italian.py", line 25, in translate_english_to_italian
    italian_text = translator(text)[0]['translation_text']
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/text2text_generation.py", line 367, in __call__
    return super().__call__(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/text2text_generation.py", line 165, in __call__
    result = super().__call__(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1140, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1147, in run_single
    model_outputs = self.forward(model_inputs, **forward_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1046, in forward
    model_outputs = self._forward(model_inputs, **forward_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/text2text_generation.py", line 187, in _forward
    output_ids = self.model.generate(**model_inputs, **generate_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/generation/utils.py", line 1492, in generate
    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/generation/utils.py", line 661, in _prepare_encoder_decoder_kwargs_for_generation
    model_kwargs["encoder_outputs"]: ModelOutput = encoder(**encoder_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/marian/modeling_marian.py", line 759, in forward
    embed_pos = self.embed_positions(input_shape)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/marian/modeling_marian.py", line 140, in forward
    return super().forward(positions)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 162, in forward
    return F.embedding(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py", line 2233, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
IndexError: index out of range in self
