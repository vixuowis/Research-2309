2023-11-12 06:33:16.148174: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 06:33:16.192505: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 06:33:16.859693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/2.05k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 2.05k/2.05k [00:00<00:00, 152kB/s]
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Downloading pytorch_model.bin:   0%|                                                                               | 0.00/94.6k [00:00<?, ?B/s]Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████| 94.6k/94.6k [00:00<00:00, 298kB/s]Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████| 94.6k/94.6k [00:00<00:00, 297kB/s]
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at anton-l/wav2vec2-random-tiny-classifier and are newly initialized: ['lm_head.bias', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
