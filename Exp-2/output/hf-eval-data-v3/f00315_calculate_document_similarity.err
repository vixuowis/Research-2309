Downloading (…)c49cd/.gitattributes:   0%|                                                                           | 0.00/968 [00:00<?, ?B/s]Downloading (…)c49cd/.gitattributes: 100%|████████████████████████████████████████████████████████████████████| 968/968 [00:00<00:00, 81.5kB/s]
Downloading (…)_Pooling/config.json:   0%|                                                                           | 0.00/190 [00:00<?, ?B/s]Downloading (…)_Pooling/config.json: 100%|████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 16.8kB/s]
Downloading (…)fc6f7c49cd/README.md:   0%|                                                                         | 0.00/4.09k [00:00<?, ?B/s]Downloading (…)fc6f7c49cd/README.md: 100%|████████████████████████████████████████████████████████████████| 4.09k/4.09k [00:00<00:00, 2.32MB/s]
Downloading (…)6f7c49cd/config.json:   0%|                                                                           | 0.00/645 [00:00<?, ?B/s]Downloading (…)6f7c49cd/config.json: 100%|█████████████████████████████████████████████████████████████████████| 645/645 [00:00<00:00, 360kB/s]
Downloading (…)ce_transformers.json:   0%|                                                                           | 0.00/122 [00:00<?, ?B/s]Downloading (…)ce_transformers.json: 100%|████████████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 67.2kB/s]
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/471M [00:00<?, ?B/s]Downloading pytorch_model.bin:   2%|█▌                                                                     | 10.5M/471M [00:05<04:21, 1.76MB/s]Downloading pytorch_model.bin:   4%|███▏                                                                   | 21.0M/471M [00:10<03:45, 1.99MB/s]Downloading pytorch_model.bin:   7%|████▋                                                                  | 31.5M/471M [00:17<04:09, 1.76MB/s]Downloading pytorch_model.bin:   7%|████▋                                                                  | 31.5M/471M [00:35<04:09, 1.76MB/s]Downloading pytorch_model.bin:   9%|██████▍                                                                 | 41.9M/471M [00:38<07:58, 896kB/s]Downloading pytorch_model.bin:  11%|████████                                                                | 52.4M/471M [00:52<08:21, 834kB/s]Downloading pytorch_model.bin:  11%|████████                                                                | 52.4M/471M [01:05<08:21, 834kB/s]Downloading pytorch_model.bin:  13%|█████████▌                                                              | 62.9M/471M [01:06<08:33, 795kB/s]Downloading pytorch_model.bin:  16%|███████████▏                                                            | 73.4M/471M [01:20<08:34, 772kB/s]Downloading pytorch_model.bin:  18%|████████████▊                                                           | 83.9M/471M [01:34<08:19, 774kB/s]Downloading pytorch_model.bin:  20%|██████████████▍                                                         | 94.4M/471M [01:43<07:21, 853kB/s]Downloading pytorch_model.bin:  22%|████████████████▎                                                        | 105M/471M [01:53<06:38, 917kB/s]Downloading pytorch_model.bin:  25%|█████████████████▉                                                       | 115M/471M [02:02<05:59, 989kB/s]Downloading pytorch_model.bin:  25%|█████████████████▉                                                       | 115M/471M [02:15<05:59, 989kB/s]Downloading pytorch_model.bin:  27%|███████████████████▌                                                     | 126M/471M [02:20<07:06, 808kB/s]Downloading pytorch_model.bin:  27%|███████████████████▌                                                     | 126M/471M [02:35<07:06, 808kB/s]Downloading pytorch_model.bin:  29%|█████████████████████▏                                                   | 136M/471M [03:02<11:34, 482kB/s]Downloading pytorch_model.bin:  29%|█████████████████████▏                                                   | 136M/471M [03:15<11:34, 482kB/s]Downloading pytorch_model.bin:  31%|██████████████████████▊                                                  | 147M/471M [03:39<13:30, 400kB/s]Downloading pytorch_model.bin:  31%|██████████████████████▊                                                  | 147M/471M [03:55<13:30, 400kB/s]Downloading pytorch_model.bin:  33%|████████████████████████▍                                                | 157M/471M [04:08<13:30, 387kB/s]Downloading pytorch_model.bin:  36%|██████████████████████████                                               | 168M/471M [04:21<11:02, 457kB/s]Downloading pytorch_model.bin:  36%|██████████████████████████                                               | 168M/471M [04:35<11:02, 457kB/s]Downloading pytorch_model.bin:  38%|███████████████████████████▋                                             | 178M/471M [04:36<09:31, 511kB/s]Downloading pytorch_model.bin:  40%|█████████████████████████████▎                                           | 189M/471M [04:51<08:29, 553kB/s]Downloading pytorch_model.bin:  42%|██████████████████████████████▉                                          | 199M/471M [05:02<07:06, 637kB/s]Downloading pytorch_model.bin:  45%|████████████████████████████████▌                                        | 210M/471M [05:11<05:53, 739kB/s]Downloading pytorch_model.bin:  47%|██████████████████████████████████▏                                      | 220M/471M [05:23<05:26, 768kB/s]Downloading pytorch_model.bin:  47%|██████████████████████████████████▏                                      | 220M/471M [05:35<05:26, 768kB/s]Downloading pytorch_model.bin:  49%|███████████████████████████████████▊                                     | 231M/471M [05:37<05:15, 762kB/s]Downloading pytorch_model.bin:  51%|█████████████████████████████████████▍                                   | 241M/471M [05:50<04:54, 781kB/s]Downloading pytorch_model.bin:  51%|█████████████████████████████████████▍                                   | 241M/471M [06:05<04:54, 781kB/s]Downloading pytorch_model.bin:  53%|███████████████████████████████████████                                  | 252M/471M [07:01<10:42, 341kB/s]Downloading pytorch_model.bin:  53%|███████████████████████████████████████                                  | 252M/471M [07:15<10:42, 341kB/s]Downloading pytorch_model.bin:  55%|████████████████████████████████████████▎                                | 260M/471M [07:57<13:31, 259kB/s]Downloading pytorch_model.bin:  55%|████████████████████████████████████████▎                                | 260M/471M [07:57<06:25, 545kB/s]
Downloading (…)nce_bert_config.json:   0%|                                                                          | 0.00/53.0 [00:00<?, ?B/s]Downloading (…)nce_bert_config.json: 100%|██████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 10.0kB/s]
Downloading (…)tencepiece.bpe.model:   0%|                                                                         | 0.00/5.07M [00:00<?, ?B/s]Downloading (…)tencepiece.bpe.model: 100%|████████████████████████████████████████████████████████████████| 5.07M/5.07M [00:04<00:00, 1.07MB/s]Downloading (…)tencepiece.bpe.model: 100%|████████████████████████████████████████████████████████████████| 5.07M/5.07M [00:04<00:00, 1.07MB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                           | 0.00/239 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 149kB/s]
Downloading tokenizer.json:   0%|                                                                                  | 0.00/9.08M [00:00<?, ?B/s]Downloading tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████| 9.08M/9.08M [00:01<00:00, 8.39MB/s]Downloading tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████| 9.08M/9.08M [00:01<00:00, 8.35MB/s]
Downloading (…)okenizer_config.json:   0%|                                                                           | 0.00/480 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████| 480/480 [00:00<00:00, 385kB/s]
Downloading unigram.json:   0%|                                                                                    | 0.00/14.8M [00:00<?, ?B/s]Downloading unigram.json:  71%|█████████████████████████████████████████████████████▎                     | 10.5M/14.8M [00:00<00:00, 15.2MB/s]Downloading unigram.json: 100%|███████████████████████████████████████████████████████████████████████████| 14.8M/14.8M [00:01<00:00, 14.0MB/s]Downloading unigram.json: 100%|███████████████████████████████████████████████████████████████████████████| 14.8M/14.8M [00:01<00:00, 14.2MB/s]
Downloading (…)f7c49cd/modules.json:   0%|                                                                           | 0.00/229 [00:00<?, ?B/s]Downloading (…)f7c49cd/modules.json: 100%|████████████████████████████████████████████████████████████████████| 229/229 [00:00<00:00, 20.5kB/s]
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 488, in load_state_dict
    return torch.load(checkpoint_file, map_location=map_location)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py", line 993, in load
    with _open_zipfile_reader(opened_file) as opened_zipfile:
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py", line 447, in __init__
    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))
RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 492, in load_state_dict
    if f.read(7) == "version":
  File "/root/miniconda3/envs/py38/lib/python3.8/codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./f00315_calculate_document_similarity.py", line 36, in <module>
    test_calculate_document_similarity()
  File "./f00315_calculate_document_similarity.py", line 27, in test_calculate_document_similarity
    similarity_matrix = calculate_document_similarity(documents)
  File "./f00315_calculate_document_similarity.py", line 18, in calculate_document_similarity
    model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py", line 95, in __init__
    modules = self._load_sbert_model(model_path)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py", line 840, in _load_sbert_model
    module = module_class.load(os.path.join(model_path, module_config['path']))
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py", line 137, in load
    return Transformer(model_name_or_path=input_path, **config)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py", line 29, in __init__
    self._load_model(model_name_or_path, config, cache_dir)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py", line 49, in _load_model
    self.auto_model = AutoModel.from_pretrained(model_name_or_path, config=config, cache_dir=cache_dir)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2883, in from_pretrained
    state_dict = load_state_dict(resolved_archive_file)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 504, in load_state_dict
    raise OSError(
OSError: Unable to load weights from pytorch checkpoint file for '/root/.cache/torch/sentence_transformers/sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2/pytorch_model.bin' at '/root/.cache/torch/sentence_transformers/sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2/pytorch_model.bin'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True.
