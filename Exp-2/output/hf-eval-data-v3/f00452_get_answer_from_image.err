2023-11-12 00:36:56.489782: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 00:36:56.534249: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 00:36:57.154490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)rocessor_config.json:   0%|                                                                           | 0.00/432 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|████████████████████████████████████████████████████████████████████| 432/432 [00:00<00:00, 37.2kB/s]
Downloading (…)okenizer_config.json:   0%|                                                                           | 0.00/904 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████████████████████████| 904/904 [00:00<00:00, 75.0kB/s]
Downloading (…)/main/tokenizer.json:   0%|                                                                         | 0.00/2.11M [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████████████████████████████| 2.11M/2.11M [00:02<00:00, 1.00MB/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████████████████████████████| 2.11M/2.11M [00:02<00:00, 1.00MB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                           | 0.00/548 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████████| 548/548 [00:00<00:00, 231kB/s]
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. 
The class this function is called from is 'BertTokenizerFast'.
Traceback (most recent call last):
  File "./f00452_get_answer_from_image.py", line 43, in <module>
    test_get_answer_from_image()
  File "./f00452_get_answer_from_image.py", line 36, in test_get_answer_from_image
    assert get_answer_from_image('https://placekitten.com/200/300', 'What color is the cat?') == 'The cat is brown.'
  File "./f00452_get_answer_from_image.py", line 22, in get_answer_from_image
    processor = BlipProcessor.from_pretrained('Salesforce/blip2-opt-2.7b')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/processing_utils.py", line 226, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/processing_utils.py", line 270, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 1854, in from_pretrained
    return cls._from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2017, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/bert/tokenization_bert_fast.py", line 235, in __init__
    normalizer_state = json.loads(self.backend_tokenizer.normalizer.__getstate__())
AttributeError: 'NoneType' object has no attribute '__getstate__'
