{'code': "###Instruction: We are developing an application for Japanese language learners. We need to extract text from Japanese manga pages for our users.\n###Output: <<<domain>>>: Multimodal Image-to-Text\n<<<api_call>>>: pipeline('ocr', model='kha-white/manga-ocr-base')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the pipeline function from the transformers package provided by Hugging Face.\n2. We use the pipeline function to create an OCR model specifically designed for Japanese text and manga by specifying the model 'kha-white/manga-ocr-base'.\n3. This model has been trained on a large corpus of Japanese manga and is designed to extract text accurately from manga pages, even in cases where the text is overlaid on images or in unusual font styles.\n4. The created OCR pipeline can be used to process images of manga pages and extract the Japanese text contained within them.\n<<<code>>>: from transformers import pipeline\nocr_pipeline = pipeline('ocr', model='kha-white/manga-ocr-base')\nmanga_image = 'path/to/your/manga_page.jpg'  # Replace this with the path to your manga page image\nextracted_text = ocr_pipeline(manga_image)\n", 'api_call': "pipeline('ocr', model='kha-white/manga-ocr-base')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Multimodal Image-to-Text', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'kha-white/manga-ocr-base', 'api_call': "pipeline('ocr', model='kha-white/manga-ocr-base')", 'api_arguments': 'image', 'python_environment_requirements': 'transformers', 'example_code': '', 'performance': {'dataset': 'manga109s', 'accuracy': ''}, 'description': 'Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images.'}}

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00551_extract_text_from_manga.py", line 43, in <module>
    test_extract_text_from_manga()
  File "output/hf-eval-data-v2/f00551_extract_text_from_manga.py", line 38, in test_extract_text_from_manga
    result = extract_text_from_manga(test_image_path)
  File "output/hf-eval-data-v2/f00551_extract_text_from_manga.py", line 20, in extract_text_from_manga
    ocr_pipeline = pipeline('ocr', model='kha-white/manga-ocr-base')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 780, in pipeline
    normalized_task, targeted_task, task_options = check_task(task)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 499, in check_task
    return PIPELINE_REGISTRY.check_task(task)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1215, in check_task
    raise KeyError(
KeyError: "Unknown task ocr, available tasks are ['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']"
