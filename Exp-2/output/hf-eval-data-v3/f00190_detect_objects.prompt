{'code': "###Instruction: Our delivery drones need to detect and avoid obstacles while flying. Develop a solution for them to detect objects in their path.\n###Output: <<<domain>>>: Computer Vision Object Detection\n<<<api_call>>>: YolosForObjectDetection.from_pretrained('hustvl/yolos-small')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. We first import the necessary classes from the transformers and PIL packages. This includes YolosForObjectDetection for the object detection model and Image for processing image data.\n2. We then use the from_pretrained method of the YolosForObjectDetection class to load the pre-trained model 'hustvl/yolos-small'. This model has been fine-tuned on the COCO 2017 object detection dataset and is suitable for detecting obstacles in the drone's path.\n3. We load the image data from the drone's camera.\n4. This model can then be used to analyze an image and identify the various objects in it, enabling the drone to detect and avoid obstacles while flying.\n<<<code>>>: from transformers import YolosForObjectDetection\nfrom PIL import Image\nimage = Image.open('image_path.jpg')\n# replace 'image_path.jpg' with path to your image\nmodel = YolosForObjectDetection.from_pretrained('hustvl/yolos-small')\ninputs = feature_extractor(images=image, return_tensors='pt')\noutputs = model(**inputs)\n", 'api_call': "YolosForObjectDetection.from_pretrained('hustvl/yolos-small')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Computer Vision Object Detection', 'framework': 'Hugging Face Transformers', 'functionality': 'Object Detection', 'api_name': 'hustvl/yolos-small', 'api_call': "YolosForObjectDetection.from_pretrained('hustvl/yolos-small')", 'api_arguments': {'model_name': 'hustvl/yolos-small'}, 'python_environment_requirements': {'packages': ['transformers', 'PIL', 'requests']}, 'example_code': {'import': ['from transformers import YolosFeatureExtractor, YolosForObjectDetection', 'from PIL import Image', 'import requests'], 'url': 'http://images.cocodataset.org/val2017/000000039769.jpg', 'image': 'Image.open(requests.get(url, stream=True).raw)', 'feature_extractor': "YolosFeatureExtractor.from_pretrained('hustvl/yolos-small')", 'model': "YolosForObjectDetection.from_pretrained('hustvl/yolos-small')", 'inputs': "feature_extractor(images=image, return_tensors='pt')", 'outputs': 'model(**inputs)', 'logits': 'outputs.logits', 'bboxes': 'outputs.pred_boxes'}, 'performance': {'dataset': 'COCO 2017 validation', 'accuracy': '36.1 AP'}, 'description': 'YOLOS model fine-tuned on COCO 2017 object detection (118k annotated images). It was introduced in the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Fang et al. and first released in this repository. YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN).'}}




/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/yolos/feature_extraction_yolos.py:28: FutureWarning: The class YolosFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use YolosImageProcessor instead.
  warnings.warn(
The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.
