{'code': '###Instruction: I am a financial analyst, and I receive report after report filled with charts helping to explain trends and data in my field. However, I also need to have this information in tabular format. Please help me extract a linearized table from this chart.\n###Output: <<<domain>>>: Multimodal Image-to-Text\n<<<api_call>>>: Pix2StructForConditionalGeneration.from_pretrained(\'google/deplot\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. We will import the necessary classes from the transformers library, which include Pix2StructForConditionalGeneration and Pix2StructProcessor. We also need the \'requests\' library for downloading images and \'Image\' from PIL for image handling.\n2. We\'ll then load the pre-trained model \'google/deplot\' using the from_pretrained method of Pix2StructForConditionalGeneration. The model is used for translating images of plots or charts into linearized tables.\n3. We will also load the processor using the from_pretrained method of Pix2StructProcessor.\n4. We will open the image file that contains the chart, and use the processor to convert the image into the required format.\n5. The model will then process the image and generate the underlying data table as a linearized text.\n<<<code>>>: from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\nimport requests\nfrom PIL import Image\n\nmodel = Pix2StructForConditionalGeneration.from_pretrained(\'google/deplot\')\nprocessor = Pix2StructProcessor.from_pretrained(\'google/deplot\')\n\nchart_url = "https://example.com/chart_image.png"\nimage = Image.open(requests.get(chart_url, stream=True).raw)\n\ninputs = processor(images=image, text="Generate underlying data table of the figure below:", return_tensors=\'pt\')\npredictions = model.generate(**inputs, max_new_tokens=512)\n\ntable = processor.decode(predictions[0], skip_special_tokens=True)\n', 'api_call': "Pix2StructForConditionalGeneration.from_pretrained('google/deplot')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Multimodal Image-to-Text', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'google/deplot', 'api_call': "Pix2StructForConditionalGeneration.from_pretrained('google/deplot')", 'api_arguments': {'images': 'image', 'text': 'question', 'return_tensors': 'pt', 'max_new_tokens': 512}, 'python_environment_requirements': {'transformers': 'Pix2StructForConditionalGeneration, Pix2StructProcessor', 'requests': 'requests', 'PIL': 'Image'}, 'example_code': "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\nimport requests\nfrom PIL import Image\nmodel = Pix2StructForConditionalGeneration.from_pretrained('google/deplot')\nprocessor = Pix2StructProcessor.from_pretrained('google/deplot')\nurl = https://raw.githubusercontent.com/vis-nlp/ChartQA/main/ChartQA%20Dataset/val/png/5090.png\nimage = Image.open(requests.get(url, stream=True).raw)\ninputs = processor(images=image, text=Generate underlying data table of the figure below:, return_tensors=pt)\npredictions = model.generate(**inputs, max_new_tokens=512)\nprint(processor.decode(predictions[0], skip_special_tokens=True))", 'performance': {'dataset': 'ChartQA', 'accuracy': '24.0% improvement over finetuned SOTA'}, 'description': 'DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs.'}}



  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 710, in _error_catcher
    yield
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 835, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
urllib3.exceptions.IncompleteRead: IncompleteRead(683637375 bytes read, 445540601 more expected)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 940, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 911, in read
    data = self._raw_read(amt)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 835, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/root/miniconda3/envs/py38/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 727, in _error_catcher
    raise ProtocolError(f"Connection broken: {e!r}", e) from e
urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(683637375 bytes read, 445540601 more expected)', IncompleteRead(683637375 bytes read, 445540601 more expected))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00008_extract_table_from_chart.py", line 42, in <module>
    test_extract_table_from_chart()
  File "output/hf-eval-data-v2/f00008_extract_table_from_chart.py", line 37, in test_extract_table_from_chart
    result = extract_table_from_chart(chart_url)
  File "output/hf-eval-data-v2/f00008_extract_table_from_chart.py", line 19, in extract_table_from_chart
    model = Pix2StructForConditionalGeneration.from_pretrained('google/deplot')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2773, in from_pretrained
    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1429, in hf_hub_download
    http_get(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 551, in http_get
    for chunk in r.iter_content(chunk_size=10 * 1024 * 1024):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 818, in generate
    raise ChunkedEncodingError(e)
requests.exceptions.ChunkedEncodingError: ('Connection broken: IncompleteRead(683637375 bytes read, 445540601 more expected)', IncompleteRead(683637375 bytes read, 445540601 more expected))

