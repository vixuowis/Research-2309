2023-11-12 04:09:26.706223: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 04:09:26.767596: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 04:09:27.732629: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)lve/main/config.json:   0%|                                                                           | 0.00/956 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████| 956/956 [00:00<00:00, 85.9kB/s]
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/245M [00:00<?, ?B/s]Downloading pytorch_model.bin:   4%|███                                                                    | 10.5M/245M [00:01<00:41, 5.72MB/s]Downloading pytorch_model.bin:   9%|██████                                                                 | 21.0M/245M [00:02<00:23, 9.34MB/s]Downloading pytorch_model.bin:  13%|█████████                                                              | 31.5M/245M [00:03<00:18, 11.8MB/s]Downloading pytorch_model.bin:  17%|████████████▏                                                          | 41.9M/245M [00:03<00:14, 13.7MB/s]Downloading pytorch_model.bin:  21%|███████████████▏                                                       | 52.4M/245M [00:04<00:13, 14.4MB/s]Downloading pytorch_model.bin:  26%|██████████████████▏                                                    | 62.9M/245M [00:04<00:12, 15.2MB/s]Downloading pytorch_model.bin:  30%|█████████████████████▎                                                 | 73.4M/245M [00:05<00:10, 15.7MB/s]Downloading pytorch_model.bin:  34%|████████████████████████▎                                              | 83.9M/245M [00:06<00:09, 16.2MB/s]Downloading pytorch_model.bin:  38%|███████████████████████████▎                                           | 94.4M/245M [00:06<00:09, 16.5MB/s]Downloading pytorch_model.bin:  43%|██████████████████████████████▊                                         | 105M/245M [00:07<00:08, 16.8MB/s]Downloading pytorch_model.bin:  47%|█████████████████████████████████▊                                      | 115M/245M [00:08<00:07, 16.6MB/s]Downloading pytorch_model.bin:  51%|████████████████████████████████████▉                                   | 126M/245M [00:08<00:07, 16.3MB/s]Downloading pytorch_model.bin:  56%|████████████████████████████████████████                                | 136M/245M [00:09<00:08, 13.6MB/s]Downloading pytorch_model.bin:  60%|███████████████████████████████████████████                             | 147M/245M [00:13<00:15, 6.51MB/s]Downloading pytorch_model.bin:  60%|███████████████████████████████████████████                             | 147M/245M [00:27<00:15, 6.51MB/s]Downloading pytorch_model.bin:  64%|██████████████████████████████████████████████▊                          | 157M/245M [01:33<03:32, 413kB/s]Downloading pytorch_model.bin:  68%|█████████████████████████████████████████████████▉                       | 168M/245M [01:35<02:14, 575kB/s]Downloading pytorch_model.bin:  73%|█████████████████████████████████████████████████████                    | 178M/245M [01:36<01:23, 801kB/s]Downloading pytorch_model.bin:  77%|███████████████████████████████████████████████████████▍                | 189M/245M [01:37<00:50, 1.12MB/s]Downloading pytorch_model.bin:  81%|██████████████████████████████████████████████████████████▍             | 199M/245M [01:37<00:29, 1.55MB/s]Downloading pytorch_model.bin:  86%|█████████████████████████████████████████████████████████████▌          | 210M/245M [01:38<00:16, 2.13MB/s]Downloading pytorch_model.bin:  90%|████████████████████████████████████████████████████████████████▋       | 220M/245M [01:39<00:08, 2.88MB/s]Downloading pytorch_model.bin:  94%|███████████████████████████████████████████████████████████████████▋    | 231M/245M [01:39<00:03, 3.82MB/s]Downloading pytorch_model.bin:  98%|██████████████████████████████████████████████████████████████████████▊ | 241M/245M [01:40<00:00, 4.96MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████| 245M/245M [01:40<00:00, 5.48MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████| 245M/245M [01:40<00:00, 2.43MB/s]
Downloading (…)rocessor_config.json:   0%|                                                                           | 0.00/135 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|████████████████████████████████████████████████████████████████████| 135/135 [00:00<00:00, 57.3kB/s]
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Traceback (most recent call last):
  File "./f00561_estimate_depth.py", line 36, in <module>
    test_estimate_depth()
  File "./f00561_estimate_depth.py", line 29, in test_estimate_depth
    depth_map = estimate_depth(sample_image)
  File "./f00561_estimate_depth.py", line 19, in estimate_depth
    depth_map = depth_model(image)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/depth_estimation.py", line 85, in __call__
    return super().__call__(images, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1140, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1146, in run_single
    model_inputs = self.preprocess(inputs, **preprocess_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/depth_estimation.py", line 94, in preprocess
    image = load_image(image, timeout)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/image_utils.py", line 317, in load_image
    raise ValueError(
ValueError: Incorrect format used for image. Should be an url linking to an image, a base64 string, a local path, or a PIL image.
