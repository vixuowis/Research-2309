{'code': "###Instruction: A kid's educational toy company is including a voice assistant that recognizes simple voice commands from children. They need an example on how to recognize spoken digits.\n###Output: <<<domain>>>: Audio Audio Classification\n<<<api_call>>>: pipeline('audio-classification', model='MIT/ast-finetuned-speech-commands-v2')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the required pipeline function from the transformers library provided by Hugging Face.\n2. Define the classifier by specifying the 'audio-classification' pipeline and the pre-trained 'MIT/ast-finetuned-speech-commands-v2' model.\n3. The classifier can now be used to analyze spoken digit audio samples and classify them into appropriate digits.\n4. The provided audio files should be in the expected format for the audio classification pipeline to work efficiently.\n<<<code>>>: from transformers import pipeline\nspoken_digit_classifier = pipeline('audio-classification', model='MIT/ast-finetuned-speech-commands-v2')\ndigit_prediction = spoken_digit_classifier(audio_sample_path)\n", 'api_call': "pipeline('audio-classification', model= 'MIT/ast-finetuned-speech-commands-v2')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Audio Audio Classification', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'mazkooleg/0-9up-ast-ft', 'api_call': "pipeline('audio-classification', model= 'MIT/ast-finetuned-speech-commands-v2')", 'api_arguments': '', 'python_environment_requirements': 'Transformers 4.26.1, Pytorch 1.11.0+cpu, Datasets 2.10.0, Tokenizers 0.12.1', 'example_code': '', 'performance': {'dataset': 'mazkooleg/0-9up_google_speech_commands_augmented_raw', 'accuracy': 0.9979}, 'description': 'This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979'}}

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00716_classify_spoken_digit.py", line 35, in <module>
    test_classify_spoken_digit()
  File "output/hf-eval-data-v2/f00716_classify_spoken_digit.py", line 28, in test_classify_spoken_digit
    prediction = classify_spoken_digit(sample_audio_path)
  File "output/hf-eval-data-v2/f00716_classify_spoken_digit.py", line 17, in classify_spoken_digit
    spoken_digit_classifier = pipeline('audio-classification', model='MIT/ast-finetuned-speech-commands-v2')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 729, in pipeline
    maybe_adapter_path = find_adapter_config_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/peft_utils.py", line 87, in find_adapter_config_file
    adapter_cached_filename = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1193, in hf_hub_download
    os.makedirs(storage_folder, exist_ok=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/os.py", line 223, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/root/autodl-tmp/.cache/huggingface/hub/models--MIT--ast-finetuned-speech-commands-v2'
