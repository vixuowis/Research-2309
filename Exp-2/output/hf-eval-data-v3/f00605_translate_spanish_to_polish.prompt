{'code': "###Instruction: We need a solution for creating Polish subtitles for YouTube videos in Spanish. The AI should provide the translation.\n###Output: <<<domain>>>: Natural Language Processing Translation\n<<<api_call>>>: MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n<<<api_provider>>>: Hugging Face\n<<<explanation>>>: 1. We first import the necessary classes from the transformers library provided by Hugging Face. These include MBartForConditionalGeneration for the translation model and MBart50TokenizerFast for tokenizing the text.\n2. We then use the from_pretrained method of the MBartForConditionalGeneration class to load the pre-trained model 'facebook/mbart-large-50-many-to-many-mmt'. This model has been trained to translate text between any pair of 50 languages, including Spanish to Polish.\n3. We create an MBart50TokenizerFast instance and set its source language to Spanish (es_ES) and tokenize the Spanish text (e.g., YouTube video transcript).\n4. The model is then used to generate translated text (Polish subtitles) by setting the forced_bos_token_id to Polish (pl_PL).\n5. Finally, we decode the generated tokens into a human-readable string (Polish subtitles).\n<<<code>>>: from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\nmodel = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\ntokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\ntokenizer.src_lang = 'es_ES'\nencoded_spanish = tokenizer(spanish_text, return_tensors='pt')\ngenerated_tokens = model.generate(**encoded_spanish, forced_bos_token_id=tokenizer.lang_code_to_id['pl_PL'])\npolish_subtitles = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n", 'api_call': "MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')", 'provider': 'Hugging Face', 'api_data': {'domain': 'Natural Language Processing Translation', 'framework': 'Hugging Face', 'functionality': 'Text2Text Generation', 'api_name': 'facebook/mbart-large-50-many-to-many-mmt', 'api_call': "MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')", 'api_arguments': {'pretrained_model_name_or_path': 'facebook/mbart-large-50-many-to-many-mmt'}, 'python_environment_requirements': {'transformers': '4.0.0'}, 'example_code': 'from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\narticle_hi model = MBartForConditionalGeneration.from_pretrained(facebook/mbart-large-50-many-to-many-mmt)\ntokenizer = MBart50TokenizerFast.from_pretrained(facebook/mbart-large-50-many-to-many-mmt)\ntokenizer.src_lang = hi_IN\nencoded_hi = tokenizer(article_hi, return_tensors=pt)\ngenerated_tokens = model.generate(\n **encoded_hi,\n forced_bos_token_id=tokenizer.lang_code_to_id[fr_XX]\n)\ntokenizer.batch_decode(generated_tokens, skip_special_tokens=True)', 'performance': {'dataset': 'Multilingual Translation', 'accuracy': 'Not specified'}, 'description': 'mBART-50 many-to-many multilingual machine translation model can translate directly between any pair of 50 languages. It was introduced in the Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper.'}}

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00605_translate_spanish_to_polish.py", line 37, in <module>
    test_translate_spanish_to_polish()
  File "output/hf-eval-data-v2/f00605_translate_spanish_to_polish.py", line 32, in test_translate_spanish_to_polish
    polish_text = translate_spanish_to_polish(spanish_text)
  File "output/hf-eval-data-v2/f00605_translate_spanish_to_polish.py", line 17, in translate_spanish_to_polish
    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2377, in from_pretrained
    resolved_config_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1193, in hf_hub_download
    os.makedirs(storage_folder, exist_ok=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/os.py", line 223, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/root/autodl-tmp/.cache/huggingface/hub/models--facebook--mbart-large-50-many-to-many-mmt'
