Downloading (…)lve/main/config.json:   0%|                                                                                     | 0.00/1.32k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████████████████| 1.32k/1.32k [00:00<00:00, 124kB/s]
Downloading pytorch_model.bin:   0%|                                                                                            | 0.00/892M [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|▉                                                                                  | 10.5M/892M [00:00<00:10, 84.4MB/s]Downloading pytorch_model.bin:   4%|██▉                                                                                 | 31.5M/892M [00:00<00:06, 139MB/s]Downloading pytorch_model.bin:   6%|████▉                                                                               | 52.4M/892M [00:00<00:05, 164MB/s]Downloading pytorch_model.bin:   8%|██████▉                                                                             | 73.4M/892M [00:00<00:04, 165MB/s]Downloading pytorch_model.bin:  11%|████████▉                                                                           | 94.4M/892M [00:00<00:04, 162MB/s]Downloading pytorch_model.bin:  13%|██████████▉                                                                          | 115M/892M [00:00<00:04, 164MB/s]Downloading pytorch_model.bin:  15%|████████████▉                                                                        | 136M/892M [00:00<00:04, 165MB/s]Downloading pytorch_model.bin:  18%|██████████████▉                                                                      | 157M/892M [00:00<00:04, 166MB/s]Downloading pytorch_model.bin:  20%|████████████████▉                                                                    | 178M/892M [00:01<00:04, 177MB/s]Downloading pytorch_model.bin:  22%|██████████████████▉                                                                  | 199M/892M [00:01<00:03, 182MB/s]Downloading pytorch_model.bin:  25%|████████████████████▉                                                                | 220M/892M [00:01<00:03, 184MB/s]Downloading pytorch_model.bin:  27%|██████████████████████▉                                                              | 241M/892M [00:01<00:03, 185MB/s]Downloading pytorch_model.bin:  29%|████████████████████████▉                                                            | 262M/892M [00:01<00:03, 185MB/s]Downloading pytorch_model.bin:  32%|██████████████████████████▉                                                          | 283M/892M [00:01<00:03, 186MB/s]Downloading pytorch_model.bin:  34%|████████████████████████████▉                                                        | 304M/892M [00:01<00:03, 186MB/s]Downloading pytorch_model.bin:  36%|██████████████████████████████▉                                                      | 325M/892M [00:01<00:03, 188MB/s]Downloading pytorch_model.bin:  39%|████████████████████████████████▉                                                    | 346M/892M [00:01<00:02, 190MB/s]Downloading pytorch_model.bin:  41%|██████████████████████████████████▉                                                  | 367M/892M [00:02<00:02, 188MB/s]Downloading pytorch_model.bin:  44%|████████████████████████████████████▉                                                | 388M/892M [00:02<00:02, 185MB/s]Downloading pytorch_model.bin:  46%|██████████████████████████████████████▉                                              | 409M/892M [00:02<00:02, 182MB/s]Downloading pytorch_model.bin:  48%|████████████████████████████████████████▉                                            | 430M/892M [00:02<00:02, 174MB/s]Downloading pytorch_model.bin:  51%|██████████████████████████████████████████▉                                          | 451M/892M [00:02<00:02, 168MB/s]Downloading pytorch_model.bin:  53%|████████████████████████████████████████████▉                                        | 472M/892M [00:02<00:02, 175MB/s]Downloading pytorch_model.bin:  55%|██████████████████████████████████████████████▉                                      | 493M/892M [00:02<00:02, 182MB/s]Downloading pytorch_model.bin:  58%|████████████████████████████████████████████████▉                                    | 514M/892M [00:02<00:02, 181MB/s]Downloading pytorch_model.bin:  60%|██████████████████████████████████████████████████▉                                  | 535M/892M [00:03<00:02, 171MB/s]Downloading pytorch_model.bin:  62%|████████████████████████████████████████████████████▉                                | 556M/892M [00:03<00:01, 172MB/s]Downloading pytorch_model.bin:  65%|██████████████████████████████████████████████████████▉                              | 577M/892M [00:03<00:01, 176MB/s]Downloading pytorch_model.bin:  67%|████████████████████████████████████████████████████████▉                            | 598M/892M [00:03<00:01, 176MB/s]Downloading pytorch_model.bin:  69%|██████████████████████████████████████████████████████████▉                          | 619M/892M [00:03<00:01, 176MB/s]Downloading pytorch_model.bin:  72%|████████████████████████████████████████████████████████████▉                        | 640M/892M [00:03<00:01, 174MB/s]Downloading pytorch_model.bin:  74%|██████████████████████████████████████████████████████████████▉                      | 661M/892M [00:03<00:01, 180MB/s]Downloading pytorch_model.bin:  76%|████████████████████████████████████████████████████████████████▉                    | 682M/892M [00:03<00:01, 184MB/s]Downloading pytorch_model.bin:  79%|██████████████████████████████████████████████████████████████████▉                  | 703M/892M [00:03<00:01, 186MB/s]Downloading pytorch_model.bin:  81%|████████████████████████████████████████████████████████████████████▉                | 724M/892M [00:04<00:00, 189MB/s]Downloading pytorch_model.bin:  83%|██████████████████████████████████████████████████████████████████████▉              | 744M/892M [00:04<00:00, 189MB/s]Downloading pytorch_model.bin:  86%|████████████████████████████████████████████████████████████████████████▉            | 765M/892M [00:04<00:00, 191MB/s]Downloading pytorch_model.bin:  88%|██████████████████████████████████████████████████████████████████████████▉          | 786M/892M [00:04<00:00, 185MB/s]Downloading pytorch_model.bin:  92%|█████████████████████████████████████████████████████████████████████████████▉       | 818M/892M [00:04<00:00, 194MB/s]Downloading pytorch_model.bin:  94%|███████████████████████████████████████████████████████████████████████████████▉     | 839M/892M [00:04<00:00, 193MB/s]Downloading pytorch_model.bin:  96%|█████████████████████████████████████████████████████████████████████████████████▉   | 860M/892M [00:04<00:00, 188MB/s]Downloading pytorch_model.bin:  99%|███████████████████████████████████████████████████████████████████████████████████▉ | 881M/892M [00:04<00:00, 185MB/s]Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████████████████| 892M/892M [00:04<00:00, 179MB/s]
Downloading (…)okenizer_config.json:   0%|                                                                                     | 0.00/1.89k [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████████████████████████████████| 1.89k/1.89k [00:00<00:00, 1.23MB/s]
Downloading spiece.model:   0%|                                                                                                 | 0.00/792k [00:00<?, ?B/s]Downloading spiece.model: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 792k/792k [00:00<00:00, 123MB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                                     | 0.00/1.79k [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████████████| 1.79k/1.79k [00:00<00:00, 1.12MB/s]
Downloading (…)/main/tokenizer.json:   0%|                                                                                     | 0.00/1.39M [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████| 1.39M/1.39M [00:00<00:00, 1.41MB/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████████████████████████████████████████████████████████| 1.39M/1.39M [00:00<00:00, 1.41MB/s]
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "./f00797_generate_questions.py", line 40, in <module>
    test_generate_questions()
  File "./f00797_generate_questions.py", line 34, in test_generate_questions
    assert 'Eiffel Tower' in questions
AssertionError
