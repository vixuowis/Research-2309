{'code': '###Instruction: The company needs to summarize articles for its news application. Provide guidelines to use PEGASUS for this purpose.\n###Output: <<<domain>>>: Natural Language Processing Summarization\n<<<api_call>>>: pipeline(\'summarization\', model=\'google/pegasus-large\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. First, install the "transformers" library provided by Hugging Face.\n2. Import the "pipeline" function from the transformers library.\n3. Create an instance of the PEGASUS summarizer by calling the pipeline function with \'summarization\' and model=\'google/pegasus-large\'.\n4. Use this summarizer instance on the articles\' text to obtain a summarized version of the content.\n5. Integrate the summarizer into your news application to provide condensed news articles to the users.\n<<<code>>>: from transformers import pipeline\nsummarizer = pipeline(\'summarization\', model=\'google/pegasus-large\')\nsummary = summarizer(article_text)', 'api_call': "pipeline('summarization', model='google/pegasus-large')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Summarization', 'framework': 'Hugging Face Transformers', 'functionality': 'Summarization', 'api_name': 'google/pegasus-large', 'api_call': "pipeline('summarization', model='google/pegasus-large')", 'api_arguments': 'text', 'python_environment_requirements': 'transformers', 'example_code': "from transformers import pipeline\nsummarizer = pipeline('summarization', model='google/pegasus-large')\nsummary = summarizer('your_text_here')", 'performance': {'dataset': [{'name': 'xsum', 'accuracy': '47.60/24.83/39.64'}, {'name': 'cnn_dailymail', 'accuracy': '44.16/21.56/41.30'}, {'name': 'newsroom', 'accuracy': '45.98/34.20/42.18'}, {'name': 'multi_news', 'accuracy': '47.65/18.75/24.95'}, {'name': 'gigaword', 'accuracy': '39.65/20.47/36.76'}, {'name': 'wikihow', 'accuracy': '46.39/22.12/38.41'}, {'name': 'reddit_tifu', 'accuracy': '27.99/9.81/22.94'}, {'name': 'big_patent', 'accuracy': '52.29/33.08/41.66'}, {'name': 'arxiv', 'accuracy': '44.21/16.95/25.67'}, {'name': 'pubmed', 'accuracy': '45.97/20.15/28.25'}, {'name': 'aeslc', 'accuracy': '37.68/21.25/36.51'}, {'name': 'billsum', 'accuracy': '59.67/41.58/47.59'}]}, 'description': 'google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks.'}}

