{'code': '###Instruction: Our customer wants to have this Chinese text "<Chinese_text>" read aloud as an audio file in female voice.\n\n###Input: "<Chinese_text>": "你好，欢迎来到数字世界。"\n\n###Output: <<<domain>>>: Audio Text-to-Speech\n<<<api_call>>>: load_model_ensemble_and_task_from_hf_hub(\'facebook/tts_transformer-zh-cv7_css10\', arg_overrides={\'vocoder\': \'hifigan\', \'fp16\': False})\n<<<api_provider>>>: Fairseq\n<<<explanation>>>: 1. Import the necessary libraries from fairseq package.\n2. Load the pre-trained model \'facebook/tts_transformer-zh-cv7_css10\' using the load_model_ensemble_and_task_from_hf_hub function from fairseq. This model is trained on the Chinese language, specifically Simplified Chinese.\n3. Configure the vocoder to be \'hifigan\' and disable FP16 by setting \'fp16\' to False.\n4. Create a generator using the configuration and \'TTSHubInterface.get_model_input()\' function.\n5. Provide the Chinese text as input to the model and generate an audio file in the form of a waveform and sample rate.\n6. Play the audio file using IPython.display.Audio.\n<<<code>>>: from fairseq.models.text_to_speech.hub_interface import TTSHubInterface\nfrom fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\nimport IPython.display as ipd\n\nmodels, cfg, task = load_model_ensemble_and_task_from_hf_hub(\n    \'facebook/tts_transformer-zh-cv7_css10\',\n    arg_overrides={\'vocoder\': \'hifigan\', \'fp16\': False}\n)\nmodel = models[0]\nTTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)\ngenerator = task.build_generator(model, cfg)\ntext = "你好，欢迎来到数字世界。"\nsample = TTSHubInterface.get_model_input(task, text)\nwav, rate = TTSHubInterface.get_prediction(task, model, generator, sample)\nipd.Audio(wav, rate=rate)', 'api_call': "load_model_ensemble_and_task_from_hf_hub('facebook/tts_transformer-zh-cv7_css10', arg_overrides={'vocoder': 'hifigan', 'fp16': False})", 'provider': 'Fairseq', 'api_data': {'domain': 'Audio Text-to-Speech', 'framework': 'Fairseq', 'functionality': 'Text-to-Speech', 'api_name': 'facebook/tts_transformer-zh-cv7_css10', 'api_call': "load_model_ensemble_and_task_from_hf_hub('facebook/tts_transformer-zh-cv7_css10', arg_overrides={'vocoder': 'hifigan', 'fp16': False})", 'api_arguments': {'task': 'task', 'model': 'model', 'generator': 'generator', 'sample': 'sample'}, 'python_environment_requirements': {'fairseq': 'latest'}, 'example_code': 'from fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\nfrom fairseq.models.text_to_speech.hub_interface import TTSHubInterface\nimport IPython.display as ipd\nmodels, cfg, task = load_model_ensemble_and_task_from_hf_hub(\n facebook/tts_transformer-zh-cv7_css10,\n arg_overrides={vocoder: hifigan, fp16: False}\n)\nmodel = models[0]\nTTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)\ngenerator = task.build_generator(model, cfg)\ntext = \nsample = TTSHubInterface.get_model_input(task, text)\nwav, rate = TTSHubInterface.get_prediction(task, model, generator, sample)\nipd.Audio(wav, rate=rate)', 'performance': {'dataset': 'common_voice', 'accuracy': 'Not provided'}, 'description': 'Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10.'}}

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00418_generate_audio_from_text.py", line 3, in <module>
    from fairseq.models.text_to_speech.hub_interface import TTSHubInterface
ModuleNotFoundError: No module named 'fairseq'
