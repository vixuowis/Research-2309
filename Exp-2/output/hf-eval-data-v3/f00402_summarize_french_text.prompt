{'code': '###Instruction: An editor wants to summarize his article in French.\n###Input: "Selon un rapport récent, les constructeurs automobiles prévoient d\'accélérer la production de voitures électriques et de réduire la production de voitures à moteur à combustion interne. Les constructeurs prévoient de consacrer davantage de ressources à la recherche et au développement de technologies pour améliorer l\'efficacité des batteries, réduire les coûts de production et étendre le réseau de recharge. Les gouvernements du monde entier continuent de soutenir l\'adoption de la mobilité électrique à travers des incitations financières et des objectifs ambitieux de réduction des émissions de CO2."\n###Output: <<<domain>>>: Natural Language Processing Summarization\n<<<api_call>>>: T5ForConditionalGeneration.from_pretrained(\'plguillou/t5-base-fr-sum-cnndm\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. To summarize the article in French, we will use the T5ForConditionalGeneration model from the Hugging Face Transformers library. Specifically, we\'ll use the \'plguillou/t5-base-fr-sum-cnndm\' model which is fine-tuned for French abstractive text summarization.\n2. Import the required classes from the transformers package, namely T5Tokenizer and T5ForConditionalGeneration.\n3. Load the pre-trained French summarization model and the corresponding tokenizer using the from_pretrained method.\n4. Tokenize the input article text using the T5Tokenizer.\n5. Generate the summary using the T5ForConditionalGeneration model and the tokenized input text.\n6. Decode the generated summary tokens to get the final summary text.\n<<<code>>>: from transformers import T5Tokenizer, T5ForConditionalGeneration\ntokenizer = T5Tokenizer.from_pretrained(\'plguillou/t5-base-fr-sum-cnndm\')\nmodel = T5ForConditionalGeneration.from_pretrained(\'plguillou/t5-base-fr-sum-cnndm\')\ninput_text = "summarize: Selon un rapport récent, les constructeurs automobiles prévoient..."\ninput_tokens = tokenizer.encode(input_text, return_tensors=\'pt\')\nsummary_ids = model.generate(input_tokens)\nsummary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n', 'api_call': "T5ForConditionalGeneration.from_pretrained('plguillou/t5-base-fr-sum-cnndm')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Summarization', 'framework': 'Hugging Face Transformers', 'functionality': 'Abstractive Text Summarization', 'api_name': 'plguillou/t5-base-fr-sum-cnndm', 'api_call': "T5ForConditionalGeneration.from_pretrained('plguillou/t5-base-fr-sum-cnndm')", 'api_arguments': {'input_text': 'summarize: ARTICLE'}, 'python_environment_requirements': {'transformers': 'from transformers import T5Tokenizer, T5ForConditionalGeneration'}, 'example_code': 'tokenizer = T5Tokenizer.from_pretrained(plguillou/t5-base-fr-sum-cnndm)\nmodel = T5ForConditionalGeneration.from_pretrained(plguillou/t5-base-fr-sum-cnndm)', 'performance': {'dataset': 'cnn_dailymail', 'ROUGE-1': 44.5252, 'ROUGE-2': 22.652, 'ROUGE-L': 29.8866}, 'description': 'This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization.'}}






You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565

