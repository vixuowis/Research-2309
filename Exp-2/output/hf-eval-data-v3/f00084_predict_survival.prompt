{'code': "###Instruction: Build a simple application to predict the survival status of passengers on the Titanic based on their age, gender, and passenger class.\n###Output: <<<domain>>>: Tabular Classification\n<<<api_call>>>: AutoModel.from_pretrained('harithapliyal/autotrain-tatanic-survival-51030121311')\n<<<api_provider>>>: Hugging Face\n<<<explanation>>>: 1. First, we import the required Python libraries including joblib, pandas, and the AutoModel class from Hugging Face's AutoTrain framework.\n2. We then load the pre-trained model 'harithapliyal/autotrain-tatanic-survival-51030121311' available in the Hugging Face Model Hub to get the classifier.\n3. Next, we preprocess the input data which should be in a CSV file containing columns such as 'age', 'gender', and 'passenger class', according to the expected features in the model.\n4. Finally, we call the predict method on the classifier with the input data to obtain survival status predictions for each passenger.\n<<<code>>>: import joblib\nimport pandas as pd\nfrom transformers import AutoModel\n\nmodel = AutoModel.from_pretrained('harithapliyal/autotrain-tatanic-survival-51030121311')\ndata = pd.read_csv('data.csv')\ndata = data[['age', 'gender', 'passenger_class']]  # Subset the data for the relevant features\npredictions = model.predict(data)\n", 'api_call': "AutoModel.from_pretrained('harithapliyal/autotrain-tatanic-survival-51030121311')", 'provider': 'Hugging Face', 'api_data': {'domain': 'Tabular Tabular Classification', 'framework': 'Hugging Face', 'functionality': 'Binary Classification', 'api_name': 'harithapliyal/autotrain-tatanic-survival-51030121311', 'api_call': "AutoModel.from_pretrained('harithapliyal/autotrain-tatanic-survival-51030121311')", 'api_arguments': ['data'], 'python_environment_requirements': ['joblib', 'pandas'], 'example_code': "import json\nimport joblib\nimport pandas as pd\nmodel = joblib.load('model.joblib')\nconfig = json.load(open('config.json'))\nfeatures = config['features']\ndata = pd.read_csv('data.csv')\ndata = data[features]\ndata.columns = ['feat_' + str(col) for col in data.columns]\npredictions = model.predict(data)", 'performance': {'dataset': 'harithapliyal/autotrain-data-tatanic-survival', 'accuracy': 0.872}, 'description': 'A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class.'}}


Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00084_predict_survival.py", line 39, in <module>
    test_predict_survival()
  File "output/hf-eval-data-v2/f00084_predict_survival.py", line 32, in test_predict_survival
    predictions = predict_survival(test_data_path)
  File "output/hf-eval-data-v2/f00084_predict_survival.py", line 19, in predict_survival
    model = AutoModel.from_pretrained('harithapliyal/autotrain-tatanic-survival-51030121311')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 527, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 1039, in from_pretrained
    config_class = CONFIG_MAPPING[config_dict["model_type"]]
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 734, in __getitem__
    raise KeyError(key)
KeyError: 'xgboost'
