{'code': "###Instruction: Build an AI model that can recognize the objects in a given image and draw a boundary around them.\n###Output: <<<domain>>>: Computer Vision Image Segmentation\n<<<api_call>>>: MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-tiny-coco')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import the required libraries such as MaskFormerFeatureExtractor, MaskFormerForInstanceSegmentation, Image, and requests.\n2. Instantiate the feature_extractor using MaskFormerFeatureExtractor.from_pretrained() method with 'facebook/maskformer-swin-tiny-coco' model as the pretrained model.\n3. Instantiate the model using MaskFormerForInstanceSegmentation.from_pretrained() method which is trained on COCO panoptic segmentation.\n4. The input image should be opened using the Image class from PIL and the Image.open() method.\n5. Next, we preprocess this image using the feature_extractor for the MaskFormer model.\n6. Pass the preprocessed image tensors into the model to get the object detection results and segmentation masks.\n7. The outputs contain class_queries_logits and masks_queries_logits, which can be processed using the feature_extractor.post_process_panoptic_segmentation() method.\n8. The post-processed output is a predicted panoptic map containing recognized objects and their boundaries.\n<<<code>>>: from transformers import MaskFormerFeatureExtractor, MaskFormerForInstanceSegmentation\nfrom PIL import Image\nimport requests\nfeature_extractor = MaskFormerFeatureExtractor.from_pretrained('facebook/maskformer-swin-tiny-coco')\nmodel = MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-tiny-coco')\nurl = 'http://images.cocodataset.org/val2017/000000039769.jpg'\nimage = Image.open(requests.get(url, stream=True).raw)\ninputs = feature_extractor(images=image, return_tensors='pt')\noutputs = model(**inputs)\nclass_queries_logits = outputs.class_queries_logits\nmasks_queries_logits = outputs.masks_queries_logits\nresult = feature_extractor.post_process_panoptic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\npredicted_panoptic_map = result['segmentation']", 'api_call': "MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-tiny-coco')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Computer Vision Image Segmentation', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'facebook/maskformer-swin-tiny-coco', 'api_call': "MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-tiny-coco')", 'api_arguments': ['image', 'return_tensors'], 'python_environment_requirements': ['transformers', 'PIL', 'requests'], 'example_code': "from transformers import MaskFormerFeatureExtractor, MaskFormerForInstanceSegmentation\nfrom PIL import Image\nimport requests\n\nfeature_extractor = MaskFormerFeatureExtractor.from_pretrained('facebook/maskformer-swin-tiny-coco')\nmodel = MaskFormerForInstanceSegmentation.from_pretrained('facebook/maskformer-swin-tiny-coco')\nurl = 'http://images.cocodataset.org/val2017/000000039769.jpg'\nimage = Image.open(requests.get(url, stream=True).raw)\ninputs = feature_extractor(images=image, return_tensors='pt')\noutputs = model(**inputs)\nclass_queries_logits = outputs.class_queries_logits\nmasks_queries_logits = outputs.masks_queries_logits\nresult = feature_extractor.post_process_panoptic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\npredicted_panoptic_map = result['segmentation']", 'performance': {'dataset': 'COCO panoptic segmentation', 'accuracy': 'Not provided'}, 'description': 'MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository.'}}

