Downloading (…)lve/main/config.json:   0%|                                                                           | 0.00/642 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████| 642/642 [00:00<00:00, 59.8kB/s]
Downloading pytorch_model.bin:   0%|                                                                                | 0.00/436M [00:00<?, ?B/s]Downloading pytorch_model.bin:   5%|███▍                                                                    | 21.0M/436M [00:00<00:02, 153MB/s]Downloading pytorch_model.bin:  10%|██████▉                                                                 | 41.9M/436M [00:00<00:02, 179MB/s]Downloading pytorch_model.bin:  14%|██████████▍                                                             | 62.9M/436M [00:00<00:02, 178MB/s]Downloading pytorch_model.bin:  19%|█████████████▊                                                          | 83.9M/436M [00:00<00:01, 183MB/s]Downloading pytorch_model.bin:  24%|█████████████████▌                                                       | 105M/436M [00:00<00:01, 189MB/s]Downloading pytorch_model.bin:  31%|██████████████████████▊                                                  | 136M/436M [00:00<00:01, 202MB/s]Downloading pytorch_model.bin:  39%|████████████████████████████                                             | 168M/436M [00:00<00:01, 203MB/s]Downloading pytorch_model.bin:  43%|███████████████████████████████▋                                         | 189M/436M [00:00<00:01, 197MB/s]Downloading pytorch_model.bin:  48%|███████████████████████████████████▏                                     | 210M/436M [00:01<00:01, 192MB/s]Downloading pytorch_model.bin:  53%|██████████████████████████████████████▋                                  | 231M/436M [00:01<00:01, 194MB/s]Downloading pytorch_model.bin:  58%|██████████████████████████████████████████▏                              | 252M/436M [00:01<00:00, 195MB/s]Downloading pytorch_model.bin:  63%|█████████████████████████████████████████████▋                           | 273M/436M [00:01<00:00, 197MB/s]Downloading pytorch_model.bin:  70%|██████████████████████████████████████████████████▉                      | 304M/436M [00:01<00:00, 206MB/s]Downloading pytorch_model.bin:  77%|████████████████████████████████████████████████████████▏                | 336M/436M [00:01<00:00, 209MB/s]Downloading pytorch_model.bin:  84%|█████████████████████████████████████████████████████████████▍           | 367M/436M [00:01<00:00, 211MB/s]Downloading pytorch_model.bin:  91%|██████████████████████████████████████████████████████████████████▊      | 398M/436M [00:01<00:00, 212MB/s]Downloading pytorch_model.bin:  99%|████████████████████████████████████████████████████████████████████████ | 430M/436M [00:02<00:00, 213MB/s]Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████| 436M/436M [00:02<00:00, 200MB/s]
Downloading (…)okenizer_config.json:   0%|                                                                           | 0.00/365 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████| 365/365 [00:00<00:00, 200kB/s]
Downloading (…)solve/main/vocab.txt:   0%|                                                                          | 0.00/226k [00:00<?, ?B/s]Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████████████████████████████| 226k/226k [00:00<00:00, 276kB/s]Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████████████████████████████| 226k/226k [00:00<00:00, 276kB/s]
Downloading (…)/main/tokenizer.json:   0%|                                                                          | 0.00/461k [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|███████████████████████████████████████████████████████████████████| 461k/461k [00:00<00:00, 956kB/s]Downloading (…)/main/tokenizer.json: 100%|███████████████████████████████████████████████████████████████████| 461k/461k [00:00<00:00, 954kB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                           | 0.00/112 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 62.0kB/s]
Traceback (most recent call last):
  File "./f00296_extract_answer.py", line 41, in <module>
    test_extract_answer()
  File "./f00296_extract_answer.py", line 30, in test_extract_answer
    assert extract_answer(context, question) == 'on the Inference API on-demand'
AssertionError
