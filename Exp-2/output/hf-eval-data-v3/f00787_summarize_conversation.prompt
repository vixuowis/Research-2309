{'code': "###Instruction: Now I need to create a summary of my chat with my friend last night.\n###Input: conversation = '''Hannah: Hey, do you have Betty's number?\nAmanda: Lemme check\nAmanda: Sorry, can't find it.\nAmanda: Ask Larry\nAmanda: He called her last time we were at the park together\nHannah: I don't know him well\nAmanda: Don't be shy, he's very nice\nHannah: If you say so..\nHannah: I'd rather you texted him\nAmanda: Just text him ðŸ™‚\nHannah: Urgh.. Alright\nHannah: Bye\nAmanda: Bye bye\n'''\n###Output: <<<domain>>>: Natural Language Processing Text Generation\n<<<api_call>>>: pipeline('summarization', model='lidiya/bart-large-xsum-samsum')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import the pipeline function from the transformers library provided by Hugging Face.\n2. Use the pipeline function to create a summarization model.\n3. Specify the model 'lidiya/bart-large-xsum-samsum' to be loaded. This model is fine-tuned for summarizing conversational data.\n4. Pass your conversation text to the created summarizer model, which will provide you with a summary of the chat.\n5. The summary will provide you with an easily digestible version of the conversation.\n<<<code>>>: from transformers import pipeline\nsummarizer = pipeline('summarization', model='lidiya/bart-large-xsum-samsum')\nconversation = '''Hannah: Hey, do you have Betty's number?\nAmanda: Lemme check\nAmanda: Sorry, can't find it.\nAmanda: Ask Larry\nAmanda: He called her last time we were at the park together\nHannah: I don't know him well\nAmanda: Don't be shy, he's very nice\nHannah: If you say so..\nHannah: I'd rather you texted him\nAmanda: Just text him ðŸ™‚\nHannah: Urgh.. Alright\nHannah: Bye\nAmanda: Bye bye\n'''\nsummary = summarizer(conversation)\n", 'api_call': "pipeline('summarization', model='lidiya/bart-large-xsum-samsum')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Text Generation', 'framework': 'Hugging Face Transformers', 'functionality': 'Summarization', 'api_name': 'lidiya/bart-large-xsum-samsum', 'api_call': "pipeline('summarization', model='lidiya/bart-large-xsum-samsum')", 'api_arguments': 'conversation', 'python_environment_requirements': 'transformers', 'example_code': "from transformers import pipeline\nsummarizer = pipeline(summarization, model=lidiya/bart-large-xsum-samsum)\nconversation = '''Hannah: Hey, do you have Betty's number?\nAmanda: Lemme check\nAmanda: Sorry, can't find it.\nAmanda: Ask Larry\nAmanda: He called her last time we were at the park together\nHannah: I don't know him well\nAmanda: Don't be shy, he's very nice\nHannah: If you say so..\nHannah: I'd rather you texted him\nAmanda: Just text him ðŸ™‚\nHannah: Urgh.. Alright\nHannah: Bye\nAmanda: Bye bye <br />\n'''\nsummarizer(conversation)", 'performance': {'dataset': 'SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization', 'accuracy': {'rouge1': 53.306, 'rouge2': 28.355, 'rougeL': 44.095}}, 'description': 'This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset.'}}

