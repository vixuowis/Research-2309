{'code': "###Instruction: We are currently working on the development of a speech-to-text application for transcription purposes. Can you help generate the required transcription code?\n###Output: <<<domain>>>: Audio Automatic Speech Recognition\n<<<api_call>>>: WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny.en')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the necessary classes, WhisperProcessor and WhisperForConditionalGeneration, from the transformers package. Also, import the load_dataset function from the datasets package.\n2. Load the pre-trained model 'openai/whisper-tiny.en' using the from_pretrained() methods for both WhisperProcessor and WhisperForConditionalGeneration.\n3. Load the audio dataset using the load_dataset() function.\n4. Retrieve the audio sample from the dataset and process the audio using the WhisperProcessor instance.\n5. Use the pre-trained model instance to generate the predicted token ids.\n6. Decode the predicted token ids into textual transcriptions using the processor's batch_decode method.\n<<<code>>>: from transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom datasets import load_dataset\nprocessor = WhisperProcessor.from_pretrained('openai/whisper-tiny.en')\nmodel = WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny.en')\nds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split='validation')\nsample = ds[0]['audio']\ninput_features = processor(sample['array'], sampling_rate=sample['sampling_rate'], return_tensors='pt').input_features\npredicted_ids = model.generate(input_features)\ntranscription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n", 'api_call': "WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny.en')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Audio Automatic Speech Recognition', 'framework': 'Hugging Face Transformers', 'functionality': 'Transcription', 'api_name': 'openai/whisper-tiny.en', 'api_call': "WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny.en')", 'api_arguments': {'model_name': 'openai/whisper-tiny.en'}, 'python_environment_requirements': ['transformers', 'datasets', 'torch'], 'example_code': ['from transformers import WhisperProcessor, WhisperForConditionalGeneration', 'from datasets import load_dataset', 'processor = WhisperProcessor.from_pretrained(openai/whisper-tiny.en)', 'model = WhisperForConditionalGeneration.from_pretrained(openai/whisper-tiny.en)', 'ds = load_dataset(hf-internal-testing/librispeech_asr_dummy, clean, split=validation)', 'sample = ds[0][audio]', 'input_features = processor(sample[array], sampling_rate=sample[sampling_rate], return_tensors=pt).input_features', 'predicted_ids = model.generate(input_features)', 'transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)'], 'performance': {'dataset': 'LibriSpeech (clean)', 'accuracy': 8.437}, 'description': 'Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning.'}}



Extracting data files:   0%|                                                   | 0/1 [00:00<?, ?it/s]
Extracting data files: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00, 2219.21it/s]

Generating validation split: 0 examples [00:00, ? examples/s]
Generating validation split: 0 examples [00:00, ? examples/s]
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/audio.py", line 91, in encode_example
    import soundfile as sf  # soundfile is a dependency of librosa, needed to decode audio files.
ModuleNotFoundError: No module named 'soundfile'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1693, in _prepare_split_single
    example = self.info.features.encode_example(record) if self.info.features is not None else record
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1852, in encode_example
    return encode_nested_example(self, example)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1229, in encode_nested_example
    {
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1230, in <dictcomp>
    k: encode_nested_example(sub_schema, sub_obj, level=level + 1)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1284, in encode_nested_example
    return schema.encode_example(obj) if obj is not None else None
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/audio.py", line 93, in encode_example
    raise ImportError("To support encoding audio data, please install 'soundfile'.") from err
ImportError: To support encoding audio data, please install 'soundfile'.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00157_transcribe_audio.py", line 57, in <module>
    test_transcribe_audio()
  File "output/hf-eval-data-v2/f00157_transcribe_audio.py", line 43, in test_transcribe_audio
    ds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split='validation')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/load.py", line 2153, in load_dataset
    builder_instance.download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 954, in download_and_prepare
    self._download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1717, in _download_and_prepare
    super()._download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1049, in _download_and_prepare
    self._prepare_split(split_generator, **prepare_split_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1555, in _prepare_split
    for job_id, done, content in self._prepare_split_single(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1712, in _prepare_split_single
    raise DatasetGenerationError("An error occurred while generating the dataset") from e
datasets.builder.DatasetGenerationError: An error occurred while generating the dataset
