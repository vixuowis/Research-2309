{'code': "###Instruction: We are an analytics company that needs help in extracting data tables from plots and charts efficiently.\n###Output: <<<domain>>>: Multimodal Image-to-Text\n<<<api_call>>>: Pix2StructForConditionalGeneration.from_pretrained('google/deplot')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import the required classes from the transformers package, Pix2StructForConditionalGeneration for the multimodal image-to-text model, and Pix2StructProcessor for processing the input data. We also import the necessary libraries for handling images.\n2. Load the pre-trained model 'google/deplot' using the from_pretrained method of the Pix2StructForConditionalGeneration class. This model can translate the image of a plot or chart to a linearized table format. Also, load the associated processor using the from_pretrained method of the Pix2StructProcessor class.\n3. Provide an image of the plot or chart you want to extract data from. You can either load the image from a file or use a URL to get the image.\n4. Use the processor to generate the inputs for the model, including the image and a question or prompt.\n5. Call the generate method of the model with the inputs to obtain the predicted data table.\n6. You can now use this extracted data table for further analysis.\n<<<code>>>: from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\nfrom PIL import Image\n\nmodel = Pix2StructForConditionalGeneration.from_pretrained('google/deplot')\nprocessor = Pix2StructProcessor.from_pretrained('google/deplot')\n\nimage = Image.open('plot_image_path.png')\n# replace 'plot_image_path.png' with path to your plot or chart image\n\ninputs = processor(images=image, text='Generate underlying data table of the figure below:', return_tensors='pt')\npredictions = model.generate(**inputs, max_new_tokens=512)\ndata_table = processor.decode(predictions[0], skip_special_tokens=True)\n\nprint(data_table)", 'api_call': "Pix2StructForConditionalGeneration.from_pretrained('google/deplot')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Multimodal Image-to-Text', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'google/deplot', 'api_call': "Pix2StructForConditionalGeneration.from_pretrained('google/deplot')", 'api_arguments': {'images': 'image', 'text': 'question', 'return_tensors': 'pt', 'max_new_tokens': 512}, 'python_environment_requirements': {'transformers': 'Pix2StructForConditionalGeneration, Pix2StructProcessor', 'requests': 'requests', 'PIL': 'Image'}, 'example_code': "from transformers import Pix2StructForConditionalGeneration, Pix2StructProcessor\nimport requests\nfrom PIL import Image\nmodel = Pix2StructForConditionalGeneration.from_pretrained('google/deplot')\nprocessor = Pix2StructProcessor.from_pretrained('google/deplot')\nurl = https://raw.githubusercontent.com/vis-nlp/ChartQA/main/ChartQA%20Dataset/val/png/5090.png\nimage = Image.open(requests.get(url, stream=True).raw)\ninputs = processor(images=image, text=Generate underlying data table of the figure below:, return_tensors=pt)\npredictions = model.generate(**inputs, max_new_tokens=512)\nprint(processor.decode(predictions[0], skip_special_tokens=True))", 'performance': {'dataset': 'ChartQA', 'accuracy': '24.0% improvement over finetuned SOTA'}, 'description': 'DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs.'}}







Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00264_extract_data_from_plot.py", line 47, in <module>
    test_extract_data_from_plot()
  File "output/hf-eval-data-v2/f00264_extract_data_from_plot.py", line 38, in test_extract_data_from_plot
    data_table = extract_data_from_plot(image_path)
  File "output/hf-eval-data-v2/f00264_extract_data_from_plot.py", line 21, in extract_data_from_plot
    image = Image.open(image_path)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/PIL/Image.py", line 3218, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: 'test_plot_image_path.png'
