{'code': '###Instruction: A media company needs to summarize a news article in order to make it easy for their audience to understand the main points quickly.\n###Output:<<<domain>>>: Natural Language Processing Summarization\n<<<api_call>>>: AutoModelForSeq2SeqLM.from_pretrained(\'csebuetnlp/mT5_multilingual_XLSum\')\n<<<api_provider>>>: Transformers\n<<<explanation>>>: 1. Import the necessary classes, AutoTokenizer and AutoModelForSeq2SeqLM, from the transformers package.\n2. Load the pre-trained model \'csebuetnlp/mT5_multilingual_XLSum\'. This model has been fine-tuned on the XL-Sum dataset to provide abstractive summarization in multiple languages.\n3. Use the AutoTokenizer to tokenize the given news article.\n4. Use the AutoModelForSeq2SeqLM to generate a summary based on the tokenized input.\n5. Decode the summary from the output IDs, converting it back to human-readable text.\n<<<code>>>:\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\narticle_text = "..."\nmodel_name = \'csebuetnlp/mT5_multilingual_XLSum\'\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\ninput_ids = tokenizer(article_text, return_tensors=\'pt\', padding=True, truncation=True, max_length=512).input_ids\noutput_ids = model.generate(input_ids, max_length=84, no_repeat_ngram_size=2, num_beams=4)[0]\nsummary = tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n\nprint(summary)', 'api_call': "AutoModelForSeq2SeqLM.from_pretrained('csebuetnlp/mT5_multilingual_XLSum')", 'provider': 'Transformers', 'api_data': {'domain': 'Natural Language Processing Summarization', 'framework': 'Transformers', 'functionality': 'text2text-generation', 'api_name': 'csebuetnlp/mT5_multilingual_XLSum', 'api_call': "AutoModelForSeq2SeqLM.from_pretrained('csebuetnlp/mT5_multilingual_XLSum')", 'api_arguments': ['model_name'], 'python_environment_requirements': ['transformers==4.11.0.dev0'], 'example_code': "import re\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nWHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\narticle_text = Videos that say approved vaccines are dangerous and cause autism, cancer or infertility are among those that will be taken down, the company said. The policy includes the termination of accounts of anti-vaccine influencers. Tech giants have been criticised for not doing more to counter false health information on their sites. In July, US President Joe Biden said social media platforms were largely responsible for people's scepticism in getting vaccinated by spreading misinformation, and appealed for them to address the issue. YouTube, which is owned by Google, said 130,000 videos were removed from its platform since last year, when it implemented a ban on content spreading misinformation about Covid vaccines. In a blog post, the company said it had seen false claims about Covid jabs spill over into misinformation about vaccines in general. The new policy covers long-approved vaccines, such as those against measles or hepatitis B. We're expanding our medical misinformation policies on YouTube with new guidelines on currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and the WHO, the post said, referring to the World Health Organization.\nmodel_name = csebuetnlp/mT5_multilingual_XLSum\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ninput_ids = tokenizer(\n [WHITESPACE_HANDLER(article_text)],\n return_tensors=pt,\n padding=max_length,\n truncation=True,\n max_length=512\n)[input_ids]\noutput_ids = model.generate(\n input_ids=input_ids,\n max_length=84,\n no_repeat_ngram_size=2,\n num_beams=4\n)[0]\nsummary = tokenizer.decode(\n output_ids,\n skip_special_tokens=True,\n clean_up_tokenization_spaces=False\n)\nprint(summary)", 'performance': {'dataset': 'xsum', 'accuracy': {'ROUGE-1': 36.5, 'ROUGE-2': 13.934, 'ROUGE-L': 28.988, 'ROUGE-LSUM': 28.996, 'loss': 2.067, 'gen_len': 26.973}}, 'description': 'This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages.'}}

You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
