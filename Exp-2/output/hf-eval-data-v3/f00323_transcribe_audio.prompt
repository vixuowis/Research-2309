{'code': "###Instruction: My lecture has been recorded, and I would like to transcribe the audio to create a transcript of my presentation.\n###Output: <<<domain>>>: Audio Automatic Speech Recognition\n<<<api_call>>>: WhisperForConditionalGeneration.from_pretrained('openai/whisper-large-v2')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import the necessary classes from the transformers library provided by Hugging Face. This includes WhisperProcessor and WhisperForConditionalGeneration.\n2. Initialize the WhisperProcessor and the WhisperForConditionalGeneration model using the 'openai/whisper-large-v2' pretrained model for automatic speech recognition.\n3. Process your lecture's audio file with the processor to generate input features and make sure to pass the appropriate sampling rate of the audio file.\n4. Use the Whisper ASR model to generate the predicted_ids from the input_features.\n5. Decode the predicted_ids using the processor to obtain the transcription of your lecture.\n<<<code>>>: from transformers import WhisperProcessor, WhisperForConditionalGeneration\nprocessor = WhisperProcessor.from_pretrained('openai/whisper-large-v2')\nmodel = WhisperForConditionalGeneration.from_pretrained('openai/whisper-large-v2')\ninput_features = processor(audio_data, sampling_rate=audio_sampling_rate, return_tensors='pt').input_features\npredicted_ids = model.generate(input_features)\ntranscription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n", 'api_call': "WhisperForConditionalGeneration.from_pretrained('openai/whisper-large-v2')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Audio Automatic Speech Recognition', 'framework': 'Hugging Face Transformers', 'functionality': 'Automatic Speech Recognition and Speech Translation', 'api_name': 'openai/whisper-large-v2', 'api_call': "WhisperForConditionalGeneration.from_pretrained('openai/whisper-large-v2')", 'api_arguments': {'forced_decoder_ids': "WhisperProcessor.get_decoder_prompt_ids(language='english', task='transcribe')"}, 'python_environment_requirements': ['transformers', 'datasets'], 'example_code': ['from transformers import WhisperProcessor, WhisperForConditionalGeneration', 'from datasets import load_dataset', "processor = WhisperProcessor.from_pretrained('openai/whisper-large-v2')", "model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-large-v2')", 'model.config.forced_decoder_ids = None', "ds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split='validation')", "sample = ds[0]['audio']", "input_features = processor(sample['array'], sampling_rate=sample['sampling_rate'], return_tensors='pt').input_features", 'predicted_ids = model.generate(input_features)', 'transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)'], 'performance': {'dataset': 'LibriSpeech test-clean', 'accuracy': 3.0003583080317573}, 'description': 'Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning.'}}



Extracting data files:   0%|                                                   | 0/1 [00:00<?, ?it/s]
Extracting data files: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00, 1631.39it/s]

Generating validation split: 0 examples [00:00, ? examples/s]
Generating validation split: 0 examples [00:00, ? examples/s]
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/audio.py", line 91, in encode_example
    import soundfile as sf  # soundfile is a dependency of librosa, needed to decode audio files.
ModuleNotFoundError: No module named 'soundfile'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1693, in _prepare_split_single
    example = self.info.features.encode_example(record) if self.info.features is not None else record
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1852, in encode_example
    return encode_nested_example(self, example)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1229, in encode_nested_example
    {
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1230, in <dictcomp>
    k: encode_nested_example(sub_schema, sub_obj, level=level + 1)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1284, in encode_nested_example
    return schema.encode_example(obj) if obj is not None else None
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/audio.py", line 93, in encode_example
    raise ImportError("To support encoding audio data, please install 'soundfile'.") from err
ImportError: To support encoding audio data, please install 'soundfile'.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00323_transcribe_audio.py", line 53, in <module>
    test_transcribe_audio()
  File "output/hf-eval-data-v2/f00323_transcribe_audio.py", line 42, in test_transcribe_audio
    ds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split='validation')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/load.py", line 2153, in load_dataset
    builder_instance.download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 954, in download_and_prepare
    self._download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1717, in _download_and_prepare
    super()._download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1049, in _download_and_prepare
    self._prepare_split(split_generator, **prepare_split_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1555, in _prepare_split
    for job_id, done, content in self._prepare_split_single(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1712, in _prepare_split_single
    raise DatasetGenerationError("An error occurred while generating the dataset") from e
datasets.builder.DatasetGenerationError: An error occurred while generating the dataset
