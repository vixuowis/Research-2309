{'code': "###Instruction: We need to generate a short video showing Spider-Man water skiing in redshift style based on a textual prompt.\n###Output: <<<domain>>>: Multimodal Text-to-Video\n<<<api_call>>>: TuneAVideoPipeline.from_pretrained('nitrosocke/redshift-diffusion', unet=UNet3DConditionModel.from_pretrained('Tune-A-Video-library/redshift-man-skiing', subfolder='unet', torch_dtype=torch.float16), torch_dtype=torch.float16)\n<<<api_provider>>>: Hugging Face\n<<<explanation>>>: 1. Import the required libraries and modules from tuneavideo package and torch.\n2. Load the pretrained pipeline and UNet3DConditionModel using the provided model paths.\n3. Set the prompt to a text string describing the desired video, in this case '(redshift style) Spider-Man is water skiing'.\n4. Use the pipeline to generate a video based on the input prompt and desired video attributes like video_length, height, width, etc.\n5. Save the generated video as a file, in this example, as a GIF.\n<<<code>>>: from tuneavideo.pipelines.pipeline_tuneavideo import TuneAVideoPipeline\nfrom tuneavideo.models.unet import UNet3DConditionModel\nfrom tuneavideo.util import save_videos_grid\nimport torch\n\nunet = UNet3DConditionModel.from_pretrained('Tune-A-Video-library/redshift-man-skiing', subfolder='unet', torch_dtype=torch.float16).to('cuda')\npipe = TuneAVideoPipeline.from_pretrained('nitrosocke/redshift-diffusion', unet=unet, torch_dtype=torch.float16).to('cuda')\npipe.enable_xformers_memory_efficient_attention()\n\nprompt = '(redshift style) Spider-Man is water skiing'\nvideo = pipe(prompt, video_length=8, height=512, width=512, num_inference_steps=50, guidance_scale=7.5).videos\nsave_videos_grid(video, f'./{prompt}.gif')\n", 'api_call': "TuneAVideoPipeline.from_pretrained('nitrosocke/redshift-diffusion', unet=UNet3DConditionModel.from_pretrained('Tune-A-Video-library/redshift-man-skiing', subfolder='unet', torch_dtype=torch.float16), torch_dtype=torch.float16)", 'provider': 'Hugging Face', 'api_data': {'domain': 'Multimodal Text-to-Video', 'framework': 'Hugging Face', 'functionality': 'Text-to-Video Generation', 'api_name': 'redshift-man-skiing', 'api_call': "TuneAVideoPipeline.from_pretrained('nitrosocke/redshift-diffusion', unet=UNet3DConditionModel.from_pretrained('Tune-A-Video-library/redshift-man-skiing', subfolder='unet', torch_dtype=torch.float16), torch_dtype=torch.float16)", 'api_arguments': {'prompt': 'string', 'video_length': 'int', 'height': 'int', 'width': 'int', 'num_inference_steps': 'int', 'guidance_scale': 'float'}, 'python_environment_requirements': ['torch', 'tuneavideo'], 'example_code': "from tuneavideo.pipelines.pipeline_tuneavideo import TuneAVideoPipeline\nfrom tuneavideo.models.unet import UNet3DConditionModel\nfrom tuneavideo.util import save_videos_grid\nimport torch\npretrained_model_path = nitrosocke/redshift-diffusion\nunet_model_path = Tune-A-Video-library/redshift-man-skiing\nunet = UNet3DConditionModel.from_pretrained(unet_model_path, subfolder='unet', torch_dtype=torch.float16).to('cuda')\npipe = TuneAVideoPipeline.from_pretrained(pretrained_model_path, unet=unet, torch_dtype=torch.float16).to(cuda)\npipe.enable_xformers_memory_efficient_attention()\nprompt = (redshift style) spider man is skiing\nvideo = pipe(prompt, video_length=8, height=512, width=512, num_inference_steps=50, guidance_scale=7.5).videos\nsave_videos_grid(video, f./{prompt}.gif)", 'performance': {'dataset': 'N/A', 'accuracy': 'N/A'}, 'description': "Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}}

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00831_generate_video.py", line 3, in <module>
    from tuneavideo.pipelines.pipeline_tuneavideo import TuneAVideoPipeline
ModuleNotFoundError: No module named 'tuneavideo'
