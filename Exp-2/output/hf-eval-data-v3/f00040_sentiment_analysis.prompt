{'code': '###Instruction: My company is launching a social media campaign. We need an AI-based system that would automatically analyze the sentiment of any user-generated reviews or tweets concerning our product.\n###Output: <<<domain>>>: Natural Language Processing Text Classification\n<<<api_call>>>: pipeline(\'sentiment-analysis\', model=\'siebert/sentiment-roberta-large-english\')\n<<<api_provider>>>: Transformers\n<<<explanation>>>:1. Import the pipeline function from the transformers library.\n2. Use the pipeline function with \'sentiment-analysis\' as the task and the specified model \'siebert/sentiment-roberta-large-english\' to load a pre-trained model for sentiment analysis.\n3. With the loaded model, you can analyze the sentiment of any text related to your product, be it user-generated reviews or social media posts.\n4. The sentiment analysis model will return either positive (1) or negative (0) sentiment predictions for the given input text.\n<<<code>>>: from transformers import pipeline\nsentiment_analysis = pipeline(\'sentiment-analysis\', model=\'siebert/sentiment-roberta-large-english\')\n# For instance, analyzing the sentiment of a given text:\ntext = "I love the new product!"\nresult = sentiment_analysis(text)\nprint(result)\n', 'api_call': "pipeline('sentiment-analysis', model='siebert/sentiment-roberta-large-english')", 'provider': 'Transformers', 'api_data': {'domain': 'Natural Language Processing Text Classification', 'framework': 'Transformers', 'functionality': 'Sentiment Analysis', 'api_name': 'siebert/sentiment-roberta-large-english', 'api_call': "pipeline('sentiment-analysis', model='siebert/sentiment-roberta-large-english')", 'api_arguments': ['text'], 'python_environment_requirements': ['transformers'], 'example_code': 'from transformers import pipeline\nsentiment_analysis = pipeline(sentiment-analysis, model=siebert/sentiment-roberta-large-english)\nprint(sentiment_analysis(I love this!))', 'performance': {'dataset': [{'name': 'McAuley and Leskovec (2013) (Reviews)', 'accuracy': 98.0}, {'name': 'McAuley and Leskovec (2013) (Review Titles)', 'accuracy': 87.0}, {'name': 'Yelp Academic Dataset', 'accuracy': 96.5}, {'name': 'Maas et al. (2011)', 'accuracy': 96.0}, {'name': 'Kaggle', 'accuracy': 96.0}, {'name': 'Pang and Lee (2005)', 'accuracy': 91.0}, {'name': 'Nakov et al. (2013)', 'accuracy': 88.5}, {'name': 'Shamma (2009)', 'accuracy': 87.0}, {'name': 'Blitzer et al. (2007) (Books)', 'accuracy': 92.5}, {'name': 'Blitzer et al. (2007) (DVDs)', 'accuracy': 92.5}, {'name': 'Blitzer et al. (2007) (Electronics)', 'accuracy': 95.0}, {'name': 'Blitzer et al. (2007) (Kitchen devices)', 'accuracy': 98.5}, {'name': 'Pang et al. (2002)', 'accuracy': 95.5}, {'name': 'Speriosu et al. (2011)', 'accuracy': 85.5}, {'name': 'Hartmann et al. (2019)', 'accuracy': 98.0}], 'average_accuracy': 93.2}, 'description': "This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}}



