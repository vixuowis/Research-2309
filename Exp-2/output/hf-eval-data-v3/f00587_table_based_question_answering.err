2023-11-12 04:36:48.339576: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 04:36:48.400599: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 04:36:49.246911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)cial_tokens_map.json:   0%|                                                                           | 0.00/772 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████| 772/772 [00:00<00:00, 71.1kB/s]
Downloading (…)okenizer_config.json:   0%|                                                                         | 0.00/1.20k [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████| 1.20k/1.20k [00:00<00:00, 102kB/s]
Traceback (most recent call last):
  File "./f00587_table_based_question_answering.py", line 60, in <module>
    test_table_based_question_answering()
  File "./f00587_table_based_question_answering.py", line 38, in test_table_based_question_answering
    assert table_based_question_answering(table1, query1) == '2008'
  File "./f00587_table_based_question_answering.py", line 19, in table_based_question_answering
    tokenizer = TapexTokenizer.from_pretrained('microsoft/tapex-base-finetuned-wtq')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 1854, in from_pretrained
    return cls._from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2017, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/deprecated/tapex/tokenization_tapex.py", line 316, in __init__
    with open(vocab_file, encoding="utf-8") as vocab_handle:
TypeError: expected str, bytes or os.PathLike object, not NoneType
