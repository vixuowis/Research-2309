{'code': "###Instruction: We are building a fiction-sharing platform for multiple languages. Extract named entities from the given text.\n###Output: <<<domain>>>: Natural Language Processing Token Classification\n<<<api_call>>>: AutoModelForTokenClassification.from_pretrained('Babelscape/wikineural-multilingual-ner')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the required libraries for token classification. This includes AutoTokenizer and AutoModelForTokenClassification.\n2. Load the pre-trained model 'Babelscape/wikineural-multilingual-ner' for Named Entity Recognition.\n3. Initialize a NER pipeline with the model and tokenizer.\n4. Provide a multilingual text as input to the created NER pipeline, and the model will extract named entities in any of the supported languages.\n<<<code>>>: from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n\ntokenizer = AutoTokenizer.from_pretrained('Babelscape/wikineural-multilingual-ner')\nmodel = AutoModelForTokenClassification.from_pretrained('Babelscape/wikineural-multilingual-ner')\n\nner_pipeline = pipeline('ner', model=model, tokenizer=tokenizer)\nmultilingual_text = 'My name is Wolfgang and I live in Berlin. Mi nombre es Jos√© y vivo en Madrid.'\nner_results = ner_pipeline(multilingual_text)\n\nprint(ner_results)", 'api_call': "AutoModelForTokenClassification.from_pretrained('Babelscape/wikineural-multilingual-ner')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Token Classification', 'framework': 'Hugging Face Transformers', 'functionality': 'Named Entity Recognition', 'api_name': 'Babelscape/wikineural-multilingual-ner', 'api_call': "AutoModelForTokenClassification.from_pretrained('Babelscape/wikineural-multilingual-ner')", 'api_arguments': {'model': 'AutoModelForTokenClassification.from_pretrained(Babelscape/wikineural-multilingual-ner)', 'tokenizer': 'AutoTokenizer.from_pretrained(Babelscape/wikineural-multilingual-ner)'}, 'python_environment_requirements': {'transformers': 'from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline'}, 'example_code': 'tokenizer = AutoTokenizer.from_pretrained(Babelscape/wikineural-multilingual-ner)\nmodel = AutoModelForTokenClassification.from_pretrained(Babelscape/wikineural-multilingual-ner)\nnlp = pipeline(ner, model=model, tokenizer=tokenizer)\nexample = My name is Wolfgang and I live in Berlin\nner_results = nlp(example)\nprint(ner_results)', 'performance': {'dataset': 'Babelscape/wikineural-multilingual-ner', 'accuracy': 'span-based F1-score up to 6 points over previous state-of-the-art systems for data creation'}, 'description': 'A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks.'}}

