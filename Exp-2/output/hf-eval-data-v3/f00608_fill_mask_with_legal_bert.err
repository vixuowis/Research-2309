Downloading (…)okenizer_config.json:   0%|                                                                          | 0.00/48.0 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████████████████████████████████████████████████████████████| 48.0/48.0 [00:00<00:00, 5.13kB/s]
Downloading (…)lve/main/config.json:   0%|                                                                           | 0.00/989 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████| 989/989 [00:00<00:00, 72.1kB/s]
Downloading (…)solve/main/vocab.txt:   0%|                                                                          | 0.00/222k [00:00<?, ?B/s]Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████████████████████████████| 222k/222k [00:00<00:00, 448kB/s]Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████████████████████████████| 222k/222k [00:00<00:00, 447kB/s]2023-11-12 06:23:33.492886: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 06:23:33.552839: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 06:23:34.569249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

Downloading pytorch_model.bin:   0%|                                                                                | 0.00/141M [00:00<?, ?B/s]Downloading pytorch_model.bin:   7%|█████▎                                                                 | 10.5M/141M [00:02<00:32, 4.08MB/s]Downloading pytorch_model.bin:  15%|██████████▌                                                            | 21.0M/141M [00:03<00:17, 7.01MB/s]Downloading pytorch_model.bin:  22%|███████████████▊                                                       | 31.5M/141M [00:04<00:12, 9.04MB/s]Downloading pytorch_model.bin:  30%|█████████████████████                                                  | 41.9M/141M [00:04<00:09, 11.0MB/s]Downloading pytorch_model.bin:  37%|██████████████████████████▎                                            | 52.4M/141M [00:05<00:07, 12.2MB/s]Downloading pytorch_model.bin:  44%|███████████████████████████████▌                                       | 62.9M/141M [00:06<00:05, 13.3MB/s]Downloading pytorch_model.bin:  52%|████████████████████████████████████▊                                  | 73.4M/141M [00:06<00:04, 14.4MB/s]Downloading pytorch_model.bin:  59%|██████████████████████████████████████████                             | 83.9M/141M [00:07<00:03, 15.0MB/s]Downloading pytorch_model.bin:  67%|███████████████████████████████████████████████▎                       | 94.4M/141M [00:07<00:03, 15.5MB/s]Downloading pytorch_model.bin:  74%|█████████████████████████████████████████████████████▎                  | 105M/141M [00:08<00:02, 15.7MB/s]Downloading pytorch_model.bin:  82%|██████████████████████████████████████████████████████████▋             | 115M/141M [00:09<00:01, 14.3MB/s]Downloading pytorch_model.bin:  89%|████████████████████████████████████████████████████████████████        | 126M/141M [00:10<00:01, 11.8MB/s]Downloading pytorch_model.bin:  96%|█████████████████████████████████████████████████████████████████████▎  | 136M/141M [00:11<00:00, 12.8MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████| 141M/141M [00:11<00:00, 13.2MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████| 141M/141M [00:11<00:00, 12.1MB/s]
Traceback (most recent call last):
  File "./f00608_fill_mask_with_legal_bert.py", line 49, in <module>
    test_fill_mask_with_legal_bert()
  File "./f00608_fill_mask_with_legal_bert.py", line 35, in test_fill_mask_with_legal_bert
    assert fill_mask_with_legal_bert(test_text_1) == expected_output_1
  File "./f00608_fill_mask_with_legal_bert.py", line 24, in fill_mask_with_legal_bert
    predictions = outputs.logits.argmax(-1)
AttributeError: 'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'logits'
