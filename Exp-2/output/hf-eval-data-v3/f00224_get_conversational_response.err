Downloading (…)lve/main/config.json:   0%|                                                                           | 0.00/644 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████| 644/644 [00:00<00:00, 61.6kB/s]
Downloading pytorch_model.bin:   0%|                                                                               | 0.00/1.32G [00:00<?, ?B/s]Downloading pytorch_model.bin:   2%|█                                                                      | 21.0M/1.32G [00:00<00:06, 206MB/s]Downloading pytorch_model.bin:   4%|██▊                                                                    | 52.4M/1.32G [00:00<00:05, 226MB/s]Downloading pytorch_model.bin:   6%|████▍                                                                  | 83.9M/1.32G [00:00<00:05, 233MB/s]Downloading pytorch_model.bin:   9%|██████▎                                                                 | 115M/1.32G [00:00<00:05, 236MB/s]Downloading pytorch_model.bin:  11%|███████▉                                                                | 147M/1.32G [00:00<00:04, 244MB/s]Downloading pytorch_model.bin:  13%|█████████▋                                                              | 178M/1.32G [00:00<00:04, 247MB/s]Downloading pytorch_model.bin:  16%|███████████▍                                                            | 210M/1.32G [00:00<00:04, 247MB/s]Downloading pytorch_model.bin:  18%|█████████████                                                           | 241M/1.32G [00:00<00:04, 247MB/s]Downloading pytorch_model.bin:  21%|██████████████▊                                                         | 273M/1.32G [00:01<00:04, 246MB/s]Downloading pytorch_model.bin:  23%|████████████████▌                                                       | 304M/1.32G [00:01<00:04, 246MB/s]Downloading pytorch_model.bin:  25%|██████████████████▏                                                     | 336M/1.32G [00:01<00:04, 242MB/s]Downloading pytorch_model.bin:  28%|███████████████████▉                                                    | 367M/1.32G [00:01<00:03, 241MB/s]Downloading pytorch_model.bin:  30%|█████████████████████▋                                                  | 398M/1.32G [00:01<00:03, 243MB/s]Downloading pytorch_model.bin:  32%|███████████████████████▎                                                | 430M/1.32G [00:01<00:03, 250MB/s]Downloading pytorch_model.bin:  35%|█████████████████████████                                               | 461M/1.32G [00:01<00:03, 246MB/s]Downloading pytorch_model.bin:  37%|██████████████████████████▊                                             | 493M/1.32G [00:02<00:03, 241MB/s]Downloading pytorch_model.bin:  40%|████████████████████████████▍                                           | 524M/1.32G [00:02<00:03, 238MB/s]Downloading pytorch_model.bin:  42%|██████████████████████████████▏                                         | 556M/1.32G [00:02<00:03, 233MB/s]Downloading pytorch_model.bin:  44%|███████████████████████████████▉                                        | 587M/1.32G [00:02<00:03, 234MB/s]Downloading pytorch_model.bin:  47%|█████████████████████████████████▌                                      | 619M/1.32G [00:02<00:03, 235MB/s]Downloading pytorch_model.bin:  49%|███████████████████████████████████▎                                    | 650M/1.32G [00:02<00:02, 233MB/s]Downloading pytorch_model.bin:  51%|█████████████████████████████████████                                   | 682M/1.32G [00:02<00:02, 233MB/s]Downloading pytorch_model.bin:  54%|██████████████████████████████████████▋                                 | 713M/1.32G [00:02<00:02, 240MB/s]Downloading pytorch_model.bin:  56%|████████████████████████████████████████▍                               | 744M/1.32G [00:03<00:02, 237MB/s]Downloading pytorch_model.bin:  59%|██████████████████████████████████████████▏                             | 776M/1.32G [00:03<00:02, 236MB/s]Downloading pytorch_model.bin:  61%|███████████████████████████████████████████▉                            | 807M/1.32G [00:03<00:02, 236MB/s]Downloading pytorch_model.bin:  63%|█████████████████████████████████████████████▌                          | 839M/1.32G [00:03<00:02, 237MB/s]Downloading pytorch_model.bin:  66%|███████████████████████████████████████████████▎                        | 870M/1.32G [00:03<00:01, 239MB/s]Downloading pytorch_model.bin:  68%|█████████████████████████████████████████████████                       | 902M/1.32G [00:03<00:01, 241MB/s]Downloading pytorch_model.bin:  70%|██████████████████████████████████████████████████▋                     | 933M/1.32G [00:03<00:01, 242MB/s]Downloading pytorch_model.bin:  73%|████████████████████████████████████████████████████▍                   | 965M/1.32G [00:04<00:01, 245MB/s]Downloading pytorch_model.bin:  75%|██████████████████████████████████████████████████████▏                 | 996M/1.32G [00:04<00:01, 248MB/s]Downloading pytorch_model.bin:  78%|███████████████████████████████████████████████████████                | 1.03G/1.32G [00:04<00:01, 248MB/s]Downloading pytorch_model.bin:  80%|████████████████████████████████████████████████████████▊              | 1.06G/1.32G [00:04<00:01, 243MB/s]Downloading pytorch_model.bin:  82%|██████████████████████████████████████████████████████████▍            | 1.09G/1.32G [00:04<00:00, 241MB/s]Downloading pytorch_model.bin:  85%|████████████████████████████████████████████████████████████           | 1.12G/1.32G [00:04<00:00, 247MB/s]Downloading pytorch_model.bin:  87%|█████████████████████████████████████████████████████████████▊         | 1.15G/1.32G [00:04<00:00, 239MB/s]Downloading pytorch_model.bin:  89%|███████████████████████████████████████████████████████████████▍       | 1.18G/1.32G [00:04<00:00, 240MB/s]Downloading pytorch_model.bin:  92%|█████████████████████████████████████████████████████████████████▏     | 1.22G/1.32G [00:05<00:00, 242MB/s]Downloading pytorch_model.bin:  94%|██████████████████████████████████████████████████████████████████▊    | 1.25G/1.32G [00:05<00:00, 205MB/s]Downloading pytorch_model.bin:  97%|████████████████████████████████████████████████████████████████████▌  | 1.28G/1.32G [00:05<00:00, 214MB/s]Downloading pytorch_model.bin:  99%|██████████████████████████████████████████████████████████████████████▏| 1.31G/1.32G [00:05<00:00, 222MB/s]Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████| 1.32G/1.32G [00:05<00:00, 237MB/s]
Downloading (…)okenizer_config.json:   0%|                                                                           | 0.00/685 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████| 685/685 [00:00<00:00, 338kB/s]
Downloading (…)olve/main/vocab.json:   0%|                                                                          | 0.00/899k [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|██████████████████████████████████████████████████████████████████| 899k/899k [00:00<00:00, 1.08MB/s]Downloading (…)olve/main/vocab.json: 100%|██████████████████████████████████████████████████████████████████| 899k/899k [00:00<00:00, 1.08MB/s]
Downloading (…)olve/main/merges.txt:   0%|                                                                          | 0.00/456k [00:00<?, ?B/s]Downloading (…)olve/main/merges.txt: 100%|██████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 8.31MB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                           | 0.00/441 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████████| 441/441 [00:00<00:00, 311kB/s]
Traceback (most recent call last):
  File "./f00224_get_conversational_response.py", line 43, in <module>
    test_get_conversational_response()
  File "./f00224_get_conversational_response.py", line 28, in test_get_conversational_response
    response1 = get_conversational_response(question1)
  File "./f00224_get_conversational_response.py", line 18, in get_conversational_response
    response = conversational_ai(question)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/conversational.py", line 243, in __call__
    outputs = super().__call__(conversations, num_workers=num_workers, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1140, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1146, in run_single
    model_inputs = self.preprocess(inputs, **preprocess_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/conversational.py", line 250, in preprocess
    raise ValueError("ConversationalPipeline, expects Conversation as inputs")
ValueError: ConversationalPipeline, expects Conversation as inputs
