2023-11-12 08:10:51.399761: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-12 08:10:51.442071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-12 08:10:52.058595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Downloading (…)ve/main/spiece.model:   0%|                                                                          | 0.00/792k [00:00<?, ?B/s]Downloading (…)ve/main/spiece.model: 100%|███████████████████████████████████████████████████████████████████| 792k/792k [00:00<00:00, 937kB/s]Downloading (…)ve/main/spiece.model: 100%|███████████████████████████████████████████████████████████████████| 792k/792k [00:00<00:00, 935kB/s]
Downloading (…)lve/main/config.json:   0%|                                                                         | 0.00/1.21k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|█████████████████████████████████████████████████████████████████| 1.21k/1.21k [00:00<00:00, 101kB/s]
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:220: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Downloading model.safetensors:   0%|                                                                                | 0.00/892M [00:00<?, ?B/s]Downloading model.safetensors:   1%|▊                                                                      | 10.5M/892M [00:01<02:21, 6.21MB/s]Downloading model.safetensors:   2%|█▋                                                                     | 21.0M/892M [00:02<01:28, 9.82MB/s]Downloading model.safetensors:   4%|██▌                                                                    | 31.5M/892M [00:02<01:09, 12.3MB/s]Downloading model.safetensors:   5%|███▎                                                                   | 41.9M/892M [00:03<01:03, 13.4MB/s]Downloading model.safetensors:   6%|████▏                                                                  | 52.4M/892M [00:04<00:57, 14.5MB/s]Downloading model.safetensors:   7%|█████                                                                  | 62.9M/892M [00:04<00:53, 15.5MB/s]Downloading model.safetensors:   8%|█████▊                                                                 | 73.4M/892M [00:05<00:50, 16.1MB/s]Downloading model.safetensors:   9%|██████▋                                                                | 83.9M/892M [00:06<00:50, 16.1MB/s]Downloading model.safetensors:  11%|███████▌                                                               | 94.4M/892M [00:06<00:48, 16.5MB/s]Downloading model.safetensors:  12%|████████▍                                                               | 105M/892M [00:07<00:46, 16.8MB/s]Downloading model.safetensors:  13%|█████████▎                                                              | 115M/892M [00:07<00:45, 16.9MB/s]Downloading model.safetensors:  14%|██████████▏                                                             | 126M/892M [00:08<00:44, 17.2MB/s]Downloading model.safetensors:  15%|███████████                                                             | 136M/892M [00:09<00:43, 17.2MB/s]Downloading model.safetensors:  16%|███████████▊                                                            | 147M/892M [00:09<00:43, 17.2MB/s]Downloading model.safetensors:  18%|████████████▋                                                           | 157M/892M [00:10<00:42, 17.4MB/s]Downloading model.safetensors:  19%|█████████████▌                                                          | 168M/892M [00:10<00:41, 17.2MB/s]Downloading model.safetensors:  20%|██████████████▍                                                         | 178M/892M [00:11<00:40, 17.7MB/s]Downloading model.safetensors:  21%|███████████████▏                                                        | 189M/892M [00:12<00:41, 16.9MB/s]Downloading model.safetensors:  22%|████████████████                                                        | 199M/892M [00:12<00:39, 17.4MB/s]Downloading model.safetensors:  24%|████████████████▉                                                       | 210M/892M [00:13<00:40, 17.0MB/s]Downloading model.safetensors:  25%|█████████████████▊                                                      | 220M/892M [00:13<00:38, 17.4MB/s]Downloading model.safetensors:  26%|██████████████████▋                                                     | 231M/892M [00:14<00:38, 17.1MB/s]Downloading model.safetensors:  27%|███████████████████▍                                                    | 241M/892M [00:15<00:38, 17.0MB/s]Downloading model.safetensors:  28%|████████████████████▎                                                   | 252M/892M [00:15<00:37, 17.0MB/s]Downloading model.safetensors:  29%|█████████████████████▏                                                  | 262M/892M [00:16<00:36, 17.2MB/s]Downloading model.safetensors:  31%|██████████████████████                                                  | 273M/892M [00:16<00:35, 17.2MB/s]Downloading model.safetensors:  32%|██████████████████████▊                                                 | 283M/892M [00:17<00:35, 17.2MB/s]Downloading model.safetensors:  33%|███████████████████████▋                                                | 294M/892M [00:18<00:34, 17.3MB/s]Downloading model.safetensors:  34%|████████████████████████▌                                               | 304M/892M [00:18<00:33, 17.3MB/s]Downloading model.safetensors:  35%|█████████████████████████▍                                              | 315M/892M [00:19<00:33, 17.0MB/s]Downloading model.safetensors:  36%|██████████████████████████▏                                             | 325M/892M [00:20<00:33, 16.9MB/s]Downloading model.safetensors:  38%|███████████████████████████                                             | 336M/892M [00:20<00:33, 16.6MB/s]Downloading model.safetensors:  39%|███████████████████████████▉                                            | 346M/892M [00:21<00:32, 16.9MB/s]Downloading model.safetensors:  40%|████████████████████████████▊                                           | 357M/892M [00:22<00:39, 13.7MB/s]Downloading model.safetensors:  41%|█████████████████████████████▋                                          | 367M/892M [00:23<00:38, 13.6MB/s]Downloading model.safetensors:  42%|██████████████████████████████▍                                         | 377M/892M [00:23<00:36, 14.2MB/s]Downloading model.safetensors:  44%|███████████████████████████████▎                                        | 388M/892M [00:24<00:34, 14.7MB/s]Downloading model.safetensors:  45%|████████████████████████████████▏                                       | 398M/892M [00:25<00:32, 15.0MB/s]Downloading model.safetensors:  46%|█████████████████████████████████                                       | 409M/892M [00:25<00:31, 15.4MB/s]Downloading model.safetensors:  47%|█████████████████████████████████▊                                      | 419M/892M [00:26<00:30, 15.5MB/s]Downloading model.safetensors:  48%|██████████████████████████████████▋                                     | 430M/892M [00:27<00:29, 15.8MB/s]Downloading model.safetensors:  49%|███████████████████████████████████▌                                    | 440M/892M [00:28<00:31, 14.2MB/s]Downloading model.safetensors:  51%|████████████████████████████████████▍                                   | 451M/892M [00:29<00:39, 11.1MB/s]Downloading model.safetensors:  52%|█████████████████████████████████████▎                                  | 461M/892M [00:30<00:41, 10.4MB/s]Downloading model.safetensors:  53%|██████████████████████████████████████                                  | 472M/892M [00:32<00:49, 8.44MB/s]Downloading model.safetensors:  54%|██████████████████████████████████████▉                                 | 482M/892M [00:33<00:42, 9.55MB/s]Downloading model.safetensors:  55%|███████████████████████████████████████▊                                | 493M/892M [00:35<00:56, 7.06MB/s]Downloading model.safetensors:  56%|████████████████████████████████████████▋                               | 503M/892M [00:39<01:20, 4.83MB/s]Downloading model.safetensors:  58%|█████████████████████████████████████████▍                              | 514M/892M [00:40<01:02, 6.02MB/s]Downloading model.safetensors:  59%|██████████████████████████████████████████▎                             | 524M/892M [00:40<00:49, 7.38MB/s]Downloading model.safetensors:  60%|███████████████████████████████████████████▏                            | 535M/892M [00:41<00:40, 8.76MB/s]Downloading model.safetensors:  61%|████████████████████████████████████████████                            | 545M/892M [00:42<00:34, 10.1MB/s]Downloading model.safetensors:  62%|████████████████████████████████████████████▉                           | 556M/892M [00:42<00:29, 11.5MB/s]Downloading model.safetensors:  64%|█████████████████████████████████████████████▋                          | 566M/892M [00:43<00:25, 12.6MB/s]Downloading model.safetensors:  65%|██████████████████████████████████████████████▌                         | 577M/892M [00:44<00:23, 13.3MB/s]Downloading model.safetensors:  66%|███████████████████████████████████████████████▍                        | 587M/892M [00:44<00:22, 13.8MB/s]Downloading model.safetensors:  67%|████████████████████████████████████████████████▎                       | 598M/892M [00:45<00:20, 14.3MB/s]Downloading model.safetensors:  68%|█████████████████████████████████████████████████                       | 608M/892M [00:46<00:19, 14.9MB/s]Downloading model.safetensors:  69%|█████████████████████████████████████████████████▉                      | 619M/892M [00:46<00:18, 15.1MB/s]Downloading model.safetensors:  71%|██████████████████████████████████████████████████▊                     | 629M/892M [00:47<00:17, 15.4MB/s]Downloading model.safetensors:  72%|███████████████████████████████████████████████████▋                    | 640M/892M [00:48<00:16, 15.5MB/s]Downloading model.safetensors:  73%|████████████████████████████████████████████████████▍                   | 650M/892M [00:48<00:15, 15.6MB/s]Downloading model.safetensors:  74%|█████████████████████████████████████████████████████▎                  | 661M/892M [00:49<00:17, 13.1MB/s]Downloading model.safetensors:  75%|██████████████████████████████████████████████████████▏                 | 671M/892M [00:50<00:16, 13.4MB/s]Downloading model.safetensors:  76%|███████████████████████████████████████████████████████                 | 682M/892M [00:51<00:19, 10.9MB/s]Downloading model.safetensors:  78%|███████████████████████████████████████████████████████▉                | 692M/892M [00:52<00:16, 11.9MB/s]Downloading model.safetensors:  79%|████████████████████████████████████████████████████████▋               | 703M/892M [00:53<00:14, 12.7MB/s]Downloading model.safetensors:  80%|█████████████████████████████████████████████████████████▌              | 713M/892M [00:53<00:13, 13.5MB/s]Downloading model.safetensors:  81%|██████████████████████████████████████████████████████████▍             | 724M/892M [00:54<00:11, 14.2MB/s]Downloading model.safetensors:  82%|███████████████████████████████████████████████████████████▎            | 734M/892M [00:55<00:10, 14.5MB/s]Downloading model.safetensors:  83%|████████████████████████████████████████████████████████████            | 744M/892M [00:55<00:09, 15.0MB/s]Downloading model.safetensors:  85%|████████████████████████████████████████████████████████████▉           | 755M/892M [00:56<00:09, 13.7MB/s]Downloading model.safetensors:  86%|█████████████████████████████████████████████████████████████▊          | 765M/892M [00:57<00:08, 14.2MB/s]Downloading model.safetensors:  87%|██████████████████████████████████████████████████████████████▋         | 776M/892M [00:58<00:07, 14.5MB/s]Downloading model.safetensors:  88%|███████████████████████████████████████████████████████████████▌        | 786M/892M [00:58<00:07, 14.9MB/s]Downloading model.safetensors:  89%|████████████████████████████████████████████████████████████████▎       | 797M/892M [00:59<00:06, 15.2MB/s]Downloading model.safetensors:  91%|█████████████████████████████████████████████████████████████████▏      | 807M/892M [01:00<00:06, 12.5MB/s]Downloading model.safetensors:  92%|██████████████████████████████████████████████████████████████████      | 818M/892M [01:01<00:05, 13.2MB/s]Downloading model.safetensors:  93%|██████████████████████████████████████████████████████████████████▉     | 828M/892M [01:02<00:04, 13.8MB/s]Downloading model.safetensors:  94%|███████████████████████████████████████████████████████████████████▋    | 839M/892M [01:02<00:03, 14.5MB/s]Downloading model.safetensors:  95%|████████████████████████████████████████████████████████████████████▌   | 849M/892M [01:03<00:02, 14.1MB/s]Downloading model.safetensors:  96%|█████████████████████████████████████████████████████████████████████▍  | 860M/892M [01:04<00:02, 14.5MB/s]Downloading model.safetensors:  98%|██████████████████████████████████████████████████████████████████████▎ | 870M/892M [01:04<00:01, 14.8MB/s]Downloading model.safetensors:  99%|███████████████████████████████████████████████████████████████████████ | 881M/892M [01:05<00:00, 15.1MB/s]Downloading model.safetensors: 100%|███████████████████████████████████████████████████████████████████████▉| 891M/892M [01:06<00:00, 15.4MB/s]Downloading model.safetensors: 100%|████████████████████████████████████████████████████████████████████████| 892M/892M [01:06<00:00, 13.5MB/s]
Traceback (most recent call last):
  File "./f00690_extract_conclusion.py", line 47, in <module>
    test_extract_conclusion()
  File "./f00690_extract_conclusion.py", line 34, in test_extract_conclusion
    assert isinstance(extract_conclusion('Studies have been shown that owning a dog is good for you. Having a dog can help decrease stress levels, improve your mood, and increase physical activity.'), str)
  File "./f00690_extract_conclusion.py", line 27, in extract_conclusion
    outputs = model.generate(input_ids, decoder_input_ids=decoder_input_ids)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/generation/utils.py", line 1408, in generate
    self._validate_model_class()
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/generation/utils.py", line 1203, in _validate_model_class
    raise TypeError(exception_message)
TypeError: The current model class (T5Model) is not compatible with `.generate()`, as it doesn't have a language model head. Please use one of the following classes instead: {'T5ForConditionalGeneration'}
