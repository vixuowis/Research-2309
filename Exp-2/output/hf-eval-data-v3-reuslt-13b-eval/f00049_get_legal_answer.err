pytorch_model.bin:   0%|                                                             | 0.00/235M [00:00<?, ?B/s]pytorch_model.bin:   4%|██▎                                                  | 10.5M/235M [00:20<07:20, 509kB/s]pytorch_model.bin:   4%|██▎                                                  | 10.5M/235M [00:39<07:20, 509kB/s]pytorch_model.bin:   9%|████▋                                                | 21.0M/235M [00:43<07:28, 477kB/s]pytorch_model.bin:   9%|████▋                                                | 21.0M/235M [01:00<07:28, 477kB/s]pytorch_model.bin:  13%|███████                                              | 31.5M/235M [01:13<08:17, 409kB/s]pytorch_model.bin:  13%|███████                                              | 31.5M/235M [01:30<08:17, 409kB/s]pytorch_model.bin:  18%|█████████▍                                           | 41.9M/235M [01:33<07:11, 447kB/s]pytorch_model.bin:  18%|█████████▍                                           | 41.9M/235M [01:50<07:11, 447kB/s]pytorch_model.bin:  22%|███████████▊                                         | 52.4M/235M [01:52<06:16, 485kB/s]pytorch_model.bin:  22%|███████████▊                                         | 52.4M/235M [02:10<06:16, 485kB/s]pytorch_model.bin:  27%|██████████████▏                                      | 62.9M/235M [02:15<06:03, 473kB/s]pytorch_model.bin:  27%|██████████████▏                                      | 62.9M/235M [02:30<06:03, 473kB/s]pytorch_model.bin:  31%|████████████████▌                                    | 73.4M/235M [02:38<05:48, 464kB/s]pytorch_model.bin:  31%|████████████████▌                                    | 73.4M/235M [02:50<05:48, 464kB/s]pytorch_model.bin:  36%|██████████████████▉                                  | 83.9M/235M [02:59<05:18, 475kB/s]pytorch_model.bin:  36%|██████████████████▉                                  | 83.9M/235M [03:10<05:18, 475kB/s]pytorch_model.bin:  40%|█████████████████████▎                               | 94.4M/235M [03:25<05:13, 448kB/s]pytorch_model.bin:  40%|█████████████████████▎                               | 94.4M/235M [03:40<05:13, 448kB/s]pytorch_model.bin:  45%|████████████████████████                              | 105M/235M [03:57<05:20, 406kB/s]pytorch_model.bin:  45%|████████████████████████                              | 105M/235M [04:10<05:20, 406kB/s]pytorch_model.bin:  49%|██████████████████████████▌                           | 115M/235M [04:29<05:16, 378kB/s]pytorch_model.bin:  49%|██████████████████████████▌                           | 115M/235M [04:40<05:16, 378kB/s]pytorch_model.bin:  54%|████████████████████████████▉                         | 126M/235M [04:53<04:36, 394kB/s]pytorch_model.bin:  54%|████████████████████████████▉                         | 126M/235M [05:10<04:36, 394kB/s]pytorch_model.bin:  58%|███████████████████████████████▎                      | 136M/235M [05:19<04:08, 397kB/s]pytorch_model.bin:  58%|███████████████████████████████▎                      | 136M/235M [05:30<04:08, 397kB/s]pytorch_model.bin:  62%|█████████████████████████████████▋                    | 147M/235M [05:37<03:20, 440kB/s]pytorch_model.bin:  62%|█████████████████████████████████▋                    | 147M/235M [05:50<03:20, 440kB/s]pytorch_model.bin:  67%|████████████████████████████████████▏                 | 157M/235M [05:59<02:53, 447kB/s]pytorch_model.bin:  67%|████████████████████████████████████▏                 | 157M/235M [06:10<02:53, 447kB/s]pytorch_model.bin:  71%|██████████████████████████████████████▌               | 168M/235M [06:22<02:29, 448kB/s]pytorch_model.bin:  71%|██████████████████████████████████████▌               | 168M/235M [06:40<02:29, 448kB/s]pytorch_model.bin:  76%|████████████████████████████████████████▉             | 178M/235M [06:42<01:59, 472kB/s]pytorch_model.bin:  76%|████████████████████████████████████████▉             | 178M/235M [07:00<01:59, 472kB/s]pytorch_model.bin:  80%|███████████████████████████████████████████▍          | 189M/235M [07:13<01:49, 423kB/s]pytorch_model.bin:  80%|███████████████████████████████████████████▍          | 189M/235M [07:30<01:49, 423kB/s]pytorch_model.bin:  85%|█████████████████████████████████████████████▊        | 199M/235M [07:42<01:29, 400kB/s]pytorch_model.bin:  85%|█████████████████████████████████████████████▊        | 199M/235M [08:00<01:29, 400kB/s]pytorch_model.bin:  89%|████████████████████████████████████████████████▏     | 210M/235M [08:18<01:09, 362kB/s]pytorch_model.bin:  89%|████████████████████████████████████████████████▏     | 210M/235M [08:30<01:09, 362kB/s]pytorch_model.bin:  94%|██████████████████████████████████████████████████▌   | 220M/235M [08:49<00:41, 353kB/s]pytorch_model.bin:  94%|██████████████████████████████████████████████████▌   | 220M/235M [09:00<00:41, 353kB/s]pytorch_model.bin:  98%|█████████████████████████████████████████████████████ | 231M/235M [09:25<00:12, 333kB/s]pytorch_model.bin: 100%|██████████████████████████████████████████████████████| 235M/235M [09:39<00:00, 325kB/s]pytorch_model.bin: 100%|██████████████████████████████████████████████████████| 235M/235M [09:39<00:00, 405kB/s]
Some weights of the model checkpoint at ktrapeznikov/albert-xlarge-v2-squad-v2 were not used when initializing AlbertForQuestionAnswering: ['albert.pooler.weight', 'albert.pooler.bias']
- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
tokenizer_config.json:   0%|                                                         | 0.00/58.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|█████████████████████████████████████████████████| 58.0/58.0 [00:00<00:00, 15.3kB/s]
spiece.model:   0%|                                                                  | 0.00/760k [00:00<?, ?B/s]spiece.model: 100%|███████████████████████████████████████████████████████████| 760k/760k [00:01<00:00, 433kB/s]spiece.model: 100%|███████████████████████████████████████████████████████████| 760k/760k [00:01<00:00, 432kB/s]
added_tokens.json:   0%|                                                             | 0.00/2.00 [00:00<?, ?B/s]added_tokens.json: 100%|█████████████████████████████████████████████████████| 2.00/2.00 [00:00<00:00, 2.53kB/s]
special_tokens_map.json:   0%|                                                        | 0.00/156 [00:00<?, ?B/s]special_tokens_map.json: 100%|██████████████████████████████████████████████████| 156/156 [00:00<00:00, 189kB/s]
Traceback (most recent call last):
  File "./f00049_get_legal_answer.py", line 52, in <module>
    test_get_legal_answer()
  File "./f00049_get_legal_answer.py", line 44, in test_get_legal_answer
    answer = get_legal_answer(question, context)
  File "./f00049_get_legal_answer.py", line 23, in get_legal_answer
    tokenizer = AutoTokenizer.from_pretrained("ktrapeznikov/albert-xlarge-v2-squad-v2")
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 786, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2024, in from_pretrained
    return cls._from_pretrained(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2256, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/models/albert/tokenization_albert_fast.py", line 148, in __init__
    super().__init__(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py", line 120, in __init__
    raise ValueError(
ValueError: Couldn't instantiate the backend tokenizer from one of: 
(1) a `tokenizers` library serialization file, 
(2) a slow tokenizer instance to convert or 
(3) an equivalent slow tokenizer class to instantiate and convert. 
You need to have sentencepiece installed to convert a slow tokenizer to a fast one.
