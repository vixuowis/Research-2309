generation_config.json:   0%|                                                         | 0.00/147 [00:00<?, ?B/s]generation_config.json: 100%|██████████████████████████████████████████████████| 147/147 [00:00<00:00, 37.2kB/s]
/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "./f00410_generate_queries.py", line 70, in <module>
    test_generate_queries()
  File "./f00410_generate_queries.py", line 59, in test_generate_queries
    generate_queries(document3)
  File "./f00410_generate_queries.py", line 23, in generate_queries
    raise TypeError("The provided document must be a string.")
TypeError: The provided document must be a string.
