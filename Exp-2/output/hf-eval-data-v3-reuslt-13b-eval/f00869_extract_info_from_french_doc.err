2023-12-01 00:00:30.981242: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-01 00:00:31.724728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'
  warnings.warn(
config.json:   0%|                                                                    | 0.00/463 [00:00<?, ?B/s]config.json: 100%|█████████████████████████████████████████████████████████████| 463/463 [00:00<00:00, 60.6kB/s]
pytorch_model.bin:   0%|                                                             | 0.00/115M [00:00<?, ?B/s]pytorch_model.bin:   9%|████▋                                               | 10.5M/115M [00:06<01:05, 1.60MB/s]pytorch_model.bin:  18%|█████████▍                                          | 21.0M/115M [00:13<01:00, 1.56MB/s]pytorch_model.bin:  27%|██████████████▏                                     | 31.5M/115M [00:20<00:53, 1.55MB/s]pytorch_model.bin:  36%|██████████████████▉                                 | 41.9M/115M [00:32<01:02, 1.18MB/s]pytorch_model.bin:  46%|███████████████████████▋                            | 52.4M/115M [00:42<00:55, 1.13MB/s]pytorch_model.bin:  55%|████████████████████████████▍                       | 62.9M/115M [00:53<00:48, 1.07MB/s]pytorch_model.bin:  64%|█████████████████████████████████▏                  | 73.4M/115M [01:02<00:38, 1.07MB/s]pytorch_model.bin:  73%|█████████████████████████████████████▉              | 83.9M/115M [01:12<00:28, 1.08MB/s]pytorch_model.bin:  82%|██████████████████████████████████████████▋         | 94.4M/115M [01:20<00:17, 1.16MB/s]pytorch_model.bin:  91%|████████████████████████████████████████████████▎    | 105M/115M [01:30<00:09, 1.12MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 115M/115M [01:39<00:00, 1.10MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 115M/115M [01:39<00:00, 1.15MB/s]
Some weights of the model checkpoint at mrm8488/bert-small-finetuned-squadv2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
tokenizer_config.json:   0%|                                                         | 0.00/23.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|█████████████████████████████████████████████████| 23.0/23.0 [00:00<00:00, 16.4kB/s]
vocab.txt:   0%|                                                                     | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 280kB/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 280kB/s]
special_tokens_map.json:   0%|                                                        | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|█████████████████████████████████████████████████| 112/112 [00:00<00:00, 99.1kB/s]
Some weights of the model checkpoint at mrm8488/bert-small-finetuned-squadv2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at mrm8488/bert-small-finetuned-squadv2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
