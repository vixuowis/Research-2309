tokenizer_config.json:   0%|                                                         | 0.00/90.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|█████████████████████████████████████████████████| 90.0/90.0 [00:00<00:00, 16.1kB/s]
config.json:   0%|                                                                    | 0.00/656 [00:00<?, ?B/s]config.json: 100%|██████████████████████████████████████████████████████████████| 656/656 [00:00<00:00, 115kB/s]
spiece.model:   0%|                                                                  | 0.00/792k [00:00<?, ?B/s]spiece.model: 100%|███████████████████████████████████████████████████████████| 792k/792k [00:03<00:00, 243kB/s]spiece.model: 100%|███████████████████████████████████████████████████████████| 792k/792k [00:03<00:00, 243kB/s]
added_tokens.json:   0%|                                                             | 0.00/31.0 [00:00<?, ?B/s]added_tokens.json: 100%|█████████████████████████████████████████████████████| 31.0/31.0 [00:00<00:00, 41.2kB/s]
special_tokens_map.json:   0%|                                                       | 0.00/65.0 [00:00<?, ?B/s]special_tokens_map.json: 100%|███████████████████████████████████████████████| 65.0/65.0 [00:00<00:00, 76.3kB/s]
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
pytorch_model.bin:   0%|                                                             | 0.00/242M [00:00<?, ?B/s]pytorch_model.bin:   4%|██▎                                                 | 10.5M/242M [00:08<03:10, 1.21MB/s]pytorch_model.bin:   9%|████▌                                               | 21.0M/242M [00:16<02:57, 1.24MB/s]pytorch_model.bin:  13%|██████▊                                             | 31.5M/242M [00:26<02:57, 1.18MB/s]pytorch_model.bin:  17%|█████████▏                                           | 41.9M/242M [00:39<03:21, 991kB/s]pytorch_model.bin:  22%|███████████▍                                         | 52.4M/242M [00:52<03:27, 914kB/s]pytorch_model.bin:  22%|███████████▍                                         | 52.4M/242M [01:04<03:27, 914kB/s]pytorch_model.bin:  26%|█████████████▊                                       | 62.9M/242M [01:07<03:33, 839kB/s]pytorch_model.bin:  30%|████████████████                                     | 73.4M/242M [01:17<03:11, 879kB/s]pytorch_model.bin:  35%|██████████████████▎                                  | 83.9M/242M [01:29<02:56, 895kB/s]pytorch_model.bin:  39%|████████████████████▋                                | 94.4M/242M [01:41<02:47, 883kB/s]pytorch_model.bin:  39%|████████████████████▋                                | 94.4M/242M [01:54<02:47, 883kB/s]pytorch_model.bin:  43%|███████████████████████▍                              | 105M/242M [01:55<02:43, 838kB/s]pytorch_model.bin:  48%|█████████████████████████▋                            | 115M/242M [02:05<02:21, 896kB/s]pytorch_model.bin:  52%|████████████████████████████                          | 126M/242M [02:15<02:04, 934kB/s]pytorch_model.bin:  56%|█████████████████████████████▊                       | 136M/242M [02:23<01:45, 1.00MB/s]pytorch_model.bin:  61%|████████████████████████████████▏                    | 147M/242M [02:31<01:28, 1.08MB/s]pytorch_model.bin:  65%|██████████████████████████████████▍                  | 157M/242M [02:39<01:13, 1.15MB/s]pytorch_model.bin:  69%|████████████████████████████████████▋                | 168M/242M [02:50<01:09, 1.07MB/s]pytorch_model.bin:  74%|███████████████████████████████████████              | 178M/242M [03:01<01:01, 1.04MB/s]pytorch_model.bin:  74%|███████████████████████████████████████              | 178M/242M [03:14<01:01, 1.04MB/s]pytorch_model.bin:  78%|██████████████████████████████████████████            | 189M/242M [03:14<00:55, 956kB/s]pytorch_model.bin:  82%|████████████████████████████████████████████▍         | 199M/242M [03:29<00:49, 867kB/s]pytorch_model.bin:  82%|████████████████████████████████████████████▍         | 199M/242M [03:44<00:49, 867kB/s]pytorch_model.bin:  87%|██████████████████████████████████████████████▊       | 210M/242M [03:48<00:43, 744kB/s]pytorch_model.bin:  87%|██████████████████████████████████████████████▊       | 210M/242M [04:04<00:43, 744kB/s]pytorch_model.bin:  91%|█████████████████████████████████████████████████▏    | 220M/242M [04:06<00:31, 686kB/s]pytorch_model.bin:  95%|███████████████████████████████████████████████████▍  | 231M/242M [04:18<00:15, 725kB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████▊| 241M/242M [04:29<00:01, 779kB/s]pytorch_model.bin: 100%|██████████████████████████████████████████████████████| 242M/242M [04:31<00:00, 772kB/s]pytorch_model.bin: 100%|██████████████████████████████████████████████████████| 242M/242M [04:31<00:00, 892kB/s]
Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at valhalla/t5-small-qa-qg-hl and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "./f00395_answer_question.py", line 56, in <module>
    test_answer_question()
  File "./f00395_answer_question.py", line 41, in test_answer_question
    assert answer_question(question1, context1) == 'Paris'
AssertionError
