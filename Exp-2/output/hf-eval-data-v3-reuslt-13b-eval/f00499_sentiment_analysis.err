2023-11-30 19:50:15.425296: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-30 19:50:16.194265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
config.json:   0%|                                                                  | 0.00/1.39k [00:00<?, ?B/s]config.json: 100%|██████████████████████████████████████████████████████████| 1.39k/1.39k [00:00<00:00, 322kB/s]
pytorch_model.bin:   0%|                                                            | 0.00/1.23G [00:00<?, ?B/s]pytorch_model.bin:   1%|▍                                                  | 10.5M/1.23G [00:04<08:36, 2.35MB/s]pytorch_model.bin:   2%|▊                                                  | 21.0M/1.23G [00:07<06:23, 3.14MB/s]pytorch_model.bin:   3%|█▎                                                 | 31.5M/1.23G [00:10<06:10, 3.22MB/s]pytorch_model.bin:   3%|█▋                                                 | 41.9M/1.23G [00:13<05:56, 3.32MB/s]pytorch_model.bin:   4%|██▏                                                | 52.4M/1.23G [00:16<05:41, 3.44MB/s]pytorch_model.bin:   5%|██▌                                                | 62.9M/1.23G [00:18<05:15, 3.68MB/s]pytorch_model.bin:   6%|███                                                | 73.4M/1.23G [00:21<05:25, 3.55MB/s]pytorch_model.bin:   7%|███▍                                               | 83.9M/1.23G [00:26<06:20, 3.00MB/s]pytorch_model.bin:   8%|███▉                                               | 94.4M/1.23G [00:34<08:54, 2.12MB/s]pytorch_model.bin:   8%|███▉                                               | 94.4M/1.23G [00:45<08:54, 2.12MB/s]pytorch_model.bin:   9%|████▍                                               | 105M/1.23G [00:48<13:33, 1.38MB/s]pytorch_model.bin:   9%|████▉                                               | 115M/1.23G [01:01<16:26, 1.13MB/s]pytorch_model.bin:  10%|█████▎                                              | 126M/1.23G [01:12<17:12, 1.07MB/s]pytorch_model.bin:  10%|█████▎                                              | 126M/1.23G [01:25<17:12, 1.07MB/s]pytorch_model.bin:  11%|█████▉                                               | 136M/1.23G [01:26<19:08, 949kB/s]pytorch_model.bin:  12%|██████▏                                             | 147M/1.23G [01:35<17:59, 1.00MB/s]pytorch_model.bin:  13%|██████▋                                             | 157M/1.23G [01:42<16:08, 1.10MB/s]pytorch_model.bin:  14%|███████                                             | 168M/1.23G [01:51<15:46, 1.12MB/s]pytorch_model.bin:  15%|███████▌                                            | 178M/1.23G [02:01<15:52, 1.10MB/s]pytorch_model.bin:  15%|████████                                            | 189M/1.23G [02:11<15:48, 1.09MB/s]pytorch_model.bin:  16%|████████▍                                           | 199M/1.23G [02:17<14:16, 1.20MB/s]pytorch_model.bin:  17%|████████▉                                           | 210M/1.23G [02:24<12:56, 1.31MB/s]pytorch_model.bin:  18%|█████████▎                                          | 220M/1.23G [02:30<11:50, 1.42MB/s]pytorch_model.bin:  19%|█████████▊                                          | 231M/1.23G [02:36<11:16, 1.47MB/s]pytorch_model.bin:  20%|██████████▏                                         | 241M/1.23G [02:43<10:54, 1.51MB/s]pytorch_model.bin:  21%|██████████▋                                         | 252M/1.23G [02:51<11:11, 1.45MB/s]pytorch_model.bin:  21%|███████████                                         | 262M/1.23G [02:57<10:47, 1.49MB/s]pytorch_model.bin:  22%|███████████▌                                        | 273M/1.23G [03:03<10:18, 1.54MB/s]pytorch_model.bin:  23%|████████████                                        | 283M/1.23G [03:10<09:53, 1.59MB/s]pytorch_model.bin:  24%|████████████▍                                       | 294M/1.23G [03:15<09:10, 1.69MB/s]pytorch_model.bin:  25%|████████████▉                                       | 304M/1.23G [03:20<08:43, 1.76MB/s]pytorch_model.bin:  26%|█████████████▎                                      | 315M/1.23G [03:25<08:10, 1.86MB/s]pytorch_model.bin:  27%|█████████████▊                                      | 325M/1.23G [03:29<07:29, 2.01MB/s]pytorch_model.bin:  27%|██████████████▏                                     | 336M/1.23G [03:34<07:10, 2.07MB/s]pytorch_model.bin:  28%|██████████████▋                                     | 346M/1.23G [03:39<07:08, 2.05MB/s]pytorch_model.bin:  29%|███████████████                                     | 357M/1.23G [03:45<07:15, 2.00MB/s]pytorch_model.bin:  30%|███████████████▌                                    | 367M/1.23G [03:52<07:44, 1.85MB/s]pytorch_model.bin:  31%|████████████████                                    | 377M/1.23G [03:57<07:42, 1.84MB/s]pytorch_model.bin:  32%|████████████████▍                                   | 388M/1.23G [04:06<08:38, 1.62MB/s]pytorch_model.bin:  32%|████████████████▉                                   | 398M/1.23G [04:24<13:16, 1.04MB/s]pytorch_model.bin:  32%|████████████████▉                                   | 398M/1.23G [04:35<13:16, 1.04MB/s]pytorch_model.bin:  33%|█████████████████▋                                   | 409M/1.23G [04:50<19:21, 704kB/s]pytorch_model.bin:  33%|█████████████████▋                                   | 409M/1.23G [05:05<19:21, 704kB/s]pytorch_model.bin:  34%|██████████████████▏                                  | 419M/1.23G [05:23<25:52, 520kB/s]pytorch_model.bin:  34%|██████████████████▏                                  | 419M/1.23G [05:35<25:52, 520kB/s]pytorch_model.bin:  35%|██████████████████▌                                  | 430M/1.23G [05:50<28:07, 472kB/s]pytorch_model.bin:  36%|███████████████████                                  | 440M/1.23G [06:04<24:43, 530kB/s]pytorch_model.bin:  37%|███████████████████▍                                 | 451M/1.23G [06:14<20:49, 621kB/s]pytorch_model.bin:  38%|███████████████████▉                                 | 461M/1.23G [06:22<17:13, 741kB/s]pytorch_model.bin:  38%|████████████████████▍                                | 472M/1.23G [06:29<14:38, 859kB/s]pytorch_model.bin:  39%|████████████████████▊                                | 482M/1.23G [06:36<12:28, 994kB/s]pytorch_model.bin:  40%|████████████████████▉                               | 493M/1.23G [06:44<11:29, 1.06MB/s]pytorch_model.bin:  41%|█████████████████████▎                              | 503M/1.23G [06:52<10:41, 1.13MB/s]pytorch_model.bin:  42%|█████████████████████▊                              | 514M/1.23G [06:59<09:46, 1.21MB/s]pytorch_model.bin:  43%|██████████████████████▏                             | 524M/1.23G [07:05<08:27, 1.38MB/s]pytorch_model.bin:  44%|██████████████████████▋                             | 535M/1.23G [07:10<07:31, 1.53MB/s]pytorch_model.bin:  44%|███████████████████████                             | 545M/1.23G [07:17<07:29, 1.52MB/s]pytorch_model.bin:  45%|███████████████████████▌                            | 556M/1.23G [07:23<07:02, 1.59MB/s]pytorch_model.bin:  46%|████████████████████████                            | 566M/1.23G [07:28<06:24, 1.72MB/s]pytorch_model.bin:  47%|████████████████████████▍                           | 577M/1.23G [07:34<06:22, 1.70MB/s]pytorch_model.bin:  48%|████████████████████████▉                           | 587M/1.23G [07:45<07:37, 1.40MB/s]pytorch_model.bin:  48%|████████████████████████▉                           | 587M/1.23G [07:55<07:37, 1.40MB/s]pytorch_model.bin:  49%|█████████████████████████▎                          | 598M/1.23G [07:58<09:19, 1.12MB/s]pytorch_model.bin:  50%|█████████████████████████▊                          | 608M/1.23G [08:10<09:50, 1.05MB/s]pytorch_model.bin:  50%|██████████████████████████▋                          | 619M/1.23G [08:25<11:08, 910kB/s]pytorch_model.bin:  50%|██████████████████████████▋                          | 619M/1.23G [08:35<11:08, 910kB/s]pytorch_model.bin:  51%|███████████████████████████▏                         | 629M/1.23G [08:37<11:00, 904kB/s]pytorch_model.bin:  52%|███████████████████████████▋                         | 640M/1.23G [08:46<10:20, 946kB/s]pytorch_model.bin:  53%|████████████████████████████                         | 650M/1.23G [08:56<09:47, 981kB/s]pytorch_model.bin:  53%|████████████████████████████                         | 650M/1.23G [09:15<09:47, 981kB/s]pytorch_model.bin:  54%|████████████████████████████▌                        | 661M/1.23G [09:16<11:59, 786kB/s]pytorch_model.bin:  55%|█████████████████████████████                        | 671M/1.23G [09:24<10:32, 878kB/s]pytorch_model.bin:  56%|█████████████████████████████▍                       | 682M/1.23G [09:33<09:23, 967kB/s]pytorch_model.bin:  56%|█████████████████████████████▎                      | 692M/1.23G [09:40<08:26, 1.06MB/s]pytorch_model.bin:  57%|█████████████████████████████▊                      | 703M/1.23G [09:47<07:28, 1.17MB/s]pytorch_model.bin:  58%|██████████████████████████████▏                     | 713M/1.23G [09:54<06:41, 1.28MB/s]pytorch_model.bin:  59%|██████████████████████████████▋                     | 724M/1.23G [10:02<06:30, 1.29MB/s]pytorch_model.bin:  60%|███████████████████████████████                     | 734M/1.23G [10:08<05:59, 1.37MB/s]pytorch_model.bin:  61%|███████████████████████████████▌                    | 744M/1.23G [10:16<05:48, 1.38MB/s]pytorch_model.bin:  62%|████████████████████████████████                    | 755M/1.23G [10:23<05:36, 1.40MB/s]pytorch_model.bin:  62%|████████████████████████████████▍                   | 765M/1.23G [10:31<05:32, 1.39MB/s]pytorch_model.bin:  63%|████████████████████████████████▉                   | 776M/1.23G [10:38<05:25, 1.38MB/s]pytorch_model.bin:  64%|█████████████████████████████████▎                  | 786M/1.23G [10:47<05:35, 1.31MB/s]pytorch_model.bin:  65%|█████████████████████████████████▊                  | 797M/1.23G [10:58<05:57, 1.20MB/s]pytorch_model.bin:  66%|██████████████████████████████████▏                 | 807M/1.23G [11:07<05:52, 1.19MB/s]pytorch_model.bin:  67%|██████████████████████████████████▋                 | 818M/1.23G [11:15<05:39, 1.20MB/s]pytorch_model.bin:  68%|███████████████████████████████████                 | 828M/1.23G [11:24<05:36, 1.18MB/s]pytorch_model.bin:  68%|███████████████████████████████████▌                | 839M/1.23G [11:32<05:18, 1.22MB/s]pytorch_model.bin:  69%|████████████████████████████████████                | 849M/1.23G [11:40<05:03, 1.24MB/s]pytorch_model.bin:  70%|████████████████████████████████████▍               | 860M/1.23G [11:46<04:27, 1.37MB/s]pytorch_model.bin:  71%|████████████████████████████████████▉               | 870M/1.23G [11:51<03:52, 1.53MB/s]pytorch_model.bin:  72%|█████████████████████████████████████▎              | 881M/1.23G [11:57<03:32, 1.63MB/s]pytorch_model.bin:  73%|█████████████████████████████████████▊              | 891M/1.23G [12:04<03:33, 1.57MB/s]pytorch_model.bin:  74%|██████████████████████████████████████▏             | 902M/1.23G [12:11<03:33, 1.52MB/s]pytorch_model.bin:  74%|██████████████████████████████████████▋             | 912M/1.23G [12:17<03:13, 1.62MB/s]pytorch_model.bin:  75%|███████████████████████████████████████▏            | 923M/1.23G [12:23<03:01, 1.67MB/s]pytorch_model.bin:  76%|███████████████████████████████████████▌            | 933M/1.23G [12:28<02:47, 1.75MB/s]pytorch_model.bin:  77%|████████████████████████████████████████            | 944M/1.23G [12:33<02:38, 1.78MB/s]pytorch_model.bin:  78%|████████████████████████████████████████▍           | 954M/1.23G [12:39<02:33, 1.78MB/s]pytorch_model.bin:  79%|████████████████████████████████████████▉           | 965M/1.23G [12:47<02:41, 1.62MB/s]pytorch_model.bin:  80%|█████████████████████████████████████████▎          | 975M/1.23G [12:55<02:47, 1.50MB/s]pytorch_model.bin:  80%|█████████████████████████████████████████▊          | 986M/1.23G [13:05<02:58, 1.35MB/s]pytorch_model.bin:  80%|█████████████████████████████████████████▊          | 986M/1.23G [13:15<02:58, 1.35MB/s]pytorch_model.bin:  81%|██████████████████████████████████████████▏         | 996M/1.23G [13:16<03:09, 1.21MB/s]pytorch_model.bin:  82%|█████████████████████████████████████████▊         | 1.01G/1.23G [13:25<03:03, 1.20MB/s]pytorch_model.bin:  83%|██████████████████████████████████████████▎        | 1.02G/1.23G [13:31<02:41, 1.30MB/s]pytorch_model.bin:  84%|██████████████████████████████████████████▋        | 1.03G/1.23G [13:43<02:57, 1.12MB/s]pytorch_model.bin:  85%|███████████████████████████████████████████▏       | 1.04G/1.23G [13:54<02:56, 1.07MB/s]pytorch_model.bin:  85%|███████████████████████████████████████████▏       | 1.04G/1.23G [14:05<02:56, 1.07MB/s]pytorch_model.bin:  86%|████████████████████████████████████████████▍       | 1.05G/1.23G [14:07<03:03, 971kB/s]pytorch_model.bin:  86%|████████████████████████████████████████████▉       | 1.06G/1.23G [14:18<02:50, 980kB/s]pytorch_model.bin:  87%|█████████████████████████████████████████████▎      | 1.07G/1.23G [14:30<02:46, 940kB/s]pytorch_model.bin:  88%|█████████████████████████████████████████████▊      | 1.08G/1.23G [14:41<02:33, 951kB/s]pytorch_model.bin:  89%|██████████████████████████████████████████████▏     | 1.09G/1.23G [14:51<02:20, 969kB/s]pytorch_model.bin:  90%|█████████████████████████████████████████████▊     | 1.10G/1.23G [14:59<01:59, 1.05MB/s]pytorch_model.bin:  91%|██████████████████████████████████████████████▏    | 1.11G/1.23G [15:06<01:40, 1.15MB/s]pytorch_model.bin:  91%|██████████████████████████████████████████████▋    | 1.12G/1.23G [15:12<01:20, 1.29MB/s]pytorch_model.bin:  92%|███████████████████████████████████████████████    | 1.13G/1.23G [15:18<01:07, 1.39MB/s]pytorch_model.bin:  93%|███████████████████████████████████████████████▌   | 1.14G/1.23G [15:25<00:57, 1.45MB/s]pytorch_model.bin:  94%|███████████████████████████████████████████████▉   | 1.15G/1.23G [15:33<00:52, 1.40MB/s]pytorch_model.bin:  95%|████████████████████████████████████████████████▍  | 1.16G/1.23G [15:43<00:48, 1.28MB/s]pytorch_model.bin:  96%|████████████████████████████████████████████████▊  | 1.17G/1.23G [15:52<00:41, 1.24MB/s]pytorch_model.bin:  97%|█████████████████████████████████████████████████▎ | 1.18G/1.23G [16:03<00:36, 1.15MB/s]pytorch_model.bin:  97%|█████████████████████████████████████████████████▋ | 1.20G/1.23G [16:13<00:28, 1.09MB/s]pytorch_model.bin:  98%|██████████████████████████████████████████████████▏| 1.21G/1.23G [16:23<00:19, 1.07MB/s]pytorch_model.bin:  98%|██████████████████████████████████████████████████▏| 1.21G/1.23G [16:35<00:19, 1.07MB/s]pytorch_model.bin:  99%|███████████████████████████████████████████████████▌| 1.22G/1.23G [16:37<00:10, 954kB/s]pytorch_model.bin: 100%|███████████████████████████████████████████████████| 1.23G/1.23G [16:46<00:00, 1.00MB/s]pytorch_model.bin: 100%|███████████████████████████████████████████████████| 1.23G/1.23G [16:46<00:00, 1.22MB/s]
Traceback (most recent call last):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/ssl.py", line 1073, in _create
    self.do_handshake()
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/ssl.py", line 1342, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1114: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /valhalla/distilbart-mnli-12-6/resolve/main/tokenizer_config.json (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./f00499_sentiment_analysis.py", line 40, in <module>
    test_sentiment_analysis()
  File "./f00499_sentiment_analysis.py", line 32, in test_sentiment_analysis
    assert sentiment_analysis('The movie was great!')['labels'][0] == 'positive'
  File "./f00499_sentiment_analysis.py", line 18, in sentiment_analysis
    classifier = pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-6')
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 967, in pipeline
    tokenizer = AutoTokenizer.from_pretrained(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 718, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 550, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1247, in hf_hub_download
    metadata = get_hf_file_metadata(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1624, in get_hf_file_metadata
    r = _request_wrapper(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 402, in _request_wrapper
    response = _request_wrapper(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 425, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_http.py", line 63, in send
    return super().send(request, *args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/adapters.py", line 513, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /valhalla/distilbart-mnli-12-6/resolve/main/tokenizer_config.json (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out')))"), '(Request ID: 11f5f275-c66b-48c5-a739-ecafca5d0491)')
