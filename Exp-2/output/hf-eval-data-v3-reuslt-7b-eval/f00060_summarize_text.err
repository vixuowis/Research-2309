tokenizer_config.json:   0%|                                                        | 0.00/1.19k [00:00<?, ?B/s]tokenizer_config.json: 100%|████████████████████████████████████████████████| 1.19k/1.19k [00:00<00:00, 246kB/s]
config.json:   0%|                                                                  | 0.00/1.05k [00:00<?, ?B/s]config.json: 100%|██████████████████████████████████████████████████████████| 1.05k/1.05k [00:00<00:00, 258kB/s]
spiece.model:   0%|                                                                 | 0.00/1.92M [00:00<?, ?B/s]spiece.model: 100%|█████████████████████████████████████████████████████████| 1.92M/1.92M [00:09<00:00, 207kB/s]spiece.model: 100%|█████████████████████████████████████████████████████████| 1.92M/1.92M [00:09<00:00, 207kB/s]
tokenizer.json:   0%|                                                               | 0.00/3.51M [00:00<?, ?B/s]tokenizer.json: 100%|███████████████████████████████████████████████████████| 3.51M/3.51M [00:17<00:00, 201kB/s]tokenizer.json: 100%|███████████████████████████████████████████████████████| 3.51M/3.51M [00:17<00:00, 201kB/s]
special_tokens_map.json:   0%|                                                        | 0.00/775 [00:00<?, ?B/s]special_tokens_map.json: 100%|██████████████████████████████████████████████████| 775/775 [00:00<00:00, 519kB/s]
pytorch_model.bin:   0%|                                                            | 0.00/2.31G [00:00<?, ?B/s]pytorch_model.bin:   0%|                                                            | 0.00/2.31G [02:38<?, ?B/s]
Traceback (most recent call last):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 712, in _error_catcher
    yield
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 833, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
urllib3.exceptions.IncompleteRead: IncompleteRead(8666198 bytes read, 2299481961 more expected)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 934, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 905, in read
    data = self._raw_read(amt)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 833, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 729, in _error_catcher
    raise ProtocolError(f"Connection broken: {e!r}", e) from e
urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(8666198 bytes read, 2299481961 more expected)', IncompleteRead(8666198 bytes read, 2299481961 more expected))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./f00060_summarize_text.py", line 43, in <module>
    test_summarize_text()
  File "./f00060_summarize_text.py", line 36, in test_summarize_text
    assert len(summarize_text(test_text1)) < len(test_text1)
  File "./f00060_summarize_text.py", line 19, in summarize_text
    model = BigBirdPegasusForConditionalGeneration.from_pretrained('google/bigbird-pegasus-large-arxiv')
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3057, in from_pretrained
    resolved_archive_file = cached_file(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1461, in hf_hub_download
    http_get(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 541, in http_get
    for chunk in r.iter_content(chunk_size=DOWNLOAD_CHUNK_SIZE):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/models.py", line 818, in generate
    raise ChunkedEncodingError(e)
requests.exceptions.ChunkedEncodingError: ('Connection broken: IncompleteRead(8666198 bytes read, 2299481961 more expected)', IncompleteRead(8666198 bytes read, 2299481961 more expected))
