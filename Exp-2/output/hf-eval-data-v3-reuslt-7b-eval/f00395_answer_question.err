config.json:   0%|                                                                    | 0.00/493 [00:00<?, ?B/s]config.json: 100%|█████████████████████████████████████████████████████████████| 493/493 [00:00<00:00, 70.5kB/s]
model.safetensors:   0%|                                                             | 0.00/433M [00:00<?, ?B/s]model.safetensors:   2%|█▎                                                  | 10.5M/433M [00:02<01:31, 4.63MB/s]model.safetensors:   5%|██▌                                                 | 21.0M/433M [00:03<00:54, 7.51MB/s]model.safetensors:   7%|███▊                                                | 31.5M/433M [00:03<00:44, 9.09MB/s]model.safetensors:  10%|█████                                               | 41.9M/433M [00:04<00:38, 10.3MB/s]model.safetensors:  12%|██████▎                                             | 52.4M/433M [00:05<00:33, 11.5MB/s]model.safetensors:  15%|███████▌                                            | 62.9M/433M [00:06<00:35, 10.3MB/s]model.safetensors:  17%|████████▊                                           | 73.4M/433M [00:08<00:38, 9.36MB/s]model.safetensors:  19%|██████████                                          | 83.9M/433M [00:09<00:37, 9.34MB/s]model.safetensors:  22%|███████████▎                                        | 94.4M/433M [00:10<00:33, 9.98MB/s]model.safetensors:  24%|████████████▊                                        | 105M/433M [00:11<00:40, 8.06MB/s]model.safetensors:  27%|██████████████                                       | 115M/433M [00:16<01:13, 4.30MB/s]model.safetensors:  29%|███████████████▍                                     | 126M/433M [00:24<01:56, 2.64MB/s]model.safetensors:  31%|████████████████▋                                    | 136M/433M [00:32<02:28, 2.00MB/s]model.safetensors:  34%|█████████████████▉                                   | 147M/433M [00:42<03:02, 1.57MB/s]model.safetensors:  36%|███████████████████▏                                 | 157M/433M [00:54<03:36, 1.28MB/s]model.safetensors:  39%|████████████████████▌                                | 168M/433M [01:04<03:45, 1.17MB/s]model.safetensors:  41%|█████████████████████▊                               | 178M/433M [01:08<02:59, 1.42MB/s]model.safetensors:  44%|███████████████████████                              | 189M/433M [01:11<02:18, 1.76MB/s]model.safetensors:  46%|████████████████████████▎                            | 199M/433M [01:13<01:46, 2.19MB/s]model.safetensors:  48%|█████████████████████████▋                           | 210M/433M [01:15<01:23, 2.69MB/s]model.safetensors:  51%|██████████████████████████▉                          | 220M/433M [01:16<01:05, 3.25MB/s]model.safetensors:  53%|████████████████████████████▏                        | 231M/433M [01:18<00:51, 3.91MB/s]model.safetensors:  56%|█████████████████████████████▌                       | 241M/433M [01:19<00:42, 4.50MB/s]model.safetensors:  58%|██████████████████████████████▊                      | 252M/433M [01:21<00:38, 4.71MB/s]model.safetensors:  61%|████████████████████████████████                     | 262M/433M [01:31<01:13, 2.33MB/s]model.safetensors:  63%|█████████████████████████████████▎                   | 273M/433M [01:37<01:16, 2.09MB/s]model.safetensors:  65%|██████████████████████████████████▋                  | 283M/433M [01:42<01:10, 2.14MB/s]model.safetensors:  68%|███████████████████████████████████▉                 | 294M/433M [01:49<01:13, 1.90MB/s]model.safetensors:  70%|█████████████████████████████████████▏               | 304M/433M [01:53<01:02, 2.06MB/s]model.safetensors:  73%|██████████████████████████████████████▍              | 315M/433M [01:57<00:52, 2.27MB/s]model.safetensors:  75%|███████████████████████████████████████▊             | 325M/433M [02:00<00:43, 2.49MB/s]model.safetensors:  77%|█████████████████████████████████████████            | 336M/433M [02:02<00:33, 2.88MB/s]model.safetensors:  80%|██████████████████████████████████████████▎          | 346M/433M [02:04<00:26, 3.35MB/s]model.safetensors:  82%|███████████████████████████████████████████▌         | 357M/433M [02:06<00:20, 3.68MB/s]model.safetensors:  85%|████████████████████████████████████████████▉        | 367M/433M [02:08<00:15, 4.15MB/s]model.safetensors:  87%|██████████████████████████████████████████████▏      | 377M/433M [02:11<00:14, 3.89MB/s]model.safetensors:  90%|███████████████████████████████████████████████▍     | 388M/433M [02:14<00:12, 3.73MB/s]model.safetensors:  92%|████████████████████████████████████████████████▋    | 398M/433M [02:20<00:11, 2.94MB/s]model.safetensors:  94%|██████████████████████████████████████████████████   | 409M/433M [02:27<00:10, 2.25MB/s]model.safetensors:  97%|███████████████████████████████████████████████████▎ | 419M/433M [02:31<00:06, 2.28MB/s]model.safetensors:  99%|████████████████████████████████████████████████████▌| 430M/433M [02:36<00:01, 2.25MB/s]model.safetensors: 100%|█████████████████████████████████████████████████████| 433M/433M [02:37<00:00, 2.27MB/s]model.safetensors: 100%|█████████████████████████████████████████████████████| 433M/433M [02:37<00:00, 2.74MB/s]
Some weights of the model checkpoint at mrm8488/spanbert-finetuned-squadv2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']
- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
tokenizer_config.json:   0%|                                                         | 0.00/24.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|█████████████████████████████████████████████████| 24.0/24.0 [00:00<00:00, 4.96kB/s]
vocab.txt:   0%|                                                                     | 0.00/213k [00:00<?, ?B/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 213k/213k [00:01<00:00, 211kB/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 213k/213k [00:01<00:00, 211kB/s]
special_tokens_map.json:   0%|                                                        | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|█████████████████████████████████████████████████| 112/112 [00:00<00:00, 41.4kB/s]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Traceback (most recent call last):
  File "./f00395_answer_question.py", line 72, in <module>
    test_answer_question()
  File "./f00395_answer_question.py", line 57, in test_answer_question
    assert answer_question(question1, context1) == 'Paris'
AssertionError
