2023-11-30 16:54:38.776545: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-30 16:54:39.527822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
model.safetensors:   0%|                                                             | 0.00/496M [00:00<?, ?B/s]model.safetensors:   2%|█                                                 | 10.5M/496M [09:12<7:06:12, 19.0kB/s]model.safetensors:   2%|█                                                 | 10.5M/496M [09:30<7:06:12, 19.0kB/s]model.safetensors:   2%|█                                                | 10.5M/496M [15:48<12:12:20, 11.1kB/s]
Traceback (most recent call last):
  File "./f00051_get_answer_from_document.py", line 23, in get_answer_from_document
    model = AutoModel.from_pretrained("deepset/roberta-base-squad2-distilled")
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 566, in from_pretrained
    return model_class.from_pretrained(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3037, in from_pretrained
    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1461, in hf_hub_download
    http_get(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 541, in http_get
    for chunk in r.iter_content(chunk_size=DOWNLOAD_CHUNK_SIZE):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 934, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 877, in read
    data = self._raw_read(amt)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 812, in _raw_read
    data = self._fp_read(amt) if not fp_closed else b""
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 797, in _fp_read
    return self._fp.read(amt) if amt is not None else self._fp.read()
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/ssl.py", line 1274, in recv_into
    return self.read(nbytes, buffer)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/ssl.py", line 1132, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./f00051_get_answer_from_document.py", line 58, in <module>
    test_get_answer_from_document()
  File "./f00051_get_answer_from_document.py", line 43, in test_get_answer_from_document
    assert get_answer_from_document(context, question) is not None
  File "./f00051_get_answer_from_document.py", line 26, in get_answer_from_document
    raise Exception("Error initializing the model and its tokenizer. Please make sure you have downloaded them correctly.")
Exception: Error initializing the model and its tokenizer. Please make sure you have downloaded them correctly.
