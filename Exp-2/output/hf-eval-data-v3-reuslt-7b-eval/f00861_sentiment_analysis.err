2023-12-01 00:03:57.479785: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-01 00:03:58.312433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'
  warnings.warn(
config.json:   0%|                                                                    | 0.00/735 [00:00<?, ?B/s]config.json: 100%|██████████████████████████████████████████████████████████████| 735/735 [00:00<00:00, 160kB/s]
pytorch_model.bin:   0%|                                                             | 0.00/268M [00:00<?, ?B/s]pytorch_model.bin:   4%|██                                                  | 10.5M/268M [00:04<01:46, 2.41MB/s]pytorch_model.bin:   8%|████                                                | 21.0M/268M [00:07<01:21, 3.05MB/s]pytorch_model.bin:  12%|██████                                              | 31.5M/268M [00:09<01:07, 3.49MB/s]pytorch_model.bin:  16%|████████▏                                           | 41.9M/268M [00:12<00:59, 3.80MB/s]pytorch_model.bin:  20%|██████████▏                                         | 52.4M/268M [00:14<00:55, 3.90MB/s]pytorch_model.bin:  23%|████████████▏                                       | 62.9M/268M [00:18<00:59, 3.44MB/s]pytorch_model.bin:  27%|██████████████▏                                     | 73.4M/268M [00:21<00:54, 3.58MB/s]pytorch_model.bin:  31%|████████████████▎                                   | 83.9M/268M [00:23<00:49, 3.75MB/s]pytorch_model.bin:  35%|██████████████████▎                                 | 94.4M/268M [00:26<00:47, 3.65MB/s]pytorch_model.bin:  39%|████████████████████▋                                | 105M/268M [00:29<00:42, 3.82MB/s]pytorch_model.bin:  43%|██████████████████████▊                              | 115M/268M [00:32<00:41, 3.70MB/s]pytorch_model.bin:  47%|████████████████████████▉                            | 126M/268M [00:35<00:41, 3.43MB/s]pytorch_model.bin:  51%|██████████████████████████▉                          | 136M/268M [00:37<00:34, 3.86MB/s]pytorch_model.bin:  55%|█████████████████████████████                        | 147M/268M [00:39<00:28, 4.31MB/s]pytorch_model.bin:  59%|███████████████████████████████                      | 157M/268M [00:41<00:23, 4.63MB/s]pytorch_model.bin:  63%|█████████████████████████████████▏                   | 168M/268M [00:43<00:20, 4.78MB/s]pytorch_model.bin:  67%|███████████████████████████████████▎                 | 178M/268M [00:45<00:17, 5.05MB/s]pytorch_model.bin:  70%|█████████████████████████████████████▎               | 189M/268M [00:47<00:15, 5.06MB/s]pytorch_model.bin:  74%|███████████████████████████████████████▍             | 199M/268M [00:48<00:13, 5.22MB/s]pytorch_model.bin:  78%|█████████████████████████████████████████▍           | 210M/268M [00:51<00:11, 4.97MB/s]pytorch_model.bin:  82%|███████████████████████████████████████████▌         | 220M/268M [00:53<00:10, 4.76MB/s]pytorch_model.bin:  86%|█████████████████████████████████████████████▋       | 231M/268M [00:56<00:08, 4.45MB/s]pytorch_model.bin:  90%|███████████████████████████████████████████████▋     | 241M/268M [00:59<00:06, 4.13MB/s]pytorch_model.bin:  94%|█████████████████████████████████████████████████▊   | 252M/268M [01:03<00:04, 3.47MB/s]pytorch_model.bin:  98%|███████████████████████████████████████████████████▊ | 262M/268M [01:06<00:01, 3.40MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 268M/268M [01:08<00:00, 3.43MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 268M/268M [01:08<00:00, 3.92MB/s]
tokenizer_config.json:   0%|                                                          | 0.00/333 [00:00<?, ?B/s]tokenizer_config.json: 100%|████████████████████████████████████████████████████| 333/333 [00:00<00:00, 281kB/s]
vocab.txt:   0%|                                                                     | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 232k/232k [00:01<00:00, 231kB/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 232k/232k [00:01<00:00, 231kB/s]
tokenizer.json:   0%|                                                                | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|█████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 920kB/s]tokenizer.json: 100%|█████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 919kB/s]
special_tokens_map.json:   0%|                                                        | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|█████████████████████████████████████████████████| 112/112 [00:00<00:00, 95.4kB/s]
Traceback (most recent call last):
  File "./f00861_sentiment_analysis.py", line 44, in <module>
    test_sentiment_analysis()
  File "./f00861_sentiment_analysis.py", line 36, in test_sentiment_analysis
    assert positive_prediction['label'] == 'POSITIVE', f"Expected 'POSITIVE', but got {positive_prediction['label']}"
TypeError: list indices must be integers or slices, not str
