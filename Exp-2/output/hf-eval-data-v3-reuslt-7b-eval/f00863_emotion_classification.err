2023-12-01 00:22:09.577044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-01 00:22:10.476276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'
  warnings.warn(
config.json:   0%|                                                                    | 0.00/483 [00:00<?, ?B/s]config.json: 100%|█████████████████████████████████████████████████████████████| 483/483 [00:00<00:00, 68.5kB/s]
model.safetensors:   0%|                                                             | 0.00/268M [00:00<?, ?B/s]model.safetensors:   4%|██                                                  | 10.5M/268M [00:04<01:59, 2.15MB/s]model.safetensors:   8%|████                                                | 21.0M/268M [00:07<01:21, 3.02MB/s]model.safetensors:  12%|██████                                              | 31.5M/268M [00:10<01:11, 3.30MB/s]model.safetensors:  16%|████████▏                                           | 41.9M/268M [00:12<01:04, 3.48MB/s]model.safetensors:  20%|██████████▏                                         | 52.4M/268M [00:15<01:01, 3.52MB/s]model.safetensors:  23%|████████████▏                                       | 62.9M/268M [00:19<01:02, 3.28MB/s]model.safetensors:  27%|██████████████▏                                     | 73.4M/268M [00:22<00:58, 3.33MB/s]model.safetensors:  31%|████████████████▎                                   | 83.9M/268M [00:25<00:53, 3.43MB/s]model.safetensors:  35%|██████████████████▎                                 | 94.4M/268M [00:29<00:56, 3.07MB/s]model.safetensors:  39%|████████████████████▋                                | 105M/268M [00:32<00:51, 3.19MB/s]model.safetensors:  43%|██████████████████████▊                              | 115M/268M [00:35<00:46, 3.27MB/s]model.safetensors:  47%|████████████████████████▉                            | 126M/268M [00:38<00:41, 3.44MB/s]model.safetensors:  51%|██████████████████████████▉                          | 136M/268M [00:42<00:40, 3.23MB/s]model.safetensors:  55%|█████████████████████████████                        | 147M/268M [00:46<00:41, 2.90MB/s]model.safetensors:  59%|███████████████████████████████                      | 157M/268M [00:52<00:44, 2.47MB/s]model.safetensors:  63%|█████████████████████████████████▏                   | 168M/268M [00:56<00:41, 2.42MB/s]model.safetensors:  67%|███████████████████████████████████▎                 | 178M/268M [01:03<00:42, 2.12MB/s]model.safetensors:  70%|█████████████████████████████████████▎               | 189M/268M [01:09<00:40, 1.95MB/s]model.safetensors:  74%|███████████████████████████████████████▍             | 199M/268M [01:13<00:33, 2.05MB/s]model.safetensors:  78%|█████████████████████████████████████████▍           | 210M/268M [01:17<00:25, 2.27MB/s]model.safetensors:  82%|███████████████████████████████████████████▌         | 220M/268M [01:21<00:20, 2.35MB/s]model.safetensors:  86%|█████████████████████████████████████████████▋       | 231M/268M [01:25<00:15, 2.47MB/s]model.safetensors:  90%|███████████████████████████████████████████████▋     | 241M/268M [01:29<00:10, 2.49MB/s]model.safetensors:  94%|█████████████████████████████████████████████████▊   | 252M/268M [01:33<00:06, 2.43MB/s]model.safetensors:  98%|███████████████████████████████████████████████████▊ | 262M/268M [01:38<00:02, 2.44MB/s]model.safetensors: 100%|█████████████████████████████████████████████████████| 268M/268M [01:40<00:00, 2.56MB/s]model.safetensors: 100%|█████████████████████████████████████████████████████| 268M/268M [01:40<00:00, 2.68MB/s]
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
tokenizer_config.json:   0%|                                                         | 0.00/28.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|█████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 8.54kB/s]
vocab.txt:   0%|                                                                     | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 232k/232k [00:01<00:00, 203kB/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 232k/232k [00:01<00:00, 203kB/s]
tokenizer.json:   0%|                                                                | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|█████████████████████████████████████████████████████████| 466k/466k [00:01<00:00, 414kB/s]tokenizer.json: 100%|█████████████████████████████████████████████████████████| 466k/466k [00:01<00:00, 414kB/s]
Traceback (most recent call last):
  File "./f00863_emotion_classification.py", line 51, in <module>
    test_emotion_classification()
  File "./f00863_emotion_classification.py", line 42, in test_emotion_classification
    assert isinstance(emotion_classification(test_case_1), list)
AssertionError
