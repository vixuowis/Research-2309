tokenizer_config.json:   0%|                                                         | 0.00/26.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|█████████████████████████████████████████████████| 26.0/26.0 [00:00<00:00, 6.17kB/s]
config.json:   0%|                                                                    | 0.00/641 [00:00<?, ?B/s]config.json: 100%|██████████████████████████████████████████████████████████████| 641/641 [00:00<00:00, 163kB/s]
vocab.json:   0%|                                                                   | 0.00/1.04M [00:00<?, ?B/s]vocab.json: 100%|███████████████████████████████████████████████████████████| 1.04M/1.04M [00:02<00:00, 360kB/s]vocab.json: 100%|███████████████████████████████████████████████████████████| 1.04M/1.04M [00:02<00:00, 360kB/s]
merges.txt:   0%|                                                                    | 0.00/456k [00:00<?, ?B/s]merges.txt: 100%|████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 2.84MB/s]merges.txt: 100%|████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 2.82MB/s]
model.safetensors:   0%|                                                             | 0.00/351M [00:00<?, ?B/s]model.safetensors:   3%|█▌                                                  | 10.5M/351M [00:04<02:39, 2.14MB/s]model.safetensors:   6%|███                                                 | 21.0M/351M [00:10<02:55, 1.88MB/s]model.safetensors:   9%|████▋                                               | 31.5M/351M [00:15<02:30, 2.12MB/s]model.safetensors:  12%|██████▏                                             | 41.9M/351M [00:18<02:03, 2.51MB/s]model.safetensors:  15%|███████▊                                            | 52.4M/351M [00:22<01:56, 2.56MB/s]model.safetensors:  18%|█████████▎                                          | 62.9M/351M [00:25<01:48, 2.67MB/s]model.safetensors:  21%|██████████▊                                         | 73.4M/351M [00:29<01:45, 2.65MB/s]model.safetensors:  24%|████████████▍                                       | 83.9M/351M [00:33<01:35, 2.80MB/s]model.safetensors:  27%|█████████████▉                                      | 94.4M/351M [00:37<01:40, 2.55MB/s]model.safetensors:  30%|███████████████▊                                     | 105M/351M [00:42<01:37, 2.52MB/s]model.safetensors:  33%|█████████████████▍                                   | 115M/351M [00:45<01:29, 2.62MB/s]model.safetensors:  36%|██████████████████▉                                  | 126M/351M [00:49<01:20, 2.80MB/s]model.safetensors:  39%|████████████████████▌                                | 136M/351M [00:54<01:24, 2.54MB/s]model.safetensors:  42%|██████████████████████▏                              | 147M/351M [00:57<01:15, 2.71MB/s]model.safetensors:  45%|███████████████████████▋                             | 157M/351M [01:00<01:08, 2.83MB/s]model.safetensors:  48%|█████████████████████████▎                           | 168M/351M [01:03<01:02, 2.95MB/s]model.safetensors:  51%|██████████████████████████▉                          | 178M/351M [01:07<00:59, 2.92MB/s]model.safetensors:  54%|████████████████████████████▍                        | 189M/351M [01:11<00:57, 2.85MB/s]model.safetensors:  57%|██████████████████████████████                       | 199M/351M [01:15<00:53, 2.82MB/s]model.safetensors:  60%|███████████████████████████████▋                     | 210M/351M [01:20<00:54, 2.58MB/s]model.safetensors:  63%|█████████████████████████████████▏                   | 220M/351M [01:25<00:56, 2.32MB/s]model.safetensors:  66%|██████████████████████████████████▊                  | 231M/351M [01:31<00:54, 2.19MB/s]model.safetensors:  69%|████████████████████████████████████▍                | 241M/351M [01:33<00:44, 2.49MB/s]model.safetensors:  72%|█████████████████████████████████████▉               | 252M/351M [01:37<00:37, 2.66MB/s]model.safetensors:  75%|███████████████████████████████████████▌             | 262M/351M [01:40<00:31, 2.83MB/s]model.safetensors:  78%|█████████████████████████████████████████▏           | 273M/351M [01:43<00:27, 2.87MB/s]model.safetensors:  81%|██████████████████████████████████████████▋          | 283M/351M [01:46<00:22, 3.04MB/s]model.safetensors:  84%|████████████████████████████████████████████▎        | 294M/351M [01:50<00:19, 2.99MB/s]model.safetensors:  87%|█████████████████████████████████████████████▉       | 304M/351M [01:54<00:16, 2.92MB/s]model.safetensors:  90%|███████████████████████████████████████████████▍     | 315M/351M [01:58<00:12, 2.85MB/s]model.safetensors:  93%|█████████████████████████████████████████████████    | 325M/351M [02:04<00:11, 2.30MB/s]model.safetensors:  96%|██████████████████████████████████████████████████▋  | 336M/351M [02:10<00:07, 2.14MB/s]model.safetensors:  99%|████████████████████████████████████████████████████▏| 346M/351M [02:17<00:02, 1.94MB/s]model.safetensors: 100%|█████████████████████████████████████████████████████| 351M/351M [02:18<00:00, 2.10MB/s]model.safetensors: 100%|█████████████████████████████████████████████████████| 351M/351M [02:18<00:00, 2.53MB/s]
generation_config.json:   0%|                                                         | 0.00/124 [00:00<?, ?B/s]generation_config.json: 100%|██████████████████████████████████████████████████| 124/124 [00:00<00:00, 26.0kB/s]
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
