tokenizer_config.json:   0%|                                                          | 0.00/619 [00:00<?, ?B/s]tokenizer_config.json: 100%|████████████████████████████████████████████████████| 619/619 [00:00<00:00, 158kB/s]
vocab.json:   0%|                                                                    | 0.00/798k [00:00<?, ?B/s]vocab.json: 100%|█████████████████████████████████████████████████████████████| 798k/798k [00:00<00:00, 816kB/s]vocab.json: 100%|█████████████████████████████████████████████████████████████| 798k/798k [00:00<00:00, 815kB/s]
merges.txt:   0%|                                                                    | 0.00/456k [00:00<?, ?B/s]merges.txt: 100%|████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 2.74MB/s]merges.txt: 100%|████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 2.73MB/s]
tokenizer.json:   0%|                                                               | 0.00/1.37M [00:00<?, ?B/s]tokenizer.json: 100%|██████████████████████████████████████████████████████| 1.37M/1.37M [00:00<00:00, 2.80MB/s]tokenizer.json: 100%|██████████████████████████████████████████████████████| 1.37M/1.37M [00:00<00:00, 2.79MB/s]
added_tokens.json:   0%|                                                            | 0.00/4.04k [00:00<?, ?B/s]added_tokens.json: 100%|███████████████████████████████████████████████████| 4.04k/4.04k [00:00<00:00, 2.49MB/s]
special_tokens_map.json:   0%|                                                        | 0.00/357 [00:00<?, ?B/s]special_tokens_map.json: 100%|██████████████████████████████████████████████████| 357/357 [00:00<00:00, 107kB/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
config.json:   0%|                                                                    | 0.00/930 [00:00<?, ?B/s]config.json: 100%|██████████████████████████████████████████████████████████████| 930/930 [00:00<00:00, 155kB/s]
Traceback (most recent call last):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py", line 712, in urlopen
    self._prepare_proxy(conn)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1012, in _prepare_proxy
    conn.connect()
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/connection.py", line 419, in connect
    self.sock = ssl_wrap_socket(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 449, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 493, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/ssl.py", line 1073, in _create
    self.do_handshake()
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/ssl.py", line 1342, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1114: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/connectionpool.py", line 799, in urlopen
    retries = retries.increment(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /EleutherAI/gpt-j-6B/0e183edc2025ecfdba4429ba43c960224103b3c3dc26616503cdc2158a3d6c93?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1701594810&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMTU5NDgxMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9FbGV1dGhlckFJL2dwdC1qLTZCLzBlMTgzZWRjMjAyNWVjZmRiYTQ0MjliYTQzYzk2MDIyNDEwM2IzYzNkYzI2NjE2NTAzY2RjMjE1OGEzZDZjOTM~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=YaudlaUaEDv96FgwFm1aEMRadGy-eJeawlzOyoG2GdZOeOdJQTOwURecJwpUb8mHJCZSvyOiDCyFwIGMFmwdMrne8W9U4E1Or2~p0kiQcWCHhHSAjKOa4KulKVOu0utZXb61i5Jvuo02GayAZ9nr8l7cbWLYpGNBgTFmLTJTn73aAg2aL~W15h5osoAg4P-X6m0pi3IRaavAoTlcXGBapeqJRtUAbIAFfZ7eTY4tUBPLU76iivt7V1eADutt2W-dlP7jGXIKSkByV3MMfb82ENT7gGKz0KDArwLem~Ni8QkrPzRDn6IxyrcjD6rV7pxGMAohKC7i6VX-rUQaB8M1jQ__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./f00307_generate_code.py", line 40, in <module>
    test_generate_code()
  File "./f00307_generate_code.py", line 32, in test_generate_code
    assert generate_code('Create a simple loading spinner for maintenance.') is not None
  File "./f00307_generate_code.py", line 18, in generate_code
    model = AutoModelForCausalLM.from_pretrained("EleutherAI/gpt-j-6B")
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 566, in from_pretrained
    return model_class.from_pretrained(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3057, in from_pretrained
    resolved_archive_file = cached_file(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1461, in hf_hub_download
    http_get(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 468, in http_get
    r = _request_wrapper(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 425, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_http.py", line 63, in send
    return super().send(request, *args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/adapters.py", line 513, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: (MaxRetryError("HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Max retries exceeded with url: /EleutherAI/gpt-j-6B/0e183edc2025ecfdba4429ba43c960224103b3c3dc26616503cdc2158a3d6c93?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1701594810&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMTU5NDgxMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9FbGV1dGhlckFJL2dwdC1qLTZCLzBlMTgzZWRjMjAyNWVjZmRiYTQ0MjliYTQzYzk2MDIyNDEwM2IzYzNkYzI2NjE2NTAzY2RjMjE1OGEzZDZjOTM~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=YaudlaUaEDv96FgwFm1aEMRadGy-eJeawlzOyoG2GdZOeOdJQTOwURecJwpUb8mHJCZSvyOiDCyFwIGMFmwdMrne8W9U4E1Or2~p0kiQcWCHhHSAjKOa4KulKVOu0utZXb61i5Jvuo02GayAZ9nr8l7cbWLYpGNBgTFmLTJTn73aAg2aL~W15h5osoAg4P-X6m0pi3IRaavAoTlcXGBapeqJRtUAbIAFfZ7eTY4tUBPLU76iivt7V1eADutt2W-dlP7jGXIKSkByV3MMfb82ENT7gGKz0KDArwLem~Ni8QkrPzRDn6IxyrcjD6rV7pxGMAohKC7i6VX-rUQaB8M1jQ__&Key-Pair-Id=KVTP0A1DKRTAX (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out')))"), '(Request ID: dac62043-fb7d-44da-bbe6-071f558456fc)')
