{'code': "###Instruction: We have a surveillance camera in our backyard. We would like to analyze the captured videos to recognize the activities taking place in the backyard.\n###Output: <<<domain>>>: Computer Vision Video Classification\n<<<api_call>>>: AutoModelForVideoClassification.from_pretrained('sayakpaul/videomae-base-finetuned-ucf101-subset')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import the necessary classes, such as AutoModelForVideoClassification and AutoTokenizer, from the transformers library provided by Hugging Face.\n2. Load the pre-trained model 'sayakpaul/videomae-base-finetuned-ucf101-subset' using the from_pretrained method of the AutoModelForVideoClassification class.\n3. Load the tokenizer using the from_pretrained method of the AutoTokenizer class, specifying the same model.\n4. The loaded model can be used to analyze the videos captured by the surveillance camera and recognize the activities taking place in the backyard. This can be helpful for monitoring and security purposes.\n<<<code>>>: from transformers import AutoModelForVideoClassification, AutoTokenizer\n\nmodel = AutoModelForVideoClassification.from_pretrained('sayakpaul/videomae-base-finetuned-ucf101-subset')\ntokenizer = AutoTokenizer.from_pretrained('sayakpaul/videomae-base-finetuned-ucf101-subset')\n\n# Use the model and tokenizer to analyze the video and recognize activities.\n", 'api_call': "AutoModelForVideoClassification.from_pretrained('sayakpaul/videomae-base-finetuned-ucf101-subset')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Computer Vision Video Classification', 'framework': 'Hugging Face Transformers', 'functionality': 'Video Classification', 'api_name': 'sayakpaul/videomae-base-finetuned-ucf101-subset', 'api_call': "AutoModelForVideoClassification.from_pretrained('sayakpaul/videomae-base-finetuned-ucf101-subset')", 'api_arguments': {'learning_rate': 5e-05, 'train_batch_size': 8, 'eval_batch_size': 8, 'seed': 42, 'optimizer': 'Adam with betas=(0.9,0.999) and epsilon=1e-08', 'lr_scheduler_type': 'linear', 'lr_scheduler_warmup_ratio': 0.1, 'training_steps': 148}, 'python_environment_requirements': {'Transformers': '4.24.0', 'Pytorch': '1.12.1+cu113', 'Datasets': '2.6.1', 'Tokenizers': '0.13.2'}, 'example_code': "from transformers import AutoModelForVideoClassification, AutoTokenizer\nmodel = AutoModelForVideoClassification.from_pretrained('sayakpaul/videomae-base-finetuned-ucf101-subset')\ntokenizer = AutoTokenizer.from_pretrained('sayakpaul/videomae-base-finetuned-ucf101-subset')", 'performance': {'dataset': 'unknown', 'accuracy': 0.8645}, 'description': 'This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645.'}}

