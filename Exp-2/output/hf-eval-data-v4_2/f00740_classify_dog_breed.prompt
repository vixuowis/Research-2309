{'code': "###Instruction: My pet store website needs a tool to recognize different dog breeds from user uploaded images.\n###Output: <<<domain>>>: Computer Vision Image Classification\n<<<api_call>>>: ConvNextForImageClassification.from_pretrained('facebook/convnext-tiny-224')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the necessary libraries, including ConvNextFeatureExtractor and ConvNextForImageClassification from the transformers package.\n2. Load the pre-trained model 'facebook/convnext-tiny-224' which has been trained on the ImageNet-1k dataset containing different classes, including dog breeds.\n3. To process the input image, create an instance of the ConvNextFeatureExtractor class and use the from_pretrained() method to load the appropriate pre-trained feature extractor.\n4. Use the feature_extractor to convert the image into a suitable format for the model.\n5. Pass the processed image through the instantiated model to get the logits for each class.\n6. Find the predicted class label by taking the argmax of the logits.\n7. Finally, use the model's config.id2label dictionary to convert the predicted label index into a human-readable class name.\n<<<code>>>: from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification\nimport torch\nfeature_extractor = ConvNextFeatureExtractor.from_pretrained('facebook/convnext-tiny-224')\nmodel = ConvNextForImageClassification.from_pretrained('facebook/convnext-tiny-224')\ninputs = feature_extractor(user_uploaded_image, return_tensors='pt')\nwith torch.no_grad():\n    logits = model(**inputs).logits\npredicted_label = logits.argmax(-1).item()\ndog_breed = model.config.id2label[predicted_label]\n", 'api_call': "ConvNextForImageClassification.from_pretrained('facebook/convnext-tiny-224')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Computer Vision Image Classification', 'framework': 'Hugging Face Transformers', 'functionality': 'Image Classification', 'api_name': 'facebook/convnext-tiny-224', 'api_call': "ConvNextForImageClassification.from_pretrained('facebook/convnext-tiny-224')", 'api_arguments': {'pretrained_model_name_or_path': 'facebook/convnext-tiny-224'}, 'python_environment_requirements': ['transformers', 'torch', 'datasets'], 'example_code': "from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification\nimport torch\nfrom datasets import load_dataset\ndataset = load_dataset('huggingface/cats-image')\nimage = dataset['test']['image'][0]\nfeature_extractor = ConvNextFeatureExtractor.from_pretrained('facebook/convnext-tiny-224')\nmodel = ConvNextForImageClassification.from_pretrained('facebook/convnext-tiny-224')\ninputs = feature_extractor(image, return_tensors='pt')\nwith torch.no_grad():\n logits = model(**inputs).logits\npredicted_label = logits.argmax(-1).item()\nprint(model.config.id2label[predicted_label])", 'performance': {'dataset': 'imagenet-1k', 'accuracy': 'Not specified'}, 'description': 'ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification.'}}

