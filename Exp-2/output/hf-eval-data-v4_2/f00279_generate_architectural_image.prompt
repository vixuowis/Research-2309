{'code': '###Instruction: We are now working on an architectural image generation project to generate different images of architecture.\n###Output: <<<domain>>>: Computer Vision Image-to-Image\n<<<api_call>>>: ControlNetModel.from_pretrained(\'lllyasviel/sd-controlnet-mlsd\')\n<<<api_provider>>>: Hugging Face\n<<<explanation>>>: 1. Import the necessary libraries and classes, such as Image from PIL, StableDiffusionControlNetPipeline and ControlNetModel from the diffusers package, MLSDdetector, load_image function, and torch library.\n2. Load the M-LSD straight line detection model and the ControlNet MLM model, \'lllyasviel/sd-controlnet-mlsd\', using the from_pretrained method.\n3. Load the existing architectural image using the load_image function.\n4. Process the input image with the MLSDdetector to extract straight lines from the image.\n5. Create the StableDiffusionControlNetPipeline with the ControlNet model and the appropriate scheduler.\n6. Enable the memory-efficient attention and CPU offloading for the pipeline.\n7. Pass the input image through the pipeline to generate a new architectural image with the straight line structure extracted by the MLSDdetector.\n8. Save the generated image to a file, such as \'images/room_mlsd_out.png\'.\n<<<code>>>: from PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import MLSDdetector\nfrom diffusers.utils import load_image\n\nmlsd = MLSDdetector.from_pretrained(\'lllyasviel/ControlNet\')\nimage_path = "path_to_architectural_image.jpg"\nimage = load_image(image_path)\nimage = mlsd(image)\ncontrolnet = ControlNetModel.from_pretrained(\'lllyasviel/sd-controlnet-mlsd\', torch_dtype=torch.float16)\npipe = StableDiffusionControlNetPipeline.from_pretrained(\'runwayml/stable-diffusion-v1-5\', controlnet=controlnet, safety_checker=None, torch_dtype=torch.float16)\npipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\npipe.enable_xformers_memory_efficient_attention()\npipe.enable_model_cpu_offload()\n\ngenerated_image = pipe(image, num_inference_steps=20).images[0]\ngenerated_image.save("images/generated_architecture.png")\n', 'api_call': "ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-mlsd')", 'provider': 'Hugging Face', 'api_data': {'domain': 'Computer Vision Image-to-Image', 'framework': 'Hugging Face', 'functionality': 'ControlNet - M-LSD Straight Line Version', 'api_name': 'lllyasviel/sd-controlnet-mlsd', 'api_call': "ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-mlsd')", 'api_arguments': {'torch_dtype': 'torch.float16'}, 'python_environment_requirements': {'diffusers': 'pip install diffusers', 'transformers': 'pip install transformers', 'accelerate': 'pip install accelerate', 'controlnet_aux': 'pip install controlnet_aux'}, 'example_code': {'import': ['from PIL import Image', 'from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler', 'import torch', 'from controlnet_aux import MLSDdetector', 'from diffusers.utils import load_image'], 'setup': ["mlsd = MLSDdetector.from_pretrained('lllyasviel/ControlNet')", 'image = load_image(https://huggingface.co/lllyasviel/sd-controlnet-mlsd/resolve/main/images/room.png)', 'image = mlsd(image)', 'controlnet = ControlNetModel.from_pretrained(lllyasviel/sd-controlnet-mlsd, torch_dtype=torch.float16)', 'pipe = StableDiffusionControlNetPipeline.from_pretrained(runwayml/stable-diffusion-v1-5, controlnet=controlnet, safety_checker=None, torch_dtype=torch.float16)', 'pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)'], 'execution': ['pipe.enable_xformers_memory_efficient_attention()', 'pipe.enable_model_cpu_offload()', 'image = pipe(room, image, num_inference_steps=20).images[0]', "image.save('images/room_mlsd_out.png')"]}, 'performance': {'dataset': '600k edge-image, caption pairs generated from Places2', 'accuracy': 'Not specified'}, 'description': 'ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion.'}}

