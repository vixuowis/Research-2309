{'code': '###Instruction: We are building a content moderation system. Our clients upload the content, it can be generated by human or AI. We want to have a filtering API to advise on the original text if it is generated by GPT-2.\n###Output: <<<domain>>>: Natural Language Processing Text Classification\n<<<api_call>>>: pipeline(\'text-classification\', model=\'roberta-base-openai-detector\')\n<<<api_provider>>>: Transformers\n<<<explanation>>>: 1. First, import the necessary libraries, which are \'pipeline\' from transformers.\n2. Use the \'pipeline\' function from transformers to load the \'roberta-base-openai-detector\' model for text classification.\n3. The model can detect if the text has been generated by a GPT-2 model or is human-written. This can be useful for content moderation systems to identify AI-generated text.\n4. Provide the text as input to the loaded pipeline, and the model will return a prediction, indicating whether the text was generated by GPT-2 or not.\n<<<code>>>: from transformers import pipeline\npipe = pipeline(\'text-classification\', model=\'roberta-base-openai-detector\')\ntext = "Hello world! Is this content AI-generated?"\nprediction = pipe(text)\n', 'api_call': "pipeline('text-classification', model='roberta-base-openai-detector')", 'provider': 'Transformers', 'api_data': {'domain': 'Natural Language Processing Text Classification', 'framework': 'Transformers', 'functionality': 'Detect GPT-2 generated text', 'api_name': 'roberta-base-openai-detector', 'api_call': "pipeline('text-classification', model='roberta-base-openai-detector')", 'api_arguments': ['text'], 'python_environment_requirements': ['transformers'], 'example_code': 'from transformers import pipeline\npipe = pipeline(text-classification, model=roberta-base-openai-detector)\nprint(pipe(Hello world! Is this content AI-generated?))', 'performance': {'dataset': 'WebText', 'accuracy': '95%'}, 'description': 'RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model.'}}

