{'code': '###Instruction: I am an interior designer and want to showcase a modern living room with a fireplace and a large window overlooking a forest. Create an image according to this description.\n###Output: <<<domain>>>: Multimodal Text-to-Image\n<<<api_call>>>: StableDiffusionInpaintPipeline.from_pretrained(\'stabilityai/stable-diffusion-2-inpainting\', torch_dtype=torch.float16)\n<<<api_provider>>>: Hugging Face\n<<<explanation>>>: 1. Load the necessary libraries, including \'StableDiffusionInpaintPipeline\' from diffusers package.\n2. Use \'StableDiffusionInpaintPipeline.from_pretrained\' function and specify the pre-trained model \'stabilityai/stable-diffusion-2-inpainting\' to initialize a pipeline capable of generating images based on text prompts.\n3. Provide the text prompt describing the desired image: "A modern living room with a fireplace and a large window overlooking a forest."\n4. Use pipeline\'s \'prompt\' parameter to pass the text prompt, which would generate the image according to the given description.\n5. Save the generated image to a file, for instance, \'modern_living_room.png\'.\n<<<code>>>: from diffusers import StableDiffusionInpaintPipeline\nimport torch\n\npipe = StableDiffusionInpaintPipeline.from_pretrained(\'stabilityai/stable-diffusion-2-inpainting\', torch_dtype=torch.float16)\npipe.to(torch.device(\'cuda\' if torch.cuda.is_available() else \'cpu\'))\n\nprompt = "A modern living room with a fireplace and a large window overlooking a forest."\ngenerated_image = pipe(prompt=prompt).images[0]\ngenerated_image.save(\'modern_living_room.png\')\n', 'api_call': "StableDiffusionInpaintPipeline.from_pretrained('stabilityai/stable-diffusion-2-inpainting', torch_dtype=torch.float16)", 'provider': 'Hugging Face', 'api_data': {'domain': 'Multimodal Text-to-Image', 'framework': 'Hugging Face', 'functionality': 'Image generation and modification based on text prompts', 'api_name': 'stabilityai/stable-diffusion-2-inpainting', 'api_call': "StableDiffusionInpaintPipeline.from_pretrained('stabilityai/stable-diffusion-2-inpainting', torch_dtype=torch.float16)", 'api_arguments': ['prompt', 'image', 'mask_image'], 'python_environment_requirements': ['diffusers', 'transformers', 'accelerate', 'scipy', 'safetensors'], 'example_code': "from diffusers import StableDiffusionInpaintPipeline\npipe = StableDiffusionInpaintPipeline.from_pretrained('stabilityai/stable-diffusion-2-inpainting', torch_dtype=torch.float16)\n\npipe.to(cuda)\nprompt = Face of a yellow cat, high resolution, sitting on a park bench\nimage = pipe(prompt=prompt, image=image, mask_image=mask_image).images[0]\nimage.save(./yellow_cat_on_park_bench.png)", 'performance': {'dataset': 'COCO2017 validation set', 'accuracy': 'Not optimized for FID scores'}, 'description': 'A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts.'}}

