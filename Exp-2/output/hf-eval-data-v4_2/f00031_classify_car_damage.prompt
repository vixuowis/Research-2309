{'code': "###Instruction: I am an insurance adjustor. I need a zero-shot image classifier that will tell me whether a car has been involved in a major accident or had minor damages.\n###Output: <<<domain>>>: Computer Vision Zero-Shot Image Classification\n<<<api_call>>>: pipeline('image-classification', model='laion/CLIP-ViT-B-16-laion2B-s34B-b88K')\n<<<api_provider>>>: Hugging Face\n<<<explanation>>>: 1. Import the 'pipeline' function from the 'transformers' package.\n2. Load the pre-trained 'laion/CLIP-ViT-B-16-laion2B-s34B-b88K' model using the 'pipeline' function. This model is well-suited for zero-shot image classification tasks, such as determining the severity of car damage.\n3. After loading the model, pass the given image of the car along with the list of possible classes ('major accident', 'minor damages') to the model for classification.\n4. The model will return the classification result indicating whether the car has been involved in a major accident or had minor damages.\n<<<code>>>: from transformers import pipeline\nclassifier = pipeline('image-classification', model='laion/CLIP-ViT-B-16-laion2B-s34B-b88K')\nimage_path = '/path/to/car_image.jpg'\nclass_names = ['major accident', 'minor damages']\nresult = classifier(image_path, class_names)\n", 'api_call': "pipeline('image-classification', model='laion/CLIP-ViT-B-16-laion2B-s34B-b88K')", 'provider': 'Hugging Face', 'api_data': {'domain': 'Computer Vision Zero-Shot Image Classification', 'framework': 'Hugging Face', 'functionality': 'Zero-Shot Image Classification', 'api_name': 'laion/CLIP-ViT-B-16-laion2B-s34B-b88K', 'api_call': "pipeline('image-classification', model='laion/CLIP-ViT-B-16-laion2B-s34B-b88K')", 'api_arguments': {'image': 'Path to image file or URL', 'class_names': 'List of possible class names (comma-separated)'}, 'python_environment_requirements': {'transformers': '>=4.11.0'}, 'example_code': "from transformers import pipeline; classify = pipeline('image-classification', model='laion/CLIP-ViT-B-16-laion2B-s34B-b88K'); classify('/path/to/image.jpg', ['cat', 'dog'])", 'performance': {'dataset': 'ImageNet-1k', 'accuracy': '70.2%'}, 'description': 'A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks.'}}

