{'code': "###Instruction: Our client is building an application that converts scanned tables into structured data. We need to detect the rows and columns in a given table image.\n###Output: <<<domain>>>: Computer Vision Object Detection\n<<<api_call>>>: pipeline('object-detection', model='microsoft/table-transformer-structure-recognition')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. We import the pipeline function from the transformers library provided by Hugging Face.\n2. Using the pipeline function, we create an object detection model capable of detecting the structure (like rows, columns) in tables.\n3. We specify the model 'microsoft/table-transformer-structure-recognition' to be loaded. This model is trained on the PubTables1M dataset for detecting rows and columns in tables.\n4. The created object detector can be used to detect rows and columns in a given table image, which can then be used to extract and structure the data within.\n<<<code>>>: from transformers import pipeline\ntable_detector = pipeline('object-detection', model='microsoft/table-transformer-structure-recognition')\ntable_structure = table_detector(table_image)\n", 'api_call': "pipeline('object-detection', model='microsoft/table-transformer-structure-recognition')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Computer Vision Object Detection', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'microsoft/table-transformer-structure-recognition', 'api_call': "pipeline('object-detection', model='microsoft/table-transformer-structure-recognition')", 'api_arguments': '', 'python_environment_requirements': 'transformers', 'example_code': '', 'performance': {'dataset': 'PubTables1M', 'accuracy': ''}, 'description': 'Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables.'}}

