{'code': '###Instruction: I have a list of Olympic Game host cities and their corresponding years. I want to know which year the games were held in Beijing.\n###Output: <<<domain>>>: Natural Language Processing Table Question Answering\n<<<api_call>>>: BartForConditionalGeneration.from_pretrained(\'microsoft/tapex-base\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the required libraries: TapexTokenizer and BartForConditionalGeneration from transformers, and pandas.\n2. Load the TAPEX tokenizer and BartForConditionalGeneration model.\n3. Create a pandas DataFrame containing the list of Olympic Game host cities and their corresponding years.\n4. Set the query as "select year where city = beijing".\n5. Tokenize the table and query using the TAPEX tokenizer.\n6. Use the BartForConditionalGeneration model to generate an answer to the query by passing the tokenized encoding.\n7. Decode the answer and print the result.\n<<<code>>>: from transformers import TapexTokenizer, BartForConditionalGeneration\nimport pandas as pd\ntokenizer = TapexTokenizer.from_pretrained(\'microsoft/tapex-base\')\nmodel = BartForConditionalGeneration.from_pretrained(\'microsoft/tapex-base\')\ndata = {\n    \'year\': [1896, 1900, 1904, 2004, 2008, 2012],\n    \'city\': [\'athens\', \'paris\', \'st. louis\', \'athens\', \'beijing\', \'london\']\n}\ntable = pd.DataFrame.from_dict(data)\nquery = "select year where city = beijing"\nencoding = tokenizer(table=table, query=query, return_tensors=\'pt\')\noutputs = model.generate(**encoding)\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n', 'api_call': "BartForConditionalGeneration.from_pretrained('microsoft/tapex-base')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Table Question Answering', 'framework': 'Hugging Face Transformers', 'functionality': 'Transformers', 'api_name': 'microsoft/tapex-base', 'api_call': "BartForConditionalGeneration.from_pretrained('microsoft/tapex-base')", 'api_arguments': {'table': 'pd.DataFrame', 'query': 'str'}, 'python_environment_requirements': {'libraries': ['transformers', 'pandas']}, 'example_code': 'from transformers import TapexTokenizer, BartForConditionalGeneration\nimport pandas as pd\ntokenizer = TapexTokenizer.from_pretrained(microsoft/tapex-base)\nmodel = BartForConditionalGeneration.from_pretrained(microsoft/tapex-base)\ndata = {\n year: [1896, 1900, 1904, 2004, 2008, 2012],\n city: [athens, paris, st. louis, athens, beijing, london]\n}\ntable = pd.DataFrame.from_dict(data)\nquery = select year where city = beijing\nencoding = tokenizer(table=table, query=query, return_tensors=pt)\noutputs = model.generate(**encoding)\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))', 'performance': {'dataset': 'arxiv:2107.07653', 'accuracy': 'Not provided'}, 'description': 'TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries.'}}

