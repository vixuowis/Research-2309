{'code': "###Instruction: I am an author. I have a new book that needs a summary. I want the summary to resemble the style of SparkNotes.\n###Output: <<<domain>>>: Natural Language Processing Text2Text Generation\n<<<api_call>>>: T5ForConditionalGeneration.from_pretrained('pszemraj/long-t5-tglobal-base-16384-book-summary')\n<<<api_provider>>>: Transformers\n<<<explanation>>>: 1. Import T5ForConditionalGeneration and transformers features from the transformers library provided by Hugging Face.\n2. Load the pre-trained model 'pszemraj/long-t5-tglobal-base-16384-book-summary'. This model is specifically tailored for summarizing long text in a SparkNotes-like style. It is fine-tuned on the kmfoda/booksum dataset.\n3. Create a text summarization pipeline using the loaded model and set the appropriate device for processing (using GPU if available or otherwise CPU).\n4. Provide your book's content as input to the summarizer. The model will generate a SparkNotes-esque summary of your text.\n<<<code>>>: from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\nimport torch\ntokenizer = T5Tokenizer.from_pretrained('pszemraj/long-t5-tglobal-base-16384-book-summary')\nres = pipeline(\n    'summarization',\n    tokenizer=tokenizer,\n    model='pszemraj/long-t5-tglobal-base-16384-book-summary',\n    device=0 if torch.cuda.is_available() else -1)\nsummary = res(book_text)\n", 'api_call': "T5ForConditionalGeneration.from_pretrained('pszemraj/long-t5-tglobal-base-16384-book-summary')", 'provider': 'Transformers', 'api_data': {'domain': 'Natural Language Processing Text2Text Generation', 'framework': 'Transformers', 'functionality': 'Summarization', 'api_name': 'pszemraj/long-t5-tglobal-base-16384-book-summary', 'api_call': "T5ForConditionalGeneration.from_pretrained('pszemraj/long-t5-tglobal-base-16384-book-summary')", 'api_arguments': ['long_text'], 'python_environment_requirements': ['transformers'], 'example_code': "from transformers import pipeline\nimport torch\nsummarizer = pipeline(\n summarization,\n pszemraj/long-t5-tglobal-base-16384-book-summary,\n device=0 if torch.cuda.is_available() else -1,\n)\nlong_text = Here is a lot of text I don't want to read. Replace me\nresult = summarizer(long_text)\nprint(result[0][summary_text])", 'performance': {'dataset': 'kmfoda/booksum', 'accuracy': {'ROUGE-1': 36.408, 'ROUGE-2': 6.065, 'ROUGE-L': 16.721, 'ROUGE-LSUM': 33.34}}, 'description': 'A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text.'}}

