{'code': '###Instruction: I work for a financial company that stores all of its data in tables. We need a way to extract key information efficiently by asking natural language questions.\n###Output: <<<domain>>>: Natural Language Processing Table Question Answering\n<<<api_call>>>: AutoModelForSeq2SeqLM.from_pretrained(\'neulab/omnitab-large-1024shot\')\n<<<api_provider>>>: PyTorch Transformers\n<<<explanation>>>:1. We import the necessary libraries from Python transformers and pandas packages.\n2. Load the pre-trained \'neulab/omnitab-large-1024shot\' model using the from_pretrained method of the AutoModelForSeq2SeqLM class. This model has been specifically designed for the task of table-based question-answering.\n3. Load the financial company\'s data as a pandas dataframe using \'pd.DataFrame.from_dict(data)\'.\n4. To extract the key information, a natural language question is generated and used as input along with the table data. The model will then predict an answer in the form of a string containing the key information. \n<<<code>>>: from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport pandas as pd\ntokenizer = AutoTokenizer.from_pretrained(\'neulab/omnitab-large-1024shot\')\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\'neulab/omnitab-large-1024shot\')\ndata = {\'year\': [1896, 1900, 1904, 2004, 2008, 2012], \'city\': [\'Athens\', \'Paris\', \'St. Louis\', \'Athens\', \'Beijing\', \'London\']}\ntable = pd.DataFrame.from_dict(data)\nquery = "In which year did Beijing host the Olympic Games?"\nencoding = tokenizer(table=table, query=query, return_tensors=\'pt\')\noutputs = model.generate(**encoding)\nanswer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\nprint(answer)', 'api_call': "AutoModelForSeq2SeqLM.from_pretrained('neulab/omnitab-large-1024shot')", 'provider': 'PyTorch Transformers', 'api_data': {'domain': 'Natural Language Processing Table Question Answering', 'framework': 'PyTorch Transformers', 'functionality': 'Table-based QA', 'api_name': 'neulab/omnitab-large-1024shot', 'api_call': "AutoModelForSeq2SeqLM.from_pretrained('neulab/omnitab-large-1024shot')", 'api_arguments': {'table': 'pd.DataFrame.from_dict(data)', 'query': 'str'}, 'python_environment_requirements': ['transformers', 'pandas'], 'example_code': 'from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport pandas as pd\ntokenizer = AutoTokenizer.from_pretrained(neulab/omnitab-large-1024shot)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(neulab/omnitab-large-1024shot)\ndata = {\n year: [1896, 1900, 1904, 2004, 2008, 2012],\n city: [athens, paris, st. louis, athens, beijing, london]\n}\ntable = pd.DataFrame.from_dict(data)\nquery = In which year did beijing host the Olympic Games?\nencoding = tokenizer(table=table, query=query, return_tensors=pt)\noutputs = model.generate(**encoding)\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))', 'performance': {'dataset': 'wikitablequestions', 'accuracy': 'Not provided'}, 'description': 'OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting).'}}

