{'code': '###Instruction: As a translation company, we are translating messages between co-workers in a multinational company. Translate the message from Hindi to French.\n###Input: "आपकी प्रेज़टेशन का आधार अच्छा था, लेकिन डेटा विश्लेषण पर ध्यान देना चाहिए।"\n###Output: <<<domain>>>: Natural Language Processing Translation\n<<<api_call>>>: MBartForConditionalGeneration.from_pretrained(\'facebook/mbart-large-50-many-to-many-mmt\')\n<<<api_provider>>>: Hugging Face\n<<<explanation>>>: 1. We first import the necessary classes from the transformers package. This includes MBartForConditionalGeneration for the text-to-text generation model and MBart50TokenizerFast for tokenizing the input and generated text.\n2. We then use the from_pretrained method of the MBart50TokenizerFast and MBartForConditionalGeneration classes to load the pre-trained tokenizer and model \'facebook/mbart-large-50-many-to-many-mmt\'. This model has been trained for translation tasks between 50 languages, including Hindi and French.\n3. We provide the input message in Hindi, and set the desired output language (French) using the tokenizer\'s lang_code_to_id dictionary.\n4. This model can then be used to translate the input message into French.\n<<<code>>>: from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\nmessage_hi = "आपकी प्रेज़टेशन का आधार अच्छा था, लेकिन डेटा विश्लेषण पर ध्यान देना चाहिए।"\nmodel = MBartForConditionalGeneration.from_pretrained(\'facebook/mbart-large-50-many-to-many-mmt\')\ntokenizer = MBart50TokenizerFast.from_pretrained(\'facebook/mbart-large-50-many-to-many-mmt\')\ntokenizer.src_lang = "hi_IN"\nencoded_hi = tokenizer(message_hi, return_tensors=\'pt\')\ngenerated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.lang_code_to_id[\'fr_XX\'])\ntranslated_message = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n', 'api_call': "MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')", 'provider': 'Hugging Face', 'api_data': {'domain': 'Natural Language Processing Translation', 'framework': 'Hugging Face', 'functionality': 'Text2Text Generation', 'api_name': 'facebook/mbart-large-50-many-to-many-mmt', 'api_call': "MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')", 'api_arguments': {'pretrained_model_name_or_path': 'facebook/mbart-large-50-many-to-many-mmt'}, 'python_environment_requirements': {'transformers': '4.0.0'}, 'example_code': 'from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\narticle_hi model = MBartForConditionalGeneration.from_pretrained(facebook/mbart-large-50-many-to-many-mmt)\ntokenizer = MBart50TokenizerFast.from_pretrained(facebook/mbart-large-50-many-to-many-mmt)\ntokenizer.src_lang = hi_IN\nencoded_hi = tokenizer(article_hi, return_tensors=pt)\ngenerated_tokens = model.generate(\n **encoded_hi,\n forced_bos_token_id=tokenizer.lang_code_to_id[fr_XX]\n)\ntokenizer.batch_decode(generated_tokens, skip_special_tokens=True)', 'performance': {'dataset': 'Multilingual Translation', 'accuracy': 'Not specified'}, 'description': 'mBART-50 many-to-many multilingual machine translation model can translate directly between any pair of 50 languages. It was introduced in the Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper.'}}

