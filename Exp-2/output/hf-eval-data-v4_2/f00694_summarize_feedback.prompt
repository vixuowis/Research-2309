{'code': "###Instruction: We received a customer feedback document which is very lengthy. We need a summarization of it.\n###Input: The customer support service was excellent. All our concerns were attended to promptly by the friendly and knowledgeable staff. The user interface, however, could use some improvement. Navigating through the platform can be challenging, and it took us quite some time to find the relevant information we needed.\n\nAdditionally, some of our team members faced technical issues while using the platform, particularly with the integration of third-party tools. We had to reach out to the support team multiple times to resolve these issues. Overall, while we genuinely appreciate your team's assistance, we expect better performance from the platform itself.\n###Output: <<<domain>>>: Natural Language Processing Summarization\n<<<api_call>>>: pipeline('summarization', model='philschmid/bart-large-cnn-samsum')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Start by importing the pipeline function from the transformers library provided by Hugging Face.\n2. Create a summarization model using the pipeline function, specifying 'philschmid/bart-large-cnn-samsum' as the model.\n3. Pass the customer feedback document as input to the model, and it will produce an abstractive summary of the text.\n<<<code>>>: from transformers import pipeline\nsummarizer = pipeline('summarization', model='philschmid/bart-large-cnn-samsum')\nfeedback = 'The customer support service was excellent. All our concerns were attended to promptly by the friendly and knowledgeable staff. ...'\nsummary = summarizer(feedback)\n", 'api_call': "pipeline('summarization', model='philschmid/bart-large-cnn-samsum')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Summarization', 'framework': 'Hugging Face Transformers', 'functionality': 'Text-to-Text Generation', 'api_name': 'philschmid/bart-large-cnn-samsum', 'api_call': "pipeline('summarization', model='philschmid/bart-large-cnn-samsum')", 'api_arguments': {'model': 'philschmid/bart-large-cnn-samsum'}, 'python_environment_requirements': {'transformers': 'latest'}, 'example_code': "from transformers import pipeline\nsummarizer = pipeline(summarization, model=philschmid/bart-large-cnn-samsum)\nconversation = '''Jeff: Can I train a ðŸ¤— Transformers model on Amazon SageMaker? \nPhilipp: Sure you can use the new Hugging Face Deep Learning Container. \nJeff: ok.\nJeff: and how can I get started? \nJeff: where can I find documentation? \nPhilipp: ok, ok you can find everything here. https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face <br />\n'''\nsummarizer(conversation)", 'performance': {'dataset': 'samsum', 'accuracy': {'eval_rouge1': 42.621, 'eval_rouge2': 21.9825, 'eval_rougeL': 33.034, 'eval_rougeLsum': 39.6783, 'test_rouge1': 41.3174, 'test_rouge2': 20.8716, 'test_rougeL': 32.1337, 'test_rougeLsum': 38.4149}}, 'description': 'philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations.'}}

