{'code': "###Instruction: Our company is providing translation services for business clients. We need to translate English contracts to French.\n###Output: <<<domain>>>: Natural Language Processing Text2Text Generation\n<<<api_call>>>: MT5ForConditionalGeneration.from_pretrained('google/mt5-base')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import the MT5ForConditionalGeneration class and the tokenizer from the transformers library provided by Hugging Face.\n2. Load the pre-trained model 'google/mt5-base' using the MT5ForConditionalGeneration class. This model is a multilingual text-to-text transfer transformer that was pre-trained on a wide variety of languages, including English and French.\n3. Encode the English contract text using the tokenizer, specify the return_tensors='pt'.\n4. Translate the encoded contract text to French using the model's generate method, set the target language to French in the prompt.\n5. Decode the generated output using the tokenizer to obtain the translated French text.\n<<<code>>>: from transformers import MT5ForConditionalGeneration, MT5Tokenizer\nmodel = MT5ForConditionalGeneration.from_pretrained('google/mt5-base')\ntokenizer = MT5Tokenizer.from_pretrained('google/mt5-base')\ninputs = tokenizer.encode('translate English to French: ' + english_contract_text, return_tensors='pt')\noutputs = model.generate(inputs, max_length=1000, num_return_sequences=1)\ntranslated_french_text = tokenizer.decode(outputs[0], skip_special_tokens=True)", 'api_call': "MT5ForConditionalGeneration.from_pretrained('google/mt5-base')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Text2Text Generation', 'framework': 'Hugging Face Transformers', 'functionality': 'Text-to-Text Transfer Transformer', 'api_name': 'google/mt5-base', 'api_call': "MT5ForConditionalGeneration.from_pretrained('google/mt5-base')", 'api_arguments': ['model_name', 'input_text', 'generated_text'], 'python_environment_requirements': ['transformers', 'torch'], 'example_code': "model = MT5ForConditionalGeneration.from_pretrained('google/mt5-base')\ntokenizer = MT5Tokenizer.from_pretrained('google/mt5-base')\ninputs = tokenizer.encode('translate English to German: The house is wonderful.', return_tensors='pt')\noutputs = model.generate(inputs, max_length=40, num_return_sequences=1)\ndecoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)", 'performance': {'dataset': 'mc4', 'accuracy': 'Not provided'}, 'description': 'mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks.'}}

