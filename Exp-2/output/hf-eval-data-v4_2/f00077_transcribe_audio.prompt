{'code': "###Instruction: We are a media company and we have a large volume of Chinese language audio files. We want to transcribe the audios into chinese text.\n###Output: <<<domain>>>: Audio Automatic Speech Recognition\n<<<api_call>>>: Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the SpeechRecognitionModel from the huggingsound library provided by Hugging Face.\n2. Use the model from the 'jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn' that is fine-tuned for Chinese speech recognition.\n3. You can create an instance of the SpeechRecognitionModel using the pretrained model.\n4. Provide a list of audio file paths, and then use the transcribe method of the SpeechRecognitionModel instance to convert the audio files into transcriptions.\n5. The transcriptions will be returned in a list format with one transcription for each audio file.\n<<<code>>>: from huggingsound import SpeechRecognitionModel\nmodel = SpeechRecognitionModel('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')\naudio_paths = ['/path/to/first_file.mp3', '/path/to/second_file.wav']\ntranscriptions = model.transcribe(audio_paths)\n", 'api_call': "Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Audio Automatic Speech Recognition', 'framework': 'Hugging Face Transformers', 'functionality': 'Speech Recognition', 'api_name': 'jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn', 'api_call': "Wav2Vec2Model.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')", 'api_arguments': ['audio_paths'], 'python_environment_requirements': ['huggingsound', 'torch', 'librosa', 'datasets', 'transformers'], 'example_code': "from huggingsound import SpeechRecognitionModel\nmodel = SpeechRecognitionModel('jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn')\naudio_paths = ['/path/to/file.mp3', '/path/to/another_file.wav']\ntranscriptions = model.transcribe(audio_paths)", 'performance': {'dataset': 'Common Voice zh-CN', 'accuracy': {'WER': 82.37, 'CER': 19.03}}, 'description': 'Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS.'}}

