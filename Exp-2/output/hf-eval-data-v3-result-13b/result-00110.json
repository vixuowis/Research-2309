{"path": "output/hf-eval-data-v3-valid/f00472_estimate_human_pose.py", "content": "# function_import --------------------\n\nfrom PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import OpenposeDetector\nimport os\n\n# function_code --------------------\n\ndef estimate_human_pose(image_path: str, output_path: str) -> None:\n    \"\"\"\n    Estimate the human pose from an image of a user performing an exercise.\n\n    Args:\n        image_path (str): The path to the image file.\n        output_path (str): The path to save the output image with estimated pose.\n\n    Returns:\n        None\n    \"\"\"\n    openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n    image = Image.open(image_path)\n    image = openpose(image)\n\n    controlnet = ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-openpose', torch_dtype=torch.float16)\n    image = pipe('chef in the kitchen', image, num_inference_steps=20).images[0]\n    image.save(output_path)\n\n# test_function_code --------------------\n\ndef test_estimate_human_pose():\n    \"\"\"\n    Test the function estimate_human_pose.\n    \"\"\"\n    # Test case 1\n    estimate_human_pose('test_images/exercise1.jpg', 'test_output/pose1_out.png')\n    assert os.path.exists('test_output/pose1_out.png')\n\n    # Test case 2\n    estimate_human_pose('test_images/exercise2.jpg', 'test_output/pose2_out.png')\n    assert os.path.exists('test_output/pose2_out.png')\n\n    # Test case 3\n    estimate_human_pose('test_images/exercise3.jpg', 'test_output/pose3_out.png')\n    assert os.path.exists('test_output/pose3_out.png')\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_estimate_human_pose()", "function_import": "# function_import --------------------\n\nfrom PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import OpenposeDetector\nimport os\n\n", "function_code": "# function_code --------------------\n\ndef estimate_human_pose(image_path: str, output_path: str) -> None:\n    \"\"\"\n    Estimate the human pose from an image of a user performing an exercise.\n\n    Args:\n        image_path (str): The path to the image file.\n        output_path (str): The path to save the output image with estimated pose.\n\n    Returns:\n        None\n    \"\"\"\n    openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n    image = Image.open(image_path)\n    image = openpose(image)\n\n    controlnet = ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-openpose', torch_dtype=torch.float16)\n    image = pipe('chef in the kitchen', image, num_inference_steps=20).images[0]\n    image.save(output_path)\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_estimate_human_pose():\n    \"\"\"\n    Test the function estimate_human_pose.\n    \"\"\"\n    # Test case 1\n    estimate_human_pose('test_images/exercise1.jpg', 'test_output/pose1_out.png')\n    assert os.path.exists('test_output/pose1_out.png')\n\n    # Test case 2\n    estimate_human_pose('test_images/exercise2.jpg', 'test_output/pose2_out.png')\n    assert os.path.exists('test_output/pose2_out.png')\n\n    # Test case 3\n    estimate_human_pose('test_images/exercise3.jpg', 'test_output/pose3_out.png')\n    assert os.path.exists('test_output/pose3_out.png')\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_estimate_human_pose()", "instruct": "# function_import --------------------\n\nfrom PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import OpenposeDetector\nimport os\n\n# function_code --------------------\n\ndef estimate_human_pose(image_path: str, output_path: str) -> None:\n    \"\"\"\n    Estimate the human pose from an image of a user performing an exercise.\n\n    Args:\n        image_path (str): The path to the image file.\n        output_path (str): The path to save the output image with estimated pose.\n\n    Returns:\n        None\n    \"\"\"", "answer": "\n    openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n    image = Image.open(image_path)\n    image = openpose(image)\n\n    controlnet = ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-openpose', torch_dtype=torch.float16)\n    image = pipe('chef in the kitchen', image, num_inference_steps=20).images[0]\n    image.save(output_path)\n\n", "prediction": "\n    # load model and detector\n    cuda = torch.cuda.is_available()\n    device = \"cuda\" if cuda else \"cpu\"\n    diffuser_model_path = os.getenv(\"DIFFUSER_MODEL\")\n    controlnet_model_path = os.getenv(\"CONTROLNET_MODEL\")\n    model = ControlNetModel(diffuser_model_path, controlnet_model_path).to(device)\n    detector = OpenposeDetector()\n    \n    # preprocess image\n    input_image = Image.open(image_path)\n\n    try:\n        pose_data = detector.run_on_input(input_image, True)[-1]\n        \n        # draw pose on the image\n        output_img = input_image.copy()\n        for key in [\"left_wrist\", \"right_wrist\"]:\n            x = int(pose_data[key][0])\n            y = int(pose_data[key][1])\n            output_img.putpixel((x,y), (256, 0, 0))\n\n        # estimate the pose\n        diffuser_pipeline = StableDiffusionControlNetPipeline()\n        scheduler = UniPCMultistepScheduler(model)\n        \n        output_image = diffuser_pipeline.infer(scheduler, torch.from_numpy(pose_data[\"keypoints\"][None].transpose((2,0,1))).to(\"cuda\"), 150)[-1]\n            \n        # save result image to disk\n        output_image = (output_image[-1].detach().cpu()*256).numpy()\n        Image.fromarray(np.flipud(output_image)).save(output_path)\n    except Exception as e:\n        print(\"Could not estimate pose from image {}: {}\".format(image_path, str(e)))"}