{"path": "output/hf-eval-data-v3-valid/f00410_generate_queries.py", "content": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# function_code --------------------\n\ndef generate_queries(document: str) -> str:\n    '''\n    Generate possible user queries for a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The input document for which to generate queries.\n\n    Returns:\n        str: The generated queries.\n\n    Raises:\n        ValueError: If the input document is not a string.\n    '''\n    if not isinstance(document, str):\n        raise ValueError('Input document must be a string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    input_ids = tokenizer.encode(document, return_tensors='pt')\n    generated_ids = model.generate(input_ids)\n    generated_queries = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    return generated_queries\n\n# test_function_code --------------------\n\ndef test_generate_queries():\n    '''\n    Test the generate_queries function.\n    '''\n    document1 = 'This is a test document.'\n    document2 = 'Another test document.'\n    document3 = 123\n\n    assert isinstance(generate_queries(document1), str)\n    assert isinstance(generate_queries(document2), str)\n    try:\n        generate_queries(document3)\n    except ValueError:\n        pass\n    else:\n        raise AssertionError('ValueError not raised for non-string input.')\n\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\ntest_generate_queries()", "function_import": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n", "function_code": "# function_code --------------------\n\ndef generate_queries(document: str) -> str:\n    '''\n    Generate possible user queries for a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The input document for which to generate queries.\n\n    Returns:\n        str: The generated queries.\n\n    Raises:\n        ValueError: If the input document is not a string.\n    '''\n    if not isinstance(document, str):\n        raise ValueError('Input document must be a string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    input_ids = tokenizer.encode(document, return_tensors='pt')\n    generated_ids = model.generate(input_ids)\n    generated_queries = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    return generated_queries\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_queries():\n    '''\n    Test the generate_queries function.\n    '''\n    document1 = 'This is a test document.'\n    document2 = 'Another test document.'\n    document3 = 123\n\n    assert isinstance(generate_queries(document1), str)\n    assert isinstance(generate_queries(document2), str)\n    try:\n        generate_queries(document3)\n    except ValueError:\n        pass\n    else:\n        raise AssertionError('ValueError not raised for non-string input.')\n\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_generate_queries()", "instruct": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# function_code --------------------\n\ndef generate_queries(document: str) -> str:\n    '''\n    Generate possible user queries for a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The input document for which to generate queries.\n\n    Returns:\n        str: The generated queries.\n\n    Raises:\n        ValueError: If the input document is not a string.\n    '''", "answer": "\n    if not isinstance(document, str):\n        raise ValueError('Input document must be a string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    input_ids = tokenizer.encode(document, return_tensors='pt')\n    generated_ids = model.generate(input_ids)\n    generated_queries = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    return generated_queries\n\n", "prediction": "\n    \n    # Ensure that the argument is of type 'string'.\n    if not isinstance(document, str):\n        raise TypeError(\"The provided document must be a string.\")\n        \n    # Load the model and tokenizer.\n    t5_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n    \n    # Tokenize inputs, and padding and make them both an integer sequences. \n    # Note that the input document must be a string of sentences seperated by full stops (\".\").\n    tokens = tokenizer([document], return_tensors=\"pt\", padding=True)\n    \n    # Generate queries.\n    query = t5_model.generate(tokens['input_ids'], \n                              num_beams=6, \n                              early_stopping=True, \n                              max_length=30,\n                              repetition_penalty=2., \n                              length_penalty=.15)\n    \n    # Decode the tokenized queries.\n    decoded = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in query]\n    \n    return ' '.join([sentence.lstrip(' ') for sentence in decoded])"}