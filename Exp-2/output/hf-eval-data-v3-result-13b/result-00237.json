{"path": "output/hf-eval-data-v3-valid/f00890_translate_english_to_german.py", "content": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_english_to_german(src_text):\n    \"\"\"\n    Translates English text to German using the MBartForConditionalGeneration model.\n\n    Args:\n        src_text (str): The source text in English that needs to be translated.\n\n    Returns:\n        str: The translated text in German.\n\n    Raises:\n        OSError: If there is an issue with loading the pre-trained model or tokenizers.\n    \"\"\"\n    try:\n        model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50')\n        tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50', src_lang='en_XX', tgt_lang='de_DE')\n        translated_output = model.generate(**tokenizer(src_text, return_tensors='pt'))\n        tgt_text = tokenizer.batch_decode(translated_output, skip_special_tokens=True)\n        return tgt_text\n    except OSError as e:\n        print(f'Error: {e}')\n\n# test_function_code --------------------\n\ndef test_translate_english_to_german():\n    \"\"\"\n    Tests the translate_english_to_german function with some test cases.\n    \"\"\"\n    assert translate_english_to_german('Hello, how are you?') is not None\n    assert translate_english_to_german('This is a test sentence.') is not None\n    assert translate_english_to_german('I love programming.') is not None\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_translate_english_to_german()", "function_import": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n", "function_code": "# function_code --------------------\n\ndef translate_english_to_german(src_text):\n    \"\"\"\n    Translates English text to German using the MBartForConditionalGeneration model.\n\n    Args:\n        src_text (str): The source text in English that needs to be translated.\n\n    Returns:\n        str: The translated text in German.\n\n    Raises:\n        OSError: If there is an issue with loading the pre-trained model or tokenizers.\n    \"\"\"\n    try:\n        model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50')\n        tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50', src_lang='en_XX', tgt_lang='de_DE')\n        translated_output = model.generate(**tokenizer(src_text, return_tensors='pt'))\n        tgt_text = tokenizer.batch_decode(translated_output, skip_special_tokens=True)\n        return tgt_text\n    except OSError as e:\n        print(f'Error: {e}')\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_translate_english_to_german():\n    \"\"\"\n    Tests the translate_english_to_german function with some test cases.\n    \"\"\"\n    assert translate_english_to_german('Hello, how are you?') is not None\n    assert translate_english_to_german('This is a test sentence.') is not None\n    assert translate_english_to_german('I love programming.') is not None\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_translate_english_to_german()", "instruct": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_english_to_german(src_text):\n    \"\"\"\n    Translates English text to German using the MBartForConditionalGeneration model.\n\n    Args:\n        src_text (str): The source text in English that needs to be translated.\n\n    Returns:\n        str: The translated text in German.\n\n    Raises:\n        OSError: If there is an issue with loading the pre-trained model or tokenizers.\n    \"\"\"", "answer": "\n    try:\n        model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50')\n        tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50', src_lang='en_XX', tgt_lang='de_DE')\n        translated_output = model.generate(**tokenizer(src_text, return_tensors='pt'))\n        tgt_text = tokenizer.batch_decode(translated_output, skip_special_tokens=True)\n        return tgt_text\n    except OSError as e:\n        print(f'Error: {e}')\n\n", "prediction": "\n    \n    # Load pre-trained model and tokenizer\n    try: \n        model = MBartForConditionalGeneration.from_pretrained(\n            \"facebook/mbart-large-50\", force_download=True)\n        tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\")\n    except OSError:\n        print(\"There was an issue with loading the pre-trained model or tokenizers.\")  # noqa: E501\n    \n    # Tokenize inputs (src, mt)\n    src_tokenizer = tokenizer.get_tokenizer()\n    src_model_inputs = tokenizer(src_text, return_tensors=\"pt\")\n        \n    # Predict and decode translation\n    translated = model.generate(**src_model_inputs)\n    tgt_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n    \n    return tgt_text[0]"}