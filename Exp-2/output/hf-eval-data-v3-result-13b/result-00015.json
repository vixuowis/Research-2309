{"path": "output/hf-eval-data-v3-valid/f00075_transcribe_audio.py", "content": "# function_import --------------------\n\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom datasets import load_dataset\n\n# function_code --------------------\n\ndef transcribe_audio(audio_sample):\n    '''\n    Transcribe audio using the openai/whisper-tiny model.\n\n    Args:\n        audio_sample (dict): A dictionary containing 'array' and 'sampling_rate' of the audio.\n\n    Returns:\n        str: The transcribed text.\n    '''\n    processor = WhisperProcessor.from_pretrained('openai/whisper-tiny')\n    model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny')\n    input_features = processor(audio_sample['array'], sampling_rate=audio_sample['sampling_rate'], return_tensors='pt').input_features\n    predicted_ids = model.generate(input_features)\n    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n    return transcription[0]\n\n# test_function_code --------------------\n\ndef test_transcribe_audio():\n    '''\n    Test the transcribe_audio function.\n    '''\n    ds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split='validation')\n    sample = ds[0]['audio']\n    transcription = transcribe_audio(sample)\n    assert isinstance(transcription, str), 'The result should be a string.'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_transcribe_audio()", "function_import": "# function_import --------------------\n\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom datasets import load_dataset\n\n", "function_code": "# function_code --------------------\n\ndef transcribe_audio(audio_sample):\n    '''\n    Transcribe audio using the openai/whisper-tiny model.\n\n    Args:\n        audio_sample (dict): A dictionary containing 'array' and 'sampling_rate' of the audio.\n\n    Returns:\n        str: The transcribed text.\n    '''\n    processor = WhisperProcessor.from_pretrained('openai/whisper-tiny')\n    model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny')\n    input_features = processor(audio_sample['array'], sampling_rate=audio_sample['sampling_rate'], return_tensors='pt').input_features\n    predicted_ids = model.generate(input_features)\n    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n    return transcription[0]\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_transcribe_audio():\n    '''\n    Test the transcribe_audio function.\n    '''\n    ds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split='validation')\n    sample = ds[0]['audio']\n    transcription = transcribe_audio(sample)\n    assert isinstance(transcription, str), 'The result should be a string.'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_transcribe_audio()", "instruct": "# function_import --------------------\n\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom datasets import load_dataset\n\n# function_code --------------------\n\ndef transcribe_audio(audio_sample):\n    '''\n    Transcribe audio using the openai/whisper-tiny model.\n\n    Args:\n        audio_sample (dict): A dictionary containing 'array' and 'sampling_rate' of the audio.\n\n    Returns:\n        str: The transcribed text.\n    '''", "answer": "\n    processor = WhisperProcessor.from_pretrained('openai/whisper-tiny')\n    model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny')\n    input_features = processor(audio_sample['array'], sampling_rate=audio_sample['sampling_rate'], return_tensors='pt').input_features\n    predicted_ids = model.generate(input_features)\n    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n    return transcription[0]\n\n", "prediction": "\n    \n    processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny-random\")\n    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny-random\").to('cuda').half()\n    \n    ds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split=\"validation\")\n    processor.save_pretrained('processor')\n    model.config.label_names = ['intent']\n    model.config.return_dict = True    \n    model.generate(**processor(ds['text'][0], return_tensors='pt'))\n    model.to('cuda').half()\n\n# -------------------- function_code --------------------"}