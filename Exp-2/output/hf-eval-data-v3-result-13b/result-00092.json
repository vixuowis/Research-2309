{"path": "output/hf-eval-data-v3-valid/f00399_detect_russian_sentence_contradiction.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef detect_russian_sentence_contradiction(sentence1: str, sentence2: str) -> bool:\n    \"\"\"\n    Determine if one Russian sentence logically contradicts the information provided by another Russian sentence.\n\n    Args:\n        sentence1 (str): The first Russian sentence.\n        sentence2 (str): The second Russian sentence.\n\n    Returns:\n        bool: True if contradiction is detected, False otherwise.\n    \"\"\"\n    model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n    if torch.cuda.is_available():\n        model.cuda()\n    with torch.inference_mode():\n        out = model(**tokenizer(sentence1, sentence2, return_tensors='pt').to(model.device))\n        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n    predicted_label = {v: proba[k] for k, v in model.config.id2label.items()}\n    return predicted_label['contradiction'] > predicted_label['neutral'] and predicted_label['contradiction'] > predicted_label['entailment']\n\n# test_function_code --------------------\n\ndef test_detect_russian_sentence_contradiction():\n    assert detect_russian_sentence_contradiction('\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430', '\u042d\u0442\u043e \u0441\u0438\u043d\u044f\u044f \u043c\u0430\u0448\u0438\u043d\u0430') == True\n    assert detect_russian_sentence_contradiction('\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430', '\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430') == False\n    assert detect_russian_sentence_contradiction('\u041e\u043d \u043b\u044e\u0431\u0438\u0442 \u043a\u043e\u0448\u0435\u043a', '\u041e\u043d \u043d\u0435\u043d\u0430\u0432\u0438\u0434\u0438\u0442 \u043a\u043e\u0448\u0435\u043a') == True\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_detect_russian_sentence_contradiction()", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n", "function_code": "# function_code --------------------\n\ndef detect_russian_sentence_contradiction(sentence1: str, sentence2: str) -> bool:\n    \"\"\"\n    Determine if one Russian sentence logically contradicts the information provided by another Russian sentence.\n\n    Args:\n        sentence1 (str): The first Russian sentence.\n        sentence2 (str): The second Russian sentence.\n\n    Returns:\n        bool: True if contradiction is detected, False otherwise.\n    \"\"\"\n    model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n    if torch.cuda.is_available():\n        model.cuda()\n    with torch.inference_mode():\n        out = model(**tokenizer(sentence1, sentence2, return_tensors='pt').to(model.device))\n        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n    predicted_label = {v: proba[k] for k, v in model.config.id2label.items()}\n    return predicted_label['contradiction'] > predicted_label['neutral'] and predicted_label['contradiction'] > predicted_label['entailment']\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_detect_russian_sentence_contradiction():\n    assert detect_russian_sentence_contradiction('\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430', '\u042d\u0442\u043e \u0441\u0438\u043d\u044f\u044f \u043c\u0430\u0448\u0438\u043d\u0430') == True\n    assert detect_russian_sentence_contradiction('\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430', '\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430') == False\n    assert detect_russian_sentence_contradiction('\u041e\u043d \u043b\u044e\u0431\u0438\u0442 \u043a\u043e\u0448\u0435\u043a', '\u041e\u043d \u043d\u0435\u043d\u0430\u0432\u0438\u0434\u0438\u0442 \u043a\u043e\u0448\u0435\u043a') == True\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_detect_russian_sentence_contradiction()", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef detect_russian_sentence_contradiction(sentence1: str, sentence2: str) -> bool:\n    \"\"\"\n    Determine if one Russian sentence logically contradicts the information provided by another Russian sentence.\n\n    Args:\n        sentence1 (str): The first Russian sentence.\n        sentence2 (str): The second Russian sentence.\n\n    Returns:\n        bool: True if contradiction is detected, False otherwise.\n    \"\"\"", "answer": "\n    model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n    if torch.cuda.is_available():\n        model.cuda()\n    with torch.inference_mode():\n        out = model(**tokenizer(sentence1, sentence2, return_tensors='pt').to(model.device))\n        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n    predicted_label = {v: proba[k] for k, v in model.config.id2label.items()}\n    return predicted_label['contradiction'] > predicted_label['neutral'] and predicted_label['contradiction'] > predicted_label['entailment']\n\n", "prediction": "\n    \n    # load pre-trained model and tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\"deepmipt/tardigrade-russian-bert-base-finetuned-paraphrase\")\n    model = AutoModelForSequenceClassification.from_pretrained(\"deepmipt/tardigrade-russian-bert-base-finetuned-paraphrase\")\n\n    # tokenize input texts\n    text1 = [sentence1]\n    text2 = [sentence2]\n    encoded_text1 = tokenizer(text1, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n    encoded_text2 = tokenizer(text2, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n\n    # calculate embeddings for input texts and make predictions on them\n    with torch.no_grad():    \n        model.eval()\n        outputs1 = model(encoded_text1[\"input_ids\"], encoded_text1[\"attention_mask\"])\n        logits1 = outputs1.logits\n        prediction1 = torch.argmax(logits1).numpy().tolist()\n    \n    with torch.no_grad():    \n        model.eval()\n        outputs2 = model(encoded_text2[\"input_ids\"], encoded_text2[\"attention_mask\"])\n        logits2 = outputs2.logits\n        prediction2 = torch.argmax(logits2).numpy().tolist()\n    \n    # check for contradiction between input sentences\n    if (prediction1 != prediction2):\n        return True\n    else:\n        return False"}