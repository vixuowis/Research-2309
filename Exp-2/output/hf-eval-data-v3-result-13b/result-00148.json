{"path": "output/hf-eval-data-v3-valid/f00605_translate_spanish_to_polish.py", "content": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_spanish_to_polish(spanish_text):\n    \"\"\"\n    Translate Spanish text to Polish using Hugging Face's MBartForConditionalGeneration model.\n\n    Args:\n        spanish_text (str): The Spanish text to be translated.\n\n    Returns:\n        str: The translated Polish text.\n    \"\"\"\n    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer.src_lang = 'es_ES'\n    encoded_spanish = tokenizer(spanish_text, return_tensors='pt')\n    generated_tokens = model.generate(**encoded_spanish, forced_bos_token_id=tokenizer.lang_code_to_id['pl_PL'])\n    polish_subtitles = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n    return polish_subtitles[0]\n\n# test_function_code --------------------\n\ndef test_translate_spanish_to_polish():\n    \"\"\"\n    Test the function translate_spanish_to_polish.\n    \"\"\"\n    spanish_text = 'Hola, \u00bfc\u00f3mo est\u00e1s?'\n    polish_text = translate_spanish_to_polish(spanish_text)\n    assert isinstance(polish_text, str), 'The result should be a string.'\n    assert polish_text != '', 'The result should not be an empty string.'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_translate_spanish_to_polish()", "function_import": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n", "function_code": "# function_code --------------------\n\ndef translate_spanish_to_polish(spanish_text):\n    \"\"\"\n    Translate Spanish text to Polish using Hugging Face's MBartForConditionalGeneration model.\n\n    Args:\n        spanish_text (str): The Spanish text to be translated.\n\n    Returns:\n        str: The translated Polish text.\n    \"\"\"\n    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer.src_lang = 'es_ES'\n    encoded_spanish = tokenizer(spanish_text, return_tensors='pt')\n    generated_tokens = model.generate(**encoded_spanish, forced_bos_token_id=tokenizer.lang_code_to_id['pl_PL'])\n    polish_subtitles = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n    return polish_subtitles[0]\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_translate_spanish_to_polish():\n    \"\"\"\n    Test the function translate_spanish_to_polish.\n    \"\"\"\n    spanish_text = 'Hola, \u00bfc\u00f3mo est\u00e1s?'\n    polish_text = translate_spanish_to_polish(spanish_text)\n    assert isinstance(polish_text, str), 'The result should be a string.'\n    assert polish_text != '', 'The result should not be an empty string.'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_translate_spanish_to_polish()", "instruct": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_spanish_to_polish(spanish_text):\n    \"\"\"\n    Translate Spanish text to Polish using Hugging Face's MBartForConditionalGeneration model.\n\n    Args:\n        spanish_text (str): The Spanish text to be translated.\n\n    Returns:\n        str: The translated Polish text.\n    \"\"\"", "answer": "\n    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer.src_lang = 'es_ES'\n    encoded_spanish = tokenizer(spanish_text, return_tensors='pt')\n    generated_tokens = model.generate(**encoded_spanish, forced_bos_token_id=tokenizer.lang_code_to_id['pl_PL'])\n    polish_subtitles = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n    return polish_subtitles[0]\n\n", "prediction": "\n\n    # Load the model and tokenizer\n    model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\", force_download=True)\n    tokenizer = MBart50TokenizerFast.from_pretrained(\n        \"facebook/mbart-large-50\", src_lang=\"es_XX\", tgt_lang=\"pl_PL\", add_prefix_space=True,\n    )\n\n    # Tokenize the input text\n    tokenized_text = tokenizer.prepare_seq2seq_batch([spanish_text])\n\n    # Get the generated translation\n    translated = model.generate(**tokenized_text)\n\n    return tokenizer.postprocess_translation(translated, skip_special_tokens=True)[0]\n"}