{"path": "output/hf-eval-data-v3-valid/f00258_extract_features.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\n# function_code --------------------\n\ndef extract_features(text):\n    \"\"\"\n    Extract features from the given text using the 'DeepPavlov/rubert-base-cased' model.\n\n    Args:\n        text (str): The text from which to extract features.\n\n    Returns:\n        torch.Tensor: The extracted features.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n    model = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased')\n    inputs = tokenizer(text, return_tensors='pt')\n    outputs = model(**inputs)\n    features = outputs.last_hidden_state\n    return features\n\n# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Test the extract_features function.\n    \"\"\"\n    text = '\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0442\u0435\u043a\u0441\u0442 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435 \u0437\u0434\u0435\u0441\u044c'\n    features = extract_features(text)\n    assert features is not None\n    assert features.size(0) == 1\n\n    text = '\u042d\u0442\u043e \u0435\u0449\u0435 \u043e\u0434\u0438\u043d \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u0442\u0435\u043a\u0441\u0442'\n    features = extract_features(text)\n    assert features is not None\n    assert features.size(0) == 1\n\n    text = '\u0418 \u044d\u0442\u043e \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u0442\u0435\u043a\u0441\u0442'\n    features = extract_features(text)\n    assert features is not None\n    assert features.size(0) == 1\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_extract_features()", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef extract_features(text):\n    \"\"\"\n    Extract features from the given text using the 'DeepPavlov/rubert-base-cased' model.\n\n    Args:\n        text (str): The text from which to extract features.\n\n    Returns:\n        torch.Tensor: The extracted features.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n    model = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased')\n    inputs = tokenizer(text, return_tensors='pt')\n    outputs = model(**inputs)\n    features = outputs.last_hidden_state\n    return features\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Test the extract_features function.\n    \"\"\"\n    text = '\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0442\u0435\u043a\u0441\u0442 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435 \u0437\u0434\u0435\u0441\u044c'\n    features = extract_features(text)\n    assert features is not None\n    assert features.size(0) == 1\n\n    text = '\u042d\u0442\u043e \u0435\u0449\u0435 \u043e\u0434\u0438\u043d \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u0442\u0435\u043a\u0441\u0442'\n    features = extract_features(text)\n    assert features is not None\n    assert features.size(0) == 1\n\n    text = '\u0418 \u044d\u0442\u043e \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u0442\u0435\u043a\u0441\u0442'\n    features = extract_features(text)\n    assert features is not None\n    assert features.size(0) == 1\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_extract_features()", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\n# function_code --------------------\n\ndef extract_features(text):\n    \"\"\"\n    Extract features from the given text using the 'DeepPavlov/rubert-base-cased' model.\n\n    Args:\n        text (str): The text from which to extract features.\n\n    Returns:\n        torch.Tensor: The extracted features.\n    \"\"\"", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n    model = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased')\n    inputs = tokenizer(text, return_tensors='pt')\n    outputs = model(**inputs)\n    features = outputs.last_hidden_state\n    return features\n\n", "prediction": "\n    \n    # get model and tokenizer\n    model = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased')\n    tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n    \n    # encode text and get features\n    encoded = tokenizer(text, return_tensors='pt', padding=True)\n    with torch.no_grad():\n        features = model(**encoded).pooler_output[0]\n        \n    return features"}