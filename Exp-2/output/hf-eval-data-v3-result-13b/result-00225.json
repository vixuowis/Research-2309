{"path": "output/hf-eval-data-v3-valid/f00858_classify_image.py", "content": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef classify_image(img_url: str):\n    \"\"\"\n    Classify an image using a pretrained CLIP model.\n\n    Args:\n        img_url (str): The URL of the image to classify.\n\n    Returns:\n        dict: A dictionary where keys are labels and values are probabilities.\n    \"\"\"\n    model = CLIPModel.from_pretrained('flax-community/clip-rsicd-v2')\n    processor = CLIPProcessor.from_pretrained('flax-community/clip-rsicd-v2')\n    image = Image.open(requests.get(img_url, stream=True).raw)\n    labels = ['residential area', 'playground', 'stadium', 'forest', 'airport']\n    inputs = processor(text=[f'a photo of a {l}' for l in labels], images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {l: p.item() for l, p in zip(labels, probs[0])}\n\n# test_function_code --------------------\n\ndef test_classify_image():\n    \"\"\"\n    Test the classify_image function.\n    \"\"\"\n    img_url = 'https://placekitten.com/200/300'\n    result = classify_image(img_url)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == set(['residential area', 'playground', 'stadium', 'forest', 'airport'])\n    assert all(0 <= v <= 1 for v in result.values())\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_classify_image()", "function_import": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n", "function_code": "# function_code --------------------\n\ndef classify_image(img_url: str):\n    \"\"\"\n    Classify an image using a pretrained CLIP model.\n\n    Args:\n        img_url (str): The URL of the image to classify.\n\n    Returns:\n        dict: A dictionary where keys are labels and values are probabilities.\n    \"\"\"\n    model = CLIPModel.from_pretrained('flax-community/clip-rsicd-v2')\n    processor = CLIPProcessor.from_pretrained('flax-community/clip-rsicd-v2')\n    image = Image.open(requests.get(img_url, stream=True).raw)\n    labels = ['residential area', 'playground', 'stadium', 'forest', 'airport']\n    inputs = processor(text=[f'a photo of a {l}' for l in labels], images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {l: p.item() for l, p in zip(labels, probs[0])}\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_classify_image():\n    \"\"\"\n    Test the classify_image function.\n    \"\"\"\n    img_url = 'https://placekitten.com/200/300'\n    result = classify_image(img_url)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == set(['residential area', 'playground', 'stadium', 'forest', 'airport'])\n    assert all(0 <= v <= 1 for v in result.values())\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_classify_image()", "instruct": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef classify_image(img_url: str):\n    \"\"\"\n    Classify an image using a pretrained CLIP model.\n\n    Args:\n        img_url (str): The URL of the image to classify.\n\n    Returns:\n        dict: A dictionary where keys are labels and values are probabilities.\n    \"\"\"", "answer": "\n    model = CLIPModel.from_pretrained('flax-community/clip-rsicd-v2')\n    processor = CLIPProcessor.from_pretrained('flax-community/clip-rsicd-v2')\n    image = Image.open(requests.get(img_url, stream=True).raw)\n    labels = ['residential area', 'playground', 'stadium', 'forest', 'airport']\n    inputs = processor(text=[f'a photo of a {l}' for l in labels], images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {l: p.item() for l, p in zip(labels, probs[0])}\n\n", "prediction": "\n\n    # Load a pretrained CLIP model.\n    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n    \n    # Get the image from a URL.\n    response = requests.get(img_url)\n    img = Image.open(BytesIO(response.content))\n\n    # Convert it into a tensor to be passed through the model.\n    inputs = processor(\n        text=[\"a picture\"], images=img, return_tensors=\"pt\", padding=True\n    )\n\n    # Load another pretrained CLIP model with labels for ImageNet.\n    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image  # shape = [batch_size]\n    probs = logits_per_image.softmax(dim=-1).tolist()[0]  # shape = [num_labels]\n\n    # Convert the probabilities into a dictionary where keys are labels and values are probabilities.\n    model_url = \"https://huggingface.co/openai/clip-vit-base-patch32\"\n    resp = requests.get(f\"{model_url}/api/info\")\n    \n    labels = []\n    for label in resp.json()[\"metadata\"][\"result_labels\"]:\n        labels.append(label[10:])  # Strip \"attribute_\" from the beginning of each label.\n\n    return dict(zip(labels, probs))\n"}