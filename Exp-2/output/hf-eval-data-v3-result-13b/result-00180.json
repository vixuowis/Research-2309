{"path": "output/hf-eval-data-v3-valid/f00729_extract_features.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\n# function_code --------------------\n\ndef extract_features(input_text: str):\n    \"\"\"\n    Extract features from text or code using the pre-trained CodeBERT model.\n\n    Args:\n        input_text (str): The input text or code from which to extract features.\n\n    Returns:\n        torch.Tensor: The extracted features (embeddings) from the input text or code.\n    \"\"\"\n    model = AutoModel.from_pretrained('microsoft/codebert-base')\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')\n    inputs = tokenizer(input_text, return_tensors='pt')\n    outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state\n    return embeddings\n\n# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Test the extract_features function.\n    \"\"\"\n    input_text = 'def hello_world():\\n    print(\"Hello, world!\")'\n    embeddings = extract_features(input_text)\n    assert embeddings is not None\n    assert embeddings.size(0) > 0\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    print(test_extract_features())", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef extract_features(input_text: str):\n    \"\"\"\n    Extract features from text or code using the pre-trained CodeBERT model.\n\n    Args:\n        input_text (str): The input text or code from which to extract features.\n\n    Returns:\n        torch.Tensor: The extracted features (embeddings) from the input text or code.\n    \"\"\"\n    model = AutoModel.from_pretrained('microsoft/codebert-base')\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')\n    inputs = tokenizer(input_text, return_tensors='pt')\n    outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state\n    return embeddings\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Test the extract_features function.\n    \"\"\"\n    input_text = 'def hello_world():\\n    print(\"Hello, world!\")'\n    embeddings = extract_features(input_text)\n    assert embeddings is not None\n    assert embeddings.size(0) > 0\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    print(test_extract_features())", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\n# function_code --------------------\n\ndef extract_features(input_text: str):\n    \"\"\"\n    Extract features from text or code using the pre-trained CodeBERT model.\n\n    Args:\n        input_text (str): The input text or code from which to extract features.\n\n    Returns:\n        torch.Tensor: The extracted features (embeddings) from the input text or code.\n    \"\"\"", "answer": "\n    model = AutoModel.from_pretrained('microsoft/codebert-base')\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')\n    inputs = tokenizer(input_text, return_tensors='pt')\n    outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state\n    return embeddings\n\n", "prediction": "\n    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n    \n    tokens = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n    model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n        \n    # get the mean of the first 12 layers of the encoder outputs\n    with torch.no_grad():\n        out = model(**tokens, output_hidden_states=True)[\"hidden_states\"][0:12]\n    \n    feats = [x.mean(dim=-2).squeeze() for x in out]\n        \n    return torch.stack(feats)"}