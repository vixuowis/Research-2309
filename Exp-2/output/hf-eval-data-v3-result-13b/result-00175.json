{"path": "output/hf-eval-data-v3-valid/f00705_text_to_speech.py", "content": "# function_import --------------------\n\nfrom transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\nfrom datasets import load_dataset\nimport torch\nimport soundfile as sf\n\n# function_code --------------------\n\ndef text_to_speech(text: str, speaker_id: int = 7306):\n    '''\n    Converts a given text to speech using the SpeechT5 model from Hugging Face Transformers.\n\n    Args:\n        text (str): The text to be converted to speech.\n        speaker_id (int, optional): The id of the speaker whose voice is to be used. Defaults to 7306.\n\n    Returns:\n        str: The path to the generated audio file.\n    '''\n    processor = SpeechT5Processor.from_pretrained('microsoft/speecht5_tts')\n    model = SpeechT5ForTextToSpeech.from_pretrained('microsoft/speecht5_tts')\n    vocoder = SpeechT5HifiGan.from_pretrained('microsoft/speecht5_hifigan')\n    inputs = processor(text=text, return_tensors='pt')\n    embeddings_dataset = load_dataset('Matthijs/cmu-arctic-xvectors', split='validation')\n    speaker_embeddings = torch.tensor(embeddings_dataset[speaker_id]['xvector']).unsqueeze(0)\n    speech = model.generate_speech(inputs['input_ids'], speaker_embeddings, vocoder=vocoder)\n    sf.write('speech.wav', speech.numpy(), samplerate=16000)\n    return 'speech.wav'\n\n# test_function_code --------------------\n\ndef test_text_to_speech():\n    '''\n    Tests the text_to_speech function.\n    '''\n    assert text_to_speech('Hello, world!') == 'speech.wav'\n    assert text_to_speech('This is a test.', 7306) == 'speech.wav'\n    assert text_to_speech('Another test.', 7307) == 'speech.wav'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_text_to_speech()", "function_import": "# function_import --------------------\n\nfrom transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\nfrom datasets import load_dataset\nimport torch\nimport soundfile as sf\n\n", "function_code": "# function_code --------------------\n\ndef text_to_speech(text: str, speaker_id: int = 7306):\n    '''\n    Converts a given text to speech using the SpeechT5 model from Hugging Face Transformers.\n\n    Args:\n        text (str): The text to be converted to speech.\n        speaker_id (int, optional): The id of the speaker whose voice is to be used. Defaults to 7306.\n\n    Returns:\n        str: The path to the generated audio file.\n    '''\n    processor = SpeechT5Processor.from_pretrained('microsoft/speecht5_tts')\n    model = SpeechT5ForTextToSpeech.from_pretrained('microsoft/speecht5_tts')\n    vocoder = SpeechT5HifiGan.from_pretrained('microsoft/speecht5_hifigan')\n    inputs = processor(text=text, return_tensors='pt')\n    embeddings_dataset = load_dataset('Matthijs/cmu-arctic-xvectors', split='validation')\n    speaker_embeddings = torch.tensor(embeddings_dataset[speaker_id]['xvector']).unsqueeze(0)\n    speech = model.generate_speech(inputs['input_ids'], speaker_embeddings, vocoder=vocoder)\n    sf.write('speech.wav', speech.numpy(), samplerate=16000)\n    return 'speech.wav'\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_text_to_speech():\n    '''\n    Tests the text_to_speech function.\n    '''\n    assert text_to_speech('Hello, world!') == 'speech.wav'\n    assert text_to_speech('This is a test.', 7306) == 'speech.wav'\n    assert text_to_speech('Another test.', 7307) == 'speech.wav'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_text_to_speech()", "instruct": "# function_import --------------------\n\nfrom transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\nfrom datasets import load_dataset\nimport torch\nimport soundfile as sf\n\n# function_code --------------------\n\ndef text_to_speech(text: str, speaker_id: int = 7306):\n    '''\n    Converts a given text to speech using the SpeechT5 model from Hugging Face Transformers.\n\n    Args:\n        text (str): The text to be converted to speech.\n        speaker_id (int, optional): The id of the speaker whose voice is to be used. Defaults to 7306.\n\n    Returns:\n        str: The path to the generated audio file.\n    '''", "answer": "\n    processor = SpeechT5Processor.from_pretrained('microsoft/speecht5_tts')\n    model = SpeechT5ForTextToSpeech.from_pretrained('microsoft/speecht5_tts')\n    vocoder = SpeechT5HifiGan.from_pretrained('microsoft/speecht5_hifigan')\n    inputs = processor(text=text, return_tensors='pt')\n    embeddings_dataset = load_dataset('Matthijs/cmu-arctic-xvectors', split='validation')\n    speaker_embeddings = torch.tensor(embeddings_dataset[speaker_id]['xvector']).unsqueeze(0)\n    speech = model.generate_speech(inputs['input_ids'], speaker_embeddings, vocoder=vocoder)\n    sf.write('speech.wav', speech.numpy(), samplerate=16000)\n    return 'speech.wav'\n\n", "prediction": "    \n    # load model and data collator\n    processor = SpeechT5Processor.from_pretrained(\"csukuylab/speech-t5\")\n    speech_model = SpeechT5ForTextToSpeech.from_pretrained(\"csukuylab/speech-t5\")\n    data_collator = DataCollatorCTCWithPadding(processor=processor, padding=\"longest\")\n    \n    # preprocess the text \n    input_ids = processor(text, return_tensors='pt', sampling_rate=24000).input_values\n    batch = data_collator([{\"input_ids\": input_ids}])\n        \n    # generate speech\n    with torch.no_grad():\n        logits = speech_model(**batch, labels=input_ids).logits\n    \n    # save generated audio to file\n    decoded_text = processor.batch_decode(torch.argmax(logits, dim=-1))[0]\n    wav = processor.parse_wav(decoded_text)\n    path = f\"{text}.wav\"\n    \n    # synthesize speech\n    with open(path, 'wb') as f:\n        f.write(wav)        \n    \n    return path\n\ndef speech_to_text(speech):\n    '''\n    Converts a given audio file to text using the SpeechT5 model from Hugging Face Transformers.\n\n    Args:\n        audio (str): The audio file to be converted to text.\n    \n    Returns:\n        str: The generated transcription.\n    '''\n    # load processor and model\n    speech_model = SpeechT5HifiGan.from_pretrained(\"csukuylab/speech-t5\")\n    processor = SpeechT5Processor.from_pretrained(\"csukuylab/speech-t5\")\n    \n    # load the audio file\n    input_values, sampling_rate = processor(speech, return_tensors=\"pt\").input_values\n    \n    # generate text from audio file\n    with torch"}