{"path": "output/hf-eval-data-v3-valid/f00687_classify_text.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# function_code --------------------\n\ndef classify_text(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification.\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"\n    nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    probs_list = []\n    for label in candidate_labels:\n        hypothesis = f'This example is {label}.'\n        inputs = tokenizer(sequence, hypothesis, return_tensors='pt', truncation=True)\n        logits = nli_model(**inputs)[0]\n        entail_contradiction_logits = logits[:, [0, 2]]\n        probs = entail_contradiction_logits.softmax(dim=1)\n        prob_label_is_true = probs[:, 1].item()\n        probs_list.append(prob_label_is_true)\n\n    category_index = probs_list.index(max(probs_list))\n    return candidate_labels[category_index]\n\n# test_function_code --------------------\n\ndef test_classify_text():\n    \"\"\"\n    Test the classify_text function.\n    \"\"\"\n    text_message = 'I spent hours in the kitchen trying a new recipe.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I am planning a trip to Paris.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I love to dance salsa.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_classify_text()", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef classify_text(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification.\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"\n    nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    probs_list = []\n    for label in candidate_labels:\n        hypothesis = f'This example is {label}.'\n        inputs = tokenizer(sequence, hypothesis, return_tensors='pt', truncation=True)\n        logits = nli_model(**inputs)[0]\n        entail_contradiction_logits = logits[:, [0, 2]]\n        probs = entail_contradiction_logits.softmax(dim=1)\n        prob_label_is_true = probs[:, 1].item()\n        probs_list.append(prob_label_is_true)\n\n    category_index = probs_list.index(max(probs_list))\n    return candidate_labels[category_index]\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_classify_text():\n    \"\"\"\n    Test the classify_text function.\n    \"\"\"\n    text_message = 'I spent hours in the kitchen trying a new recipe.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I am planning a trip to Paris.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I love to dance salsa.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_classify_text()", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# function_code --------------------\n\ndef classify_text(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification.\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"", "answer": "\n    nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    probs_list = []\n    for label in candidate_labels:\n        hypothesis = f'This example is {label}.'\n        inputs = tokenizer(sequence, hypothesis, return_tensors='pt', truncation=True)\n        logits = nli_model(**inputs)[0]\n        entail_contradiction_logits = logits[:, [0, 2]]\n        probs = entail_contradiction_logits.softmax(dim=1)\n        prob_label_is_true = probs[:, 1].item()\n        probs_list.append(prob_label_is_true)\n\n    category_index = probs_list.index(max(probs_list))\n    return candidate_labels[category_index]\n\n", "prediction": "\n\n    model = AutoModelForSequenceClassification.from_pretrained(\n        \"valhalla/distilbart-mnli-12-3\"\n    )\n    tokenizer = AutoTokenizer.from_pretrained(\"valhalla/distilbart-mnli-12-3\")\n    inputs = tokenizer(sequence, return_tensors=\"pt\")\n    output = model(**inputs)[\"logits\"][0]\n    result = torch.softmax(output, 0).tolist()\n    sorted_result = [(candidate_labels[i], result[i]) for i in range(len(result))]\n    sorted_result.sort(key=lambda x: x[1], reverse=True)\n    return sorted_result[0][0]"}