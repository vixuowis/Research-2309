{"path": "output/hf-eval-data-v3-valid/f00796_summarize_diary.py", "content": "# function_import --------------------\n\nfrom transformers import LEDForConditionalGeneration, AutoTokenizer\n\n# function_code --------------------\n\ndef summarize_diary(diary_entry: str) -> str:\n    '''\n    Summarizes a given diary entry using the pre-trained model 'MingZhong/DialogLED-base-16384'.\n\n    Args:\n        diary_entry (str): The diary entry to be summarized.\n\n    Returns:\n        str: The summarized text.\n    '''\n    model = LEDForConditionalGeneration.from_pretrained('MingZhong/DialogLED-base-16384')\n    tokenizer = AutoTokenizer.from_pretrained('MingZhong/DialogLED-base-16384')\n\n    input_tokens = tokenizer(diary_entry, return_tensors='pt')\n    summary_output = model.generate(**input_tokens)\n    summary_text = tokenizer.decode(summary_output[0])\n\n    return summary_text\n\n# test_function_code --------------------\n\ndef test_summarize_diary():\n    '''\n    Tests the function summarize_diary.\n    '''\n    diary_entry1 = 'Today was a great day. I managed to fix the issue with the oxygen generator and had a successful communication session with the ground control.'\n    diary_entry2 = 'I had a tough day today. The solar panels were not working properly and I had to spend the whole day fixing them.'\n    diary_entry3 = 'Today was a normal day. I did my routine checks and everything seems to be working fine.'\n\n    assert len(summarize_diary(diary_entry1)) > 0\n    assert len(summarize_diary(diary_entry2)) > 0\n    assert len(summarize_diary(diary_entry3)) > 0\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_summarize_diary()", "function_import": "# function_import --------------------\n\nfrom transformers import LEDForConditionalGeneration, AutoTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef summarize_diary(diary_entry: str) -> str:\n    '''\n    Summarizes a given diary entry using the pre-trained model 'MingZhong/DialogLED-base-16384'.\n\n    Args:\n        diary_entry (str): The diary entry to be summarized.\n\n    Returns:\n        str: The summarized text.\n    '''\n    model = LEDForConditionalGeneration.from_pretrained('MingZhong/DialogLED-base-16384')\n    tokenizer = AutoTokenizer.from_pretrained('MingZhong/DialogLED-base-16384')\n\n    input_tokens = tokenizer(diary_entry, return_tensors='pt')\n    summary_output = model.generate(**input_tokens)\n    summary_text = tokenizer.decode(summary_output[0])\n\n    return summary_text\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_summarize_diary():\n    '''\n    Tests the function summarize_diary.\n    '''\n    diary_entry1 = 'Today was a great day. I managed to fix the issue with the oxygen generator and had a successful communication session with the ground control.'\n    diary_entry2 = 'I had a tough day today. The solar panels were not working properly and I had to spend the whole day fixing them.'\n    diary_entry3 = 'Today was a normal day. I did my routine checks and everything seems to be working fine.'\n\n    assert len(summarize_diary(diary_entry1)) > 0\n    assert len(summarize_diary(diary_entry2)) > 0\n    assert len(summarize_diary(diary_entry3)) > 0\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_summarize_diary()", "instruct": "# function_import --------------------\n\nfrom transformers import LEDForConditionalGeneration, AutoTokenizer\n\n# function_code --------------------\n\ndef summarize_diary(diary_entry: str) -> str:\n    '''\n    Summarizes a given diary entry using the pre-trained model 'MingZhong/DialogLED-base-16384'.\n\n    Args:\n        diary_entry (str): The diary entry to be summarized.\n\n    Returns:\n        str: The summarized text.\n    '''", "answer": "\n    model = LEDForConditionalGeneration.from_pretrained('MingZhong/DialogLED-base-16384')\n    tokenizer = AutoTokenizer.from_pretrained('MingZhong/DialogLED-base-16384')\n\n    input_tokens = tokenizer(diary_entry, return_tensors='pt')\n    summary_output = model.generate(**input_tokens)\n    summary_text = tokenizer.decode(summary_output[0])\n\n    return summary_text\n\n", "prediction": "\n    tokenizer = AutoTokenizer.from_pretrained('MingZhong/DialogLED-base-16384')\n    model = LEDForConditionalGeneration.from_pretrained('MingZhong/DialogLED-base-16384').to('cuda')\n    \n    batch = tokenizer([diary_entry], return_tensors='pt', truncation=True, padding=\"max_length\",  max_length=2000).to('cuda')\n    summary_ids = model.generate(batch['input_ids'], num_beams=4, max_length=512, min_length=55)\n    \n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n"}