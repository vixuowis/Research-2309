{"path": "output/hf-eval-data-v3-valid/f00825_generate_question_embedding.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n\n# function_code --------------------\n\ndef generate_question_embedding(question):\n    \"\"\"\n    Generate question embedding using DPRQuestionEncoder.\n\n    Args:\n        question (str): The question to be encoded.\n\n    Returns:\n        torch.Tensor: The question embedding.\n    \"\"\"\n    tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n    model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n\n    input_ids = tokenizer(question, return_tensors='pt')['input_ids']\n    question_embedding = model(input_ids).pooler_output\n    return question_embedding\n\n# test_function_code --------------------\n\ndef test_generate_question_embedding():\n    \"\"\"\n    Test the function generate_question_embedding.\n    \"\"\"\n    question = 'What are the best attractions in Paris?'\n    embedding = generate_question_embedding(question)\n    assert embedding is not None\n    assert embedding.size() == torch.Size([1, 768])\n\n    question = 'What is the capital of France?'\n    embedding = generate_question_embedding(question)\n    assert embedding is not None\n    assert embedding.size() == torch.Size([1, 768])\n\n    question = 'Who is the president of the United States?'\n    embedding = generate_question_embedding(question)\n    assert embedding is not None\n    assert embedding.size() == torch.Size([1, 768])\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\nprint(test_generate_question_embedding())", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef generate_question_embedding(question):\n    \"\"\"\n    Generate question embedding using DPRQuestionEncoder.\n\n    Args:\n        question (str): The question to be encoded.\n\n    Returns:\n        torch.Tensor: The question embedding.\n    \"\"\"\n    tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n    model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n\n    input_ids = tokenizer(question, return_tensors='pt')['input_ids']\n    question_embedding = model(input_ids).pooler_output\n    return question_embedding\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_question_embedding():\n    \"\"\"\n    Test the function generate_question_embedding.\n    \"\"\"\n    question = 'What are the best attractions in Paris?'\n    embedding = generate_question_embedding(question)\n    assert embedding is not None\n    assert embedding.size() == torch.Size([1, 768])\n\n    question = 'What is the capital of France?'\n    embedding = generate_question_embedding(question)\n    assert embedding is not None\n    assert embedding.size() == torch.Size([1, 768])\n\n    question = 'Who is the president of the United States?'\n    embedding = generate_question_embedding(question)\n    assert embedding is not None\n    assert embedding.size() == torch.Size([1, 768])\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\nprint(test_generate_question_embedding())", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n\n# function_code --------------------\n\ndef generate_question_embedding(question):\n    \"\"\"\n    Generate question embedding using DPRQuestionEncoder.\n\n    Args:\n        question (str): The question to be encoded.\n\n    Returns:\n        torch.Tensor: The question embedding.\n    \"\"\"", "answer": "\n    tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n    model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n\n    input_ids = tokenizer(question, return_tensors='pt')['input_ids']\n    question_embedding = model(input_ids).pooler_output\n    return question_embedding\n\n", "prediction": "\n    \n    # Initialize question encoder and tokenizer.\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-multiset-base\")\n    tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-multiset-base\")\n    \n    # Move the model to target device (cuda or cpu).\n    model.to(device)\n\n    input_ids = tokenizer([question], return_tensors=\"pt\", padding=True, truncation=True).to(device)[\"input_ids\"]\n    attention_mask = torch.where(input_ids != 0, 1, 0)\n\n    # Get question embedding.\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n    \n    return outputs[\"pooler_output\"].detach().cpu()"}