{"path": "output/hf-eval-data-v3-valid/f00205_image_geolocalization.py", "content": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef image_geolocalization(url: str, choices: list):\n    \"\"\"\n    This function uses a pretrained CLIP model to identify the location of a given image.\n\n    Args:\n        url (str): The URL of the image to be geolocalized.\n        choices (list): A list of possible choices for the location of the image.\n\n    Returns:\n        dict: A dictionary with the location choices as keys and their corresponding probabilities as values.\n    \"\"\"\n    model = CLIPModel.from_pretrained('geolocal/StreetCLIP')\n    processor = CLIPProcessor.from_pretrained('geolocal/StreetCLIP')\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(text=choices, images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {choice: prob for choice, prob in zip(choices, probs.tolist()[0])}\n\n# test_function_code --------------------\n\ndef test_image_geolocalization():\n    url = 'https://placekitten.com/200/300'\n    choices = ['San Jose', 'San Diego', 'Los Angeles', 'Las Vegas', 'San Francisco']\n    result = image_geolocalization(url, choices)\n    assert isinstance(result, dict)\n    assert len(result) == len(choices)\n    assert all(isinstance(choice, str) for choice in result.keys())\n    assert all(isinstance(prob, float) for prob in result.values())\n    assert abs(sum(result.values()) - 1) < 1e-6\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_image_geolocalization()", "function_import": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n", "function_code": "# function_code --------------------\n\ndef image_geolocalization(url: str, choices: list):\n    \"\"\"\n    This function uses a pretrained CLIP model to identify the location of a given image.\n\n    Args:\n        url (str): The URL of the image to be geolocalized.\n        choices (list): A list of possible choices for the location of the image.\n\n    Returns:\n        dict: A dictionary with the location choices as keys and their corresponding probabilities as values.\n    \"\"\"\n    model = CLIPModel.from_pretrained('geolocal/StreetCLIP')\n    processor = CLIPProcessor.from_pretrained('geolocal/StreetCLIP')\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(text=choices, images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {choice: prob for choice, prob in zip(choices, probs.tolist()[0])}\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_image_geolocalization():\n    url = 'https://placekitten.com/200/300'\n    choices = ['San Jose', 'San Diego', 'Los Angeles', 'Las Vegas', 'San Francisco']\n    result = image_geolocalization(url, choices)\n    assert isinstance(result, dict)\n    assert len(result) == len(choices)\n    assert all(isinstance(choice, str) for choice in result.keys())\n    assert all(isinstance(prob, float) for prob in result.values())\n    assert abs(sum(result.values()) - 1) < 1e-6\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_image_geolocalization()", "instruct": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef image_geolocalization(url: str, choices: list):\n    \"\"\"\n    This function uses a pretrained CLIP model to identify the location of a given image.\n\n    Args:\n        url (str): The URL of the image to be geolocalized.\n        choices (list): A list of possible choices for the location of the image.\n\n    Returns:\n        dict: A dictionary with the location choices as keys and their corresponding probabilities as values.\n    \"\"\"", "answer": "\n    model = CLIPModel.from_pretrained('geolocal/StreetCLIP')\n    processor = CLIPProcessor.from_pretrained('geolocal/StreetCLIP')\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(text=choices, images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {choice: prob for choice, prob in zip(choices, probs.tolist()[0])}\n\n", "prediction": "\n\n    # Load pre-trained model and tokenizer\n    print('Loading CLIP model...')\n    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n    # Load image from URL and prepare it for the model\n    print('Loading image...')\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(text=[], images=image, return_tensors='pt', padding=True)\n\n    # Get image features from the pre-trained model and normalize them\n    print('Getting image features...')\n    outputs = clip_model.get_image_features(**inputs)\n    normed_outputs = outputs / outputs.norm(dim=-1, keepdim=True).numpy() # Normalization is important for the cosine similarity calculation\n\n    # Load choices features and normalize them as well\n    print('Getting choices features...')\n    text = [f'This is a picture of {choice}.' for choice in choices]\n    inputs_text = processor(text=text, return_tensors='pt', padding=True)\n    outputs_text = clip_model.get_text_features(**inputs_text)\n    normed_outputs_text = outputs_text / outputs_text.norm(dim=-1, keepdim=True).numpy() # Normalization is important for the cosine similarity calculation\n\n    # Calculate cosine similarity between image and choices features\n    print('Calculating cosine similarities...')\n    cos = (normed_outputs @ normed_outputs_text.T).diagonal()\n    reshaped_cos = [float(i) for i in cos] # Reshape into a list with floats instead of PyTorch tensors\n\n    return dict(zip(choices, reshaped_cos))\n"}