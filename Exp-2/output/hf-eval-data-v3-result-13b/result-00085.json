{"path": "output/hf-eval-data-v3-valid/f00365_segment_clothes.py", "content": "# function_import --------------------\n\nfrom transformers import AutoFeatureExtractor, SegformerForSemanticSegmentation\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n\n# function_code --------------------\n\ndef segment_clothes(image_path):\n    \"\"\"\n    This function segments clothes in an image using a pre-trained SegFormer model.\n\n    Args:\n        image_path (str): The path to the image file or a URL.\n\n    Returns:\n        A matplotlib figure showing the segmented image.\n    \"\"\"\n    extractor = AutoFeatureExtractor.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    image = Image.open(requests.get(image_path, stream=True).raw)\n    model = SegformerForSemanticSegmentation.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    inputs = extractor(images=image, return_tensors='pt')\n    outputs = model(**inputs)\n\n    logits = outputs.logits.cpu()\n    upsampled_logits = nn.functional.interpolate(logits, size=image.size[::-1], mode='bilinear', align_corners=False)\n    pred_seg = upsampled_logits.argmax(dim=1)[0]\n    plt.imshow(pred_seg)\n    return plt\n\n# test_function_code --------------------\n\ndef test_segment_clothes():\n    \"\"\"\n    This function tests the segment_clothes function with a few test cases.\n    \"\"\"\n    # Test case 1: An image of a person wearing clothes\n    url1 = 'https://placekitten.com/200/300'\n    result1 = segment_clothes(url1)\n    assert isinstance(result1, type(plt)), 'Test Case 1 Failed'\n\n    # Test case 2: Another image of a person wearing clothes\n    url2 = 'https://placekitten.com/400/600'\n    result2 = segment_clothes(url2)\n    assert isinstance(result2, type(plt)), 'Test Case 2 Failed'\n\n    # Test case 3: Yet another image of a person wearing clothes\n    url3 = 'https://placekitten.com/800/1200'\n    result3 = segment_clothes(url3)\n    assert isinstance(result3, type(plt)), 'Test Case 3 Failed'\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_segment_clothes()", "function_import": "# function_import --------------------\n\nfrom transformers import AutoFeatureExtractor, SegformerForSemanticSegmentation\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n\n", "function_code": "# function_code --------------------\n\ndef segment_clothes(image_path):\n    \"\"\"\n    This function segments clothes in an image using a pre-trained SegFormer model.\n\n    Args:\n        image_path (str): The path to the image file or a URL.\n\n    Returns:\n        A matplotlib figure showing the segmented image.\n    \"\"\"\n    extractor = AutoFeatureExtractor.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    image = Image.open(requests.get(image_path, stream=True).raw)\n    model = SegformerForSemanticSegmentation.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    inputs = extractor(images=image, return_tensors='pt')\n    outputs = model(**inputs)\n\n    logits = outputs.logits.cpu()\n    upsampled_logits = nn.functional.interpolate(logits, size=image.size[::-1], mode='bilinear', align_corners=False)\n    pred_seg = upsampled_logits.argmax(dim=1)[0]\n    plt.imshow(pred_seg)\n    return plt\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_segment_clothes():\n    \"\"\"\n    This function tests the segment_clothes function with a few test cases.\n    \"\"\"\n    # Test case 1: An image of a person wearing clothes\n    url1 = 'https://placekitten.com/200/300'\n    result1 = segment_clothes(url1)\n    assert isinstance(result1, type(plt)), 'Test Case 1 Failed'\n\n    # Test case 2: Another image of a person wearing clothes\n    url2 = 'https://placekitten.com/400/600'\n    result2 = segment_clothes(url2)\n    assert isinstance(result2, type(plt)), 'Test Case 2 Failed'\n\n    # Test case 3: Yet another image of a person wearing clothes\n    url3 = 'https://placekitten.com/800/1200'\n    result3 = segment_clothes(url3)\n    assert isinstance(result3, type(plt)), 'Test Case 3 Failed'\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_segment_clothes()", "instruct": "# function_import --------------------\n\nfrom transformers import AutoFeatureExtractor, SegformerForSemanticSegmentation\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n\n# function_code --------------------\n\ndef segment_clothes(image_path):\n    \"\"\"\n    This function segments clothes in an image using a pre-trained SegFormer model.\n\n    Args:\n        image_path (str): The path to the image file or a URL.\n\n    Returns:\n        A matplotlib figure showing the segmented image.\n    \"\"\"", "answer": "\n    extractor = AutoFeatureExtractor.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    image = Image.open(requests.get(image_path, stream=True).raw)\n    model = SegformerForSemanticSegmentation.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    inputs = extractor(images=image, return_tensors='pt')\n    outputs = model(**inputs)\n\n    logits = outputs.logits.cpu()\n    upsampled_logits = nn.functional.interpolate(logits, size=image.size[::-1], mode='bilinear', align_corners=False)\n    pred_seg = upsampled_logits.argmax(dim=1)[0]\n    plt.imshow(pred_seg)\n    return plt\n\n", "prediction": "\n\n    # Load the image from the given url if needed, otherwise load it directly\n    try:\n      img = Image.open(requests.get(image_path, stream=True).raw)\n    except:\n      img = Image.open(image_path)\n    \n    # Create a feature extractor and create the model from it\n    feature_extractor = AutoFeatureExtractor.from_pretrained(\"nielsr/segformer-b4\")\n    model = SegformerForSemanticSegmentation.from_pretrained(\"nielsr/segformer-b4\")\n    \n    # Get the input tensor from the image\n    inputs = feature_extractor(images=img, return_tensors=\"pt\")[\"pixel_values\"]\n    \n    # Perform inference with the model\n    outputs = model(inputs)[\"logits\"].argmax(dim=1).detach().numpy()[0]\n    \n    # Show the result\n    return plt.imshow(outputs)"}