{'code': '###Instruction: Develop a tool to help our team members find answers to essential questions from a long document.\n###Output: <<<domain>>>: Natural Language Processing Question Answering\n<<<api_call>>>: AutoModel.from_pretrained(\'bert-large-cased-whole-word-masking-finetuned-squad\')\n<<<api_provider>>>: Transformers\n<<<explanation>>>: 1. Import the necessary libraries required for the task. In this case, it is the \'pipeline\' from the transformers library.\n2. Use the \'pipeline\' function to create a question-answering model for the text data. \n3. Specify the model to be loaded as \'bert-large-cased-whole-word-masking-finetuned-squad\', which has been finetuned on the SQuAD dataset for the task of question-answering.\n4. Use the created pipeline to answer questions from the provided context. This pipeline will help your team members to find answers to essential questions from a long document.\n<<<code>>>: from transformers import pipeline\nqa_tool = pipeline(\'question-answering\', model=\'bert-large-cased-whole-word-masking-finetuned-squad\')\ncontext = "This is a long document containing company policies, financial details, and team structures."\nquestion = "What are the company policies mentioned in the document?"\nanswer = qa_tool({\'context\': context, \'question\': question})\nprint(answer)', 'api_call': "AutoModel.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')", 'provider': 'Transformers', 'api_data': {'domain': 'Natural Language Processing Question Answering', 'framework': 'Transformers', 'functionality': 'Question Answering', 'api_name': 'bert-large-cased-whole-word-masking-finetuned-squad', 'api_call': "AutoModel.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')", 'api_arguments': {'model_name_or_path': 'bert-large-cased-whole-word-masking', 'dataset_name': 'squad', 'do_train': True, 'do_eval': True, 'learning_rate': 3e-05, 'num_train_epochs': 2, 'max_seq_length': 384, 'doc_stride': 128, 'output_dir': './examples/models/wwm_cased_finetuned_squad/', 'per_device_eval_batch_size': 3, 'per_device_train_batch_size': 3}, 'python_environment_requirements': ['torch', 'transformers'], 'example_code': "from transformers import pipeline\nqa_pipeline = pipeline('question-answering', model='bert-large-cased-whole-word-masking-finetuned-squad')\nresult = qa_pipeline({'context': 'This is a context example.', 'question': 'What is this example for?'})\nprint(result)", 'performance': {'dataset': [{'name': 'BookCorpus', 'accuracy': 'N/A'}, {'name': 'English Wikipedia', 'accuracy': 'N/A'}]}, 'description': 'BERT large model (cased) whole word masking finetuned on SQuAD. This model is cased and trained with a new technique: Whole Word Masking. After pre-training, this model was fine-tuned on the SQuAD dataset.'}}

