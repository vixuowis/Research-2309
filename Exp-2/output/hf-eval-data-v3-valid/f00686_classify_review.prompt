{'code': '###Instruction: Our customer is a Spanish travel agency. They need to classify customer reviews into categories such as \'travel\', \'cooking\', and \'dancing\'.\n###Output: <<<domain>>>: Natural Language Processing Zero-Shot Classification\n<<<api_call>>>: pipeline(\'zero-shot-classification\', model=\'vicgalle/xlm-roberta-large-xnli-anli\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>: 1. Import the necessary library, which is \'pipeline\' from the transformers package provided by Hugging Face.\n2. Use the \'pipeline\' function to create a zero-shot classification model by loading the \'vicgalle/xlm-roberta-large-xnli-anli\' model. This model is specifically fine-tuned for multiple natural language inference (NLI) datasets and is suitable for zero-shot classification tasks.\n3. By providing the customer review text and candidate categories such as \'travel\', \'cooking\', and \'dancing\', the model will classify the review into one of these categories based on semantic similarity.\n<<<code>>>: from transformers import pipeline\nclassifier = pipeline(\'zero-shot-classification\', model=\'vicgalle/xlm-roberta-large-xnli-anli\')\ncustomer_review = "Algún día iré a ver el mundo"\ncategories = [\'viaje\', \'cocina\', \'danza\']\nresult = classifier(customer_review, categories)', 'api_call': "XLMRobertaForSequenceClassification.from_pretrained('vicgalle/xlm-roberta-large-xnli-anli')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Zero-Shot Classification', 'framework': 'Hugging Face Transformers', 'functionality': 'Zero-Shot Classification', 'api_name': 'vicgalle/xlm-roberta-large-xnli-anli', 'api_call': "XLMRobertaForSequenceClassification.from_pretrained('vicgalle/xlm-roberta-large-xnli-anli')", 'api_arguments': ['sequence_to_classify', 'candidate_labels'], 'python_environment_requirements': ['transformers'], 'example_code': "sequence_to_classify = Algún día iré a ver el mundo\ncandidate_labels = ['viaje', 'cocina', 'danza']\nclassifier(sequence_to_classify, candidate_labels)", 'performance': {'dataset': [{'name': 'XNLI-es', 'accuracy': '93.7%'}, {'name': 'XNLI-fr', 'accuracy': '93.2%'}, {'name': 'ANLI-R1', 'accuracy': '68.5%'}, {'name': 'ANLI-R2', 'accuracy': '53.6%'}, {'name': 'ANLI-R3', 'accuracy': '49.0%'}]}, 'description': 'XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification.'}}

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00686_classify_review.py", line 37, in <module>
    test_classify_review()
  File "output/hf-eval-data-v2/f00686_classify_review.py", line 30, in test_classify_review
    result = classify_review(review_text, categories)
  File "output/hf-eval-data-v2/f00686_classify_review.py", line 18, in classify_review
    classifier = pipeline('zero-shot-classification', model='vicgalle/xlm-roberta-large-xnli-anli')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 729, in pipeline
    maybe_adapter_path = find_adapter_config_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/peft_utils.py", line 87, in find_adapter_config_file
    adapter_cached_filename = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1193, in hf_hub_download
    os.makedirs(storage_folder, exist_ok=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/os.py", line 223, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/root/autodl-tmp/.cache/huggingface/hub/models--vicgalle--xlm-roberta-large-xnli-anli'
