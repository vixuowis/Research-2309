{'code': '###Instruction: We are a multi-national company that would like to better understand global events and extract relevant named entities across 9 languages (de, en, es, fr, it, nl, pl, pt, ru). We would like to utilize a pre-trained NER model.\n###Output: <<<domain>>>: Natural Language Processing Token Classification\n<<<api_call>>>: AutoModelForTokenClassification.from_pretrained(\'Babelscape/wikineural-multilingual-ner\')\n<<<api_provider>>>: Hugging Face Transformers\n<<<explanation>>>:1. Import the required packages and classes, such as AutoTokenizer, AutoModelForTokenClassification, and pipeline from the transformers library.\n2. Initiate tokenizer and the multilingual NER (Named Entity Recognition) model using the \'from_pretrained\' method and the provided API name \'Babelscape/wikineural-multilingual-ner\'. The model supports 9 languages (de, en, es, fr, it, nl, pl, pt, ru).\n3. With these tokenizer and model instances, create an NER pipeline.\n4. Pass your text as input to the NER pipeline and obtain the NER results.\n<<<code>>>: from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\ntokenizer = AutoTokenizer.from_pretrained(\'Babelscape/wikineural-multilingual-ner\')\nmodel = AutoModelForTokenClassification.from_pretrained(\'Babelscape/wikineural-multilingual-ner\')\nnlp = pipeline(\'ner\', model=model, tokenizer=tokenizer)\nexample = "My name is Wolfgang and I live in Berlin."\nner_results = nlp(example)\nprint(ner_results)', 'api_call': "AutoModelForTokenClassification.from_pretrained('Babelscape/wikineural-multilingual-ner')", 'provider': 'Hugging Face Transformers', 'api_data': {'domain': 'Natural Language Processing Token Classification', 'framework': 'Hugging Face Transformers', 'functionality': 'Named Entity Recognition', 'api_name': 'Babelscape/wikineural-multilingual-ner', 'api_call': "AutoModelForTokenClassification.from_pretrained('Babelscape/wikineural-multilingual-ner')", 'api_arguments': {'model': 'AutoModelForTokenClassification.from_pretrained(Babelscape/wikineural-multilingual-ner)', 'tokenizer': 'AutoTokenizer.from_pretrained(Babelscape/wikineural-multilingual-ner)'}, 'python_environment_requirements': {'transformers': 'from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline'}, 'example_code': 'tokenizer = AutoTokenizer.from_pretrained(Babelscape/wikineural-multilingual-ner)\nmodel = AutoModelForTokenClassification.from_pretrained(Babelscape/wikineural-multilingual-ner)\nnlp = pipeline(ner, model=model, tokenizer=tokenizer)\nexample = My name is Wolfgang and I live in Berlin\nner_results = nlp(example)\nprint(ner_results)', 'performance': {'dataset': 'Babelscape/wikineural-multilingual-ner', 'accuracy': 'span-based F1-score up to 6 points over previous state-of-the-art systems for data creation'}, 'description': 'A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks.'}}







