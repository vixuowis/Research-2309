Downloading (…)lve/main/config.json:   0%|                                                                           | 0.00/725 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████| 725/725 [00:00<00:00, 64.7kB/s]2023-11-11 23:22:15.026582: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-11-11 23:22:15.085381: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-11 23:22:15.962130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

Downloading pytorch_model.bin:   0%|                                                                                | 0.00/265M [00:00<?, ?B/s]Downloading pytorch_model.bin:   8%|█████▋                                                                  | 21.0M/265M [00:00<00:01, 154MB/s]Downloading pytorch_model.bin:  20%|██████████████▏                                                         | 52.4M/265M [00:00<00:01, 196MB/s]Downloading pytorch_model.bin:  32%|██████████████████████▋                                                 | 83.9M/265M [00:00<00:00, 221MB/s]Downloading pytorch_model.bin:  43%|███████████████████████████████▋                                         | 115M/265M [00:00<00:00, 232MB/s]Downloading pytorch_model.bin:  55%|████████████████████████████████████████▎                                | 147M/265M [00:00<00:00, 233MB/s]Downloading pytorch_model.bin:  67%|█████████████████████████████████████████████████                        | 178M/265M [00:00<00:00, 238MB/s]Downloading pytorch_model.bin:  79%|█████████████████████████████████████████████████████████▋               | 210M/265M [00:00<00:00, 236MB/s]Downloading pytorch_model.bin:  91%|██████████████████████████████████████████████████████████████████▎      | 241M/265M [00:01<00:00, 234MB/s]Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████| 265M/265M [00:01<00:00, 236MB/s]Downloading pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████| 265M/265M [00:01<00:00, 228MB/s]
Downloading (…)okenizer_config.json:   0%|                                                                           | 0.00/319 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████| 319/319 [00:00<00:00, 130kB/s]
Downloading (…)solve/main/vocab.txt:   0%|                                                                          | 0.00/232k [00:00<?, ?B/s]Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 415kB/s]Downloading (…)solve/main/vocab.txt: 100%|███████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 414kB/s]
Downloading (…)/main/tokenizer.json:   0%|                                                                          | 0.00/466k [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|██████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 1.50MB/s]Downloading (…)/main/tokenizer.json: 100%|██████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 1.49MB/s]
Downloading (…)cial_tokens_map.json:   0%|                                                                           | 0.00/112 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 47.7kB/s]
