from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Load pre-trained model and tokenizer
tokenizer = AutoTokenizer.from_pretrained('microsoft/GODEL-v1_1-base-seq2seq')
model = AutoModelForSeq2SeqLM.from_pretrained('microsoft/GODEL-v1_1-base-seq2seq')

def choose_best_video_game(instruction, knowledge, dialog):
    '''
    This function takes in an instruction, knowledge and dialog and returns a response generated by the GODEL model.
    
    Parameters:
    instruction (str): The instruction for the model.
    knowledge (str): The knowledge for the model.
    dialog (list): The dialog for the model.
    
    Returns:
    str: The generated response.
    '''
    # Prepare the inputs for the model
    if knowledge != '':
        knowledge = '[KNOWLEDGE] ' + knowledge
    dialog = ' EOS '.join(dialog)
    query = f'{instruction} [CONTEXT] {dialog} {knowledge}'
    input_ids = tokenizer(f'{query}', return_tensors='pt').input_ids
    
    # Generate the response
    outputs = model.generate(input_ids, max_length=128, min_length=8, top_p=0.9, do_sample=True)
    output = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    return output