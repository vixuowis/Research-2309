{"path": "output/hf-eval-data-v3-valid/f00641_get_image_summary_and_answer.py", "content": "# function_import --------------------\n\nimport requests\nfrom PIL import Image\nfrom transformers import BlipProcessor, Blip2ForConditionalGeneration\n\n# function_code --------------------\n\ndef get_image_summary_and_answer(img_url: str, question: str) -> str:\n    \"\"\"\n    Get a text summary and answer a question from an image using the 'Blip2ForConditionalGeneration' model.\n\n    Args:\n        img_url (str): The URL of the image.\n        question (str): The question to be answered.\n\n    Returns:\n        str: The answer to the question.\n\n    Raises:\n        Exception: If there is an error in processing the image or generating the answer.\n    \"\"\"\n    try:\n        processor = BlipProcessor.from_pretrained('Salesforce/blip2-opt-2.7b')\n        model = Blip2ForConditionalGeneration.from_pretrained('Salesforce/blip2-opt-2.7b')\n        raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n        inputs = processor(raw_image, question, return_tensors='pt')\n        out = model.generate(**inputs)\n        answer = processor.decode(out[0], skip_special_tokens=True)\n        return answer\n    except Exception as e:\n        raise Exception('Error in getting image summary and answer: ' + str(e))\n\n# test_function_code --------------------\n\ndef test_get_image_summary_and_answer():\n    \"\"\"\n    Test the function 'get_image_summary_and_answer'.\n    \"\"\"\n    try:\n        assert get_image_summary_and_answer('https://placekitten.com/200/300', 'What is the main color of the object?') is not None\n        assert get_image_summary_and_answer('https://placekitten.com/200/300', 'Is there a cat in the image?') is not None\n        assert get_image_summary_and_answer('https://placekitten.com/200/300', 'What is the size of the object?') is not None\n        print('All Tests Passed')\n    except Exception as e:\n        print('Test Failed: ' + str(e))\n\n# call_test_function_code --------------------\n\ntest_get_image_summary_and_answer()", "function_import": "# function_import --------------------\n\nimport requests\nfrom PIL import Image\nfrom transformers import BlipProcessor, Blip2ForConditionalGeneration\n\n", "function_code": "# function_code --------------------\n\ndef get_image_summary_and_answer(img_url: str, question: str) -> str:\n    \"\"\"\n    Get a text summary and answer a question from an image using the 'Blip2ForConditionalGeneration' model.\n\n    Args:\n        img_url (str): The URL of the image.\n        question (str): The question to be answered.\n\n    Returns:\n        str: The answer to the question.\n\n    Raises:\n        Exception: If there is an error in processing the image or generating the answer.\n    \"\"\"\n    try:\n        processor = BlipProcessor.from_pretrained('Salesforce/blip2-opt-2.7b')\n        model = Blip2ForConditionalGeneration.from_pretrained('Salesforce/blip2-opt-2.7b')\n        raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n        inputs = processor(raw_image, question, return_tensors='pt')\n        out = model.generate(**inputs)\n        answer = processor.decode(out[0], skip_special_tokens=True)\n        return answer\n    except Exception as e:\n        raise Exception('Error in getting image summary and answer: ' + str(e))\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_get_image_summary_and_answer():\n    \"\"\"\n    Test the function 'get_image_summary_and_answer'.\n    \"\"\"\n    try:\n        assert get_image_summary_and_answer('https://placekitten.com/200/300', 'What is the main color of the object?') is not None\n        assert get_image_summary_and_answer('https://placekitten.com/200/300', 'Is there a cat in the image?') is not None\n        assert get_image_summary_and_answer('https://placekitten.com/200/300', 'What is the size of the object?') is not None\n        print('All Tests Passed')\n    except Exception as e:\n        print('Test Failed: ' + str(e))\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_get_image_summary_and_answer()", "instruct": "# function_import --------------------\n\nimport requests\nfrom PIL import Image\nfrom transformers import BlipProcessor, Blip2ForConditionalGeneration\n\n# function_code --------------------\n\ndef get_image_summary_and_answer(img_url: str, question: str) -> str:\n    \"\"\"\n    Get a text summary and answer a question from an image using the 'Blip2ForConditionalGeneration' model.\n\n    Args:\n        img_url (str): The URL of the image.\n        question (str): The question to be answered.\n\n    Returns:\n        str: The answer to the question.\n\n    Raises:\n        Exception: If there is an error in processing the image or generating the answer.\n    \"\"\"", "answer": "\n    try:\n        processor = BlipProcessor.from_pretrained('Salesforce/blip2-opt-2.7b')\n        model = Blip2ForConditionalGeneration.from_pretrained('Salesforce/blip2-opt-2.7b')\n        raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n        inputs = processor(raw_image, question, return_tensors='pt')\n        out = model.generate(**inputs)\n        answer = processor.decode(out[0], skip_special_tokens=True)\n        return answer\n    except Exception as e:\n        raise Exception('Error in getting image summary and answer: ' + str(e))\n\n", "prediction": "\n    \n    # Image to text summary --------------------\n    \n    res = requests.get(img_url)\n    \n    try:\n      img = Image.open(res.content).convert(\"RGB\")\n      \n    except:\n        raise Exception('There was a problem processing the image.')\n      \n    # Image captioning --------------------\n    \n    model = Blip2ForConditionalGeneration.from_pretrained('BruceWen/blip2-causal-image-prompt')\n    processor = BlipProcessor.from_pretrained('BruceWen/blip2-causal-image-prompt')\n    \n    input_ids = processor(img, return_tensors='pt').pixel_values\n    input_ids = input_ids.to('cuda')\n    output_ids = model.generate(input_ids)\n    gen = processor.batch_decode(output_ids, skip_special_tokens=True)[0]\n    \n    # Answer a question --------------------\n    \n    question = f\"{gen} {question}\"\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    model = Blip2ForConditionalGeneration.from_pretrained(\"BruceWen/blip2-base-finetuned-q+a\")\n    processor = BlipProcessor.from_pretrained('BruceWen/blip2-base-finetuned-q+a')\n\n    inputs = processor(question, return_tensors=\"pt\").to(\"cuda\")\n    \n    output_ids = model.generate(**inputs)\n    \n    answer = processor.batch_decode(output_ids[0], skip_special_tokens=True)[0]\n    \n    # Remove the question from the answer --------------------\n    \n    answer_cleaned = answer.replace(gen,\"\")\n    return answer_cleaned\n"}