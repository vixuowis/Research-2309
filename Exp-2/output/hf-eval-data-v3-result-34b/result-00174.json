{"path": "output/hf-eval-data-v3-valid/f00704_find_most_related_faq.py", "content": "# function_import --------------------\n\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# function_code --------------------\n\ndef find_most_related_faq(faq_sentences: list, query: str) -> str:\n    \"\"\"\n    Find the most related FAQ for a given customer query using SentenceTransformer.\n\n    Args:\n        faq_sentences (list): A list of FAQ sentences.\n        query (str): A customer query.\n\n    Returns:\n        str: The most related FAQ for the given customer query.\n    \"\"\"\n    model = SentenceTransformer('sentence-transformers/paraphrase-albert-small-v2')\n    embeddings = model.encode(faq_sentences + [query])\n    query_embedding = embeddings[-1]\n    sim_scores = cosine_similarity([query_embedding], embeddings[:-1])\n    most_related_faq_index = sim_scores.argmax()\n    return faq_sentences[most_related_faq_index]\n\n# test_function_code --------------------\n\ndef test_find_most_related_faq():\n    \"\"\"Test the function find_most_related_faq.\"\"\"\n    faq_sentences = [\"FAQ1 text\", \"FAQ2 text\", \"FAQ3 text\"]\n    query = \"Customer query\"\n    assert isinstance(find_most_related_faq(faq_sentences, query), str)\n    faq_sentences = [\"What is your name?\", \"How old are you?\", \"Where are you from?\"]\n    query = \"What's your age?\"\n    assert find_most_related_faq(faq_sentences, query) == \"How old are you?\"\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_find_most_related_faq()", "function_import": "# function_import --------------------\n\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n", "function_code": "# function_code --------------------\n\ndef find_most_related_faq(faq_sentences: list, query: str) -> str:\n    \"\"\"\n    Find the most related FAQ for a given customer query using SentenceTransformer.\n\n    Args:\n        faq_sentences (list): A list of FAQ sentences.\n        query (str): A customer query.\n\n    Returns:\n        str: The most related FAQ for the given customer query.\n    \"\"\"\n    model = SentenceTransformer('sentence-transformers/paraphrase-albert-small-v2')\n    embeddings = model.encode(faq_sentences + [query])\n    query_embedding = embeddings[-1]\n    sim_scores = cosine_similarity([query_embedding], embeddings[:-1])\n    most_related_faq_index = sim_scores.argmax()\n    return faq_sentences[most_related_faq_index]\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_find_most_related_faq():\n    \"\"\"Test the function find_most_related_faq.\"\"\"\n    faq_sentences = [\"FAQ1 text\", \"FAQ2 text\", \"FAQ3 text\"]\n    query = \"Customer query\"\n    assert isinstance(find_most_related_faq(faq_sentences, query), str)\n    faq_sentences = [\"What is your name?\", \"How old are you?\", \"Where are you from?\"]\n    query = \"What's your age?\"\n    assert find_most_related_faq(faq_sentences, query) == \"How old are you?\"\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_find_most_related_faq()", "instruct": "# function_import --------------------\n\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# function_code --------------------\n\ndef find_most_related_faq(faq_sentences: list, query: str) -> str:\n    \"\"\"\n    Find the most related FAQ for a given customer query using SentenceTransformer.\n\n    Args:\n        faq_sentences (list): A list of FAQ sentences.\n        query (str): A customer query.\n\n    Returns:\n        str: The most related FAQ for the given customer query.\n    \"\"\"", "answer": "\n    model = SentenceTransformer('sentence-transformers/paraphrase-albert-small-v2')\n    embeddings = model.encode(faq_sentences + [query])\n    query_embedding = embeddings[-1]\n    sim_scores = cosine_similarity([query_embedding], embeddings[:-1])\n    most_related_faq_index = sim_scores.argmax()\n    return faq_sentences[most_related_faq_index]\n\n", "prediction": "\n\n    transformer = SentenceTransformer(\"bert-base-nli-mean-tokens\") # 768 dims, binary tokenization\n    \n    corpus_embeddings = transformer.encode(faq_sentences) # (1024, n)\n    query_embedding = transformer.encode([query]) # (1024, 1)\n    \n    cosine_similarities = cosine_similarity(query_embedding, corpus_embeddings).flatten() # (n,)\n    best_faq_index = cosine_similarities.argmax()\n    \n    return faq_sentences[best_faq_index]"}