{"path": "output/hf-eval-data-v3-valid/f00410_generate_queries.py", "content": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# function_code --------------------\n\ndef generate_queries(document: str) -> str:\n    '''\n    Generate possible user queries for a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The input document for which to generate queries.\n\n    Returns:\n        str: The generated queries.\n\n    Raises:\n        ValueError: If the input document is not a string.\n    '''\n    if not isinstance(document, str):\n        raise ValueError('Input document must be a string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    input_ids = tokenizer.encode(document, return_tensors='pt')\n    generated_ids = model.generate(input_ids)\n    generated_queries = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    return generated_queries\n\n# test_function_code --------------------\n\ndef test_generate_queries():\n    '''\n    Test the generate_queries function.\n    '''\n    document1 = 'This is a test document.'\n    document2 = 'Another test document.'\n    document3 = 123\n\n    assert isinstance(generate_queries(document1), str)\n    assert isinstance(generate_queries(document2), str)\n    try:\n        generate_queries(document3)\n    except ValueError:\n        pass\n    else:\n        raise AssertionError('ValueError not raised for non-string input.')\n\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\ntest_generate_queries()", "function_import": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n", "function_code": "# function_code --------------------\n\ndef generate_queries(document: str) -> str:\n    '''\n    Generate possible user queries for a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The input document for which to generate queries.\n\n    Returns:\n        str: The generated queries.\n\n    Raises:\n        ValueError: If the input document is not a string.\n    '''\n    if not isinstance(document, str):\n        raise ValueError('Input document must be a string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    input_ids = tokenizer.encode(document, return_tensors='pt')\n    generated_ids = model.generate(input_ids)\n    generated_queries = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    return generated_queries\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_queries():\n    '''\n    Test the generate_queries function.\n    '''\n    document1 = 'This is a test document.'\n    document2 = 'Another test document.'\n    document3 = 123\n\n    assert isinstance(generate_queries(document1), str)\n    assert isinstance(generate_queries(document2), str)\n    try:\n        generate_queries(document3)\n    except ValueError:\n        pass\n    else:\n        raise AssertionError('ValueError not raised for non-string input.')\n\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_generate_queries()", "instruct": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# function_code --------------------\n\ndef generate_queries(document: str) -> str:\n    '''\n    Generate possible user queries for a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The input document for which to generate queries.\n\n    Returns:\n        str: The generated queries.\n\n    Raises:\n        ValueError: If the input document is not a string.\n    '''", "answer": "\n    if not isinstance(document, str):\n        raise ValueError('Input document must be a string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    input_ids = tokenizer.encode(document, return_tensors='pt')\n    generated_ids = model.generate(input_ids)\n    generated_queries = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    return generated_queries\n\n", "prediction": "\n    \n    if type(document) != str:\n        raise ValueError('Input document must be of type \"str\"')\n        \n    elif len(document) == 0:\n        return ''\n        \n    else:\n\n        # load model and tokenizer\n        model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_large_paraphraser')\n        tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_large_paraphraser')\n\n        # encode input document\n        input_ids = tokenizer(document, return_tensors='pt').input_ids\n        \n        # decode paraphrases\n        input_ids = input_ids.to('cuda') if torch.cuda.is_available() else input_ids.to('cpu')\n        generated_text = model.generate(input_ids, \n                                        max_length=256,   \n                                        temperature=0.7,  \n                                        num_return_sequences=5)\n        \n        # decode and post-process output into a readable format\n        query = tokenizer.decode(generated_text[0], skip_special_tokens=True, clean_up_tokenization_spaces=False).replace(' ','').split('\\n')\n\n        # return results as a string\n        result = ''\n        \n        for q in query:\n            result += f'{q}\\n'\n            \n        return result"}