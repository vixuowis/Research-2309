{"path": "output/hf-eval-data-v3-valid/f00205_image_geolocalization.py", "content": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef image_geolocalization(url: str, choices: list):\n    \"\"\"\n    This function uses a pretrained CLIP model to identify the location of a given image.\n\n    Args:\n        url (str): The URL of the image to be geolocalized.\n        choices (list): A list of possible choices for the location of the image.\n\n    Returns:\n        dict: A dictionary with the location choices as keys and their corresponding probabilities as values.\n    \"\"\"\n    model = CLIPModel.from_pretrained('geolocal/StreetCLIP')\n    processor = CLIPProcessor.from_pretrained('geolocal/StreetCLIP')\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(text=choices, images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {choice: prob for choice, prob in zip(choices, probs.tolist()[0])}\n\n# test_function_code --------------------\n\ndef test_image_geolocalization():\n    url = 'https://placekitten.com/200/300'\n    choices = ['San Jose', 'San Diego', 'Los Angeles', 'Las Vegas', 'San Francisco']\n    result = image_geolocalization(url, choices)\n    assert isinstance(result, dict)\n    assert len(result) == len(choices)\n    assert all(isinstance(choice, str) for choice in result.keys())\n    assert all(isinstance(prob, float) for prob in result.values())\n    assert abs(sum(result.values()) - 1) < 1e-6\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_image_geolocalization()", "function_import": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n", "function_code": "# function_code --------------------\n\ndef image_geolocalization(url: str, choices: list):\n    \"\"\"\n    This function uses a pretrained CLIP model to identify the location of a given image.\n\n    Args:\n        url (str): The URL of the image to be geolocalized.\n        choices (list): A list of possible choices for the location of the image.\n\n    Returns:\n        dict: A dictionary with the location choices as keys and their corresponding probabilities as values.\n    \"\"\"\n    model = CLIPModel.from_pretrained('geolocal/StreetCLIP')\n    processor = CLIPProcessor.from_pretrained('geolocal/StreetCLIP')\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(text=choices, images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {choice: prob for choice, prob in zip(choices, probs.tolist()[0])}\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_image_geolocalization():\n    url = 'https://placekitten.com/200/300'\n    choices = ['San Jose', 'San Diego', 'Los Angeles', 'Las Vegas', 'San Francisco']\n    result = image_geolocalization(url, choices)\n    assert isinstance(result, dict)\n    assert len(result) == len(choices)\n    assert all(isinstance(choice, str) for choice in result.keys())\n    assert all(isinstance(prob, float) for prob in result.values())\n    assert abs(sum(result.values()) - 1) < 1e-6\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_image_geolocalization()", "instruct": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef image_geolocalization(url: str, choices: list):\n    \"\"\"\n    This function uses a pretrained CLIP model to identify the location of a given image.\n\n    Args:\n        url (str): The URL of the image to be geolocalized.\n        choices (list): A list of possible choices for the location of the image.\n\n    Returns:\n        dict: A dictionary with the location choices as keys and their corresponding probabilities as values.\n    \"\"\"", "answer": "\n    model = CLIPModel.from_pretrained('geolocal/StreetCLIP')\n    processor = CLIPProcessor.from_pretrained('geolocal/StreetCLIP')\n    image = Image.open(requests.get(url, stream=True).raw)\n    inputs = processor(text=choices, images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {choice: prob for choice, prob in zip(choices, probs.tolist()[0])}\n\n", "prediction": "\n\n    # get the image\n    response = requests.get(url, stream=True)\n    \n    # open the image from the URL request\n    img = Image.open(response.raw).convert(\"RGB\")\n\n    # define the processor and model for the CLIP task\n    model_name = 'openai/clip-vit-base-patch32'\n    processor = CLIPProcessor.from_pretrained(model_name)\n    model = CLIPModel.from_pretrained(model_name) \n    \n    # prepare the inputs and labels based on our task\n    inputs = processor(text=choices, images=img, return_tensors='pt')\n\n    # get the predicted probabilities for each choice\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    \n    # map the probabilities to a dictionary and normalize them\n    preds = list(logits_per_image.numpy()[0])\n    norm = [float(i)/sum(preds) for i in preds]\n    \n    # create a dictionary of choices mapped to their probabilities\n    pred_dict = dict(zip(choices, norm))\n    \n    return pred_dict"}