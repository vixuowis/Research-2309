{"path": "output/hf-eval-data-v3-valid/f00472_estimate_human_pose.py", "content": "# function_import --------------------\n\nfrom PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import OpenposeDetector\nimport os\n\n# function_code --------------------\n\ndef estimate_human_pose(image_path: str, output_path: str) -> None:\n    \"\"\"\n    Estimate the human pose from an image of a user performing an exercise.\n\n    Args:\n        image_path (str): The path to the image file.\n        output_path (str): The path to save the output image with estimated pose.\n\n    Returns:\n        None\n    \"\"\"\n    openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n    image = Image.open(image_path)\n    image = openpose(image)\n\n    controlnet = ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-openpose', torch_dtype=torch.float16)\n    image = pipe('chef in the kitchen', image, num_inference_steps=20).images[0]\n    image.save(output_path)\n\n# test_function_code --------------------\n\ndef test_estimate_human_pose():\n    \"\"\"\n    Test the function estimate_human_pose.\n    \"\"\"\n    # Test case 1\n    estimate_human_pose('test_images/exercise1.jpg', 'test_output/pose1_out.png')\n    assert os.path.exists('test_output/pose1_out.png')\n\n    # Test case 2\n    estimate_human_pose('test_images/exercise2.jpg', 'test_output/pose2_out.png')\n    assert os.path.exists('test_output/pose2_out.png')\n\n    # Test case 3\n    estimate_human_pose('test_images/exercise3.jpg', 'test_output/pose3_out.png')\n    assert os.path.exists('test_output/pose3_out.png')\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_estimate_human_pose()", "function_import": "# function_import --------------------\n\nfrom PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import OpenposeDetector\nimport os\n\n", "function_code": "# function_code --------------------\n\ndef estimate_human_pose(image_path: str, output_path: str) -> None:\n    \"\"\"\n    Estimate the human pose from an image of a user performing an exercise.\n\n    Args:\n        image_path (str): The path to the image file.\n        output_path (str): The path to save the output image with estimated pose.\n\n    Returns:\n        None\n    \"\"\"\n    openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n    image = Image.open(image_path)\n    image = openpose(image)\n\n    controlnet = ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-openpose', torch_dtype=torch.float16)\n    image = pipe('chef in the kitchen', image, num_inference_steps=20).images[0]\n    image.save(output_path)\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_estimate_human_pose():\n    \"\"\"\n    Test the function estimate_human_pose.\n    \"\"\"\n    # Test case 1\n    estimate_human_pose('test_images/exercise1.jpg', 'test_output/pose1_out.png')\n    assert os.path.exists('test_output/pose1_out.png')\n\n    # Test case 2\n    estimate_human_pose('test_images/exercise2.jpg', 'test_output/pose2_out.png')\n    assert os.path.exists('test_output/pose2_out.png')\n\n    # Test case 3\n    estimate_human_pose('test_images/exercise3.jpg', 'test_output/pose3_out.png')\n    assert os.path.exists('test_output/pose3_out.png')\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_estimate_human_pose()", "instruct": "# function_import --------------------\n\nfrom PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import OpenposeDetector\nimport os\n\n# function_code --------------------\n\ndef estimate_human_pose(image_path: str, output_path: str) -> None:\n    \"\"\"\n    Estimate the human pose from an image of a user performing an exercise.\n\n    Args:\n        image_path (str): The path to the image file.\n        output_path (str): The path to save the output image with estimated pose.\n\n    Returns:\n        None\n    \"\"\"", "answer": "\n    openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n    image = Image.open(image_path)\n    image = openpose(image)\n\n    controlnet = ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-openpose', torch_dtype=torch.float16)\n    image = pipe('chef in the kitchen', image, num_inference_steps=20).images[0]\n    image.save(output_path)\n\n", "prediction": "    \n    \n    # create a detector object\n    det = OpenposeDetector()\n    \n    # load the model\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    net = ControlNetModel(numJoints=det.numJoints, numParts=det.pairs, numCoords=2)\n    pipeline = StableDiffusionControlNetPipeline(model=net, device=device)\n    \n    # create a scheduler object\n    sched = UniPCMultistepScheduler(pipeline, diffusion_steps=1000, noise_schedule=\"cosine\")\n    \n    # load the image to be processed\n    image = Image.open(image_path)\n        \n    # estimate the human pose\n    prediction = sched(image)\n     \n    # draw estimated human pose onto original image (in red)\n    det.plotPoints(prediction, image=image) \n    \n    # save output image\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    image.save(output_path)\n"}