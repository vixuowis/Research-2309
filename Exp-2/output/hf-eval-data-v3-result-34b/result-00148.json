{"path": "output/hf-eval-data-v3-valid/f00605_translate_spanish_to_polish.py", "content": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_spanish_to_polish(spanish_text):\n    \"\"\"\n    Translate Spanish text to Polish using Hugging Face's MBartForConditionalGeneration model.\n\n    Args:\n        spanish_text (str): The Spanish text to be translated.\n\n    Returns:\n        str: The translated Polish text.\n    \"\"\"\n    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer.src_lang = 'es_ES'\n    encoded_spanish = tokenizer(spanish_text, return_tensors='pt')\n    generated_tokens = model.generate(**encoded_spanish, forced_bos_token_id=tokenizer.lang_code_to_id['pl_PL'])\n    polish_subtitles = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n    return polish_subtitles[0]\n\n# test_function_code --------------------\n\ndef test_translate_spanish_to_polish():\n    \"\"\"\n    Test the function translate_spanish_to_polish.\n    \"\"\"\n    spanish_text = 'Hola, \u00bfc\u00f3mo est\u00e1s?'\n    polish_text = translate_spanish_to_polish(spanish_text)\n    assert isinstance(polish_text, str), 'The result should be a string.'\n    assert polish_text != '', 'The result should not be an empty string.'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_translate_spanish_to_polish()", "function_import": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n", "function_code": "# function_code --------------------\n\ndef translate_spanish_to_polish(spanish_text):\n    \"\"\"\n    Translate Spanish text to Polish using Hugging Face's MBartForConditionalGeneration model.\n\n    Args:\n        spanish_text (str): The Spanish text to be translated.\n\n    Returns:\n        str: The translated Polish text.\n    \"\"\"\n    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer.src_lang = 'es_ES'\n    encoded_spanish = tokenizer(spanish_text, return_tensors='pt')\n    generated_tokens = model.generate(**encoded_spanish, forced_bos_token_id=tokenizer.lang_code_to_id['pl_PL'])\n    polish_subtitles = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n    return polish_subtitles[0]\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_translate_spanish_to_polish():\n    \"\"\"\n    Test the function translate_spanish_to_polish.\n    \"\"\"\n    spanish_text = 'Hola, \u00bfc\u00f3mo est\u00e1s?'\n    polish_text = translate_spanish_to_polish(spanish_text)\n    assert isinstance(polish_text, str), 'The result should be a string.'\n    assert polish_text != '', 'The result should not be an empty string.'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_translate_spanish_to_polish()", "instruct": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_spanish_to_polish(spanish_text):\n    \"\"\"\n    Translate Spanish text to Polish using Hugging Face's MBartForConditionalGeneration model.\n\n    Args:\n        spanish_text (str): The Spanish text to be translated.\n\n    Returns:\n        str: The translated Polish text.\n    \"\"\"", "answer": "\n    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer.src_lang = 'es_ES'\n    encoded_spanish = tokenizer(spanish_text, return_tensors='pt')\n    generated_tokens = model.generate(**encoded_spanish, forced_bos_token_id=tokenizer.lang_code_to_id['pl_PL'])\n    polish_subtitles = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n    return polish_subtitles[0]\n\n", "prediction": "\n    # set translation model parameters\n    en_to_de_model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n    model = MBartForConditionalGeneration.from_pretrained(en_to_de_model_name)\n    tokenizer = MBart50TokenizerFast.from_pretrained(en_to_de_model_name)\n    # prepare the spanish text to be translated\n    spanish_text = \">>es<< \" + spanish_text\n    input_ids = tokenizer(spanish_text, return_tensors=\"pt\").input_ids\n    # translate spanish text to polish text\n    generated_tokens = model.generate(input_ids)\n    generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n\n    return generated_text"}