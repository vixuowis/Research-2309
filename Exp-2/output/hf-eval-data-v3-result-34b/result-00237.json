{"path": "output/hf-eval-data-v3-valid/f00890_translate_english_to_german.py", "content": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_english_to_german(src_text):\n    \"\"\"\n    Translates English text to German using the MBartForConditionalGeneration model.\n\n    Args:\n        src_text (str): The source text in English that needs to be translated.\n\n    Returns:\n        str: The translated text in German.\n\n    Raises:\n        OSError: If there is an issue with loading the pre-trained model or tokenizers.\n    \"\"\"\n    try:\n        model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50')\n        tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50', src_lang='en_XX', tgt_lang='de_DE')\n        translated_output = model.generate(**tokenizer(src_text, return_tensors='pt'))\n        tgt_text = tokenizer.batch_decode(translated_output, skip_special_tokens=True)\n        return tgt_text\n    except OSError as e:\n        print(f'Error: {e}')\n\n# test_function_code --------------------\n\ndef test_translate_english_to_german():\n    \"\"\"\n    Tests the translate_english_to_german function with some test cases.\n    \"\"\"\n    assert translate_english_to_german('Hello, how are you?') is not None\n    assert translate_english_to_german('This is a test sentence.') is not None\n    assert translate_english_to_german('I love programming.') is not None\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_translate_english_to_german()", "function_import": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n", "function_code": "# function_code --------------------\n\ndef translate_english_to_german(src_text):\n    \"\"\"\n    Translates English text to German using the MBartForConditionalGeneration model.\n\n    Args:\n        src_text (str): The source text in English that needs to be translated.\n\n    Returns:\n        str: The translated text in German.\n\n    Raises:\n        OSError: If there is an issue with loading the pre-trained model or tokenizers.\n    \"\"\"\n    try:\n        model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50')\n        tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50', src_lang='en_XX', tgt_lang='de_DE')\n        translated_output = model.generate(**tokenizer(src_text, return_tensors='pt'))\n        tgt_text = tokenizer.batch_decode(translated_output, skip_special_tokens=True)\n        return tgt_text\n    except OSError as e:\n        print(f'Error: {e}')\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_translate_english_to_german():\n    \"\"\"\n    Tests the translate_english_to_german function with some test cases.\n    \"\"\"\n    assert translate_english_to_german('Hello, how are you?') is not None\n    assert translate_english_to_german('This is a test sentence.') is not None\n    assert translate_english_to_german('I love programming.') is not None\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_translate_english_to_german()", "instruct": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_english_to_german(src_text):\n    \"\"\"\n    Translates English text to German using the MBartForConditionalGeneration model.\n\n    Args:\n        src_text (str): The source text in English that needs to be translated.\n\n    Returns:\n        str: The translated text in German.\n\n    Raises:\n        OSError: If there is an issue with loading the pre-trained model or tokenizers.\n    \"\"\"", "answer": "\n    try:\n        model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50')\n        tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50', src_lang='en_XX', tgt_lang='de_DE')\n        translated_output = model.generate(**tokenizer(src_text, return_tensors='pt'))\n        tgt_text = tokenizer.batch_decode(translated_output, skip_special_tokens=True)\n        return tgt_text\n    except OSError as e:\n        print(f'Error: {e}')\n\n", "prediction": "\n    try:\n        # set up MBartForConditionalGeneration, the English to German model\n        model_name = \"facebook/mbart-large-en-ro\"\n        tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n        model = MBartForConditionalGeneration.from_pretrained(model_name).to(\"cpu\")\n    except OSError as exception:\n        raise OSError('Failed to load model and tokenizers') from exception\n    \n    # tokenize the text, getting the batch\n    tokenized_text = tokenizer(src_text, return_tensors=\"pt\")\n    batch = tokenized_text[\"input_ids\"]\n    \n    # translate\n    translated = model.generate(batch)\n    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n    \n    return tgt_text[0]  # returns just the translated text, not a list"}