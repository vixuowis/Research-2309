{"path": "output/hf-eval-data-v3-valid/f00746_segment_objects.py", "content": "# function_import --------------------\n\nimport io\nimport os\nimport requests\nimport torch\nfrom PIL import Image\nfrom transformers import DetrForSegmentation, DetrFeatureExtractor\n\n# function_code --------------------\n\ndef segment_objects(image_path):\n    \"\"\"\n    Function to segment objects in an image using a pre-trained model.\n\n    Args:\n        image_path (str): Path to the image file.\n\n    Returns:\n        PIL.Image: Image with segmented objects.\n\n    Raises:\n        PIL.UnidentifiedImageError: If the image file cannot be identified.\n    \"\"\"\n    image = Image.open(image_path)\n    feature_extractor = DetrFeatureExtractor.from_pretrained('facebook/detr-resnet-50-panoptic')\n    model = DetrForSegmentation.from_pretrained('facebook/detr-resnet-50-panoptic')\n    inputs = feature_extractor(images=image, return_tensors='pt')\n    outputs = model(**inputs)\n    segmented_objects = feature_extractor.post_process_panoptic(outputs, inputs['pixel_values'].shape[-2:])[0]['png_string']\n    segmented_image = Image.open(io.BytesIO(segmented_objects))\n    return segmented_image\n\n# test_function_code --------------------\n\ndef test_segment_objects():\n    \"\"\"\n    Test function for segment_objects function.\n    \"\"\"\n    test_image_url = 'https://placekitten.com/200/300'\n    test_image = Image.open(requests.get(test_image_url, stream=True).raw)\n    test_image.save('test_image.jpg')\n    try:\n        segmented_image = segment_objects('test_image.jpg')\n        assert isinstance(segmented_image, Image.Image)\n        print('Test Passed')\n    except Exception as e:\n        print('Test Failed: ', str(e))\n    finally:\n        os.remove('test_image.jpg')\n\n# call_test_function_code --------------------\n\ntest_segment_objects()", "function_import": "# function_import --------------------\n\nimport io\nimport os\nimport requests\nimport torch\nfrom PIL import Image\nfrom transformers import DetrForSegmentation, DetrFeatureExtractor\n\n", "function_code": "# function_code --------------------\n\ndef segment_objects(image_path):\n    \"\"\"\n    Function to segment objects in an image using a pre-trained model.\n\n    Args:\n        image_path (str): Path to the image file.\n\n    Returns:\n        PIL.Image: Image with segmented objects.\n\n    Raises:\n        PIL.UnidentifiedImageError: If the image file cannot be identified.\n    \"\"\"\n    image = Image.open(image_path)\n    feature_extractor = DetrFeatureExtractor.from_pretrained('facebook/detr-resnet-50-panoptic')\n    model = DetrForSegmentation.from_pretrained('facebook/detr-resnet-50-panoptic')\n    inputs = feature_extractor(images=image, return_tensors='pt')\n    outputs = model(**inputs)\n    segmented_objects = feature_extractor.post_process_panoptic(outputs, inputs['pixel_values'].shape[-2:])[0]['png_string']\n    segmented_image = Image.open(io.BytesIO(segmented_objects))\n    return segmented_image\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_segment_objects():\n    \"\"\"\n    Test function for segment_objects function.\n    \"\"\"\n    test_image_url = 'https://placekitten.com/200/300'\n    test_image = Image.open(requests.get(test_image_url, stream=True).raw)\n    test_image.save('test_image.jpg')\n    try:\n        segmented_image = segment_objects('test_image.jpg')\n        assert isinstance(segmented_image, Image.Image)\n        print('Test Passed')\n    except Exception as e:\n        print('Test Failed: ', str(e))\n    finally:\n        os.remove('test_image.jpg')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_segment_objects()", "instruct": "# function_import --------------------\n\nimport io\nimport os\nimport requests\nimport torch\nfrom PIL import Image\nfrom transformers import DetrForSegmentation, DetrFeatureExtractor\n\n# function_code --------------------\n\ndef segment_objects(image_path):\n    \"\"\"\n    Function to segment objects in an image using a pre-trained model.\n\n    Args:\n        image_path (str): Path to the image file.\n\n    Returns:\n        PIL.Image: Image with segmented objects.\n\n    Raises:\n        PIL.UnidentifiedImageError: If the image file cannot be identified.\n    \"\"\"", "answer": "\n    image = Image.open(image_path)\n    feature_extractor = DetrFeatureExtractor.from_pretrained('facebook/detr-resnet-50-panoptic')\n    model = DetrForSegmentation.from_pretrained('facebook/detr-resnet-50-panoptic')\n    inputs = feature_extractor(images=image, return_tensors='pt')\n    outputs = model(**inputs)\n    segmented_objects = feature_extractor.post_process_panoptic(outputs, inputs['pixel_values'].shape[-2:])[0]['png_string']\n    segmented_image = Image.open(io.BytesIO(segmented_objects))\n    return segmented_image\n\n", "prediction": "\n\n    # Load pre-trained model and feature extractor\n    url_checkpoint = 'https://huggingface.co/facebook/detr-resnet-50-panoptic/resolve/main/pytorch_model.bin'\n    url_config = 'https://huggingface.co/facebook/detr-resnet-50-panoptic/resolve/main/config.json'\n\n    try:\n        feature_extractor = DetrFeatureExtractor.from_pretrained('facebook/detr-resnet-50-panoptic')\n        model = DetrForSegmentation.from_pretrained('./pretrained_model/')  # Local file load\n    except:  # Local file load fallback\n        feature_extractor = DetrFeatureExtractor.from_pretrained(url_config)\n        model = DetrForSegmentation.from_pretrained(url_checkpoint)\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # CUDA support if possible\n    model.to(device).eval()  # Make model untrainable and put it on the correct device\n\n    # Prepare image for segmentation\n    img = Image.open(image_path)\n    pixel_values = feature_extractor(images=img, return_tensors='pt').pixel_values\n    pixel_values = pixel_values.to(device)\n\n    # Get predictions (labels, bounding boxes and masks)\n    outputs = model(pixel_values)\n    scores = outputs.logits.softmax(-1)[..., :-1].max(-1).values  # Get score of most likely class for each mask\n    keep = scores > 0.85  # Remove low-confidence masks\n    labels = outputs.logits.argmax(-1)\n    labels = labels[keep]\n    \n    # Draw segmented image\n    r, g, b = [torch.zeros_like(labels).long() for _ in range(3)]  # Create RGB layers\n    colors = [(255"}