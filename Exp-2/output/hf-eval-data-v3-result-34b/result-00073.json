{"path": "output/hf-eval-data-v3-valid/f00299_translate_catalan_to_spanish.py", "content": "# function_import --------------------\n\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# function_code --------------------\n\ndef translate_catalan_to_spanish(catalan_text):\n    \"\"\"\n    Translate Catalan text to Spanish using Hugging Face's MarianMTModel.\n\n    Args:\n        catalan_text (str): The Catalan text to be translated.\n\n    Returns:\n        str: The translated Spanish text.\n    \"\"\"\n    model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ca-es')\n    tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ca-es')\n\n    tokenized_text = tokenizer.encode(catalan_text, return_tensors='pt')\n    translated_tokens = model.generate(tokenized_text)\n    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n\n    return translated_text\n\n# test_function_code --------------------\n\ndef test_translate_catalan_to_spanish():\n    \"\"\"\n    Test the function translate_catalan_to_spanish.\n    \"\"\"\n    catalan_text1 = 'El text en catal\u00e0 que vols traduir.'\n    catalan_text2 = 'Bona tarda, com est\u00e0s?'\n    catalan_text3 = 'Estic b\u00e9, gr\u00e0cies.'\n\n    assert isinstance(translate_catalan_to_spanish(catalan_text1), str)\n    assert isinstance(translate_catalan_to_spanish(catalan_text2), str)\n    assert isinstance(translate_catalan_to_spanish(catalan_text3), str)\n\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\ntest_translate_catalan_to_spanish()", "function_import": "# function_import --------------------\n\nfrom transformers import MarianMTModel, MarianTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef translate_catalan_to_spanish(catalan_text):\n    \"\"\"\n    Translate Catalan text to Spanish using Hugging Face's MarianMTModel.\n\n    Args:\n        catalan_text (str): The Catalan text to be translated.\n\n    Returns:\n        str: The translated Spanish text.\n    \"\"\"\n    model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ca-es')\n    tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ca-es')\n\n    tokenized_text = tokenizer.encode(catalan_text, return_tensors='pt')\n    translated_tokens = model.generate(tokenized_text)\n    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n\n    return translated_text\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_translate_catalan_to_spanish():\n    \"\"\"\n    Test the function translate_catalan_to_spanish.\n    \"\"\"\n    catalan_text1 = 'El text en catal\u00e0 que vols traduir.'\n    catalan_text2 = 'Bona tarda, com est\u00e0s?'\n    catalan_text3 = 'Estic b\u00e9, gr\u00e0cies.'\n\n    assert isinstance(translate_catalan_to_spanish(catalan_text1), str)\n    assert isinstance(translate_catalan_to_spanish(catalan_text2), str)\n    assert isinstance(translate_catalan_to_spanish(catalan_text3), str)\n\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_translate_catalan_to_spanish()", "instruct": "# function_import --------------------\n\nfrom transformers import MarianMTModel, MarianTokenizer\n\n# function_code --------------------\n\ndef translate_catalan_to_spanish(catalan_text):\n    \"\"\"\n    Translate Catalan text to Spanish using Hugging Face's MarianMTModel.\n\n    Args:\n        catalan_text (str): The Catalan text to be translated.\n\n    Returns:\n        str: The translated Spanish text.\n    \"\"\"", "answer": "\n    model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ca-es')\n    tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ca-es')\n\n    tokenized_text = tokenizer.encode(catalan_text, return_tensors='pt')\n    translated_tokens = model.generate(tokenized_text)\n    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n\n    return translated_text\n\n", "prediction": "    \n    model = 'Helsinki-NLP/opus-mt-ca-es'\n    tokenizer = MarianTokenizer.from_pretrained(model)\n    model = MarianMTModel.from_pretrained(model).to(\"cuda\")\n\n    input_ids = tokenizer(catalan_text, return_tensors=\"pt\").input_ids\n    input_ids = input_ids.to(\"cuda\")\n    response = model.generate(input_ids)\n    \n    translated = [tokenizer.decode(t, skip_special_tokens=True) for t in response][0]\n    return translated\n"}