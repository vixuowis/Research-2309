{"path": "output/hf-eval-data-v3-valid/f00489_analyze_stock_forum_sentiment.py", "content": "# function_import --------------------\n\nfrom transformers import RobertaForSequenceClassification, RobertaTokenizer, pipeline\nimport pandas as pd\n\n# function_code --------------------\n\ndef analyze_stock_forum_sentiment(forum_posts):\n    \"\"\"\n    Analyze the sentiment of a stock forum using a pre-trained model.\n\n    Args:\n        forum_posts (pd.Series): A pandas Series of forum posts.\n\n    Returns:\n        list: A list of sentiment analysis results for each post.\n    \"\"\"\n    tokenizer_loaded = RobertaTokenizer.from_pretrained('zhayunduo/roberta-base-stocktwits-finetuned')\n    model_loaded = RobertaForSequenceClassification.from_pretrained('zhayunduo/roberta-base-stocktwits-finetuned')\n    nlp = pipeline('text-classification', model=model_loaded, tokenizer=tokenizer_loaded)\n    results = nlp(list(forum_posts))\n    return results\n\n# test_function_code --------------------\n\ndef test_analyze_stock_forum_sentiment():\n    \"\"\"\n    Test the analyze_stock_forum_sentiment function.\n    \"\"\"\n    forum_posts = pd.Series([\"Stock X is going up!\", \"I'm selling my shares.\", \"Buy now before it's too late!\"])\n    results = analyze_stock_forum_sentiment(forum_posts)\n    assert isinstance(results, list), 'The result should be a list.'\n    assert len(results) == len(forum_posts), 'The length of the result should be equal to the length of the input.'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_analyze_stock_forum_sentiment()", "function_import": "# function_import --------------------\n\nfrom transformers import RobertaForSequenceClassification, RobertaTokenizer, pipeline\nimport pandas as pd\n\n", "function_code": "# function_code --------------------\n\ndef analyze_stock_forum_sentiment(forum_posts):\n    \"\"\"\n    Analyze the sentiment of a stock forum using a pre-trained model.\n\n    Args:\n        forum_posts (pd.Series): A pandas Series of forum posts.\n\n    Returns:\n        list: A list of sentiment analysis results for each post.\n    \"\"\"\n    tokenizer_loaded = RobertaTokenizer.from_pretrained('zhayunduo/roberta-base-stocktwits-finetuned')\n    model_loaded = RobertaForSequenceClassification.from_pretrained('zhayunduo/roberta-base-stocktwits-finetuned')\n    nlp = pipeline('text-classification', model=model_loaded, tokenizer=tokenizer_loaded)\n    results = nlp(list(forum_posts))\n    return results\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_analyze_stock_forum_sentiment():\n    \"\"\"\n    Test the analyze_stock_forum_sentiment function.\n    \"\"\"\n    forum_posts = pd.Series([\"Stock X is going up!\", \"I'm selling my shares.\", \"Buy now before it's too late!\"])\n    results = analyze_stock_forum_sentiment(forum_posts)\n    assert isinstance(results, list), 'The result should be a list.'\n    assert len(results) == len(forum_posts), 'The length of the result should be equal to the length of the input.'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_analyze_stock_forum_sentiment()", "instruct": "# function_import --------------------\n\nfrom transformers import RobertaForSequenceClassification, RobertaTokenizer, pipeline\nimport pandas as pd\n\n# function_code --------------------\n\ndef analyze_stock_forum_sentiment(forum_posts):\n    \"\"\"\n    Analyze the sentiment of a stock forum using a pre-trained model.\n\n    Args:\n        forum_posts (pd.Series): A pandas Series of forum posts.\n\n    Returns:\n        list: A list of sentiment analysis results for each post.\n    \"\"\"", "answer": "\n    tokenizer_loaded = RobertaTokenizer.from_pretrained('zhayunduo/roberta-base-stocktwits-finetuned')\n    model_loaded = RobertaForSequenceClassification.from_pretrained('zhayunduo/roberta-base-stocktwits-finetuned')\n    nlp = pipeline('text-classification', model=model_loaded, tokenizer=tokenizer_loaded)\n    results = nlp(list(forum_posts))\n    return results\n\n", "prediction": "\n\n    # Load transformers tokenizer and model\n    tokenizer = RobertaTokenizer.from_pretrained(\n        \"cardiffnlp/twitter-roberta-base-sentiment\"\n    )\n    model = RobertaForSequenceClassification.from_pretrained(\n        \"cardiffnlp/twitter-roberta-base-sentiment\"\n    )\n\n    # Build function that classifies sentiment\n    def predict_sentiment(x):\n\n        encoded = tokenizer.encode_plus(\n            x,\n            max_length=128,\n            add_special_tokens=True,\n            return_token_type_ids=False,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors=\"pt\",\n        )\n\n        input_ids = encoded[\"input_ids\"].tolist()[0]\n        attention_mask = encoded[\"attention_mask\"].tolist()[0]\n\n        output = model(torch.tensor([input_ids]), torch.tensor([attention_mask]))\n\n        # Apply Softmax at dimension 1\n        probs = functools.reduce(torch.nn.Softmax(dim=1), output.logits)\n\n        result = {\n            \"negative\": probs[0][0].item(),\n            \"neutral\": probs[0][1].item(),\n            \"positive\": probs[0][2].item(),\n        }\n\n        return result\n\n    # Build sentiment analysis pipeline\n    text_analysis = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n\n    # Perform analysis for each forum post\n    results = []\n    for post in forum_posts:\n        result = predict_sentiment(post)\n        results.append(result)\n    \n    return results"}