{"path": "output/hf-eval-data-v3-valid/f00637_generate_image.py", "content": "# function_import --------------------\n\nfrom diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\nimport torch\nimport os\n\n# function_code --------------------\n\ndef generate_image(prompt: str, model_id: str = 'stabilityai/stable-diffusion-2-1-base', output_file: str = 'output.png'):\n    \"\"\"\n    Generate an image based on the provided text prompt using the StableDiffusionPipeline.\n\n    Args:\n        prompt (str): The text prompt to generate the image from.\n        model_id (str, optional): The model id to use for the generation. Defaults to 'stabilityai/stable-diffusion-2-1-base'.\n        output_file (str, optional): The file to save the generated image to. Defaults to 'output.png'.\n\n    Returns:\n        None\n    \"\"\"\n    scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder='scheduler')\n    pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n    pipe = pipe.to('cuda')\n    image = pipe(prompt).images[0]\n    image.save(output_file)\n\n# test_function_code --------------------\n\ndef test_generate_image():\n    \"\"\"\n    Test the generate_image function.\n    \"\"\"\n    generate_image('a lighthouse on a foggy island', output_file='test_output.png')\n    assert os.path.exists('test_output.png'), 'Test failed: Image file not found.'\n    os.remove('test_output.png')\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\ntest_generate_image()", "function_import": "# function_import --------------------\n\nfrom diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\nimport torch\nimport os\n\n", "function_code": "# function_code --------------------\n\ndef generate_image(prompt: str, model_id: str = 'stabilityai/stable-diffusion-2-1-base', output_file: str = 'output.png'):\n    \"\"\"\n    Generate an image based on the provided text prompt using the StableDiffusionPipeline.\n\n    Args:\n        prompt (str): The text prompt to generate the image from.\n        model_id (str, optional): The model id to use for the generation. Defaults to 'stabilityai/stable-diffusion-2-1-base'.\n        output_file (str, optional): The file to save the generated image to. Defaults to 'output.png'.\n\n    Returns:\n        None\n    \"\"\"\n    scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder='scheduler')\n    pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n    pipe = pipe.to('cuda')\n    image = pipe(prompt).images[0]\n    image.save(output_file)\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_image():\n    \"\"\"\n    Test the generate_image function.\n    \"\"\"\n    generate_image('a lighthouse on a foggy island', output_file='test_output.png')\n    assert os.path.exists('test_output.png'), 'Test failed: Image file not found.'\n    os.remove('test_output.png')\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_generate_image()", "instruct": "# function_import --------------------\n\nfrom diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\nimport torch\nimport os\n\n# function_code --------------------\n\ndef generate_image(prompt: str, model_id: str = 'stabilityai/stable-diffusion-2-1-base', output_file: str = 'output.png'):\n    \"\"\"\n    Generate an image based on the provided text prompt using the StableDiffusionPipeline.\n\n    Args:\n        prompt (str): The text prompt to generate the image from.\n        model_id (str, optional): The model id to use for the generation. Defaults to 'stabilityai/stable-diffusion-2-1-base'.\n        output_file (str, optional): The file to save the generated image to. Defaults to 'output.png'.\n\n    Returns:\n        None\n    \"\"\"", "answer": "\n    scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder='scheduler')\n    pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n    pipe = pipe.to('cuda')\n    image = pipe(prompt).images[0]\n    image.save(output_file)\n\n", "prediction": "    \n\n    # Check if CUDA is available and set device accordingly\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Load the model with the specified id from the hub\n    model, options = StableDiffusionPipeline.from_hub(model_id)\n\n    # Move the model to the selected device and load it into eval mode (necessary for this type of model)\n    model.to(device).eval()\n\n    # Create a sample context dictionary using the provided prompt string\n    context = {\"caption\": prompt}\n\n    # Initialize an EulerDiscreteScheduler with our options dictionary and use that to create a sampling loop\n    scheduler = EulerDiscreteScheduler(options)\n    \n    # Sample the model using the scheduler we just initialized.\n    # We don't use any labels since this is an unconditional sample\n    samples, intermediates = scheduler.sample_with_halting_criterion(model=model, options=options, context=context)\n\n    # Get the final sample out of the returned list of samples\n    sample = samples[-1]\n    \n    # Convert the generated image to RGB and save it to the output file.\n    img = Image.fromarray(sample['image'][0].astype(np.uint8))\n    img.convert('RGB').save(output_file)"}