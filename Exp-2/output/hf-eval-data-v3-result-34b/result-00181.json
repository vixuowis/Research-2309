{"path": "output/hf-eval-data-v3-valid/f00730_extract_features.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# function_code --------------------\n\ndef extract_features(source_code_text):\n    \"\"\"\n    Extracts features from the given source code text using the 'microsoft/unixcoder-base' model.\n\n    Args:\n        source_code_text (str): The source code text to extract features from.\n\n    Returns:\n        torch.Tensor: The feature matrix derived as a matrix of embeddings.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/unixcoder-base')\n    model = AutoModel.from_pretrained('microsoft/unixcoder-base')\n    inputs = tokenizer(source_code_text, return_tensors='pt')\n    outputs = model(**inputs)\n    feature_matrix = outputs.last_hidden_state\n    return feature_matrix\n\n# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Tests the 'extract_features' function.\n    \"\"\"\n    source_code_text = '/* Your source code here */'\n    feature_matrix = extract_features(source_code_text)\n    assert isinstance(feature_matrix, torch.Tensor), 'The output should be a torch.Tensor.'\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    test_extract_features()", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\n\n", "function_code": "# function_code --------------------\n\ndef extract_features(source_code_text):\n    \"\"\"\n    Extracts features from the given source code text using the 'microsoft/unixcoder-base' model.\n\n    Args:\n        source_code_text (str): The source code text to extract features from.\n\n    Returns:\n        torch.Tensor: The feature matrix derived as a matrix of embeddings.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/unixcoder-base')\n    model = AutoModel.from_pretrained('microsoft/unixcoder-base')\n    inputs = tokenizer(source_code_text, return_tensors='pt')\n    outputs = model(**inputs)\n    feature_matrix = outputs.last_hidden_state\n    return feature_matrix\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Tests the 'extract_features' function.\n    \"\"\"\n    source_code_text = '/* Your source code here */'\n    feature_matrix = extract_features(source_code_text)\n    assert isinstance(feature_matrix, torch.Tensor), 'The output should be a torch.Tensor.'\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    test_extract_features()", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# function_code --------------------\n\ndef extract_features(source_code_text):\n    \"\"\"\n    Extracts features from the given source code text using the 'microsoft/unixcoder-base' model.\n\n    Args:\n        source_code_text (str): The source code text to extract features from.\n\n    Returns:\n        torch.Tensor: The feature matrix derived as a matrix of embeddings.\n    \"\"\"", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/unixcoder-base')\n    model = AutoModel.from_pretrained('microsoft/unixcoder-base')\n    inputs = tokenizer(source_code_text, return_tensors='pt')\n    outputs = model(**inputs)\n    feature_matrix = outputs.last_hidden_state\n    return feature_matrix\n\n", "prediction": "\n    \n    # Load the model and tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/CodeBERT-small-v1\")\n    model = AutoModel.from_pretrained(\"microsoft/CodeBERT-small-v1\")\n    model.eval()\n\n    # Split the code into a list of lines\n    source_code_text = source_code_text.split(\"\\n\")[2::] # Removes header\n    \n    # Tokenize the code and add it to the input matrix\n    inputs_dict = tokenizer(source_code_text, padding=True, truncation=True, return_tensors=\"pt\")\n\n    # Extract features from the model\n    with torch.no_grad():\n        outputs = model(**inputs_dict)\n    \n    # Return the average of all code tokens as the embedding for that line\n    return torch.mean(outputs[0], 1).cpu()\n"}