{"path": "output/hf-eval-data-v3-valid/f00687_classify_text.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# function_code --------------------\n\ndef classify_text(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification.\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"\n    nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    probs_list = []\n    for label in candidate_labels:\n        hypothesis = f'This example is {label}.'\n        inputs = tokenizer(sequence, hypothesis, return_tensors='pt', truncation=True)\n        logits = nli_model(**inputs)[0]\n        entail_contradiction_logits = logits[:, [0, 2]]\n        probs = entail_contradiction_logits.softmax(dim=1)\n        prob_label_is_true = probs[:, 1].item()\n        probs_list.append(prob_label_is_true)\n\n    category_index = probs_list.index(max(probs_list))\n    return candidate_labels[category_index]\n\n# test_function_code --------------------\n\ndef test_classify_text():\n    \"\"\"\n    Test the classify_text function.\n    \"\"\"\n    text_message = 'I spent hours in the kitchen trying a new recipe.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I am planning a trip to Paris.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I love to dance salsa.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_classify_text()", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef classify_text(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification.\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"\n    nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    probs_list = []\n    for label in candidate_labels:\n        hypothesis = f'This example is {label}.'\n        inputs = tokenizer(sequence, hypothesis, return_tensors='pt', truncation=True)\n        logits = nli_model(**inputs)[0]\n        entail_contradiction_logits = logits[:, [0, 2]]\n        probs = entail_contradiction_logits.softmax(dim=1)\n        prob_label_is_true = probs[:, 1].item()\n        probs_list.append(prob_label_is_true)\n\n    category_index = probs_list.index(max(probs_list))\n    return candidate_labels[category_index]\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_classify_text():\n    \"\"\"\n    Test the classify_text function.\n    \"\"\"\n    text_message = 'I spent hours in the kitchen trying a new recipe.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I am planning a trip to Paris.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I love to dance salsa.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_classify_text()", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# function_code --------------------\n\ndef classify_text(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification.\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"", "answer": "\n    nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    probs_list = []\n    for label in candidate_labels:\n        hypothesis = f'This example is {label}.'\n        inputs = tokenizer(sequence, hypothesis, return_tensors='pt', truncation=True)\n        logits = nli_model(**inputs)[0]\n        entail_contradiction_logits = logits[:, [0, 2]]\n        probs = entail_contradiction_logits.softmax(dim=1)\n        prob_label_is_true = probs[:, 1].item()\n        probs_list.append(prob_label_is_true)\n\n    category_index = probs_list.index(max(probs_list))\n    return candidate_labels[category_index]\n\n", "prediction": "\n\n    # Load a model from huggingface library\n    model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    # Define the label candidates\n    labels = candidate_labels\n\n    # Tokenize and encode sequence to a torch tensor\n    encoding = tokenizer(sequence, return_tensors='pt', truncation=True, padding=True)\n    input_ids = encoding['input_ids']\n    attention_mask = encoding['attention_mask']\n    \n    # Perform zero-shot classification using a model from huggingface library\n    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=torch.tensor([0]))\n\n    # Get the probabilities for each candidate label\n    scores = torch.nn.Softmax(dim=-1)(outputs.logits)\n    \n    # Get the most likely label according to the model output\n    predicted_id = int(torch.argmax(scores))\n    predicted_label = labels[predicted_id]\n    \n    return predicted_label"}