{"path": "output/hf-eval-data-v3-valid/f00768_analyze_review_sentiment.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef analyze_review_sentiment(review_text):\n    \"\"\"\n    Analyze the sentiment of a restaurant review using a pre-trained model.\n\n    Args:\n        review_text (str): The text of the restaurant review.\n\n    Returns:\n        str: The sentiment of the review ('positive' or 'negative').\n\n    Raises:\n        OSError: If there is an error loading the pre-trained model or tokenizing the input text.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n    config = AutoConfig.from_pretrained('potatobunny/results-yelp')\n    model = AutoModelForSequenceClassification.from_pretrained('potatobunny/results-yelp', config=config)\n    inputs = tokenizer(review_text, return_tensors='pt')\n    outputs = model(**inputs)\n    sentiment = 'positive' if outputs.logits[0, 1] > outputs.logits[0, 0] else 'negative'\n    return sentiment\n\n# test_function_code --------------------\n\ndef test_analyze_review_sentiment():\n    \"\"\"\n    Test the analyze_review_sentiment function.\n    \"\"\"\n    positive_review = 'The food was delicious and the service was excellent.'\n    negative_review = 'The food was terrible and the service was poor.'\n    assert analyze_review_sentiment(positive_review) == 'positive'\n    assert analyze_review_sentiment(negative_review) == 'negative'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    print(test_analyze_review_sentiment())", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n\n", "function_code": "# function_code --------------------\n\ndef analyze_review_sentiment(review_text):\n    \"\"\"\n    Analyze the sentiment of a restaurant review using a pre-trained model.\n\n    Args:\n        review_text (str): The text of the restaurant review.\n\n    Returns:\n        str: The sentiment of the review ('positive' or 'negative').\n\n    Raises:\n        OSError: If there is an error loading the pre-trained model or tokenizing the input text.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n    config = AutoConfig.from_pretrained('potatobunny/results-yelp')\n    model = AutoModelForSequenceClassification.from_pretrained('potatobunny/results-yelp', config=config)\n    inputs = tokenizer(review_text, return_tensors='pt')\n    outputs = model(**inputs)\n    sentiment = 'positive' if outputs.logits[0, 1] > outputs.logits[0, 0] else 'negative'\n    return sentiment\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_analyze_review_sentiment():\n    \"\"\"\n    Test the analyze_review_sentiment function.\n    \"\"\"\n    positive_review = 'The food was delicious and the service was excellent.'\n    negative_review = 'The food was terrible and the service was poor.'\n    assert analyze_review_sentiment(positive_review) == 'positive'\n    assert analyze_review_sentiment(negative_review) == 'negative'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    print(test_analyze_review_sentiment())", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef analyze_review_sentiment(review_text):\n    \"\"\"\n    Analyze the sentiment of a restaurant review using a pre-trained model.\n\n    Args:\n        review_text (str): The text of the restaurant review.\n\n    Returns:\n        str: The sentiment of the review ('positive' or 'negative').\n\n    Raises:\n        OSError: If there is an error loading the pre-trained model or tokenizing the input text.\n    \"\"\"", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n    config = AutoConfig.from_pretrained('potatobunny/results-yelp')\n    model = AutoModelForSequenceClassification.from_pretrained('potatobunny/results-yelp', config=config)\n    inputs = tokenizer(review_text, return_tensors='pt')\n    outputs = model(**inputs)\n    sentiment = 'positive' if outputs.logits[0, 1] > outputs.logits[0, 0] else 'negative'\n    return sentiment\n\n", "prediction": "\n    \n    # Load the pre-trained model and tokenizer.\n    try:\n        \n        config = AutoConfig.from_pretrained(\"naterush/bert-base-uncased-sentiment\")\n        model = AutoModelForSequenceClassification.from_pretrained(\n            \"naterush/bert-base-uncased-sentiment\",\n            config=config)\n        \n        tokenizer = AutoTokenizer.from_pretrained(\"naterush/bert-base-uncased-sentiment\")\n    except OSError:\n        print('There was an error loading the pre-trained model or tokenizing the input text.')\n    \n    # Prepare the review text for analysis.\n    inputs = tokenizer(review_text, return_tensors=\"pt\")\n    \n    # Analyze the sentiment of the review.\n    outputs = model(**inputs)\n        \n    probabilities = torch.nn.functional.softmax(outputs[0], dim=-1)[0]\n    \n    positive_probability = round(probabilities[0].item(), 2) * 100\n    negative_probability = round(probabilities[1].item(), 2) * 100\n        \n    if positive_probability > negative_probability:\n        sentiment = 'positive'\n    else:\n        sentiment = 'negative'\n    \n    # Return the results.\n    return sentiment, positive_probability, negative_probability"}