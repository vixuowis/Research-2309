{"path": "output/hf-eval-data-v3-valid/f00217_determine_logical_relationship.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef determine_logical_relationship(text1: str, text2: str) -> dict:\n    \"\"\"\n    Determine the logical relationship between two given sentences.\n\n    Args:\n        text1 (str): The first sentence.\n        text2 (str): The second sentence.\n\n    Returns:\n        dict: A dictionary containing the probabilities of each logical relationship (entailment, contradiction, or neutral).\n    \"\"\"\n    model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n    if torch.cuda.is_available():\n        model.cuda()\n\n    with torch.inference_mode():\n        out = model(**tokenizer(text1, text2, return_tensors='pt').to(model.device))\n        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n\n    result = {v: proba[k] for k, v in model.config.id2label.items()}\n    return result\n\n# test_function_code --------------------\n\ndef test_determine_logical_relationship():\n    \"\"\"\n    Test the function determine_logical_relationship.\n    \"\"\"\n    text1 = 'The cat is on the mat.'\n    text2 = 'There is a cat on the mat.'\n    result = determine_logical_relationship(text1, text2)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == {'entailment', 'contradiction', 'neutral'}\n\n    text1 = 'It is raining.'\n    text2 = 'The weather is sunny.'\n    result = determine_logical_relationship(text1, text2)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == {'entailment', 'contradiction', 'neutral'}\n\n    text1 = 'He is a boy.'\n    text2 = 'She is a girl.'\n    result = determine_logical_relationship(text1, text2)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == {'entailment', 'contradiction', 'neutral'}\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\nprint(test_determine_logical_relationship())", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n", "function_code": "# function_code --------------------\n\ndef determine_logical_relationship(text1: str, text2: str) -> dict:\n    \"\"\"\n    Determine the logical relationship between two given sentences.\n\n    Args:\n        text1 (str): The first sentence.\n        text2 (str): The second sentence.\n\n    Returns:\n        dict: A dictionary containing the probabilities of each logical relationship (entailment, contradiction, or neutral).\n    \"\"\"\n    model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n    if torch.cuda.is_available():\n        model.cuda()\n\n    with torch.inference_mode():\n        out = model(**tokenizer(text1, text2, return_tensors='pt').to(model.device))\n        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n\n    result = {v: proba[k] for k, v in model.config.id2label.items()}\n    return result\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_determine_logical_relationship():\n    \"\"\"\n    Test the function determine_logical_relationship.\n    \"\"\"\n    text1 = 'The cat is on the mat.'\n    text2 = 'There is a cat on the mat.'\n    result = determine_logical_relationship(text1, text2)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == {'entailment', 'contradiction', 'neutral'}\n\n    text1 = 'It is raining.'\n    text2 = 'The weather is sunny.'\n    result = determine_logical_relationship(text1, text2)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == {'entailment', 'contradiction', 'neutral'}\n\n    text1 = 'He is a boy.'\n    text2 = 'She is a girl.'\n    result = determine_logical_relationship(text1, text2)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == {'entailment', 'contradiction', 'neutral'}\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\nprint(test_determine_logical_relationship())", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef determine_logical_relationship(text1: str, text2: str) -> dict:\n    \"\"\"\n    Determine the logical relationship between two given sentences.\n\n    Args:\n        text1 (str): The first sentence.\n        text2 (str): The second sentence.\n\n    Returns:\n        dict: A dictionary containing the probabilities of each logical relationship (entailment, contradiction, or neutral).\n    \"\"\"", "answer": "\n    model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n    if torch.cuda.is_available():\n        model.cuda()\n\n    with torch.inference_mode():\n        out = model(**tokenizer(text1, text2, return_tensors='pt').to(model.device))\n        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n\n    result = {v: proba[k] for k, v in model.config.id2label.items()}\n    return result\n\n", "prediction": "\n    \n    # Set up the tokenizer and model\n    tokenizer = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")\n    model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\").eval()\n\n    # Encode the sentences and convert the output to a tuple\n    inputs = tokenizer(text1, text2, return_tensors=\"pt\", truncation=True)\n    outputs = model(**inputs)[0].softmax(dim=-1).tolist()[0]\n\n    # Define the labels and probabilities\n    labels = [\"entailment\", \"neutral\", \"contradiction\"]\n    \n    return {labels[i]: outputs[i] for i in range(len(outputs))}\n"}