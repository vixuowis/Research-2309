{"path": "output/hf-eval-data-v3-valid/f00004_extract_sentence_embeddings.py", "content": "# function_import --------------------\n\nfrom transformers import AutoModel, AutoTokenizer\n\n# function_code --------------------\n\ndef extract_sentence_embeddings(input_text: str):\n    '''\n    This function takes a sentence as input and returns its embedding using the LaBSE model.\n    \n    Args:\n    input_text (str): The sentence to be encoded.\n    \n    Returns:\n    Tensor: The sentence embedding.\n    '''\n    model = AutoModel.from_pretrained('rasa/LaBSE')\n    tokenizer = AutoTokenizer.from_pretrained('rasa/LaBSE')\n    encoded_input = tokenizer(input_text, return_tensors='pt')\n    embeddings = model(**encoded_input)\n    sentence_embedding = embeddings.pooler_output\n    return sentence_embedding\n\n# test_function_code --------------------\n\ndef test_extract_sentence_embeddings():\n    '''\n    This function tests the extract_sentence_embeddings function.\n    '''\n    sentence1 = 'Here is a sentence in English.'\n    sentence2 = 'Voici une phrase en fran\u00e7ais.'\n    sentence3 = 'Aqu\u00ed hay una frase en espa\u00f1ol.'\n    \n    embedding1 = extract_sentence_embeddings(sentence1)\n    embedding2 = extract_sentence_embeddings(sentence2)\n    embedding3 = extract_sentence_embeddings(sentence3)\n    \n    assert embedding1.shape == (1, 768)\n    assert embedding2.shape == (1, 768)\n    assert embedding3.shape == (1, 768)\n    \n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_extract_sentence_embeddings()", "function_import": "# function_import --------------------\n\nfrom transformers import AutoModel, AutoTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef extract_sentence_embeddings(input_text: str):\n    '''\n    This function takes a sentence as input and returns its embedding using the LaBSE model.\n    \n    Args:\n    input_text (str): The sentence to be encoded.\n    \n    Returns:\n    Tensor: The sentence embedding.\n    '''\n    model = AutoModel.from_pretrained('rasa/LaBSE')\n    tokenizer = AutoTokenizer.from_pretrained('rasa/LaBSE')\n    encoded_input = tokenizer(input_text, return_tensors='pt')\n    embeddings = model(**encoded_input)\n    sentence_embedding = embeddings.pooler_output\n    return sentence_embedding\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_extract_sentence_embeddings():\n    '''\n    This function tests the extract_sentence_embeddings function.\n    '''\n    sentence1 = 'Here is a sentence in English.'\n    sentence2 = 'Voici une phrase en fran\u00e7ais.'\n    sentence3 = 'Aqu\u00ed hay una frase en espa\u00f1ol.'\n    \n    embedding1 = extract_sentence_embeddings(sentence1)\n    embedding2 = extract_sentence_embeddings(sentence2)\n    embedding3 = extract_sentence_embeddings(sentence3)\n    \n    assert embedding1.shape == (1, 768)\n    assert embedding2.shape == (1, 768)\n    assert embedding3.shape == (1, 768)\n    \n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_extract_sentence_embeddings()", "instruct": "# function_import --------------------\n\nfrom transformers import AutoModel, AutoTokenizer\n\n# function_code --------------------\n\ndef extract_sentence_embeddings(input_text: str):\n    '''\n    This function takes a sentence as input and returns its embedding using the LaBSE model.\n    \n    Args:\n    input_text (str): The sentence to be encoded.\n    \n    Returns:\n    Tensor: The sentence embedding.\n    '''", "answer": "\n    model = AutoModel.from_pretrained('rasa/LaBSE')\n    tokenizer = AutoTokenizer.from_pretrained('rasa/LaBSE')\n    encoded_input = tokenizer(input_text, return_tensors='pt')\n    embeddings = model(**encoded_input)\n    sentence_embedding = embeddings.pooler_output\n    return sentence_embedding\n\n", "prediction": "\n    # load model\n    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n    model = AutoModel.from_pretrained('sentence-transformers/LaBSE')\n    \n    encoded_input = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt')\n\n    with torch.no_grad():\n        model_output = model(**encoded_input)\n\n    # sentence embeddings\n    embedding = model_output.pooler_output[0]\n    \n    return embedding"}