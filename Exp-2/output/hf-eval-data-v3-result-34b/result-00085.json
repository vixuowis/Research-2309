{"path": "output/hf-eval-data-v3-valid/f00365_segment_clothes.py", "content": "# function_import --------------------\n\nfrom transformers import AutoFeatureExtractor, SegformerForSemanticSegmentation\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n\n# function_code --------------------\n\ndef segment_clothes(image_path):\n    \"\"\"\n    This function segments clothes in an image using a pre-trained SegFormer model.\n\n    Args:\n        image_path (str): The path to the image file or a URL.\n\n    Returns:\n        A matplotlib figure showing the segmented image.\n    \"\"\"\n    extractor = AutoFeatureExtractor.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    image = Image.open(requests.get(image_path, stream=True).raw)\n    model = SegformerForSemanticSegmentation.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    inputs = extractor(images=image, return_tensors='pt')\n    outputs = model(**inputs)\n\n    logits = outputs.logits.cpu()\n    upsampled_logits = nn.functional.interpolate(logits, size=image.size[::-1], mode='bilinear', align_corners=False)\n    pred_seg = upsampled_logits.argmax(dim=1)[0]\n    plt.imshow(pred_seg)\n    return plt\n\n# test_function_code --------------------\n\ndef test_segment_clothes():\n    \"\"\"\n    This function tests the segment_clothes function with a few test cases.\n    \"\"\"\n    # Test case 1: An image of a person wearing clothes\n    url1 = 'https://placekitten.com/200/300'\n    result1 = segment_clothes(url1)\n    assert isinstance(result1, type(plt)), 'Test Case 1 Failed'\n\n    # Test case 2: Another image of a person wearing clothes\n    url2 = 'https://placekitten.com/400/600'\n    result2 = segment_clothes(url2)\n    assert isinstance(result2, type(plt)), 'Test Case 2 Failed'\n\n    # Test case 3: Yet another image of a person wearing clothes\n    url3 = 'https://placekitten.com/800/1200'\n    result3 = segment_clothes(url3)\n    assert isinstance(result3, type(plt)), 'Test Case 3 Failed'\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_segment_clothes()", "function_import": "# function_import --------------------\n\nfrom transformers import AutoFeatureExtractor, SegformerForSemanticSegmentation\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n\n", "function_code": "# function_code --------------------\n\ndef segment_clothes(image_path):\n    \"\"\"\n    This function segments clothes in an image using a pre-trained SegFormer model.\n\n    Args:\n        image_path (str): The path to the image file or a URL.\n\n    Returns:\n        A matplotlib figure showing the segmented image.\n    \"\"\"\n    extractor = AutoFeatureExtractor.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    image = Image.open(requests.get(image_path, stream=True).raw)\n    model = SegformerForSemanticSegmentation.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    inputs = extractor(images=image, return_tensors='pt')\n    outputs = model(**inputs)\n\n    logits = outputs.logits.cpu()\n    upsampled_logits = nn.functional.interpolate(logits, size=image.size[::-1], mode='bilinear', align_corners=False)\n    pred_seg = upsampled_logits.argmax(dim=1)[0]\n    plt.imshow(pred_seg)\n    return plt\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_segment_clothes():\n    \"\"\"\n    This function tests the segment_clothes function with a few test cases.\n    \"\"\"\n    # Test case 1: An image of a person wearing clothes\n    url1 = 'https://placekitten.com/200/300'\n    result1 = segment_clothes(url1)\n    assert isinstance(result1, type(plt)), 'Test Case 1 Failed'\n\n    # Test case 2: Another image of a person wearing clothes\n    url2 = 'https://placekitten.com/400/600'\n    result2 = segment_clothes(url2)\n    assert isinstance(result2, type(plt)), 'Test Case 2 Failed'\n\n    # Test case 3: Yet another image of a person wearing clothes\n    url3 = 'https://placekitten.com/800/1200'\n    result3 = segment_clothes(url3)\n    assert isinstance(result3, type(plt)), 'Test Case 3 Failed'\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_segment_clothes()", "instruct": "# function_import --------------------\n\nfrom transformers import AutoFeatureExtractor, SegformerForSemanticSegmentation\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n\n# function_code --------------------\n\ndef segment_clothes(image_path):\n    \"\"\"\n    This function segments clothes in an image using a pre-trained SegFormer model.\n\n    Args:\n        image_path (str): The path to the image file or a URL.\n\n    Returns:\n        A matplotlib figure showing the segmented image.\n    \"\"\"", "answer": "\n    extractor = AutoFeatureExtractor.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    image = Image.open(requests.get(image_path, stream=True).raw)\n    model = SegformerForSemanticSegmentation.from_pretrained('mattmdjaga/segformer_b2_clothes')\n    inputs = extractor(images=image, return_tensors='pt')\n    outputs = model(**inputs)\n\n    logits = outputs.logits.cpu()\n    upsampled_logits = nn.functional.interpolate(logits, size=image.size[::-1], mode='bilinear', align_corners=False)\n    pred_seg = upsampled_logits.argmax(dim=1)[0]\n    plt.imshow(pred_seg)\n    return plt\n\n", "prediction": "    \n        \n    # Download the image from a URL if it's not already saved locally.\n    if \"https\" in image_path:\n        response = requests.get(image_path)\n        image_path = image_path.split(\"/\")[-1]\n        with open(image_path, 'wb') as f:\n            f.write(response.content)\n\n    # Load the trained model and feature extractor.\n    model = SegformerForSemanticSegmentation.from_pretrained(\"nielsr/segformer-b3-512-ade\")\n    feature_extractor = AutoFeatureExtractor.from_pretrained(\"nielsr/segformer-b3-512-ade\")\n    \n    # Preprocess the image using the feature extractor.\n    inputs = feature_extractor(images=image_path, return_tensors=\"pt\")\n\n    # Predict the segmented image and plot it.\n    outputs = model(**inputs)\n    predicted_logits = outputs.logits[0]\n\n    # Plot the predicted logits.\n    plt.figure(figsize=(21, 9))\n\n    plt.subplot(131)\n    plt.imshow(Image.open(image_path).convert(\"RGB\"))\n    plt.title(\"Input image\")\n\n    plt.subplot(132)    \n    plt.imshow(inputs[\"pixel_values\"][0].cpu().numpy().transpose(1, 2, 0), interpolation=\"nearest\")\n    plt.title(\"Preprocessed input image\")\n\n    plt.subplot(133);\n    predicted_image = outputs.logits[0].argmax(-1).squeeze().detach().cpu().numpy()\n    predicted_image = Image.fromarray(predicted_image)\n    predicted_image.putpalette([0, 0, 0, 255])  \n    plt.imshow(predicted_image.convert(\"RGB\"))\n    plt.title(\"Predicted segmentation\")"}