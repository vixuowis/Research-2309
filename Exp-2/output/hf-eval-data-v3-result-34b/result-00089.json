{"path": "output/hf-eval-data-v3-valid/f00380_detect_gpt2_generated_text.py", "content": "# function_import --------------------\n\nfrom transformers import pipeline\n\n# function_code --------------------\n\ndef detect_gpt2_generated_text(text):\n    \"\"\"\n    Detect if the given text is generated by GPT-2 model.\n\n    Args:\n        text (str): The text to be checked.\n\n    Returns:\n        dict: The prediction result, indicating whether the text was generated by GPT-2 or not.\n    \"\"\"\n    pipe = pipeline('text-classification', model='roberta-base-openai-detector')\n    prediction = pipe(text)\n    return prediction\n\n# test_function_code --------------------\n\ndef test_detect_gpt2_generated_text():\n    \"\"\"\n    Test the function detect_gpt2_generated_text.\n    \"\"\"\n    # Test case 1: AI-generated text\n    text1 = 'In a shocking turn of events, the city council has decided to turn the entire city into a giant amusement park.'\n    prediction1 = detect_gpt2_generated_text(text1)\n    assert isinstance(prediction1, list), 'The result should be a list.'\n\n    # Test case 2: Human-written text\n    text2 = 'Hello world! This is a test.'\n    prediction2 = detect_gpt2_generated_text(text2)\n    assert isinstance(prediction2, list), 'The result should be a list.'\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_detect_gpt2_generated_text()", "function_import": "# function_import --------------------\n\nfrom transformers import pipeline\n\n", "function_code": "# function_code --------------------\n\ndef detect_gpt2_generated_text(text):\n    \"\"\"\n    Detect if the given text is generated by GPT-2 model.\n\n    Args:\n        text (str): The text to be checked.\n\n    Returns:\n        dict: The prediction result, indicating whether the text was generated by GPT-2 or not.\n    \"\"\"\n    pipe = pipeline('text-classification', model='roberta-base-openai-detector')\n    prediction = pipe(text)\n    return prediction\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_detect_gpt2_generated_text():\n    \"\"\"\n    Test the function detect_gpt2_generated_text.\n    \"\"\"\n    # Test case 1: AI-generated text\n    text1 = 'In a shocking turn of events, the city council has decided to turn the entire city into a giant amusement park.'\n    prediction1 = detect_gpt2_generated_text(text1)\n    assert isinstance(prediction1, list), 'The result should be a list.'\n\n    # Test case 2: Human-written text\n    text2 = 'Hello world! This is a test.'\n    prediction2 = detect_gpt2_generated_text(text2)\n    assert isinstance(prediction2, list), 'The result should be a list.'\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_detect_gpt2_generated_text()", "instruct": "# function_import --------------------\n\nfrom transformers import pipeline\n\n# function_code --------------------\n\ndef detect_gpt2_generated_text(text):\n    \"\"\"\n    Detect if the given text is generated by GPT-2 model.\n\n    Args:\n        text (str): The text to be checked.\n\n    Returns:\n        dict: The prediction result, indicating whether the text was generated by GPT-2 or not.\n    \"\"\"", "answer": "\n    pipe = pipeline('text-classification', model='roberta-base-openai-detector')\n    prediction = pipe(text)\n    return prediction\n\n", "prediction": "\n\n    # load the fine-tuned model\n    gpt_pipeline = pipeline(\"zero-shot-classification\", \n                            model=\"seongju/gpt2-infomedia\")\n\n    # make a prediction\n    result = gpt_pipeline(text, candidate_labels=['GPT', 'Non-GPT'])\n    \n    return result"}