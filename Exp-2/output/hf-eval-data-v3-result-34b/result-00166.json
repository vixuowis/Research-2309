{"path": "output/hf-eval-data-v3-valid/f00678_tokenize_chinese_text.py", "content": "# function_import --------------------\n\nfrom transformers import BertTokenizerFast, AutoModel\n\n# function_code --------------------\n\ndef tokenize_chinese_text(text):\n    \"\"\"\n    Tokenizes Chinese text using the 'ckiplab/bert-base-chinese-ws' pretrained model.\n\n    Args:\n        text (str): The Chinese text to be tokenized.\n\n    Returns:\n        List[str]: The tokenized text.\n    \"\"\"\n    tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n    model = AutoModel.from_pretrained('ckiplab/bert-base-chinese-ws')\n    tokens = tokenizer.tokenize(text)\n    return tokens\n\n# test_function_code --------------------\n\ndef test_tokenize_chinese_text():\n    \"\"\"\n    Tests the tokenize_chinese_text function with some sample Chinese text.\n    \"\"\"\n    sample_text = '\u6211\u7231\u81ea\u7136\u8bed\u8a00\u5904\u7406'\n    tokens = tokenize_chinese_text(sample_text)\n    assert isinstance(tokens, list)\n    assert all(isinstance(token, str) for token in tokens)\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_tokenize_chinese_text()", "function_import": "# function_import --------------------\n\nfrom transformers import BertTokenizerFast, AutoModel\n\n", "function_code": "# function_code --------------------\n\ndef tokenize_chinese_text(text):\n    \"\"\"\n    Tokenizes Chinese text using the 'ckiplab/bert-base-chinese-ws' pretrained model.\n\n    Args:\n        text (str): The Chinese text to be tokenized.\n\n    Returns:\n        List[str]: The tokenized text.\n    \"\"\"\n    tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n    model = AutoModel.from_pretrained('ckiplab/bert-base-chinese-ws')\n    tokens = tokenizer.tokenize(text)\n    return tokens\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_tokenize_chinese_text():\n    \"\"\"\n    Tests the tokenize_chinese_text function with some sample Chinese text.\n    \"\"\"\n    sample_text = '\u6211\u7231\u81ea\u7136\u8bed\u8a00\u5904\u7406'\n    tokens = tokenize_chinese_text(sample_text)\n    assert isinstance(tokens, list)\n    assert all(isinstance(token, str) for token in tokens)\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_tokenize_chinese_text()", "instruct": "# function_import --------------------\n\nfrom transformers import BertTokenizerFast, AutoModel\n\n# function_code --------------------\n\ndef tokenize_chinese_text(text):\n    \"\"\"\n    Tokenizes Chinese text using the 'ckiplab/bert-base-chinese-ws' pretrained model.\n\n    Args:\n        text (str): The Chinese text to be tokenized.\n\n    Returns:\n        List[str]: The tokenized text.\n    \"\"\"", "answer": "\n    tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n    model = AutoModel.from_pretrained('ckiplab/bert-base-chinese-ws')\n    tokens = tokenizer.tokenize(text)\n    return tokens\n\n", "prediction": "\n\n    # Load Bert tokenizer for Chinese text\n    bert_tokenizer = BertTokenizerFast.from_pretrained('ckiplab/bert-base-chinese-ws')\n    \n    # Tokenize the input text and add '[CLS]' at the beginning of the sequence, as well as adding a '[SEP]' token at the end\n    tokenized_text = bert_tokenizer(text,\n                                    return_tensors='pt',\n                                    truncation=True, \n                                    max_length=512, \n                                    padding=\"max_length\", \n                                    add_special_tokens=True)[\"input_ids\"][0] # Extracts the PyTorch tensor returned by BertTokenizerFast.from_pretrained().\n    \n    # Convert tokenized text from a PyTorch tensor to a list of strings\n    tokenized_text = [bert_tokenizer.decode([token]) for token in tokenized_text]\n    \n    return tokenized_text\n\ndef load_chinesebert():\n    \"\"\"\n    Loads the 'ckiplab/bert-base-chinese-ws' pretrained model.\n\n    Returns:\n        (BertTokenizerFast, AutoModel): A tuple containing an instance of BertTokenizerFast for Chinese text and an instance of AutoModel for the pretrained model architecture.\n    \n    \"\"\"\n\n    # Load Bert tokenizer for Chinese text\n    bert_tokenizer = BertTokenizerFast.from_pretrained('ckiplab/bert-base-chinese-ws')\n    \n    # Load AutoModel of the 'ckiplab/bert-base-chinese-ws' pretrained model to get model architecture.\n    bert_model = AutoModel.from_pretrained('ckiplab/bert-base-chinese-ws',\n                                           output_attentions=True, \n                                           output_hidden_states=True)\n    \n    return (bert_tokenizer, bert_model)"}