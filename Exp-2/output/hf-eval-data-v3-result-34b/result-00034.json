{"path": "output/hf-eval-data-v3-valid/f00143_generate_code.py", "content": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# function_code --------------------\n\ndef generate_code(description: str) -> str:\n    '''\n    Generate code snippets based on natural language descriptions.\n\n    Args:\n        description (str): The natural language description.\n\n    Returns:\n        str: The generated code snippet.\n    '''\n    tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-2B-multi')\n    model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-2B-multi')\n    input_ids = tokenizer(description, return_tensors='pt').input_ids\n    generated_ids = model.generate(input_ids, max_length=128)\n    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    return generated_code\n\n# test_function_code --------------------\n\ndef test_generate_code():\n    '''\n    Test the generate_code function.\n    '''\n    description1 = 'Write a Python function to calculate the factorial of a number.'\n    description2 = 'Write a Python function to sort a list of numbers in ascending order.'\n    description3 = 'Write a Python function to reverse a string.'\n    assert isinstance(generate_code(description1), str)\n    assert isinstance(generate_code(description2), str)\n    assert isinstance(generate_code(description3), str)\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_generate_code()", "function_import": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n", "function_code": "# function_code --------------------\n\ndef generate_code(description: str) -> str:\n    '''\n    Generate code snippets based on natural language descriptions.\n\n    Args:\n        description (str): The natural language description.\n\n    Returns:\n        str: The generated code snippet.\n    '''\n    tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-2B-multi')\n    model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-2B-multi')\n    input_ids = tokenizer(description, return_tensors='pt').input_ids\n    generated_ids = model.generate(input_ids, max_length=128)\n    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    return generated_code\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_code():\n    '''\n    Test the generate_code function.\n    '''\n    description1 = 'Write a Python function to calculate the factorial of a number.'\n    description2 = 'Write a Python function to sort a list of numbers in ascending order.'\n    description3 = 'Write a Python function to reverse a string.'\n    assert isinstance(generate_code(description1), str)\n    assert isinstance(generate_code(description2), str)\n    assert isinstance(generate_code(description3), str)\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_generate_code()", "instruct": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# function_code --------------------\n\ndef generate_code(description: str) -> str:\n    '''\n    Generate code snippets based on natural language descriptions.\n\n    Args:\n        description (str): The natural language description.\n\n    Returns:\n        str: The generated code snippet.\n    '''", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-2B-multi')\n    model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-2B-multi')\n    input_ids = tokenizer(description, return_tensors='pt').input_ids\n    generated_ids = model.generate(input_ids, max_length=128)\n    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    return generated_code\n\n", "prediction": "\n    # Load the tokenizer and model from huggingface hub\n    tokenizer = AutoTokenizer.from_pretrained('planb18/GPT2LMHeadModel')\n    model = AutoModelForCausalLM.from_pretrained('planb18/GPT2LMHeadModel')\n\n    # Generate code\n    input = \"'''#description: \" + description + \"'''\\n\"\n    output = tokenizer.decode(model.generate(tokenizer.encode(input), max_length=300)[0])[len(input):]\n    return output"}