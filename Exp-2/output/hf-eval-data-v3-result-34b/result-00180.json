{"path": "output/hf-eval-data-v3-valid/f00729_extract_features.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\n# function_code --------------------\n\ndef extract_features(input_text: str):\n    \"\"\"\n    Extract features from text or code using the pre-trained CodeBERT model.\n\n    Args:\n        input_text (str): The input text or code from which to extract features.\n\n    Returns:\n        torch.Tensor: The extracted features (embeddings) from the input text or code.\n    \"\"\"\n    model = AutoModel.from_pretrained('microsoft/codebert-base')\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')\n    inputs = tokenizer(input_text, return_tensors='pt')\n    outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state\n    return embeddings\n\n# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Test the extract_features function.\n    \"\"\"\n    input_text = 'def hello_world():\\n    print(\"Hello, world!\")'\n    embeddings = extract_features(input_text)\n    assert embeddings is not None\n    assert embeddings.size(0) > 0\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    print(test_extract_features())", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef extract_features(input_text: str):\n    \"\"\"\n    Extract features from text or code using the pre-trained CodeBERT model.\n\n    Args:\n        input_text (str): The input text or code from which to extract features.\n\n    Returns:\n        torch.Tensor: The extracted features (embeddings) from the input text or code.\n    \"\"\"\n    model = AutoModel.from_pretrained('microsoft/codebert-base')\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')\n    inputs = tokenizer(input_text, return_tensors='pt')\n    outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state\n    return embeddings\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Test the extract_features function.\n    \"\"\"\n    input_text = 'def hello_world():\\n    print(\"Hello, world!\")'\n    embeddings = extract_features(input_text)\n    assert embeddings is not None\n    assert embeddings.size(0) > 0\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    print(test_extract_features())", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\n# function_code --------------------\n\ndef extract_features(input_text: str):\n    \"\"\"\n    Extract features from text or code using the pre-trained CodeBERT model.\n\n    Args:\n        input_text (str): The input text or code from which to extract features.\n\n    Returns:\n        torch.Tensor: The extracted features (embeddings) from the input text or code.\n    \"\"\"", "answer": "\n    model = AutoModel.from_pretrained('microsoft/codebert-base')\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')\n    inputs = tokenizer(input_text, return_tensors='pt')\n    outputs = model(**inputs)\n    embeddings = outputs.last_hidden_state\n    return embeddings\n\n", "prediction": "\n\n    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n    model = AutoModel.from_pretrained(\n        \"microsoft/codebert-base\",\n        output_attentions=False,\n        output_hidden_states=False)\n\n    inputs = tokenizer(input_text, return_tensors='pt')\n    outputs = model(**inputs)\n\n    # Extract features from the last layer of the pre-trained transformer model.\n    embeddings = outputs.last_hidden_state[0]  # shape: [12 x hidden_dim]\n    feature_vec = torch.mean(embeddings, dim=0)\n\n    return feature_vec\n"}