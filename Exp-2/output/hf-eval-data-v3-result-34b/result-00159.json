{"path": "output/hf-eval-data-v3-valid/f00644_generate_video_from_text.py", "content": "# function_import --------------------\n\nimport torch\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nfrom diffusers.utils import export_to_video\n\n# function_code --------------------\n\ndef generate_video_from_text(prompt: str, model_name: str = 'damo-vilab/text-to-video-ms-1.7b', num_inference_steps: int = 25) -> str:\n    '''\n    Generate a video from a text description using a pretrained model.\n\n    Args:\n        prompt (str): The text description to generate the video from.\n        model_name (str, optional): The name of the pretrained model to use. Defaults to 'damo-vilab/text-to-video-ms-1.7b'.\n        num_inference_steps (int, optional): The number of inference steps to perform. Defaults to 25.\n\n    Returns:\n        str: The path to the generated video.\n    '''\n    pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch.float16, variant='fp16')\n    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n    pipe.enable_model_cpu_offload()\n\n    video_frames = pipe(prompt, num_inference_steps=num_inference_steps).frames\n    video_path = export_to_video(video_frames)\n\n    return video_path\n\n# test_function_code --------------------\n\ndef test_generate_video_from_text():\n    '''\n    Test the generate_video_from_text function.\n    '''\n    prompts = ['cats playing with laser pointer', 'Spiderman is surfing', 'A dog chasing its tail']\n    for prompt in prompts:\n        video_path = generate_video_from_text(prompt)\n        assert isinstance(video_path, str)\n        assert video_path.endswith('.mp4')\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_generate_video_from_text()", "function_import": "# function_import --------------------\n\nimport torch\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nfrom diffusers.utils import export_to_video\n\n", "function_code": "# function_code --------------------\n\ndef generate_video_from_text(prompt: str, model_name: str = 'damo-vilab/text-to-video-ms-1.7b', num_inference_steps: int = 25) -> str:\n    '''\n    Generate a video from a text description using a pretrained model.\n\n    Args:\n        prompt (str): The text description to generate the video from.\n        model_name (str, optional): The name of the pretrained model to use. Defaults to 'damo-vilab/text-to-video-ms-1.7b'.\n        num_inference_steps (int, optional): The number of inference steps to perform. Defaults to 25.\n\n    Returns:\n        str: The path to the generated video.\n    '''\n    pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch.float16, variant='fp16')\n    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n    pipe.enable_model_cpu_offload()\n\n    video_frames = pipe(prompt, num_inference_steps=num_inference_steps).frames\n    video_path = export_to_video(video_frames)\n\n    return video_path\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_video_from_text():\n    '''\n    Test the generate_video_from_text function.\n    '''\n    prompts = ['cats playing with laser pointer', 'Spiderman is surfing', 'A dog chasing its tail']\n    for prompt in prompts:\n        video_path = generate_video_from_text(prompt)\n        assert isinstance(video_path, str)\n        assert video_path.endswith('.mp4')\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_generate_video_from_text()", "instruct": "# function_import --------------------\n\nimport torch\nfrom diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\nfrom diffusers.utils import export_to_video\n\n# function_code --------------------\n\ndef generate_video_from_text(prompt: str, model_name: str = 'damo-vilab/text-to-video-ms-1.7b', num_inference_steps: int = 25) -> str:\n    '''\n    Generate a video from a text description using a pretrained model.\n\n    Args:\n        prompt (str): The text description to generate the video from.\n        model_name (str, optional): The name of the pretrained model to use. Defaults to 'damo-vilab/text-to-video-ms-1.7b'.\n        num_inference_steps (int, optional): The number of inference steps to perform. Defaults to 25.\n\n    Returns:\n        str: The path to the generated video.\n    '''", "answer": "\n    pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch.float16, variant='fp16')\n    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n    pipe.enable_model_cpu_offload()\n\n    video_frames = pipe(prompt, num_inference_steps=num_inference_steps).frames\n    video_path = export_to_video(video_frames)\n\n    return video_path\n\n", "prediction": "\n    \n    # Initialize model and pipeline\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    schedule = DPMSolverMultistepScheduler(diffusion_steps = num_inference_steps)\n    model = DiffusionPipeline(schedule, device)\n    \n    # Generate video\n    output_video_path = f\"{model.generate_token()}.mp4\"\n    model.load_and_run(output_file=output_video_path, prompt=[prompt], model_name=model_name)\n    \n    return output_video_path"}