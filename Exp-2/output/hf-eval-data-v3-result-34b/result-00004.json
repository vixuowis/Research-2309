{"path": "output/hf-eval-data-v3-valid/f00018_estimate_image_depth.py", "content": "# function_import --------------------\n\nfrom transformers import DPTImageProcessor, DPTForDepthEstimation\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport requests\n\n# function_code --------------------\n\ndef estimate_image_depth(image_url):\n    '''\n    Estimate the depth of an image using a pretrained model from Hugging Face Transformers.\n\n    Args:\n        image_url (str): The URL of the image to be processed.\n\n    Returns:\n        depth (PIL.Image): The depth estimation of the image.\n\n    Raises:\n        requests.exceptions.RequestException: If the image cannot be loaded from the provided URL.\n        RuntimeError: If there is a problem loading the pretrained model.\n    '''\n    image = Image.open(requests.get(image_url, stream=True).raw)\n    processor = DPTImageProcessor.from_pretrained('Intel/dpt-large')\n    model = DPTForDepthEstimation.from_pretrained('Intel/dpt-large')\n    inputs = processor(images=image, return_tensors='pt')\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predicted_depth = outputs.predicted_depth\n    prediction = torch.nn.functional.interpolate(predicted_depth.unsqueeze(1), size=image.size[::-1], mode='bicubic', align_corners=False)\n    output = prediction.squeeze().cpu().numpy()\n    formatted = (output * 255 / np.max(output)).astype('uint8')\n    depth = Image.fromarray(formatted)\n    return depth\n\n# test_function_code --------------------\n\ndef test_estimate_image_depth():\n    '''\n    Test the estimate_image_depth function with different test cases.\n    '''\n    test_image_url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    result = estimate_image_depth(test_image_url)\n    assert isinstance(result, Image.Image), 'The result should be a PIL Image.'\n    test_image_url = 'https://placekitten.com/200/300'\n    result = estimate_image_depth(test_image_url)\n    assert isinstance(result, Image.Image), 'The result should be a PIL Image.'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_estimate_image_depth()", "function_import": "# function_import --------------------\n\nfrom transformers import DPTImageProcessor, DPTForDepthEstimation\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport requests\n\n", "function_code": "# function_code --------------------\n\ndef estimate_image_depth(image_url):\n    '''\n    Estimate the depth of an image using a pretrained model from Hugging Face Transformers.\n\n    Args:\n        image_url (str): The URL of the image to be processed.\n\n    Returns:\n        depth (PIL.Image): The depth estimation of the image.\n\n    Raises:\n        requests.exceptions.RequestException: If the image cannot be loaded from the provided URL.\n        RuntimeError: If there is a problem loading the pretrained model.\n    '''\n    image = Image.open(requests.get(image_url, stream=True).raw)\n    processor = DPTImageProcessor.from_pretrained('Intel/dpt-large')\n    model = DPTForDepthEstimation.from_pretrained('Intel/dpt-large')\n    inputs = processor(images=image, return_tensors='pt')\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predicted_depth = outputs.predicted_depth\n    prediction = torch.nn.functional.interpolate(predicted_depth.unsqueeze(1), size=image.size[::-1], mode='bicubic', align_corners=False)\n    output = prediction.squeeze().cpu().numpy()\n    formatted = (output * 255 / np.max(output)).astype('uint8')\n    depth = Image.fromarray(formatted)\n    return depth\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_estimate_image_depth():\n    '''\n    Test the estimate_image_depth function with different test cases.\n    '''\n    test_image_url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    result = estimate_image_depth(test_image_url)\n    assert isinstance(result, Image.Image), 'The result should be a PIL Image.'\n    test_image_url = 'https://placekitten.com/200/300'\n    result = estimate_image_depth(test_image_url)\n    assert isinstance(result, Image.Image), 'The result should be a PIL Image.'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_estimate_image_depth()", "instruct": "# function_import --------------------\n\nfrom transformers import DPTImageProcessor, DPTForDepthEstimation\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport requests\n\n# function_code --------------------\n\ndef estimate_image_depth(image_url):\n    '''\n    Estimate the depth of an image using a pretrained model from Hugging Face Transformers.\n\n    Args:\n        image_url (str): The URL of the image to be processed.\n\n    Returns:\n        depth (PIL.Image): The depth estimation of the image.\n\n    Raises:\n        requests.exceptions.RequestException: If the image cannot be loaded from the provided URL.\n        RuntimeError: If there is a problem loading the pretrained model.\n    '''", "answer": "\n    image = Image.open(requests.get(image_url, stream=True).raw)\n    processor = DPTImageProcessor.from_pretrained('Intel/dpt-large')\n    model = DPTForDepthEstimation.from_pretrained('Intel/dpt-large')\n    inputs = processor(images=image, return_tensors='pt')\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predicted_depth = outputs.predicted_depth\n    prediction = torch.nn.functional.interpolate(predicted_depth.unsqueeze(1), size=image.size[::-1], mode='bicubic', align_corners=False)\n    output = prediction.squeeze().cpu().numpy()\n    formatted = (output * 255 / np.max(output)).astype('uint8')\n    depth = Image.fromarray(formatted)\n    return depth\n\n", "prediction": "\n    \n    # load the image\n    img = _load_image(image_url)\n    \n    # load the model\n    try: \n        processor, model = _load_model()\n        \n    except RuntimeError as error:\n        return None, 'RuntimeError: Pretrained model could not be loaded.'\n        \n    # prepare the image for inference\n    prepared_img = processor(images=img, \n                             return_tensors='pt')['pixel_values']\n    \n    # get the predicted depth map\n    with torch.no_grad(): \n        prediction = model(prepared_img).logits.cpu().numpy()[0]\n        \n    # post-process the depth map\n    prediction = np.squeeze((prediction - prediction.min()) / (prediction.max() - prediction.min()) * 255)\n    prediction = Image.fromarray(prediction).convert(\"L\")\n    \n    # return a PIL image\n    depth = prediction\n    \n    return depth, None\n\ndef _load_image(image_url):\n    '''Load an image from the URL.'''\n    try: \n        img = Image.open(requests.get(image_url, stream=True).raw)\n        \n    except requests.exceptions.RequestException as error:\n        raise error\n    \n    return img\n\ndef _load_model():\n    '''Load the pretrained model from Hugging Face Transformers.'''\n    try: \n        processor = DPTImageProcessor.from_pretrained(\"Intel/dpt-large\")\n        \n        model = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-large\")\n        \n    except RuntimeError as error:\n        raise error\n    \n    return processor, model"}