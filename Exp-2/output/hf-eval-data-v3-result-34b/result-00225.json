{"path": "output/hf-eval-data-v3-valid/f00858_classify_image.py", "content": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef classify_image(img_url: str):\n    \"\"\"\n    Classify an image using a pretrained CLIP model.\n\n    Args:\n        img_url (str): The URL of the image to classify.\n\n    Returns:\n        dict: A dictionary where keys are labels and values are probabilities.\n    \"\"\"\n    model = CLIPModel.from_pretrained('flax-community/clip-rsicd-v2')\n    processor = CLIPProcessor.from_pretrained('flax-community/clip-rsicd-v2')\n    image = Image.open(requests.get(img_url, stream=True).raw)\n    labels = ['residential area', 'playground', 'stadium', 'forest', 'airport']\n    inputs = processor(text=[f'a photo of a {l}' for l in labels], images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {l: p.item() for l, p in zip(labels, probs[0])}\n\n# test_function_code --------------------\n\ndef test_classify_image():\n    \"\"\"\n    Test the classify_image function.\n    \"\"\"\n    img_url = 'https://placekitten.com/200/300'\n    result = classify_image(img_url)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == set(['residential area', 'playground', 'stadium', 'forest', 'airport'])\n    assert all(0 <= v <= 1 for v in result.values())\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_classify_image()", "function_import": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n", "function_code": "# function_code --------------------\n\ndef classify_image(img_url: str):\n    \"\"\"\n    Classify an image using a pretrained CLIP model.\n\n    Args:\n        img_url (str): The URL of the image to classify.\n\n    Returns:\n        dict: A dictionary where keys are labels and values are probabilities.\n    \"\"\"\n    model = CLIPModel.from_pretrained('flax-community/clip-rsicd-v2')\n    processor = CLIPProcessor.from_pretrained('flax-community/clip-rsicd-v2')\n    image = Image.open(requests.get(img_url, stream=True).raw)\n    labels = ['residential area', 'playground', 'stadium', 'forest', 'airport']\n    inputs = processor(text=[f'a photo of a {l}' for l in labels], images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {l: p.item() for l, p in zip(labels, probs[0])}\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_classify_image():\n    \"\"\"\n    Test the classify_image function.\n    \"\"\"\n    img_url = 'https://placekitten.com/200/300'\n    result = classify_image(img_url)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == set(['residential area', 'playground', 'stadium', 'forest', 'airport'])\n    assert all(0 <= v <= 1 for v in result.values())\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_classify_image()", "instruct": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef classify_image(img_url: str):\n    \"\"\"\n    Classify an image using a pretrained CLIP model.\n\n    Args:\n        img_url (str): The URL of the image to classify.\n\n    Returns:\n        dict: A dictionary where keys are labels and values are probabilities.\n    \"\"\"", "answer": "\n    model = CLIPModel.from_pretrained('flax-community/clip-rsicd-v2')\n    processor = CLIPProcessor.from_pretrained('flax-community/clip-rsicd-v2')\n    image = Image.open(requests.get(img_url, stream=True).raw)\n    labels = ['residential area', 'playground', 'stadium', 'forest', 'airport']\n    inputs = processor(text=[f'a photo of a {l}' for l in labels], images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {l: p.item() for l, p in zip(labels, probs[0])}\n\n", "prediction": "\n    # Download the image from the given URL.\n    r = requests.get(img_url)\n    pil_image = Image.open(BytesIO(r.content))\n    \n    # Load CLIP model and processor.\n    model_name = 'openai/clip-vit-base-patch32'\n    model = CLIPModel.from_pretrained(model_name)\n    processor = CLIPProcessor.from_pretrained(model_name)\n    \n    # Process the image and get labels and scores as a dictionary.\n    inputs = processor(pil_image, return_tensors='pt')\n    outputs = model(**inputs).logits_per_image[0].softmax(-1)\n    score_dict = {label: score for label, score in zip(processor.tokenizer.get_labels(), outputs)}\n    \n    # Remove the null class (scores of which are close to 0) and return the dictionary.\n    return {k: v for k, v in sorted(score_dict.items(), key=lambda item: -item[1]) if k != \"__null__\"}\n"}