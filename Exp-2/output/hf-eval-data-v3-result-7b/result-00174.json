{"path": "output/hf-eval-data-v3-valid/f00704_find_most_related_faq.py", "content": "# function_import --------------------\n\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# function_code --------------------\n\ndef find_most_related_faq(faq_sentences: list, query: str) -> str:\n    \"\"\"\n    Find the most related FAQ for a given customer query using SentenceTransformer.\n\n    Args:\n        faq_sentences (list): A list of FAQ sentences.\n        query (str): A customer query.\n\n    Returns:\n        str: The most related FAQ for the given customer query.\n    \"\"\"\n    model = SentenceTransformer('sentence-transformers/paraphrase-albert-small-v2')\n    embeddings = model.encode(faq_sentences + [query])\n    query_embedding = embeddings[-1]\n    sim_scores = cosine_similarity([query_embedding], embeddings[:-1])\n    most_related_faq_index = sim_scores.argmax()\n    return faq_sentences[most_related_faq_index]\n\n# test_function_code --------------------\n\ndef test_find_most_related_faq():\n    \"\"\"Test the function find_most_related_faq.\"\"\"\n    faq_sentences = [\"FAQ1 text\", \"FAQ2 text\", \"FAQ3 text\"]\n    query = \"Customer query\"\n    assert isinstance(find_most_related_faq(faq_sentences, query), str)\n    faq_sentences = [\"What is your name?\", \"How old are you?\", \"Where are you from?\"]\n    query = \"What's your age?\"\n    assert find_most_related_faq(faq_sentences, query) == \"How old are you?\"\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_find_most_related_faq()", "function_import": "# function_import --------------------\n\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n", "function_code": "# function_code --------------------\n\ndef find_most_related_faq(faq_sentences: list, query: str) -> str:\n    \"\"\"\n    Find the most related FAQ for a given customer query using SentenceTransformer.\n\n    Args:\n        faq_sentences (list): A list of FAQ sentences.\n        query (str): A customer query.\n\n    Returns:\n        str: The most related FAQ for the given customer query.\n    \"\"\"\n    model = SentenceTransformer('sentence-transformers/paraphrase-albert-small-v2')\n    embeddings = model.encode(faq_sentences + [query])\n    query_embedding = embeddings[-1]\n    sim_scores = cosine_similarity([query_embedding], embeddings[:-1])\n    most_related_faq_index = sim_scores.argmax()\n    return faq_sentences[most_related_faq_index]\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_find_most_related_faq():\n    \"\"\"Test the function find_most_related_faq.\"\"\"\n    faq_sentences = [\"FAQ1 text\", \"FAQ2 text\", \"FAQ3 text\"]\n    query = \"Customer query\"\n    assert isinstance(find_most_related_faq(faq_sentences, query), str)\n    faq_sentences = [\"What is your name?\", \"How old are you?\", \"Where are you from?\"]\n    query = \"What's your age?\"\n    assert find_most_related_faq(faq_sentences, query) == \"How old are you?\"\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_find_most_related_faq()", "instruct": "# function_import --------------------\n\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# function_code --------------------\n\ndef find_most_related_faq(faq_sentences: list, query: str) -> str:\n    \"\"\"\n    Find the most related FAQ for a given customer query using SentenceTransformer.\n\n    Args:\n        faq_sentences (list): A list of FAQ sentences.\n        query (str): A customer query.\n\n    Returns:\n        str: The most related FAQ for the given customer query.\n    \"\"\"", "answer": "\n    model = SentenceTransformer('sentence-transformers/paraphrase-albert-small-v2')\n    embeddings = model.encode(faq_sentences + [query])\n    query_embedding = embeddings[-1]\n    sim_scores = cosine_similarity([query_embedding], embeddings[:-1])\n    most_related_faq_index = sim_scores.argmax()\n    return faq_sentences[most_related_faq_index]\n\n", "prediction": "\n    \n    # Preparing data.\n    query = [query] * len(faq_sentences)\n    embeddings1 = model.encode(faq_sentences, convert_to_tensor=True)\n    embeddings2 = model.encode(query, convert_to_tensor=True)\n    \n    # Calculating cosine similarity.\n    cosine_scores = cosine_similarity(embeddings1, embeddings2).flatten()\n        \n    return faq_sentences[cosine_scores.argmax()]\n    \ndef find_most_related_faq_v2(faq_sentences: list, query: str) -> str:\n    \"\"\"\n    Find the most related FAQ for a given customer query using SentenceTransformer and cosine similarity.\n\n    Args:\n        faq_sentences (list): A list of FAQ sentences.\n        query (str): A customer query.\n\n    Returns:\n        str: The most related FAQ for the given customer query.\n    \"\"\"\n    \n    # Preparing data.\n    query = [query] * len(faq_sentences)\n    embeddings1 = model.encode(faq_sentences, convert_to_tensor=True)\n    embeddings2 = model.encode(query, convert_to_tensor=True)\n    \n    return faq_sentences[cosine_scores.argmax()]"}