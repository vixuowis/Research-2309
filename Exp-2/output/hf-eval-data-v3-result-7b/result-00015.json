{"path": "output/hf-eval-data-v3-valid/f00075_transcribe_audio.py", "content": "# function_import --------------------\n\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom datasets import load_dataset\n\n# function_code --------------------\n\ndef transcribe_audio(audio_sample):\n    '''\n    Transcribe audio using the openai/whisper-tiny model.\n\n    Args:\n        audio_sample (dict): A dictionary containing 'array' and 'sampling_rate' of the audio.\n\n    Returns:\n        str: The transcribed text.\n    '''\n    processor = WhisperProcessor.from_pretrained('openai/whisper-tiny')\n    model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny')\n    input_features = processor(audio_sample['array'], sampling_rate=audio_sample['sampling_rate'], return_tensors='pt').input_features\n    predicted_ids = model.generate(input_features)\n    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n    return transcription[0]\n\n# test_function_code --------------------\n\ndef test_transcribe_audio():\n    '''\n    Test the transcribe_audio function.\n    '''\n    ds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split='validation')\n    sample = ds[0]['audio']\n    transcription = transcribe_audio(sample)\n    assert isinstance(transcription, str), 'The result should be a string.'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_transcribe_audio()", "function_import": "# function_import --------------------\n\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom datasets import load_dataset\n\n", "function_code": "# function_code --------------------\n\ndef transcribe_audio(audio_sample):\n    '''\n    Transcribe audio using the openai/whisper-tiny model.\n\n    Args:\n        audio_sample (dict): A dictionary containing 'array' and 'sampling_rate' of the audio.\n\n    Returns:\n        str: The transcribed text.\n    '''\n    processor = WhisperProcessor.from_pretrained('openai/whisper-tiny')\n    model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny')\n    input_features = processor(audio_sample['array'], sampling_rate=audio_sample['sampling_rate'], return_tensors='pt').input_features\n    predicted_ids = model.generate(input_features)\n    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n    return transcription[0]\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_transcribe_audio():\n    '''\n    Test the transcribe_audio function.\n    '''\n    ds = load_dataset('hf-internal-testing/librispeech_asr_dummy', 'clean', split='validation')\n    sample = ds[0]['audio']\n    transcription = transcribe_audio(sample)\n    assert isinstance(transcription, str), 'The result should be a string.'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_transcribe_audio()", "instruct": "# function_import --------------------\n\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom datasets import load_dataset\n\n# function_code --------------------\n\ndef transcribe_audio(audio_sample):\n    '''\n    Transcribe audio using the openai/whisper-tiny model.\n\n    Args:\n        audio_sample (dict): A dictionary containing 'array' and 'sampling_rate' of the audio.\n\n    Returns:\n        str: The transcribed text.\n    '''", "answer": "\n    processor = WhisperProcessor.from_pretrained('openai/whisper-tiny')\n    model = WhisperForConditionalGeneration.from_pretrained('openai/whisper-tiny')\n    input_features = processor(audio_sample['array'], sampling_rate=audio_sample['sampling_rate'], return_tensors='pt').input_features\n    predicted_ids = model.generate(input_features)\n    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n    return transcription[0]\n\n", "prediction": "\n    \n    processor = WhisperProcessor().from_pretrained(\"facebook/whisper-large-10m-en-de\")\n    model = WhisperForConditionalGeneration(processor.feature_extractor, \n                                            processor.tokenizer, \n                                            processor.config).from_pretrained(\"facebook/whisper-large-10m-en-de\")\n    \n    input_audio = processor(audio=audio_sample['array'], sampling_rate=audio_sample['sampling_rate']).input_values\n\n    generated_text = model.generate(input_ids=input_audio)\n\n    text = processor.batch_decode(generated_text, skip_special_tokens=True)[0]\n\n    return text\n\n# function_import --------------------\n\ndataset = load_dataset(\"common_voice\", \"fr\")\n\ndataset['train'].map(lambda audio: {\"transcription\": transcribe_audio({'array': audio[\"audio\"], 'sampling_rate': 16000})})"}