{"path": "output/hf-eval-data-v3-valid/f00796_summarize_diary.py", "content": "# function_import --------------------\n\nfrom transformers import LEDForConditionalGeneration, AutoTokenizer\n\n# function_code --------------------\n\ndef summarize_diary(diary_entry: str) -> str:\n    '''\n    Summarizes a given diary entry using the pre-trained model 'MingZhong/DialogLED-base-16384'.\n\n    Args:\n        diary_entry (str): The diary entry to be summarized.\n\n    Returns:\n        str: The summarized text.\n    '''\n    model = LEDForConditionalGeneration.from_pretrained('MingZhong/DialogLED-base-16384')\n    tokenizer = AutoTokenizer.from_pretrained('MingZhong/DialogLED-base-16384')\n\n    input_tokens = tokenizer(diary_entry, return_tensors='pt')\n    summary_output = model.generate(**input_tokens)\n    summary_text = tokenizer.decode(summary_output[0])\n\n    return summary_text\n\n# test_function_code --------------------\n\ndef test_summarize_diary():\n    '''\n    Tests the function summarize_diary.\n    '''\n    diary_entry1 = 'Today was a great day. I managed to fix the issue with the oxygen generator and had a successful communication session with the ground control.'\n    diary_entry2 = 'I had a tough day today. The solar panels were not working properly and I had to spend the whole day fixing them.'\n    diary_entry3 = 'Today was a normal day. I did my routine checks and everything seems to be working fine.'\n\n    assert len(summarize_diary(diary_entry1)) > 0\n    assert len(summarize_diary(diary_entry2)) > 0\n    assert len(summarize_diary(diary_entry3)) > 0\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_summarize_diary()", "function_import": "# function_import --------------------\n\nfrom transformers import LEDForConditionalGeneration, AutoTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef summarize_diary(diary_entry: str) -> str:\n    '''\n    Summarizes a given diary entry using the pre-trained model 'MingZhong/DialogLED-base-16384'.\n\n    Args:\n        diary_entry (str): The diary entry to be summarized.\n\n    Returns:\n        str: The summarized text.\n    '''\n    model = LEDForConditionalGeneration.from_pretrained('MingZhong/DialogLED-base-16384')\n    tokenizer = AutoTokenizer.from_pretrained('MingZhong/DialogLED-base-16384')\n\n    input_tokens = tokenizer(diary_entry, return_tensors='pt')\n    summary_output = model.generate(**input_tokens)\n    summary_text = tokenizer.decode(summary_output[0])\n\n    return summary_text\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_summarize_diary():\n    '''\n    Tests the function summarize_diary.\n    '''\n    diary_entry1 = 'Today was a great day. I managed to fix the issue with the oxygen generator and had a successful communication session with the ground control.'\n    diary_entry2 = 'I had a tough day today. The solar panels were not working properly and I had to spend the whole day fixing them.'\n    diary_entry3 = 'Today was a normal day. I did my routine checks and everything seems to be working fine.'\n\n    assert len(summarize_diary(diary_entry1)) > 0\n    assert len(summarize_diary(diary_entry2)) > 0\n    assert len(summarize_diary(diary_entry3)) > 0\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_summarize_diary()", "instruct": "# function_import --------------------\n\nfrom transformers import LEDForConditionalGeneration, AutoTokenizer\n\n# function_code --------------------\n\ndef summarize_diary(diary_entry: str) -> str:\n    '''\n    Summarizes a given diary entry using the pre-trained model 'MingZhong/DialogLED-base-16384'.\n\n    Args:\n        diary_entry (str): The diary entry to be summarized.\n\n    Returns:\n        str: The summarized text.\n    '''", "answer": "\n    model = LEDForConditionalGeneration.from_pretrained('MingZhong/DialogLED-base-16384')\n    tokenizer = AutoTokenizer.from_pretrained('MingZhong/DialogLED-base-16384')\n\n    input_tokens = tokenizer(diary_entry, return_tensors='pt')\n    summary_output = model.generate(**input_tokens)\n    summary_text = tokenizer.decode(summary_output[0])\n\n    return summary_text\n\n", "prediction": "\n    \n    # Preprocess text into input format for LED model.\n    tokenizer = AutoTokenizer.from_pretrained('MingZhong/DialogLED-base-16384')\n    inputs = tokenizer(diary_entry, return_tensors='pt')\n    \n    # Load pre-trained model for summarization.\n    model = LEDForConditionalGeneration.from_pretrained('MingZhong/DialogLED-base-16384')\n    \n    # Generate summary using pre-trained model and return it as a string.\n    summary_ids = model.generate(inputs['input_ids'], \n                                num_beams=4, \n                                max_length=50)\n    return tokenizer.batch_decode(summary_ids, skip_special_tokens=True)[0]"}