{"path": "output/hf-eval-data-v3-valid/f00380_detect_gpt2_generated_text.py", "content": "# function_import --------------------\n\nfrom transformers import pipeline\n\n# function_code --------------------\n\ndef detect_gpt2_generated_text(text):\n    \"\"\"\n    Detect if the given text is generated by GPT-2 model.\n\n    Args:\n        text (str): The text to be checked.\n\n    Returns:\n        dict: The prediction result, indicating whether the text was generated by GPT-2 or not.\n    \"\"\"\n    pipe = pipeline('text-classification', model='roberta-base-openai-detector')\n    prediction = pipe(text)\n    return prediction\n\n# test_function_code --------------------\n\ndef test_detect_gpt2_generated_text():\n    \"\"\"\n    Test the function detect_gpt2_generated_text.\n    \"\"\"\n    # Test case 1: AI-generated text\n    text1 = 'In a shocking turn of events, the city council has decided to turn the entire city into a giant amusement park.'\n    prediction1 = detect_gpt2_generated_text(text1)\n    assert isinstance(prediction1, list), 'The result should be a list.'\n\n    # Test case 2: Human-written text\n    text2 = 'Hello world! This is a test.'\n    prediction2 = detect_gpt2_generated_text(text2)\n    assert isinstance(prediction2, list), 'The result should be a list.'\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_detect_gpt2_generated_text()", "function_import": "# function_import --------------------\n\nfrom transformers import pipeline\n\n", "function_code": "# function_code --------------------\n\ndef detect_gpt2_generated_text(text):\n    \"\"\"\n    Detect if the given text is generated by GPT-2 model.\n\n    Args:\n        text (str): The text to be checked.\n\n    Returns:\n        dict: The prediction result, indicating whether the text was generated by GPT-2 or not.\n    \"\"\"\n    pipe = pipeline('text-classification', model='roberta-base-openai-detector')\n    prediction = pipe(text)\n    return prediction\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_detect_gpt2_generated_text():\n    \"\"\"\n    Test the function detect_gpt2_generated_text.\n    \"\"\"\n    # Test case 1: AI-generated text\n    text1 = 'In a shocking turn of events, the city council has decided to turn the entire city into a giant amusement park.'\n    prediction1 = detect_gpt2_generated_text(text1)\n    assert isinstance(prediction1, list), 'The result should be a list.'\n\n    # Test case 2: Human-written text\n    text2 = 'Hello world! This is a test.'\n    prediction2 = detect_gpt2_generated_text(text2)\n    assert isinstance(prediction2, list), 'The result should be a list.'\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_detect_gpt2_generated_text()", "instruct": "# function_import --------------------\n\nfrom transformers import pipeline\n\n# function_code --------------------\n\ndef detect_gpt2_generated_text(text):\n    \"\"\"\n    Detect if the given text is generated by GPT-2 model.\n\n    Args:\n        text (str): The text to be checked.\n\n    Returns:\n        dict: The prediction result, indicating whether the text was generated by GPT-2 or not.\n    \"\"\"", "answer": "\n    pipe = pipeline('text-classification', model='roberta-base-openai-detector')\n    prediction = pipe(text)\n    return prediction\n\n", "prediction": "\n    \n    # Setup the pipeline and predict\n    summarizer = pipeline(\"summarization\")\n    predict_result = summarizer(text)\n    \n    # Detect if the given text is generated by GPT-2 model\n    gpt2_generated = False\n    for pred in predict_result:\n        if pred[\"summary_text\"] == text or len(pred[\"summary_text\"].split()) <= 5:\n            continue\n        \n        # Get the ratio of overlapping words with reference text\n        overlap_ratio = get_overlap_ratio(text, pred[\"summary_text\"])\n        \n        # Update gpt2_generated\n        if overlap_ratio > 0.5:\n            gpt2_generated = True\n    \n    return {\"generated\": gpt2_generated}\n\ndef get_overlap_ratio(text, summary):\n    \"\"\"\n    Get the ratio of overlapping words with reference text and generated summary.\n\n    Args:\n        text (str): The reference text to be checked.\n        summary (str): The generated summary.\n    \n    Returns:\n        float: The ratio of overlapping words with reference text.\n    \"\"\"\n    \n    # Get word list from text and summary\n    text_list = [word.lower() for word in re.sub(r\"\\W+\", \" \", text).split() if len(word) > 1]\n    summary_list = [word.lower() for word in re.sub(r\"\\W+\", \" \", summary).split() if len(word) > 1]\n    \n    # Get overlapping count between two word lists\n    text_count, summary_count = 0, 0\n    for w in text_list:\n        if w in summary_list:\n            text_count += 1\n    for w in summary_list:\n        if w in text_list:\n            summary_count += 1\n    \n    # Get overlap ratio\n    return max(text_count / len(text_list), summary_count / len(summary_list))\n"}