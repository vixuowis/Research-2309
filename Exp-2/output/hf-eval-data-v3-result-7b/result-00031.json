{"path": "output/hf-eval-data-v3-valid/f00139_summarize_news.py", "content": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# function_code --------------------\n\ndef summarize_news(article_text: str, model_name: str = 'csebuetnlp/mT5_multilingual_XLSum') -> str:\n    \"\"\"\n    Summarize a news article using a pre-trained model from the transformers library.\n\n    Args:\n        article_text (str): The text of the news article to be summarized.\n        model_name (str, optional): The name of the pre-trained model to use. Defaults to 'csebuetnlp/mT5_multilingual_XLSum'.\n\n    Returns:\n        str: The summarized text.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n    input_ids = tokenizer.encode(article_text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n    output_ids = model.generate(input_ids, max_length=84, no_repeat_ngram_size=2, num_beams=4)\n    summary = tokenizer.decode(output_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n\n    return summary\n\n# test_function_code --------------------\n\ndef test_summarize_news():\n    \"\"\"\n    Test the summarize_news function.\n    \"\"\"\n    article_text = 'International news article text here...'\n    summary = summarize_news(article_text)\n    assert isinstance(summary, str), 'The output should be a string.'\n    assert len(summary) > 0, 'The output should not be empty.'\n\n    article_text = 'Another international news article text here...'\n    summary = summarize_news(article_text)\n    assert isinstance(summary, str), 'The output should be a string.'\n    assert len(summary) > 0, 'The output should not be empty.'\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_summarize_news()", "function_import": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n", "function_code": "# function_code --------------------\n\ndef summarize_news(article_text: str, model_name: str = 'csebuetnlp/mT5_multilingual_XLSum') -> str:\n    \"\"\"\n    Summarize a news article using a pre-trained model from the transformers library.\n\n    Args:\n        article_text (str): The text of the news article to be summarized.\n        model_name (str, optional): The name of the pre-trained model to use. Defaults to 'csebuetnlp/mT5_multilingual_XLSum'.\n\n    Returns:\n        str: The summarized text.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n    input_ids = tokenizer.encode(article_text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n    output_ids = model.generate(input_ids, max_length=84, no_repeat_ngram_size=2, num_beams=4)\n    summary = tokenizer.decode(output_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n\n    return summary\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_summarize_news():\n    \"\"\"\n    Test the summarize_news function.\n    \"\"\"\n    article_text = 'International news article text here...'\n    summary = summarize_news(article_text)\n    assert isinstance(summary, str), 'The output should be a string.'\n    assert len(summary) > 0, 'The output should not be empty.'\n\n    article_text = 'Another international news article text here...'\n    summary = summarize_news(article_text)\n    assert isinstance(summary, str), 'The output should be a string.'\n    assert len(summary) > 0, 'The output should not be empty.'\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_summarize_news()", "instruct": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# function_code --------------------\n\ndef summarize_news(article_text: str, model_name: str = 'csebuetnlp/mT5_multilingual_XLSum') -> str:\n    \"\"\"\n    Summarize a news article using a pre-trained model from the transformers library.\n\n    Args:\n        article_text (str): The text of the news article to be summarized.\n        model_name (str, optional): The name of the pre-trained model to use. Defaults to 'csebuetnlp/mT5_multilingual_XLSum'.\n\n    Returns:\n        str: The summarized text.\n    \"\"\"", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n    input_ids = tokenizer.encode(article_text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n    output_ids = model.generate(input_ids, max_length=84, no_repeat_ngram_size=2, num_beams=4)\n    summary = tokenizer.decode(output_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n\n    return summary\n\n", "prediction": "    \n    # initialize tokenizer and model\n    print('Initializing model...')\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n    # encode text for summarization\n    print('Summarizing text...')\n    input_ids = tokenizer(article_text, return_tensors=\"pt\").input_ids \n\n    # get summary\n    summary_ids = model.generate(input_ids)[0]  \n    output = tokenizer.decode(summary_ids, skip_special_tokens=True)\n    \n    return output"}