{"path": "output/hf-eval-data-v3-valid/f00687_classify_text.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# function_code --------------------\n\ndef classify_text(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification.\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"\n    nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    probs_list = []\n    for label in candidate_labels:\n        hypothesis = f'This example is {label}.'\n        inputs = tokenizer(sequence, hypothesis, return_tensors='pt', truncation=True)\n        logits = nli_model(**inputs)[0]\n        entail_contradiction_logits = logits[:, [0, 2]]\n        probs = entail_contradiction_logits.softmax(dim=1)\n        prob_label_is_true = probs[:, 1].item()\n        probs_list.append(prob_label_is_true)\n\n    category_index = probs_list.index(max(probs_list))\n    return candidate_labels[category_index]\n\n# test_function_code --------------------\n\ndef test_classify_text():\n    \"\"\"\n    Test the classify_text function.\n    \"\"\"\n    text_message = 'I spent hours in the kitchen trying a new recipe.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I am planning a trip to Paris.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I love to dance salsa.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_classify_text()", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n", "function_code": "# function_code --------------------\n\ndef classify_text(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification.\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"\n    nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    probs_list = []\n    for label in candidate_labels:\n        hypothesis = f'This example is {label}.'\n        inputs = tokenizer(sequence, hypothesis, return_tensors='pt', truncation=True)\n        logits = nli_model(**inputs)[0]\n        entail_contradiction_logits = logits[:, [0, 2]]\n        probs = entail_contradiction_logits.softmax(dim=1)\n        prob_label_is_true = probs[:, 1].item()\n        probs_list.append(prob_label_is_true)\n\n    category_index = probs_list.index(max(probs_list))\n    return candidate_labels[category_index]\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_classify_text():\n    \"\"\"\n    Test the classify_text function.\n    \"\"\"\n    text_message = 'I spent hours in the kitchen trying a new recipe.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I am planning a trip to Paris.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    text_message = 'I love to dance salsa.'\n    categories = ['travel', 'cooking', 'dancing']\n    result = classify_text(text_message, categories)\n    assert result in categories\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_classify_text()", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# function_code --------------------\n\ndef classify_text(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification.\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"", "answer": "\n    nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n    tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n\n    probs_list = []\n    for label in candidate_labels:\n        hypothesis = f'This example is {label}.'\n        inputs = tokenizer(sequence, hypothesis, return_tensors='pt', truncation=True)\n        logits = nli_model(**inputs)[0]\n        entail_contradiction_logits = logits[:, [0, 2]]\n        probs = entail_contradiction_logits.softmax(dim=1)\n        prob_label_is_true = probs[:, 1].item()\n        probs_list.append(prob_label_is_true)\n\n    category_index = probs_list.index(max(probs_list))\n    return candidate_labels[category_index]\n\n", "prediction": "\n    \n    # Load pretrained model and tokenizer\n    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(candidate_labels))\n    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n    # Prepare inputs for model (last hidden state)\n    encoded_input = tokenizer.encode_plus(sequence, None, return_tensors=\"pt\", add_special_tokens=True)\n    input_ids, attention_masks = encoded_input[\"input_ids\"], encoded_input[\"attention_mask\"]\n\n    # Compute prediction\n    with torch.no_grad():\n        logits = model(input_ids, attention_masks)[0]\n    \n    # Obtain probability distribution\n    probabilities = softmax(logits)\n\n    return candidate_labels[probabilities.argmax()]\n\ndef classify_text_multi(sequence: str, candidate_labels: list):\n    \"\"\"\n    Classify a text sequence into one of the candidate labels using zero-shot classification (for multi-label problems).\n\n    Args:\n        sequence (str): The text sequence to classify.\n        candidate_labels (list): A list of candidate labels.\n\n    Returns:\n        str: The label that the sequence is classified into.\n    \"\"\"\n    \n    # Load pretrained model and tokenizer\n    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(candidate_labels))\n    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n    # Prepare inputs for model (last hidden state)\n    encoded_input = tokenizer.encode_plus(sequence, None, return_tensors=\"pt\", add_special_tokens=True)\n    input_ids, attention_masks = encoded_input[\"input_ids\"], encoded_input[\"attention_mask\"]\n    \n    # Compute prediction for each candidate label (independent predictions)\n    with torch.no_grad():\n        logits"}