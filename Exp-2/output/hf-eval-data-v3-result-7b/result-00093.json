{"path": "output/hf-eval-data-v3-valid/f00410_generate_queries.py", "content": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# function_code --------------------\n\ndef generate_queries(document: str) -> str:\n    '''\n    Generate possible user queries for a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The input document for which to generate queries.\n\n    Returns:\n        str: The generated queries.\n\n    Raises:\n        ValueError: If the input document is not a string.\n    '''\n    if not isinstance(document, str):\n        raise ValueError('Input document must be a string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    input_ids = tokenizer.encode(document, return_tensors='pt')\n    generated_ids = model.generate(input_ids)\n    generated_queries = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    return generated_queries\n\n# test_function_code --------------------\n\ndef test_generate_queries():\n    '''\n    Test the generate_queries function.\n    '''\n    document1 = 'This is a test document.'\n    document2 = 'Another test document.'\n    document3 = 123\n\n    assert isinstance(generate_queries(document1), str)\n    assert isinstance(generate_queries(document2), str)\n    try:\n        generate_queries(document3)\n    except ValueError:\n        pass\n    else:\n        raise AssertionError('ValueError not raised for non-string input.')\n\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\ntest_generate_queries()", "function_import": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n", "function_code": "# function_code --------------------\n\ndef generate_queries(document: str) -> str:\n    '''\n    Generate possible user queries for a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The input document for which to generate queries.\n\n    Returns:\n        str: The generated queries.\n\n    Raises:\n        ValueError: If the input document is not a string.\n    '''\n    if not isinstance(document, str):\n        raise ValueError('Input document must be a string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    input_ids = tokenizer.encode(document, return_tensors='pt')\n    generated_ids = model.generate(input_ids)\n    generated_queries = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    return generated_queries\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_queries():\n    '''\n    Test the generate_queries function.\n    '''\n    document1 = 'This is a test document.'\n    document2 = 'Another test document.'\n    document3 = 123\n\n    assert isinstance(generate_queries(document1), str)\n    assert isinstance(generate_queries(document2), str)\n    try:\n        generate_queries(document3)\n    except ValueError:\n        pass\n    else:\n        raise AssertionError('ValueError not raised for non-string input.')\n\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_generate_queries()", "instruct": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# function_code --------------------\n\ndef generate_queries(document: str) -> str:\n    '''\n    Generate possible user queries for a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The input document for which to generate queries.\n\n    Returns:\n        str: The generated queries.\n\n    Raises:\n        ValueError: If the input document is not a string.\n    '''", "answer": "\n    if not isinstance(document, str):\n        raise ValueError('Input document must be a string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    input_ids = tokenizer.encode(document, return_tensors='pt')\n    generated_ids = model.generate(input_ids)\n    generated_queries = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n    return generated_queries\n\n", "prediction": "\n\n    if not isinstance(document, str):\n        raise ValueError('The given document must be of type string!')\n\n    document = ' '.join([token.text for token in nlp(document)]) # Tokenize and join tokens\n    \n    # Create query generation prompt from document\n    query_generation_prompt = f'generate possible queries for the following text: {document}'\n    \n    # Generate query using the pre-trained model\n    model.generate(inputs=query_generation_prompt)\n\n"}