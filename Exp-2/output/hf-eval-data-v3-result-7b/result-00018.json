{"path": "output/hf-eval-data-v3-valid/f00088_calculate_carbon_emissions.py", "content": "# function_import --------------------\n\nimport joblib\nimport pandas as pd\nimport json\nimport numpy as np\n\n# function_code --------------------\n\ndef calculate_carbon_emissions(data_file):\n    \"\"\"\n    Calculate the carbon emissions for given data.\n\n    Args:\n        data_file (str): The path to the input data file in CSV format.\n\n    Returns:\n        numpy.ndarray: The predicted carbon emissions.\n\n    Raises:\n        FileNotFoundError: If the model or config file does not exist.\n        pd.errors.EmptyDataError: If the data file is empty.\n    \"\"\"\n    model = joblib.load('model.joblib')\n    config = json.load(open('config.json'))\n    features = config['features']\n\n    data = pd.read_csv(data_file)\n    data = data[features]\n    data.columns = ['feat_' + str(col) for col in data.columns]\n\n    predictions = model.predict(data)\n    return predictions\n\n# test_function_code --------------------\n\ndef test_calculate_carbon_emissions():\n    \"\"\"Test the calculate_carbon_emissions function.\"\"\"\n    data_file = 'test_data.csv'\n    try:\n        predictions = calculate_carbon_emissions(data_file)\n        assert isinstance(predictions, np.ndarray), 'The result should be a numpy array.'\n        assert predictions.shape[0] > 0, 'The result should not be empty.'\n    except FileNotFoundError:\n        print('The model or config file does not exist.')\n    except pd.errors.EmptyDataError:\n        print('The data file is empty.')\n    else:\n        print('All tests passed.')\n\n# call_test_function_code --------------------\n\ntest_calculate_carbon_emissions()", "function_import": "# function_import --------------------\n\nimport joblib\nimport pandas as pd\nimport json\nimport numpy as np\n\n", "function_code": "# function_code --------------------\n\ndef calculate_carbon_emissions(data_file):\n    \"\"\"\n    Calculate the carbon emissions for given data.\n\n    Args:\n        data_file (str): The path to the input data file in CSV format.\n\n    Returns:\n        numpy.ndarray: The predicted carbon emissions.\n\n    Raises:\n        FileNotFoundError: If the model or config file does not exist.\n        pd.errors.EmptyDataError: If the data file is empty.\n    \"\"\"\n    model = joblib.load('model.joblib')\n    config = json.load(open('config.json'))\n    features = config['features']\n\n    data = pd.read_csv(data_file)\n    data = data[features]\n    data.columns = ['feat_' + str(col) for col in data.columns]\n\n    predictions = model.predict(data)\n    return predictions\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_calculate_carbon_emissions():\n    \"\"\"Test the calculate_carbon_emissions function.\"\"\"\n    data_file = 'test_data.csv'\n    try:\n        predictions = calculate_carbon_emissions(data_file)\n        assert isinstance(predictions, np.ndarray), 'The result should be a numpy array.'\n        assert predictions.shape[0] > 0, 'The result should not be empty.'\n    except FileNotFoundError:\n        print('The model or config file does not exist.')\n    except pd.errors.EmptyDataError:\n        print('The data file is empty.')\n    else:\n        print('All tests passed.')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_calculate_carbon_emissions()", "instruct": "# function_import --------------------\n\nimport joblib\nimport pandas as pd\nimport json\nimport numpy as np\n\n# function_code --------------------\n\ndef calculate_carbon_emissions(data_file):\n    \"\"\"\n    Calculate the carbon emissions for given data.\n\n    Args:\n        data_file (str): The path to the input data file in CSV format.\n\n    Returns:\n        numpy.ndarray: The predicted carbon emissions.\n\n    Raises:\n        FileNotFoundError: If the model or config file does not exist.\n        pd.errors.EmptyDataError: If the data file is empty.\n    \"\"\"", "answer": "\n    model = joblib.load('model.joblib')\n    config = json.load(open('config.json'))\n    features = config['features']\n\n    data = pd.read_csv(data_file)\n    data = data[features]\n    data.columns = ['feat_' + str(col) for col in data.columns]\n\n    predictions = model.predict(data)\n    return predictions\n\n", "prediction": "\n    \n    # load the trained model\n    model = joblib.load('data/model.pkl')\n    \n    # load the feature mappings\n    feature_mappings = json.loads(open(\"data/feature_names.json\", \"r\").read()) \n    \n    # read the input data into a pandas dataframe\n    df = pd.read_csv(data_file)\n    \n    if df.empty:\n        raise pd.errors.EmptyDataError('Input file is empty')\n        \n    features = [x for x in list(df)]\n    \n    # check the feature names to see whether they match with those used\n    # during training, raise an exception otherwise\n    \n    if len(features) != len(feature_mappings):\n        raise Exception('Mismatch between number of features')\n        \n    for x in range(len(features)):\n        if feature_mappings[x]['feature'] != features[x]:\n            raise Exception('Feature name mismatch: {} vs. {}'.format(\\\n                            feature_mappings[x]['feature'], features[x]))\n    \n    # remove the index columns and drop rows with null values\n    df = df.drop(columns=['Unnamed: 0'])\n    df = df.fillna(0)\n        \n    # get the data in numpy format, ready for inference\n    X = []\n    for feature_set in list(df):\n        X.append(list(df[feature_set].values))\n    \n    X = np.array(X).reshape((1, -1)).astype('float')\n        \n    # apply the same preprocessing steps as during training\n    X = (X - model['mean']) / model['std']\n    \n    return model['scaler'].transform(model['pipeline'].predict(X))"}