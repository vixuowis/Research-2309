{"path": "output/hf-eval-data-v3-valid/f00307_generate_code.py", "content": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# function_code --------------------\n\ndef generate_code(text):\n    \"\"\"\n    Generate executable code based on the input prompt using Hugging Face Transformers.\n\n    Args:\n        text (str): The input prompt in English.\n\n    Returns:\n        str: The generated executable code.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-350M-multi')\n    model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-350M-multi')\n    input_ids = tokenizer(text, return_tensors='pt').input_ids\n    generated_ids = model.generate(input_ids, max_length=128)\n    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n# test_function_code --------------------\n\ndef test_generate_code():\n    \"\"\"\n    Test the function generate_code.\n    \"\"\"\n    assert generate_code('Create a simple loading spinner for maintenance.') is not None\n    assert generate_code('Create a function to add two numbers.') is not None\n    assert generate_code('Create a function to calculate the factorial of a number.') is not None\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_generate_code()", "function_import": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n", "function_code": "# function_code --------------------\n\ndef generate_code(text):\n    \"\"\"\n    Generate executable code based on the input prompt using Hugging Face Transformers.\n\n    Args:\n        text (str): The input prompt in English.\n\n    Returns:\n        str: The generated executable code.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-350M-multi')\n    model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-350M-multi')\n    input_ids = tokenizer(text, return_tensors='pt').input_ids\n    generated_ids = model.generate(input_ids, max_length=128)\n    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_code():\n    \"\"\"\n    Test the function generate_code.\n    \"\"\"\n    assert generate_code('Create a simple loading spinner for maintenance.') is not None\n    assert generate_code('Create a function to add two numbers.') is not None\n    assert generate_code('Create a function to calculate the factorial of a number.') is not None\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_generate_code()", "instruct": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# function_code --------------------\n\ndef generate_code(text):\n    \"\"\"\n    Generate executable code based on the input prompt using Hugging Face Transformers.\n\n    Args:\n        text (str): The input prompt in English.\n\n    Returns:\n        str: The generated executable code.\n    \"\"\"", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-350M-multi')\n    model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-350M-multi')\n    input_ids = tokenizer(text, return_tensors='pt').input_ids\n    generated_ids = model.generate(input_ids, max_length=128)\n    return tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n\n", "prediction": "    \n    tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n    model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n\n    input_ids = tokenizer(f\"{text} <|endoftext|>\", return_tensors=\"pt\").input_ids\n    \n    outputs = model.generate(input_ids, do_sample=True, top_k=50)\n\n    return tokenizer.decode(outputs[0])"}