{"path": "output/hf-eval-data-v3-valid/f00700_translate_hindi_to_french.py", "content": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_hindi_to_french(message):\n    \"\"\"\n    Translates a message from Hindi to French using the Hugging Face's MBartForConditionalGeneration model.\n\n    Args:\n        message (str): The message in Hindi to be translated.\n\n    Returns:\n        str: The translated message in French.\n    \"\"\"\n    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer.src_lang = 'hi_IN'\n    encoded_hi = tokenizer(message, return_tensors='pt')\n    generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.lang_code_to_id['fr_XX'])\n    translated_message = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n    return translated_message\n\n# test_function_code --------------------\n\ndef test_translate_hindi_to_french():\n    \"\"\"\n    Tests the translate_hindi_to_french function with some example messages.\n    \"\"\"\n    message1 = '\u0906\u092a\u0915\u0940 \u092a\u094d\u0930\u0947\u091c\u093c\u091f\u0947\u0936\u0928 \u0915\u093e \u0906\u0927\u093e\u0930 \u0905\u091a\u094d\u091b\u093e \u0925\u093e, \u0932\u0947\u0915\u093f\u0928 \u0921\u0947\u091f\u093e \u0935\u093f\u0936\u094d\u0932\u0947\u0937\u0923 \u092a\u0930 \u0927\u094d\u092f\u093e\u0928 \u0926\u0947\u0928\u093e \u091a\u093e\u0939\u093f\u090f\u0964'\n    message2 = '\u092e\u0948\u0902 \u0906\u092a\u0915\u0947 \u0938\u0941\u091d\u093e\u0935 \u092a\u0930 \u0935\u093f\u091a\u093e\u0930 \u0915\u0930\u0942\u0902\u0917\u093e\u0964'\n    message3 = '\u092f\u0939 \u090f\u0915 \u0909\u0924\u094d\u0915\u0943\u0937\u094d\u091f \u092a\u094d\u0930\u0926\u0930\u094d\u0936\u0928 \u0925\u093e\u0964'\n    assert isinstance(translate_hindi_to_french(message1), str)\n    assert isinstance(translate_hindi_to_french(message2), str)\n    assert isinstance(translate_hindi_to_french(message3), str)\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\ntest_translate_hindi_to_french()", "function_import": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n", "function_code": "# function_code --------------------\n\ndef translate_hindi_to_french(message):\n    \"\"\"\n    Translates a message from Hindi to French using the Hugging Face's MBartForConditionalGeneration model.\n\n    Args:\n        message (str): The message in Hindi to be translated.\n\n    Returns:\n        str: The translated message in French.\n    \"\"\"\n    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer.src_lang = 'hi_IN'\n    encoded_hi = tokenizer(message, return_tensors='pt')\n    generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.lang_code_to_id['fr_XX'])\n    translated_message = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n    return translated_message\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_translate_hindi_to_french():\n    \"\"\"\n    Tests the translate_hindi_to_french function with some example messages.\n    \"\"\"\n    message1 = '\u0906\u092a\u0915\u0940 \u092a\u094d\u0930\u0947\u091c\u093c\u091f\u0947\u0936\u0928 \u0915\u093e \u0906\u0927\u093e\u0930 \u0905\u091a\u094d\u091b\u093e \u0925\u093e, \u0932\u0947\u0915\u093f\u0928 \u0921\u0947\u091f\u093e \u0935\u093f\u0936\u094d\u0932\u0947\u0937\u0923 \u092a\u0930 \u0927\u094d\u092f\u093e\u0928 \u0926\u0947\u0928\u093e \u091a\u093e\u0939\u093f\u090f\u0964'\n    message2 = '\u092e\u0948\u0902 \u0906\u092a\u0915\u0947 \u0938\u0941\u091d\u093e\u0935 \u092a\u0930 \u0935\u093f\u091a\u093e\u0930 \u0915\u0930\u0942\u0902\u0917\u093e\u0964'\n    message3 = '\u092f\u0939 \u090f\u0915 \u0909\u0924\u094d\u0915\u0943\u0937\u094d\u091f \u092a\u094d\u0930\u0926\u0930\u094d\u0936\u0928 \u0925\u093e\u0964'\n    assert isinstance(translate_hindi_to_french(message1), str)\n    assert isinstance(translate_hindi_to_french(message2), str)\n    assert isinstance(translate_hindi_to_french(message3), str)\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_translate_hindi_to_french()", "instruct": "# function_import --------------------\n\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n\n# function_code --------------------\n\ndef translate_hindi_to_french(message):\n    \"\"\"\n    Translates a message from Hindi to French using the Hugging Face's MBartForConditionalGeneration model.\n\n    Args:\n        message (str): The message in Hindi to be translated.\n\n    Returns:\n        str: The translated message in French.\n    \"\"\"", "answer": "\n    model = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n    tokenizer.src_lang = 'hi_IN'\n    encoded_hi = tokenizer(message, return_tensors='pt')\n    generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.lang_code_to_id['fr_XX'])\n    translated_message = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n    return translated_message\n\n", "prediction": "    \n    tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n    model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n    \n    inputs = tokenizer([message], return_tensors=\"pt\", padding=True)\n\n    translated = model.generate(inputs[\"input_ids\"])\n    tgt_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n    \n    return tgt_text[0]"}