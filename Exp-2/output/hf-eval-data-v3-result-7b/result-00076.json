{"path": "output/hf-eval-data-v3-valid/f00310_generate_query.py", "content": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# function_code --------------------\n\ndef generate_query(document):\n    \"\"\"\n    Generate a query from a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The document from which to generate the query.\n\n    Returns:\n        str: The generated query.\n\n    Raises:\n        ValueError: If the document is not a string or is empty.\n    \"\"\"\n    if not isinstance(document, str) or not document:\n        raise ValueError('Document must be a non-empty string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    inputs = tokenizer.encode('generate query: ' + document, return_tensors='pt', max_length=512, truncation=True)\n    outputs = model.generate(inputs, num_return_sequences=1, max_length=40)\n\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# test_function_code --------------------\n\ndef test_generate_query():\n    \"\"\"\n    Test the generate_query function.\n    \"\"\"\n    # Test with a valid document\n    document = 'This is a test document.'\n    query = generate_query(document)\n    assert isinstance(query, str), 'Query must be a string.'\n\n    # Test with an empty document\n    try:\n        generate_query('')\n    except ValueError as e:\n        assert str(e) == 'Document must be a non-empty string.', 'Exception message must be correct.'\n\n    # Test with a non-string document\n    try:\n        generate_query(None)\n    except ValueError as e:\n        assert str(e) == 'Document must be a non-empty string.', 'Exception message must be correct.'\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_generate_query()", "function_import": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n", "function_code": "# function_code --------------------\n\ndef generate_query(document):\n    \"\"\"\n    Generate a query from a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The document from which to generate the query.\n\n    Returns:\n        str: The generated query.\n\n    Raises:\n        ValueError: If the document is not a string or is empty.\n    \"\"\"\n    if not isinstance(document, str) or not document:\n        raise ValueError('Document must be a non-empty string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    inputs = tokenizer.encode('generate query: ' + document, return_tensors='pt', max_length=512, truncation=True)\n    outputs = model.generate(inputs, num_return_sequences=1, max_length=40)\n\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_query():\n    \"\"\"\n    Test the generate_query function.\n    \"\"\"\n    # Test with a valid document\n    document = 'This is a test document.'\n    query = generate_query(document)\n    assert isinstance(query, str), 'Query must be a string.'\n\n    # Test with an empty document\n    try:\n        generate_query('')\n    except ValueError as e:\n        assert str(e) == 'Document must be a non-empty string.', 'Exception message must be correct.'\n\n    # Test with a non-string document\n    try:\n        generate_query(None)\n    except ValueError as e:\n        assert str(e) == 'Document must be a non-empty string.', 'Exception message must be correct.'\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_generate_query()", "instruct": "# function_import --------------------\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\n# function_code --------------------\n\ndef generate_query(document):\n    \"\"\"\n    Generate a query from a given document using a pre-trained T5 model.\n\n    Args:\n        document (str): The document from which to generate the query.\n\n    Returns:\n        str: The generated query.\n\n    Raises:\n        ValueError: If the document is not a string or is empty.\n    \"\"\"", "answer": "\n    if not isinstance(document, str) or not document:\n        raise ValueError('Document must be a non-empty string.')\n\n    tokenizer = T5Tokenizer.from_pretrained('castorini/doc2query-t5-base-msmarco')\n    model = T5ForConditionalGeneration.from_pretrained('castorini/doc2query-t5-base-msmarco')\n\n    inputs = tokenizer.encode('generate query: ' + document, return_tensors='pt', max_length=512, truncation=True)\n    outputs = model.generate(inputs, num_return_sequences=1, max_length=40)\n\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n", "prediction": "\n    \n    # Check if the argument is valid.\n    if not isinstance(document, str) or len(document.strip()) == 0:\n        raise ValueError('Document must be provided as a non-empty string!')\n        \n    # Load the pre-trained model and tokenizer.\n    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n    t5model = T5ForConditionalGeneration.from_pretrained(\"rinna/japanese-gpt2-query-generation\")\n    \n    # Encode the input document and query prompts.\n    text = \"generate questions: \" + document\n    encoding = tokenizer.encode_plus(text, return_tensors=\"pt\", max_length=512, padding='max_length', truncation=True)\n    \n    # Generate the output using our pre-trained model.\n    output = t5model.generate(input_ids=encoding['input_ids'], attention_mask=encoding['attention_mask'])\n    \n    # Decode and return the generated query.\n    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n    return decoded"}