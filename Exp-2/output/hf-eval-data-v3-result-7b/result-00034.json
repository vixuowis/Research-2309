{"path": "output/hf-eval-data-v3-valid/f00143_generate_code.py", "content": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# function_code --------------------\n\ndef generate_code(description: str) -> str:\n    '''\n    Generate code snippets based on natural language descriptions.\n\n    Args:\n        description (str): The natural language description.\n\n    Returns:\n        str: The generated code snippet.\n    '''\n    tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-2B-multi')\n    model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-2B-multi')\n    input_ids = tokenizer(description, return_tensors='pt').input_ids\n    generated_ids = model.generate(input_ids, max_length=128)\n    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    return generated_code\n\n# test_function_code --------------------\n\ndef test_generate_code():\n    '''\n    Test the generate_code function.\n    '''\n    description1 = 'Write a Python function to calculate the factorial of a number.'\n    description2 = 'Write a Python function to sort a list of numbers in ascending order.'\n    description3 = 'Write a Python function to reverse a string.'\n    assert isinstance(generate_code(description1), str)\n    assert isinstance(generate_code(description2), str)\n    assert isinstance(generate_code(description3), str)\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_generate_code()", "function_import": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n", "function_code": "# function_code --------------------\n\ndef generate_code(description: str) -> str:\n    '''\n    Generate code snippets based on natural language descriptions.\n\n    Args:\n        description (str): The natural language description.\n\n    Returns:\n        str: The generated code snippet.\n    '''\n    tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-2B-multi')\n    model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-2B-multi')\n    input_ids = tokenizer(description, return_tensors='pt').input_ids\n    generated_ids = model.generate(input_ids, max_length=128)\n    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    return generated_code\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_code():\n    '''\n    Test the generate_code function.\n    '''\n    description1 = 'Write a Python function to calculate the factorial of a number.'\n    description2 = 'Write a Python function to sort a list of numbers in ascending order.'\n    description3 = 'Write a Python function to reverse a string.'\n    assert isinstance(generate_code(description1), str)\n    assert isinstance(generate_code(description2), str)\n    assert isinstance(generate_code(description3), str)\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_generate_code()", "instruct": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# function_code --------------------\n\ndef generate_code(description: str) -> str:\n    '''\n    Generate code snippets based on natural language descriptions.\n\n    Args:\n        description (str): The natural language description.\n\n    Returns:\n        str: The generated code snippet.\n    '''", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-2B-multi')\n    model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-2B-multi')\n    input_ids = tokenizer(description, return_tensors='pt').input_ids\n    generated_ids = model.generate(input_ids, max_length=128)\n    generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n    return generated_code\n\n", "prediction": "\n\n    \n    model_name = 'microsoft/DialoGPT-medium'   # or 'gpt2', 'openai-gpt' and more\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForCausalLM.from_pretrained(model_name)\n\n    \n    def _get_code_line(text):  # generate a line of code from the given description\n        input_context = 'if True:\\n' if text[0] == '@' else ''\n        return f\"{input_context}{text.replace(' ', '')}\\n\"\n    \n    encoded_prompt = tokenizer.encode(description, add_special_tokens=False, return_tensors='pt')\n    encoded_prompt = encoded_prompt.to(device) if device.type != 'cpu' else encoded_prompt\n    output_sequences = model.generate(\n        input_ids=encoded_prompt, \n        max_length=50, \n        temperature=1., \n        top_k=50,\n        top_p=1.0\n    )\n    \n    generated_sequence = output_sequences[0]\n    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n    code_lines = [_get_code_line(line) for line in text.split('\\n') if line and (not '|' in line)]\n    \n    return '\\n'.join(code_lines)"}