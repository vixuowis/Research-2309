{"path": "output/hf-eval-data-v3-valid/f00018_estimate_image_depth.py", "content": "# function_import --------------------\n\nfrom transformers import DPTImageProcessor, DPTForDepthEstimation\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport requests\n\n# function_code --------------------\n\ndef estimate_image_depth(image_url):\n    '''\n    Estimate the depth of an image using a pretrained model from Hugging Face Transformers.\n\n    Args:\n        image_url (str): The URL of the image to be processed.\n\n    Returns:\n        depth (PIL.Image): The depth estimation of the image.\n\n    Raises:\n        requests.exceptions.RequestException: If the image cannot be loaded from the provided URL.\n        RuntimeError: If there is a problem loading the pretrained model.\n    '''\n    image = Image.open(requests.get(image_url, stream=True).raw)\n    processor = DPTImageProcessor.from_pretrained('Intel/dpt-large')\n    model = DPTForDepthEstimation.from_pretrained('Intel/dpt-large')\n    inputs = processor(images=image, return_tensors='pt')\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predicted_depth = outputs.predicted_depth\n    prediction = torch.nn.functional.interpolate(predicted_depth.unsqueeze(1), size=image.size[::-1], mode='bicubic', align_corners=False)\n    output = prediction.squeeze().cpu().numpy()\n    formatted = (output * 255 / np.max(output)).astype('uint8')\n    depth = Image.fromarray(formatted)\n    return depth\n\n# test_function_code --------------------\n\ndef test_estimate_image_depth():\n    '''\n    Test the estimate_image_depth function with different test cases.\n    '''\n    test_image_url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    result = estimate_image_depth(test_image_url)\n    assert isinstance(result, Image.Image), 'The result should be a PIL Image.'\n    test_image_url = 'https://placekitten.com/200/300'\n    result = estimate_image_depth(test_image_url)\n    assert isinstance(result, Image.Image), 'The result should be a PIL Image.'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_estimate_image_depth()", "function_import": "# function_import --------------------\n\nfrom transformers import DPTImageProcessor, DPTForDepthEstimation\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport requests\n\n", "function_code": "# function_code --------------------\n\ndef estimate_image_depth(image_url):\n    '''\n    Estimate the depth of an image using a pretrained model from Hugging Face Transformers.\n\n    Args:\n        image_url (str): The URL of the image to be processed.\n\n    Returns:\n        depth (PIL.Image): The depth estimation of the image.\n\n    Raises:\n        requests.exceptions.RequestException: If the image cannot be loaded from the provided URL.\n        RuntimeError: If there is a problem loading the pretrained model.\n    '''\n    image = Image.open(requests.get(image_url, stream=True).raw)\n    processor = DPTImageProcessor.from_pretrained('Intel/dpt-large')\n    model = DPTForDepthEstimation.from_pretrained('Intel/dpt-large')\n    inputs = processor(images=image, return_tensors='pt')\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predicted_depth = outputs.predicted_depth\n    prediction = torch.nn.functional.interpolate(predicted_depth.unsqueeze(1), size=image.size[::-1], mode='bicubic', align_corners=False)\n    output = prediction.squeeze().cpu().numpy()\n    formatted = (output * 255 / np.max(output)).astype('uint8')\n    depth = Image.fromarray(formatted)\n    return depth\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_estimate_image_depth():\n    '''\n    Test the estimate_image_depth function with different test cases.\n    '''\n    test_image_url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n    result = estimate_image_depth(test_image_url)\n    assert isinstance(result, Image.Image), 'The result should be a PIL Image.'\n    test_image_url = 'https://placekitten.com/200/300'\n    result = estimate_image_depth(test_image_url)\n    assert isinstance(result, Image.Image), 'The result should be a PIL Image.'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_estimate_image_depth()", "instruct": "# function_import --------------------\n\nfrom transformers import DPTImageProcessor, DPTForDepthEstimation\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport requests\n\n# function_code --------------------\n\ndef estimate_image_depth(image_url):\n    '''\n    Estimate the depth of an image using a pretrained model from Hugging Face Transformers.\n\n    Args:\n        image_url (str): The URL of the image to be processed.\n\n    Returns:\n        depth (PIL.Image): The depth estimation of the image.\n\n    Raises:\n        requests.exceptions.RequestException: If the image cannot be loaded from the provided URL.\n        RuntimeError: If there is a problem loading the pretrained model.\n    '''", "answer": "\n    image = Image.open(requests.get(image_url, stream=True).raw)\n    processor = DPTImageProcessor.from_pretrained('Intel/dpt-large')\n    model = DPTForDepthEstimation.from_pretrained('Intel/dpt-large')\n    inputs = processor(images=image, return_tensors='pt')\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predicted_depth = outputs.predicted_depth\n    prediction = torch.nn.functional.interpolate(predicted_depth.unsqueeze(1), size=image.size[::-1], mode='bicubic', align_corners=False)\n    output = prediction.squeeze().cpu().numpy()\n    formatted = (output * 255 / np.max(output)).astype('uint8')\n    depth = Image.fromarray(formatted)\n    return depth\n\n", "prediction": "\n\n    # Load Image --------------------\n\n    try:\n        response = requests.get(image_url)\n        img = Image.open(response.content).convert(\"RGB\")\n    except Exception as e:\n        raise ValueError('Image could not be loaded from the provided URL')\n\n    # Preprocess --------------------\n        \n    image_processor = DPTImageProcessor()\n    \n    input, original_size = image_processor(img)\n    input = input.unsqueeze(0).to(\"cuda\")\n    model = DPTForDepthEstimation(pretrained=True)\n    model.to('cuda')\n    model.eval()\n    \n    # Process --------------------\n    \n    with torch.no_grad():\n        try:\n            outputs = model(input)\n            predictions = (outputs[(\"depth\", 0)]).view(*original_size).detach().cpu().numpy()\n            \n        except RuntimeError as e:\n            raise ValueError('Pretrained depth estimation model could not be loaded')\n        \n    # Postprocess --------------------\n    \n    depth = (np.tanh(predictions) + 1) / 2 * 255\n    depth = Image.fromarray((depth*255).astype('uint8'))\n    \n    return depth"}