{"path": "output/hf-eval-data-v3-valid/f00049_get_legal_answer.py", "content": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\nimport torch\n\n# function_code --------------------\n\ndef get_legal_answer(question: str, context: str) -> str:\n    \"\"\"\n    This function uses a pretrained model from Hugging Face Transformers to answer questions based on a given context.\n\n    Args:\n        question (str): The question to be answered.\n        context (str): The context in which the question is to be answered.\n\n    Returns:\n        str: The answer to the question based on the context.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('Rakib/roberta-base-on-cuad')\n    model = AutoModelForQuestionAnswering.from_pretrained('Rakib/roberta-base-on-cuad')\n    inputs = tokenizer(question, context, return_tensors='pt')\n    outputs = model(**inputs)\n    answer_start = torch.argmax(outputs.start_logits)\n    answer_end = torch.argmax(outputs.end_logits) + 1\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n    return answer\n\n# test_function_code --------------------\n\ndef test_get_legal_answer():\n    question = 'Who is the licensee?'\n    context = 'We hereby grant the Licensee the exclusive right to develop, construct, operate and promote the Project, as well as to manage the daily operations of the Licensed Facilities during the Term. In consideration for the grant of the License, the Licensee shall pay to the Licensor the full amount of Ten Million (10,000,000) Dollars within thirty (30) days after the execution hereof.'\n    answer = get_legal_answer(question, context)\n    assert isinstance(answer, str), 'The answer should be a string.'\n    assert answer != '', 'The answer should not be an empty string.'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_get_legal_answer()", "function_import": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\nimport torch\n\n", "function_code": "# function_code --------------------\n\ndef get_legal_answer(question: str, context: str) -> str:\n    \"\"\"\n    This function uses a pretrained model from Hugging Face Transformers to answer questions based on a given context.\n\n    Args:\n        question (str): The question to be answered.\n        context (str): The context in which the question is to be answered.\n\n    Returns:\n        str: The answer to the question based on the context.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('Rakib/roberta-base-on-cuad')\n    model = AutoModelForQuestionAnswering.from_pretrained('Rakib/roberta-base-on-cuad')\n    inputs = tokenizer(question, context, return_tensors='pt')\n    outputs = model(**inputs)\n    answer_start = torch.argmax(outputs.start_logits)\n    answer_end = torch.argmax(outputs.end_logits) + 1\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n    return answer\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_get_legal_answer():\n    question = 'Who is the licensee?'\n    context = 'We hereby grant the Licensee the exclusive right to develop, construct, operate and promote the Project, as well as to manage the daily operations of the Licensed Facilities during the Term. In consideration for the grant of the License, the Licensee shall pay to the Licensor the full amount of Ten Million (10,000,000) Dollars within thirty (30) days after the execution hereof.'\n    answer = get_legal_answer(question, context)\n    assert isinstance(answer, str), 'The answer should be a string.'\n    assert answer != '', 'The answer should not be an empty string.'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_get_legal_answer()", "instruct": "# function_import --------------------\n\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\nimport torch\n\n# function_code --------------------\n\ndef get_legal_answer(question: str, context: str) -> str:\n    \"\"\"\n    This function uses a pretrained model from Hugging Face Transformers to answer questions based on a given context.\n\n    Args:\n        question (str): The question to be answered.\n        context (str): The context in which the question is to be answered.\n\n    Returns:\n        str: The answer to the question based on the context.\n    \"\"\"", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained('Rakib/roberta-base-on-cuad')\n    model = AutoModelForQuestionAnswering.from_pretrained('Rakib/roberta-base-on-cuad')\n    inputs = tokenizer(question, context, return_tensors='pt')\n    outputs = model(**inputs)\n    answer_start = torch.argmax(outputs.start_logits)\n    answer_end = torch.argmax(outputs.end_logits) + 1\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n    return answer\n\n", "prediction": "    \n    tokenizer = AutoTokenizer.from_pretrained(\"KB/bert-base-swedish-cased-squad2\")\n    model = AutoModelForQuestionAnswering.from_pretrained(\"KB/bert-base-swedish-cased-squad2\")\n    \n    inputs = tokenizer(question, context, return_tensors='pt')  # encode using pretrained vocabulary\n    input_ids = inputs['input_ids'].tolist()[0]\n    \n    answer_start_scores, answer_end_scores = model(**inputs)\n    \n    answer_start = torch.argmax(answer_start_scores)  # get start index for answer\n    answer_end = torch.argmax(answer_end_scores) + 1  # get end index for answer\n    predicted_token_ids = input_ids[answer_start:answer_end]\n    \n    return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(predicted_token_ids))"}