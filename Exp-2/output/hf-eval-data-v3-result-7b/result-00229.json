{"path": "output/hf-eval-data-v3-valid/f00869_extract_info_from_french_doc.py", "content": "# function_import --------------------\n\nfrom transformers import pipeline\n\n# function_code --------------------\n\ndef extract_info_from_french_doc(context: str, question: str) -> str:\n    '''\n    Extracts specific information from a French business document using a multilingual question-answering model.\n\n    Args:\n        context (str): The French text document from which to extract information.\n        question (str): The specific question in French to answer based on the context.\n\n    Returns:\n        str: The answer to the question based on the context.\n    '''\n    qa_pipeline = pipeline('question-answering', model='mrm8488/bert-multi-cased-finetuned-xquadv1', tokenizer='mrm8488/bert-multi-cased-finetuned-xquadv1')\n    answer = qa_pipeline({'context': context, 'question': question})\n    return answer['answer']\n\n# test_function_code --------------------\n\ndef test_extract_info_from_french_doc():\n    '''\n    Tests the function extract_info_from_french_doc.\n    '''\n    context = 'Manuel Romero travaille dur dans le d\u00e9p\u00f4t hugginface/transformers r\u00e9cemment.'\n    question = 'Qui a travaill\u00e9 dur pour hugginface/transformers r\u00e9cemment?'\n    assert isinstance(extract_info_from_french_doc(context, question), str)\n    context = 'La tour Eiffel est situ\u00e9e \u00e0 Paris.'\n    question = 'O\u00f9 se trouve la tour Eiffel?'\n    assert isinstance(extract_info_from_french_doc(context, question), str)\n    context = 'Le pr\u00e9sident actuel de la France est Emmanuel Macron.'\n    question = 'Qui est le pr\u00e9sident actuel de la France?'\n    assert isinstance(extract_info_from_french_doc(context, question), str)\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_extract_info_from_french_doc()", "function_import": "# function_import --------------------\n\nfrom transformers import pipeline\n\n", "function_code": "# function_code --------------------\n\ndef extract_info_from_french_doc(context: str, question: str) -> str:\n    '''\n    Extracts specific information from a French business document using a multilingual question-answering model.\n\n    Args:\n        context (str): The French text document from which to extract information.\n        question (str): The specific question in French to answer based on the context.\n\n    Returns:\n        str: The answer to the question based on the context.\n    '''\n    qa_pipeline = pipeline('question-answering', model='mrm8488/bert-multi-cased-finetuned-xquadv1', tokenizer='mrm8488/bert-multi-cased-finetuned-xquadv1')\n    answer = qa_pipeline({'context': context, 'question': question})\n    return answer['answer']\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_extract_info_from_french_doc():\n    '''\n    Tests the function extract_info_from_french_doc.\n    '''\n    context = 'Manuel Romero travaille dur dans le d\u00e9p\u00f4t hugginface/transformers r\u00e9cemment.'\n    question = 'Qui a travaill\u00e9 dur pour hugginface/transformers r\u00e9cemment?'\n    assert isinstance(extract_info_from_french_doc(context, question), str)\n    context = 'La tour Eiffel est situ\u00e9e \u00e0 Paris.'\n    question = 'O\u00f9 se trouve la tour Eiffel?'\n    assert isinstance(extract_info_from_french_doc(context, question), str)\n    context = 'Le pr\u00e9sident actuel de la France est Emmanuel Macron.'\n    question = 'Qui est le pr\u00e9sident actuel de la France?'\n    assert isinstance(extract_info_from_french_doc(context, question), str)\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_extract_info_from_french_doc()", "instruct": "# function_import --------------------\n\nfrom transformers import pipeline\n\n# function_code --------------------\n\ndef extract_info_from_french_doc(context: str, question: str) -> str:\n    '''\n    Extracts specific information from a French business document using a multilingual question-answering model.\n\n    Args:\n        context (str): The French text document from which to extract information.\n        question (str): The specific question in French to answer based on the context.\n\n    Returns:\n        str: The answer to the question based on the context.\n    '''", "answer": "\n    qa_pipeline = pipeline('question-answering', model='mrm8488/bert-multi-cased-finetuned-xquadv1', tokenizer='mrm8488/bert-multi-cased-finetuned-xquadv1')\n    answer = qa_pipeline({'context': context, 'question': question})\n    return answer['answer']\n\n", "prediction": "\n    \n    # load model --------------------\n    \n    multilingual_qa = pipeline(\"question-answering\", model=\"valhalla/t5-base-qa-multilingual-v1\") \n    \n    # preprocessing --------------------\n    \n    inputs = {\"french\": context, \"question\" : question}\n    input_dict = {k: [v] for k, v in inputs.items()}\n    input_ids = multilingual_qa.tokenizer(input_dict)[\"input_ids\"] \n    \n    # model execution --------------------\n    \n    answer = multilingual_qa({'input_ids': input_ids, 'language': \"french\"})['answer'][0]\n    \n    return answer"}