{"path": "output/hf-eval-data-v3-valid/f00795_generate_marketing_content.py", "content": "# function_import --------------------\n\nfrom transformers import pipeline, set_seed\n\n# function_code --------------------\n\ndef generate_marketing_content(prompt: str) -> str:\n    \"\"\"\n    Generate marketing content using the OPT pre-trained transformer 'facebook/opt-125m'.\n\n    Args:\n        prompt (str): The initial prompt to feed to the text generation model.\n\n    Returns:\n        str: The generated marketing content.\n\n    Raises:\n        OSError: If there is a problem with the disk quota.\n    \"\"\"\n    set_seed(42)\n    generator = pipeline('text-generation', model='facebook/opt-125m')\n    generated_content = generator(prompt, max_length=100, do_sample=True)[0]['generated_text']\n    return generated_content\n\n# test_function_code --------------------\n\ndef test_generate_marketing_content():\n    \"\"\"\n    Test the generate_marketing_content function.\n    \"\"\"\n    prompt = 'Introducing our new line of eco-friendly kitchenware:'\n    generated_content = generate_marketing_content(prompt)\n    assert isinstance(generated_content, str)\n    assert len(generated_content) > 0\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    test_generate_marketing_content()", "function_import": "# function_import --------------------\n\nfrom transformers import pipeline, set_seed\n\n", "function_code": "# function_code --------------------\n\ndef generate_marketing_content(prompt: str) -> str:\n    \"\"\"\n    Generate marketing content using the OPT pre-trained transformer 'facebook/opt-125m'.\n\n    Args:\n        prompt (str): The initial prompt to feed to the text generation model.\n\n    Returns:\n        str: The generated marketing content.\n\n    Raises:\n        OSError: If there is a problem with the disk quota.\n    \"\"\"\n    set_seed(42)\n    generator = pipeline('text-generation', model='facebook/opt-125m')\n    generated_content = generator(prompt, max_length=100, do_sample=True)[0]['generated_text']\n    return generated_content\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_generate_marketing_content():\n    \"\"\"\n    Test the generate_marketing_content function.\n    \"\"\"\n    prompt = 'Introducing our new line of eco-friendly kitchenware:'\n    generated_content = generate_marketing_content(prompt)\n    assert isinstance(generated_content, str)\n    assert len(generated_content) > 0\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    test_generate_marketing_content()", "instruct": "# function_import --------------------\n\nfrom transformers import pipeline, set_seed\n\n# function_code --------------------\n\ndef generate_marketing_content(prompt: str) -> str:\n    \"\"\"\n    Generate marketing content using the OPT pre-trained transformer 'facebook/opt-125m'.\n\n    Args:\n        prompt (str): The initial prompt to feed to the text generation model.\n\n    Returns:\n        str: The generated marketing content.\n\n    Raises:\n        OSError: If there is a problem with the disk quota.\n    \"\"\"", "answer": "\n    set_seed(42)\n    generator = pipeline('text-generation', model='facebook/opt-125m')\n    generated_content = generator(prompt, max_length=100, do_sample=True)[0]['generated_text']\n    return generated_content\n\n", "prediction": "    \n        \n    # Create and configure pipeline for generation --------------------\n    try:\n        set_seed(42)\n        model = \"facebook/opt-125m\"\n        tokenizer = \"facebook/opt-125m\"\n        summarization_pipeline = pipeline(\"summarization\", \n                                          model=model, \n                                          tokenizer=tokenizer)\n    except OSError as err:\n        print(f'Error code:\\t{err.errno}\\n\\nError message:\\t{err.strerror}')\n        \n    # Generate marketing content --------------------\n    \n    try:\n        prompt = summarization_pipeline(prompt)[0]['summary_text']\n    except IndexError as err:\n        print(f'Error code:\\t\\t\\t{err.args[1]}\\nError message:\\t\\t{err.args[0]}')\n        \n    return prompt"}