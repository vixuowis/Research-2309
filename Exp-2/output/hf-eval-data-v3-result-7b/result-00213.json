{"path": "output/hf-eval-data-v3-valid/f00823_extract_features.py", "content": "# function_import --------------------\n\nfrom transformers import BertTokenizer, AutoModel\nimport torch\n\n# function_code --------------------\n\ndef extract_features(input_text):\n    \"\"\"\n    Extracts contextual representation of the input text using IndoBERT model.\n\n    Args:\n        input_text (str): The input text in Indonesian language.\n\n    Returns:\n        torch.Tensor: The contextual representation of the input text.\n\n    Raises:\n        OSError: If there is a problem in loading the pretrained model or tokenizer.\n    \"\"\"\n    tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n    model = AutoModel.from_pretrained('indobenchmark/indobert-base-p1')\n    encoded_input = tokenizer.encode(input_text, return_tensors='pt')\n    contextual_representation = model(encoded_input)[0]\n    return contextual_representation\n\n# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Tests the function 'extract_features'.\n    \"\"\"\n    sample_text = 'Saya suka makan nasi goreng'\n    output = extract_features(sample_text)\n    assert isinstance(output, torch.Tensor), 'Output is not a torch.Tensor'\n    assert output.shape[0] == 1, 'Output shape is not correct'\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\ntest_extract_features()", "function_import": "# function_import --------------------\n\nfrom transformers import BertTokenizer, AutoModel\nimport torch\n\n", "function_code": "# function_code --------------------\n\ndef extract_features(input_text):\n    \"\"\"\n    Extracts contextual representation of the input text using IndoBERT model.\n\n    Args:\n        input_text (str): The input text in Indonesian language.\n\n    Returns:\n        torch.Tensor: The contextual representation of the input text.\n\n    Raises:\n        OSError: If there is a problem in loading the pretrained model or tokenizer.\n    \"\"\"\n    tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n    model = AutoModel.from_pretrained('indobenchmark/indobert-base-p1')\n    encoded_input = tokenizer.encode(input_text, return_tensors='pt')\n    contextual_representation = model(encoded_input)[0]\n    return contextual_representation\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Tests the function 'extract_features'.\n    \"\"\"\n    sample_text = 'Saya suka makan nasi goreng'\n    output = extract_features(sample_text)\n    assert isinstance(output, torch.Tensor), 'Output is not a torch.Tensor'\n    assert output.shape[0] == 1, 'Output shape is not correct'\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_extract_features()", "instruct": "# function_import --------------------\n\nfrom transformers import BertTokenizer, AutoModel\nimport torch\n\n# function_code --------------------\n\ndef extract_features(input_text):\n    \"\"\"\n    Extracts contextual representation of the input text using IndoBERT model.\n\n    Args:\n        input_text (str): The input text in Indonesian language.\n\n    Returns:\n        torch.Tensor: The contextual representation of the input text.\n\n    Raises:\n        OSError: If there is a problem in loading the pretrained model or tokenizer.\n    \"\"\"", "answer": "\n    tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n    model = AutoModel.from_pretrained('indobenchmark/indobert-base-p1')\n    encoded_input = tokenizer.encode(input_text, return_tensors='pt')\n    contextual_representation = model(encoded_input)[0]\n    return contextual_representation\n\n", "prediction": "\n    try:\n        \n        # Initialize IndoBERT Model and Tokenizer\n        \n        print(\"[INFO] Loading Pre-Trained Models\")\n        tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n        model = AutoModel.from_pretrained('indobenchmark/indobert-base-p1') # or indobenchmark/indobert-large-p2\n\n        input_ids = torch.tensor(tokenizer.encode(input_text)).unsqueeze(0) \n        \n        # Extract Features using IndoBERT model (Encoder)\n        \n        with torch.no_grad():\n            last_hidden_states = model(input_ids)[0] # [batch, seq, dim]\n            \n    except OSError as err:\n        print(\"[ERROR] Cannot load the pre-trained models.\")\n        raise\n    \n    return last_hidden_states.squeeze()"}