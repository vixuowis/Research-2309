{"path": "output/hf-eval-data-v3-valid/f00114_segment_city_layout.py", "content": "# function_import --------------------\n\nfrom transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor\nfrom PIL import Image\nimport requests\n\n# function_code --------------------\n\ndef segment_city_layout(image_url):\n    \"\"\"\n    This function takes an image URL of a city layout and returns the segmented image using a pre-trained model.\n    The model used is 'nvidia/segformer-b5-finetuned-cityscapes-1024-1024' from Hugging Face Transformers.\n\n    Args:\n        image_url (str): The URL of the city layout image.\n\n    Returns:\n        torch.Tensor: The segmented image.\n\n    Raises:\n        requests.exceptions.RequestException: If there is a problem with the network connection.\n        requests.exceptions.HTTPError: If there is an HTTP error.\n        requests.exceptions.Timeout: If the request times out.\n        requests.exceptions.TooManyRedirects: If the request exceeds the configured number of maximum redirections.\n    \"\"\"\n    # Load the feature extractor and model\n    feature_extractor = SegformerFeatureExtractor.from_pretrained('nvidia/segformer-b5-finetuned-cityscapes-1024-1024')\n    model = SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b5-finetuned-cityscapes-1024-1024')\n\n    # Load the image from the URL\n    response = requests.get(image_url, stream=True)\n    response.raise_for_status()\n    image = Image.open(response.raw)\n\n    # Prepare the inputs\n    inputs = feature_extractor(images=image, return_tensors='pt')\n\n    # Compute the segmentation\n    outputs = model(**inputs)\n\n    return outputs.logits\n\n# test_function_code --------------------\n\ndef test_segment_city_layout():\n    \"\"\"Tests the `segment_city_layout` function.\"\"\"\n    # Test with a city layout image\n    image_url = 'https://placekitten.com/200/300'\n    output = segment_city_layout(image_url)\n    assert output is not None, 'The output should not be None.'\n    assert output.shape[0] == 1, 'The output shape should be (1, num_classes, height, width).'\n\n    # Test with another city layout image\n    image_url = 'https://placekitten.com/200/300'\n    output = segment_city_layout(image_url)\n    assert output is not None, 'The output should not be None.'\n    assert output.shape[0] == 1, 'The output shape should be (1, num_classes, height, width).'\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_segment_city_layout()", "function_import": "# function_import --------------------\n\nfrom transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor\nfrom PIL import Image\nimport requests\n\n", "function_code": "# function_code --------------------\n\ndef segment_city_layout(image_url):\n    \"\"\"\n    This function takes an image URL of a city layout and returns the segmented image using a pre-trained model.\n    The model used is 'nvidia/segformer-b5-finetuned-cityscapes-1024-1024' from Hugging Face Transformers.\n\n    Args:\n        image_url (str): The URL of the city layout image.\n\n    Returns:\n        torch.Tensor: The segmented image.\n\n    Raises:\n        requests.exceptions.RequestException: If there is a problem with the network connection.\n        requests.exceptions.HTTPError: If there is an HTTP error.\n        requests.exceptions.Timeout: If the request times out.\n        requests.exceptions.TooManyRedirects: If the request exceeds the configured number of maximum redirections.\n    \"\"\"\n    # Load the feature extractor and model\n    feature_extractor = SegformerFeatureExtractor.from_pretrained('nvidia/segformer-b5-finetuned-cityscapes-1024-1024')\n    model = SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b5-finetuned-cityscapes-1024-1024')\n\n    # Load the image from the URL\n    response = requests.get(image_url, stream=True)\n    response.raise_for_status()\n    image = Image.open(response.raw)\n\n    # Prepare the inputs\n    inputs = feature_extractor(images=image, return_tensors='pt')\n\n    # Compute the segmentation\n    outputs = model(**inputs)\n\n    return outputs.logits\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_segment_city_layout():\n    \"\"\"Tests the `segment_city_layout` function.\"\"\"\n    # Test with a city layout image\n    image_url = 'https://placekitten.com/200/300'\n    output = segment_city_layout(image_url)\n    assert output is not None, 'The output should not be None.'\n    assert output.shape[0] == 1, 'The output shape should be (1, num_classes, height, width).'\n\n    # Test with another city layout image\n    image_url = 'https://placekitten.com/200/300'\n    output = segment_city_layout(image_url)\n    assert output is not None, 'The output should not be None.'\n    assert output.shape[0] == 1, 'The output shape should be (1, num_classes, height, width).'\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_segment_city_layout()", "instruct": "# function_import --------------------\n\nfrom transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor\nfrom PIL import Image\nimport requests\n\n# function_code --------------------\n\ndef segment_city_layout(image_url):\n    \"\"\"\n    This function takes an image URL of a city layout and returns the segmented image using a pre-trained model.\n    The model used is 'nvidia/segformer-b5-finetuned-cityscapes-1024-1024' from Hugging Face Transformers.\n\n    Args:\n        image_url (str): The URL of the city layout image.\n\n    Returns:\n        torch.Tensor: The segmented image.\n\n    Raises:\n        requests.exceptions.RequestException: If there is a problem with the network connection.\n        requests.exceptions.HTTPError: If there is an HTTP error.\n        requests.exceptions.Timeout: If the request times out.\n        requests.exceptions.TooManyRedirects: If the request exceeds the configured number of maximum redirections.\n    \"\"\"", "answer": "\n    # Load the feature extractor and model\n    feature_extractor = SegformerFeatureExtractor.from_pretrained('nvidia/segformer-b5-finetuned-cityscapes-1024-1024')\n    model = SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b5-finetuned-cityscapes-1024-1024')\n\n    # Load the image from the URL\n    response = requests.get(image_url, stream=True)\n    response.raise_for_status()\n    image = Image.open(response.raw)\n\n    # Prepare the inputs\n    inputs = feature_extractor(images=image, return_tensors='pt')\n\n    # Compute the segmentation\n    outputs = model(**inputs)\n\n    return outputs.logits\n\n", "prediction": "\n    \n    # load model -------------------------------\n\n    segformer_model = SegformerForSemanticSegmentation.from_pretrained(\n        \"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\"\n    )\n    \n    # load image -------------------------------\n\n    try:\n        response = requests.get(image_url, timeout=5)\n    except (requests.exceptions.RequestException):\n        raise requests.exceptions.RequestException(\"There was a problem with the network connection.\")\n    if response.status_code != 200:\n        raise requests.exceptions.HTTPError(f\"The HTTP error code is {response.status_code}.\")\n    \n    try:\n        image = Image.open(BytesIO(response.content))\n    except (OSError):\n        raise requests.exceptions.Timeout(\"The request timed out.\")\n    \n    # preprocess image -------------------------------\n\n    feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\")\n    \n    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n    \n    # run model -------------------------------\n    \n    outputs = segformer_model(**inputs)\n    \n    # postprocess image -------------------------------\n    \n    masked_image = inputs['pixel_values'].clone()\n    for i in range(masked_image.size(-1)):\n        masked_image[:, :, i] *= outputs.logits[0, 4*i:4*(i+1)] > -5\n    \n    return masked_image\n"}