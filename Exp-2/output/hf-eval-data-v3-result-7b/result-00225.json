{"path": "output/hf-eval-data-v3-valid/f00858_classify_image.py", "content": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef classify_image(img_url: str):\n    \"\"\"\n    Classify an image using a pretrained CLIP model.\n\n    Args:\n        img_url (str): The URL of the image to classify.\n\n    Returns:\n        dict: A dictionary where keys are labels and values are probabilities.\n    \"\"\"\n    model = CLIPModel.from_pretrained('flax-community/clip-rsicd-v2')\n    processor = CLIPProcessor.from_pretrained('flax-community/clip-rsicd-v2')\n    image = Image.open(requests.get(img_url, stream=True).raw)\n    labels = ['residential area', 'playground', 'stadium', 'forest', 'airport']\n    inputs = processor(text=[f'a photo of a {l}' for l in labels], images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {l: p.item() for l, p in zip(labels, probs[0])}\n\n# test_function_code --------------------\n\ndef test_classify_image():\n    \"\"\"\n    Test the classify_image function.\n    \"\"\"\n    img_url = 'https://placekitten.com/200/300'\n    result = classify_image(img_url)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == set(['residential area', 'playground', 'stadium', 'forest', 'airport'])\n    assert all(0 <= v <= 1 for v in result.values())\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_classify_image()", "function_import": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n", "function_code": "# function_code --------------------\n\ndef classify_image(img_url: str):\n    \"\"\"\n    Classify an image using a pretrained CLIP model.\n\n    Args:\n        img_url (str): The URL of the image to classify.\n\n    Returns:\n        dict: A dictionary where keys are labels and values are probabilities.\n    \"\"\"\n    model = CLIPModel.from_pretrained('flax-community/clip-rsicd-v2')\n    processor = CLIPProcessor.from_pretrained('flax-community/clip-rsicd-v2')\n    image = Image.open(requests.get(img_url, stream=True).raw)\n    labels = ['residential area', 'playground', 'stadium', 'forest', 'airport']\n    inputs = processor(text=[f'a photo of a {l}' for l in labels], images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {l: p.item() for l, p in zip(labels, probs[0])}\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_classify_image():\n    \"\"\"\n    Test the classify_image function.\n    \"\"\"\n    img_url = 'https://placekitten.com/200/300'\n    result = classify_image(img_url)\n    assert isinstance(result, dict)\n    assert set(result.keys()) == set(['residential area', 'playground', 'stadium', 'forest', 'airport'])\n    assert all(0 <= v <= 1 for v in result.values())\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_classify_image()", "instruct": "# function_import --------------------\n\nfrom PIL import Image\nimport requests\nfrom transformers import CLIPProcessor, CLIPModel\n\n# function_code --------------------\n\ndef classify_image(img_url: str):\n    \"\"\"\n    Classify an image using a pretrained CLIP model.\n\n    Args:\n        img_url (str): The URL of the image to classify.\n\n    Returns:\n        dict: A dictionary where keys are labels and values are probabilities.\n    \"\"\"", "answer": "\n    model = CLIPModel.from_pretrained('flax-community/clip-rsicd-v2')\n    processor = CLIPProcessor.from_pretrained('flax-community/clip-rsicd-v2')\n    image = Image.open(requests.get(img_url, stream=True).raw)\n    labels = ['residential area', 'playground', 'stadium', 'forest', 'airport']\n    inputs = processor(text=[f'a photo of a {l}' for l in labels], images=image, return_tensors='pt', padding=True)\n    outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = logits_per_image.softmax(dim=1)\n    return {l: p.item() for l, p in zip(labels, probs[0])}\n\n", "prediction": "\n\n    # Download Image --------------------\n    image = Image.open(requests.get(img_url, stream=True).raw)\n\n    # Process Image --------------------\n    image = preprocess(image)\n\n    # Predict Image --------------------\n    model = load_model()\n    text = predict(image, model)\n\n    return text\n\ndef preprocess(image: Image):\n    \"\"\"Preprocess an image for a CLIP model.\n\n    Args:\n        image (PIL.Image): The image to process.\n\n    Returns:\n        torch.Tensor: A tensor representing the processed image.\n    \"\"\"\n    return clip_processor(images=image, return_tensors=\"pt\").pixel_values\n    \ndef load_model():\n    \"\"\"Load a CLIP model for classification.\n\n    Args:\n        None\n    \n    Returns:\n        transformers.CLIPModel: The CLIP model to use for classification.\n    \"\"\"\n    return clip_model\n\n# function_import --------------------\n\nclip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\nclip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n"}