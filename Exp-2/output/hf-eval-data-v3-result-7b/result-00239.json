{"path": "output/hf-eval-data-v3-valid/f00895_text_to_speech.py", "content": "# function_import --------------------\n\nimport os\nimport torchaudio\nfrom speechbrain.pretrained import Tacotron2, HIFIGAN\n\n# function_code --------------------\n\ndef text_to_speech(text: str, output_file: str):\n    '''\n    Convert the input text into speech and save the audio to a .wav file.\n\n    Args:\n        text (str): The input text to be converted into speech.\n        output_file (str): The path of the output .wav file.\n\n    Returns:\n        None\n    '''\n    tacotron2 = Tacotron2.from_hparams(source='speechbrain/tts-tacotron2-ljspeech')\n    hifi_gan = HIFIGAN.from_hparams(source='speechbrain/tts-hifigan-ljspeech')\n    mel_output, mel_length, alignment = tacotron2.encode_text(text)\n    waveforms = hifi_gan.decode_batch(mel_output)\n    torchaudio.save(output_file, waveforms.squeeze(1), 22050)\n\n# test_function_code --------------------\n\ndef test_text_to_speech():\n    '''\n    Test the text_to_speech function.\n    '''\n    text_to_speech('The sun was shining brightly, and the birds were singing sweetly.', 'test_TTS.wav')\n    assert os.path.exists('test_TTS.wav'), 'The output file does not exist.'\n    os.remove('test_TTS.wav')\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_text_to_speech()", "function_import": "# function_import --------------------\n\nimport os\nimport torchaudio\nfrom speechbrain.pretrained import Tacotron2, HIFIGAN\n\n", "function_code": "# function_code --------------------\n\ndef text_to_speech(text: str, output_file: str):\n    '''\n    Convert the input text into speech and save the audio to a .wav file.\n\n    Args:\n        text (str): The input text to be converted into speech.\n        output_file (str): The path of the output .wav file.\n\n    Returns:\n        None\n    '''\n    tacotron2 = Tacotron2.from_hparams(source='speechbrain/tts-tacotron2-ljspeech')\n    hifi_gan = HIFIGAN.from_hparams(source='speechbrain/tts-hifigan-ljspeech')\n    mel_output, mel_length, alignment = tacotron2.encode_text(text)\n    waveforms = hifi_gan.decode_batch(mel_output)\n    torchaudio.save(output_file, waveforms.squeeze(1), 22050)\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_text_to_speech():\n    '''\n    Test the text_to_speech function.\n    '''\n    text_to_speech('The sun was shining brightly, and the birds were singing sweetly.', 'test_TTS.wav')\n    assert os.path.exists('test_TTS.wav'), 'The output file does not exist.'\n    os.remove('test_TTS.wav')\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_text_to_speech()", "instruct": "# function_import --------------------\n\nimport os\nimport torchaudio\nfrom speechbrain.pretrained import Tacotron2, HIFIGAN\n\n# function_code --------------------\n\ndef text_to_speech(text: str, output_file: str):\n    '''\n    Convert the input text into speech and save the audio to a .wav file.\n\n    Args:\n        text (str): The input text to be converted into speech.\n        output_file (str): The path of the output .wav file.\n\n    Returns:\n        None\n    '''", "answer": "\n    tacotron2 = Tacotron2.from_hparams(source='speechbrain/tts-tacotron2-ljspeech')\n    hifi_gan = HIFIGAN.from_hparams(source='speechbrain/tts-hifigan-ljspeech')\n    mel_output, mel_length, alignment = tacotron2.encode_text(text)\n    waveforms = hifi_gan.decode_batch(mel_output)\n    torchaudio.save(output_file, waveforms.squeeze(1), 22050)\n\n", "prediction": "\n    \n    print('Preparing...')\n    # Preparation -------------------\n\n    # Check if text is in string format and convert it into a list\n    assert type(text) == str, 'Input text is not in string format.'\n    \n    text = [text]\n    \n    output_format = 'wav'\n    model = HIFIGAN()\n\n    # Processing --------------------\n    print('Processing...')\n\n    with torch.no_grad():\n        # Preprocess text\n        ids = model.tokenizer(text).input_ids\n        \n        # Compute the spectrograms using Tacotron2 & GAN vocoder\n        specs, alignments, stop_tokens = model(torch.LongTensor(ids))\n    \n    # Save as wav file --------------\n    print('Saving...')\n\n    if os.path.exists(output_file):\n        os.remove(output_file)\n        \n    specs = specs[0].numpy()\n    torchaudio.save_wav(\n        filepath=output_file, \n        tensors=specs, \n        sample_rate=model.sample_rate\n    )\n    \n    print('Finished')"}