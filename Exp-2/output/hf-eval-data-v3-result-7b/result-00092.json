{"path": "output/hf-eval-data-v3-valid/f00399_detect_russian_sentence_contradiction.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef detect_russian_sentence_contradiction(sentence1: str, sentence2: str) -> bool:\n    \"\"\"\n    Determine if one Russian sentence logically contradicts the information provided by another Russian sentence.\n\n    Args:\n        sentence1 (str): The first Russian sentence.\n        sentence2 (str): The second Russian sentence.\n\n    Returns:\n        bool: True if contradiction is detected, False otherwise.\n    \"\"\"\n    model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n    if torch.cuda.is_available():\n        model.cuda()\n    with torch.inference_mode():\n        out = model(**tokenizer(sentence1, sentence2, return_tensors='pt').to(model.device))\n        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n    predicted_label = {v: proba[k] for k, v in model.config.id2label.items()}\n    return predicted_label['contradiction'] > predicted_label['neutral'] and predicted_label['contradiction'] > predicted_label['entailment']\n\n# test_function_code --------------------\n\ndef test_detect_russian_sentence_contradiction():\n    assert detect_russian_sentence_contradiction('\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430', '\u042d\u0442\u043e \u0441\u0438\u043d\u044f\u044f \u043c\u0430\u0448\u0438\u043d\u0430') == True\n    assert detect_russian_sentence_contradiction('\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430', '\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430') == False\n    assert detect_russian_sentence_contradiction('\u041e\u043d \u043b\u044e\u0431\u0438\u0442 \u043a\u043e\u0448\u0435\u043a', '\u041e\u043d \u043d\u0435\u043d\u0430\u0432\u0438\u0434\u0438\u0442 \u043a\u043e\u0448\u0435\u043a') == True\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_detect_russian_sentence_contradiction()", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n", "function_code": "# function_code --------------------\n\ndef detect_russian_sentence_contradiction(sentence1: str, sentence2: str) -> bool:\n    \"\"\"\n    Determine if one Russian sentence logically contradicts the information provided by another Russian sentence.\n\n    Args:\n        sentence1 (str): The first Russian sentence.\n        sentence2 (str): The second Russian sentence.\n\n    Returns:\n        bool: True if contradiction is detected, False otherwise.\n    \"\"\"\n    model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n    if torch.cuda.is_available():\n        model.cuda()\n    with torch.inference_mode():\n        out = model(**tokenizer(sentence1, sentence2, return_tensors='pt').to(model.device))\n        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n    predicted_label = {v: proba[k] for k, v in model.config.id2label.items()}\n    return predicted_label['contradiction'] > predicted_label['neutral'] and predicted_label['contradiction'] > predicted_label['entailment']\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_detect_russian_sentence_contradiction():\n    assert detect_russian_sentence_contradiction('\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430', '\u042d\u0442\u043e \u0441\u0438\u043d\u044f\u044f \u043c\u0430\u0448\u0438\u043d\u0430') == True\n    assert detect_russian_sentence_contradiction('\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430', '\u042d\u0442\u043e \u043a\u0440\u0430\u0441\u043d\u0430\u044f \u043c\u0430\u0448\u0438\u043d\u0430') == False\n    assert detect_russian_sentence_contradiction('\u041e\u043d \u043b\u044e\u0431\u0438\u0442 \u043a\u043e\u0448\u0435\u043a', '\u041e\u043d \u043d\u0435\u043d\u0430\u0432\u0438\u0434\u0438\u0442 \u043a\u043e\u0448\u0435\u043a') == True\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_detect_russian_sentence_contradiction()", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef detect_russian_sentence_contradiction(sentence1: str, sentence2: str) -> bool:\n    \"\"\"\n    Determine if one Russian sentence logically contradicts the information provided by another Russian sentence.\n\n    Args:\n        sentence1 (str): The first Russian sentence.\n        sentence2 (str): The second Russian sentence.\n\n    Returns:\n        bool: True if contradiction is detected, False otherwise.\n    \"\"\"", "answer": "\n    model_checkpoint = 'cointegrated/rubert-base-cased-nli-threeway'\n    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n    if torch.cuda.is_available():\n        model.cuda()\n    with torch.inference_mode():\n        out = model(**tokenizer(sentence1, sentence2, return_tensors='pt').to(model.device))\n        proba = torch.softmax(out.logits, -1).cpu().numpy()[0]\n    predicted_label = {v: proba[k] for k, v in model.config.id2label.items()}\n    return predicted_label['contradiction'] > predicted_label['neutral'] and predicted_label['contradiction'] > predicted_label['entailment']\n\n", "prediction": "\n    tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3large\")\n    model = AutoModelForSequenceClassification.from_pretrained(\"sberbank-ai/rugpt3large\")\n\n    input1 = tokenizer(sentence1, truncation=True)\n    input2 = tokenizer(sentence2, truncation=True)\n    \n    output1 = model(**input1)[0].tolist()[0][-1] # get final logit value for contradiction\n    output2 = model(**input2)[0].tolist()[0][-1] # get final logit value for contradiction\n\n    return bool((output1 < output2) & (output1 > -1 * output2))\n    "}