{"path": "output/hf-eval-data-v3-valid/f00768_analyze_review_sentiment.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef analyze_review_sentiment(review_text):\n    \"\"\"\n    Analyze the sentiment of a restaurant review using a pre-trained model.\n\n    Args:\n        review_text (str): The text of the restaurant review.\n\n    Returns:\n        str: The sentiment of the review ('positive' or 'negative').\n\n    Raises:\n        OSError: If there is an error loading the pre-trained model or tokenizing the input text.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n    config = AutoConfig.from_pretrained('potatobunny/results-yelp')\n    model = AutoModelForSequenceClassification.from_pretrained('potatobunny/results-yelp', config=config)\n    inputs = tokenizer(review_text, return_tensors='pt')\n    outputs = model(**inputs)\n    sentiment = 'positive' if outputs.logits[0, 1] > outputs.logits[0, 0] else 'negative'\n    return sentiment\n\n# test_function_code --------------------\n\ndef test_analyze_review_sentiment():\n    \"\"\"\n    Test the analyze_review_sentiment function.\n    \"\"\"\n    positive_review = 'The food was delicious and the service was excellent.'\n    negative_review = 'The food was terrible and the service was poor.'\n    assert analyze_review_sentiment(positive_review) == 'positive'\n    assert analyze_review_sentiment(negative_review) == 'negative'\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    print(test_analyze_review_sentiment())", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n\n", "function_code": "# function_code --------------------\n\ndef analyze_review_sentiment(review_text):\n    \"\"\"\n    Analyze the sentiment of a restaurant review using a pre-trained model.\n\n    Args:\n        review_text (str): The text of the restaurant review.\n\n    Returns:\n        str: The sentiment of the review ('positive' or 'negative').\n\n    Raises:\n        OSError: If there is an error loading the pre-trained model or tokenizing the input text.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n    config = AutoConfig.from_pretrained('potatobunny/results-yelp')\n    model = AutoModelForSequenceClassification.from_pretrained('potatobunny/results-yelp', config=config)\n    inputs = tokenizer(review_text, return_tensors='pt')\n    outputs = model(**inputs)\n    sentiment = 'positive' if outputs.logits[0, 1] > outputs.logits[0, 0] else 'negative'\n    return sentiment\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_analyze_review_sentiment():\n    \"\"\"\n    Test the analyze_review_sentiment function.\n    \"\"\"\n    positive_review = 'The food was delicious and the service was excellent.'\n    negative_review = 'The food was terrible and the service was poor.'\n    assert analyze_review_sentiment(positive_review) == 'positive'\n    assert analyze_review_sentiment(negative_review) == 'negative'\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    print(test_analyze_review_sentiment())", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n\n# function_code --------------------\n\ndef analyze_review_sentiment(review_text):\n    \"\"\"\n    Analyze the sentiment of a restaurant review using a pre-trained model.\n\n    Args:\n        review_text (str): The text of the restaurant review.\n\n    Returns:\n        str: The sentiment of the review ('positive' or 'negative').\n\n    Raises:\n        OSError: If there is an error loading the pre-trained model or tokenizing the input text.\n    \"\"\"", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n    config = AutoConfig.from_pretrained('potatobunny/results-yelp')\n    model = AutoModelForSequenceClassification.from_pretrained('potatobunny/results-yelp', config=config)\n    inputs = tokenizer(review_text, return_tensors='pt')\n    outputs = model(**inputs)\n    sentiment = 'positive' if outputs.logits[0, 1] > outputs.logits[0, 0] else 'negative'\n    return sentiment\n\n", "prediction": "\n    \n    # Load pre-trained model --------------------\n    \n    try:\n        \n        # Download the pre-trained model from the Hugging Face Hub.\n        model_name = \"cardiffnlp/twitter_roberta_base_sentiment\"\n        config = AutoConfig.from_pretrained(model_name)\n    \n    except OSError:\n        \n        # Download the pre-trained model from the Hugging Face Hub.\n        model_name = \"cardiffnlp/twitter_roberta_base_sentiment\"\n        config = AutoConfig.from_pretrained(model_name)\n    \n    try:\n        \n        # Download the pre-trained model from the Hugging Face Hub.\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n    \n    except OSError:\n        \n        return \"Error: could not download the tokenizer for '{}'.\".format(review_text)\n    \n    try:\n        \n        # Download the pre-trained model from the Hugging Face Hub.\n        roberta = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n    \n    except OSError:\n            \n        return \"Error: could not download the model for '{}'.\".format(review_text)\n        \n    # Pre-process review --------------------\n    \n    try:\n                \n        # Tokenize the text using RoBERTa tokenizer, truncate to 512 tokens max.\n        inputs = roberta.encode(review_text, add_special_tokens=True)\n        \n        # Add [CLS] and [SEP] tokens at the beginning and end respectively.\n        input_ids = torch.LongTensor([tokenizer.cls_token_id] + inputs[:510] + [tokenizer.sep_token_id])\n    \n    except OSError:\n        \n        return \"Error: could not tokenize '{}'.\".format(review_text)\n            \n    # Predict the sentiment of the review --------------------\n    \n    # Put the model in evaluation mode.\n   "}