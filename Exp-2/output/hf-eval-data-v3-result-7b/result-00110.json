{"path": "output/hf-eval-data-v3-valid/f00472_estimate_human_pose.py", "content": "# function_import --------------------\n\nfrom PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import OpenposeDetector\nimport os\n\n# function_code --------------------\n\ndef estimate_human_pose(image_path: str, output_path: str) -> None:\n    \"\"\"\n    Estimate the human pose from an image of a user performing an exercise.\n\n    Args:\n        image_path (str): The path to the image file.\n        output_path (str): The path to save the output image with estimated pose.\n\n    Returns:\n        None\n    \"\"\"\n    openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n    image = Image.open(image_path)\n    image = openpose(image)\n\n    controlnet = ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-openpose', torch_dtype=torch.float16)\n    image = pipe('chef in the kitchen', image, num_inference_steps=20).images[0]\n    image.save(output_path)\n\n# test_function_code --------------------\n\ndef test_estimate_human_pose():\n    \"\"\"\n    Test the function estimate_human_pose.\n    \"\"\"\n    # Test case 1\n    estimate_human_pose('test_images/exercise1.jpg', 'test_output/pose1_out.png')\n    assert os.path.exists('test_output/pose1_out.png')\n\n    # Test case 2\n    estimate_human_pose('test_images/exercise2.jpg', 'test_output/pose2_out.png')\n    assert os.path.exists('test_output/pose2_out.png')\n\n    # Test case 3\n    estimate_human_pose('test_images/exercise3.jpg', 'test_output/pose3_out.png')\n    assert os.path.exists('test_output/pose3_out.png')\n\n    return 'All Tests Passed'\n\n# call_test_function_code --------------------\n\ntest_estimate_human_pose()", "function_import": "# function_import --------------------\n\nfrom PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import OpenposeDetector\nimport os\n\n", "function_code": "# function_code --------------------\n\ndef estimate_human_pose(image_path: str, output_path: str) -> None:\n    \"\"\"\n    Estimate the human pose from an image of a user performing an exercise.\n\n    Args:\n        image_path (str): The path to the image file.\n        output_path (str): The path to save the output image with estimated pose.\n\n    Returns:\n        None\n    \"\"\"\n    openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n    image = Image.open(image_path)\n    image = openpose(image)\n\n    controlnet = ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-openpose', torch_dtype=torch.float16)\n    image = pipe('chef in the kitchen', image, num_inference_steps=20).images[0]\n    image.save(output_path)\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_estimate_human_pose():\n    \"\"\"\n    Test the function estimate_human_pose.\n    \"\"\"\n    # Test case 1\n    estimate_human_pose('test_images/exercise1.jpg', 'test_output/pose1_out.png')\n    assert os.path.exists('test_output/pose1_out.png')\n\n    # Test case 2\n    estimate_human_pose('test_images/exercise2.jpg', 'test_output/pose2_out.png')\n    assert os.path.exists('test_output/pose2_out.png')\n\n    # Test case 3\n    estimate_human_pose('test_images/exercise3.jpg', 'test_output/pose3_out.png')\n    assert os.path.exists('test_output/pose3_out.png')\n\n    return 'All Tests Passed'\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\ntest_estimate_human_pose()", "instruct": "# function_import --------------------\n\nfrom PIL import Image\nfrom diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nimport torch\nfrom controlnet_aux import OpenposeDetector\nimport os\n\n# function_code --------------------\n\ndef estimate_human_pose(image_path: str, output_path: str) -> None:\n    \"\"\"\n    Estimate the human pose from an image of a user performing an exercise.\n\n    Args:\n        image_path (str): The path to the image file.\n        output_path (str): The path to save the output image with estimated pose.\n\n    Returns:\n        None\n    \"\"\"", "answer": "\n    openpose = OpenposeDetector.from_pretrained('lllyasviel/ControlNet')\n    image = Image.open(image_path)\n    image = openpose(image)\n\n    controlnet = ControlNetModel.from_pretrained('lllyasviel/sd-controlnet-openpose', torch_dtype=torch.float16)\n    image = pipe('chef in the kitchen', image, num_inference_steps=20).images[0]\n    image.save(output_path)\n\n", "prediction": "\n    detector = OpenposeDetector(\n        weights_dir='./weights/openpose/',\n        model_name=\"COCO\")\n    detections, image_rgb = detector.detect_humans(image_path)\n\n    ndet = len(detections[\"body\"][0])  # number of people detected\n\n    for i in range(ndet):\n        pose_keypoints = detections[\"body\"][i].tolist()\n        body_keypoints = torch.tensor([pose_keypoints]).float().to('cuda')\n        output_image = Image.fromarray(((image_rgb * 255 / image_rgb.max())[:, :, [2,1,0]]).astype(np.uint8))\n        draw_body(output_image, body_keypoints)\n        # save image\n        output_image.save(os.path.join(output_path,'{}_pose.png'.format(i)))\n\ndef main():\n    import argparse\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument('--image', help='Image path', type=str)\n    parser.add_argument('--output', help='Output dir', default='./data/results', type=str)\n    args = parser.parse_args()\n    \n    if not os.path.exists(args.output):\n        os.mkdir(args.output)\n        \n    estimate_human_pose(args.image, args.output)\n\n# main --------------------\nif __name__ == '__main__':\n    main()"}