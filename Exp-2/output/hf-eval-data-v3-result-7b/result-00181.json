{"path": "output/hf-eval-data-v3-valid/f00730_extract_features.py", "content": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# function_code --------------------\n\ndef extract_features(source_code_text):\n    \"\"\"\n    Extracts features from the given source code text using the 'microsoft/unixcoder-base' model.\n\n    Args:\n        source_code_text (str): The source code text to extract features from.\n\n    Returns:\n        torch.Tensor: The feature matrix derived as a matrix of embeddings.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/unixcoder-base')\n    model = AutoModel.from_pretrained('microsoft/unixcoder-base')\n    inputs = tokenizer(source_code_text, return_tensors='pt')\n    outputs = model(**inputs)\n    feature_matrix = outputs.last_hidden_state\n    return feature_matrix\n\n# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Tests the 'extract_features' function.\n    \"\"\"\n    source_code_text = '/* Your source code here */'\n    feature_matrix = extract_features(source_code_text)\n    assert isinstance(feature_matrix, torch.Tensor), 'The output should be a torch.Tensor.'\n    print('All Tests Passed')\n\n# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    test_extract_features()", "function_import": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\n\n", "function_code": "# function_code --------------------\n\ndef extract_features(source_code_text):\n    \"\"\"\n    Extracts features from the given source code text using the 'microsoft/unixcoder-base' model.\n\n    Args:\n        source_code_text (str): The source code text to extract features from.\n\n    Returns:\n        torch.Tensor: The feature matrix derived as a matrix of embeddings.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/unixcoder-base')\n    model = AutoModel.from_pretrained('microsoft/unixcoder-base')\n    inputs = tokenizer(source_code_text, return_tensors='pt')\n    outputs = model(**inputs)\n    feature_matrix = outputs.last_hidden_state\n    return feature_matrix\n\n", "test_function_code": "# test_function_code --------------------\n\ndef test_extract_features():\n    \"\"\"\n    Tests the 'extract_features' function.\n    \"\"\"\n    source_code_text = '/* Your source code here */'\n    feature_matrix = extract_features(source_code_text)\n    assert isinstance(feature_matrix, torch.Tensor), 'The output should be a torch.Tensor.'\n    print('All Tests Passed')\n\n", "call_test_function_code": "# call_test_function_code --------------------\n\nif __name__ == '__main__':\n    test_extract_features()", "instruct": "# function_import --------------------\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# function_code --------------------\n\ndef extract_features(source_code_text):\n    \"\"\"\n    Extracts features from the given source code text using the 'microsoft/unixcoder-base' model.\n\n    Args:\n        source_code_text (str): The source code text to extract features from.\n\n    Returns:\n        torch.Tensor: The feature matrix derived as a matrix of embeddings.\n    \"\"\"", "answer": "\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/unixcoder-base')\n    model = AutoModel.from_pretrained('microsoft/unixcoder-base')\n    inputs = tokenizer(source_code_text, return_tensors='pt')\n    outputs = model(**inputs)\n    feature_matrix = outputs.last_hidden_state\n    return feature_matrix\n\n", "prediction": "\n\n    # Setup\n    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")\n    model = AutoModel.from_pretrained(\"microsoft/unixcoder-base\").to(torch.device('cpu'))\n\n    # Preprocessing\n    inputs = tokenizer([source_code_text], return_tensors=\"pt\", padding=True)\n    \n    # Feature extraction\n    with torch.no_grad():\n        outputs = model(**inputs)[0].mean(dim=1).numpy()\n        \n    return outputs[0]"}