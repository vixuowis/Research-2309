2023-12-01 00:36:39.469293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-12-01 00:36:40.219857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'
  warnings.warn(
vocab.json:   0%|                                                                    | 0.00/899k [00:00<?, ?B/s]vocab.json: 100%|█████████████████████████████████████████████████████████████| 899k/899k [00:01<00:00, 586kB/s]vocab.json: 100%|█████████████████████████████████████████████████████████████| 899k/899k [00:01<00:00, 585kB/s]
merges.txt:   0%|                                                                    | 0.00/456k [00:00<?, ?B/s]merges.txt: 100%|████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 3.19MB/s]merges.txt: 100%|████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 3.17MB/s]
special_tokens_map.json:   0%|                                                        | 0.00/150 [00:00<?, ?B/s]special_tokens_map.json: 100%|██████████████████████████████████████████████████| 150/150 [00:00<00:00, 114kB/s]
config.json:   0%|                                                                    | 0.00/747 [00:00<?, ?B/s]config.json: 100%|██████████████████████████████████████████████████████████████| 747/747 [00:00<00:00, 820kB/s]
pytorch_model.bin:   0%|                                                             | 0.00/499M [00:00<?, ?B/s]pytorch_model.bin:   2%|█                                                   | 10.5M/499M [00:02<02:00, 4.04MB/s]pytorch_model.bin:   4%|██▏                                                 | 21.0M/499M [00:03<01:24, 5.63MB/s]pytorch_model.bin:   6%|███▎                                                | 31.5M/499M [00:05<01:16, 6.09MB/s]pytorch_model.bin:   8%|████▎                                               | 41.9M/499M [00:06<01:08, 6.67MB/s]pytorch_model.bin:  11%|█████▍                                              | 52.4M/499M [00:08<01:00, 7.33MB/s]pytorch_model.bin:  13%|██████▌                                             | 62.9M/499M [00:10<01:11, 6.11MB/s]pytorch_model.bin:  15%|███████▋                                            | 73.4M/499M [00:12<01:09, 6.09MB/s]pytorch_model.bin:  17%|████████▋                                           | 83.9M/499M [00:13<01:11, 5.82MB/s]pytorch_model.bin:  19%|█████████▊                                          | 94.4M/499M [00:15<01:01, 6.53MB/s]pytorch_model.bin:  21%|███████████▏                                         | 105M/499M [00:17<01:06, 5.89MB/s]pytorch_model.bin:  23%|████████████▎                                        | 115M/499M [00:18<01:01, 6.19MB/s]pytorch_model.bin:  25%|█████████████▎                                       | 126M/499M [00:20<00:58, 6.42MB/s]pytorch_model.bin:  27%|██████████████▍                                      | 136M/499M [00:21<00:55, 6.56MB/s]pytorch_model.bin:  29%|███████████████▌                                     | 147M/499M [00:23<00:52, 6.71MB/s]pytorch_model.bin:  32%|████████████████▋                                    | 157M/499M [00:24<00:51, 6.59MB/s]pytorch_model.bin:  34%|█████████████████▊                                   | 168M/499M [00:26<00:49, 6.71MB/s]pytorch_model.bin:  36%|██████████████████▉                                  | 178M/499M [00:28<00:53, 6.03MB/s]pytorch_model.bin:  38%|████████████████████                                 | 189M/499M [00:30<00:52, 5.92MB/s]pytorch_model.bin:  40%|█████████████████████▏                               | 199M/499M [00:32<00:53, 5.65MB/s]pytorch_model.bin:  42%|██████████████████████▎                              | 210M/499M [00:34<00:49, 5.81MB/s]pytorch_model.bin:  44%|███████████████████████▍                             | 220M/499M [00:35<00:47, 5.90MB/s]pytorch_model.bin:  46%|████████████████████████▌                            | 231M/499M [00:37<00:43, 6.12MB/s]pytorch_model.bin:  48%|█████████████████████████▋                           | 241M/499M [00:39<00:42, 6.12MB/s]pytorch_model.bin:  50%|██████████████████████████▋                          | 252M/499M [00:41<00:42, 5.87MB/s]pytorch_model.bin:  53%|███████████████████████████▊                         | 262M/499M [00:43<00:42, 5.60MB/s]pytorch_model.bin:  55%|████████████████████████████▉                        | 273M/499M [00:44<00:36, 6.25MB/s]pytorch_model.bin:  57%|██████████████████████████████                       | 283M/499M [00:46<00:33, 6.36MB/s]pytorch_model.bin:  59%|███████████████████████████████▏                     | 294M/499M [00:47<00:30, 6.65MB/s]pytorch_model.bin:  61%|████████████████████████████████▎                    | 304M/499M [00:49<00:29, 6.62MB/s]pytorch_model.bin:  63%|█████████████████████████████████▍                   | 315M/499M [00:51<00:30, 6.04MB/s]pytorch_model.bin:  65%|██████████████████████████████████▌                  | 325M/499M [00:53<00:31, 5.44MB/s]pytorch_model.bin:  67%|███████████████████████████████████▋                 | 336M/499M [00:55<00:28, 5.80MB/s]pytorch_model.bin:  69%|████████████████████████████████████▊                | 346M/499M [00:56<00:24, 6.12MB/s]pytorch_model.bin:  71%|█████████████████████████████████████▉               | 357M/499M [00:58<00:25, 5.65MB/s]pytorch_model.bin:  74%|███████████████████████████████████████              | 367M/499M [01:00<00:21, 6.15MB/s]pytorch_model.bin:  76%|████████████████████████████████████████             | 377M/499M [01:01<00:19, 6.15MB/s]pytorch_model.bin:  78%|█████████████████████████████████████████▏           | 388M/499M [01:03<00:17, 6.16MB/s]pytorch_model.bin:  80%|██████████████████████████████████████████▎          | 398M/499M [01:05<00:16, 5.93MB/s]pytorch_model.bin:  82%|███████████████████████████████████████████▍         | 409M/499M [01:07<00:15, 5.94MB/s]pytorch_model.bin:  84%|████████████████████████████████████████████▌        | 419M/499M [01:08<00:12, 6.19MB/s]pytorch_model.bin:  86%|█████████████████████████████████████████████▋       | 430M/499M [01:10<00:10, 6.40MB/s]pytorch_model.bin:  88%|██████████████████████████████████████████████▊      | 440M/499M [01:11<00:08, 6.61MB/s]pytorch_model.bin:  90%|███████████████████████████████████████████████▉     | 451M/499M [01:13<00:07, 6.60MB/s]pytorch_model.bin:  93%|█████████████████████████████████████████████████    | 461M/499M [01:15<00:06, 5.99MB/s]pytorch_model.bin:  95%|██████████████████████████████████████████████████▏  | 472M/499M [01:16<00:04, 6.34MB/s]pytorch_model.bin:  97%|███████████████████████████████████████████████████▎ | 482M/499M [01:18<00:02, 6.93MB/s]pytorch_model.bin:  99%|████████████████████████████████████████████████████▍| 493M/499M [01:19<00:00, 7.18MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 499M/499M [01:20<00:00, 7.26MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 499M/499M [01:20<00:00, 6.22MB/s]
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  warnings.warn(
Traceback (most recent call last):
  File "./f00489_analyze_stock_forum_sentiment.py", line 82, in <module>
    test_analyze_stock_forum_sentiment()
  File "./f00489_analyze_stock_forum_sentiment.py", line 74, in test_analyze_stock_forum_sentiment
    results = analyze_stock_forum_sentiment(forum_posts)
  File "./f00489_analyze_stock_forum_sentiment.py", line 62, in analyze_stock_forum_sentiment
    result = predict_sentiment(post)
  File "./f00489_analyze_stock_forum_sentiment.py", line 43, in predict_sentiment
    output = model(torch.tensor([input_ids]), torch.tensor([attention_mask]))
NameError: name 'torch' is not defined
