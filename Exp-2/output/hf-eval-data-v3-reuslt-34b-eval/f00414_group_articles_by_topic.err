.gitattributes:   0%|                                                                 | 0.00/523 [00:00<?, ?B/s].gitattributes: 100%|██████████████████████████████████████████████████████████| 523/523 [00:00<00:00, 99.0kB/s]
1_Pooling/config.json:   0%|                                                          | 0.00/190 [00:00<?, ?B/s]1_Pooling/config.json: 100%|███████████████████████████████████████████████████| 190/190 [00:00<00:00, 50.8kB/s]
README.md:   0%|                                                                    | 0.00/3.93k [00:00<?, ?B/s]README.md: 100%|███████████████████████████████████████████████████████████| 3.93k/3.93k [00:00<00:00, 3.64MB/s]
config.json:   0%|                                                                    | 0.00/539 [00:00<?, ?B/s]config.json: 100%|██████████████████████████████████████████████████████████████| 539/539 [00:00<00:00, 490kB/s]
config_sentence_transformers.json:   0%|                                              | 0.00/122 [00:00<?, ?B/s]config_sentence_transformers.json: 100%|████████████████████████████████████████| 122/122 [00:00<00:00, 117kB/s]
pytorch_model.bin:   0%|                                                             | 0.00/265M [00:00<?, ?B/s]pytorch_model.bin:   4%|██                                                  | 10.5M/265M [00:02<01:05, 3.87MB/s]pytorch_model.bin:   8%|████                                                | 21.0M/265M [00:03<00:36, 6.70MB/s]pytorch_model.bin:  12%|██████▏                                             | 31.5M/265M [00:04<00:26, 8.70MB/s]pytorch_model.bin:  16%|████████▏                                           | 41.9M/265M [00:05<00:25, 8.64MB/s]pytorch_model.bin:  20%|██████████▎                                         | 52.4M/265M [00:06<00:24, 8.72MB/s]pytorch_model.bin:  24%|████████████▎                                       | 62.9M/265M [00:07<00:23, 8.75MB/s]pytorch_model.bin:  28%|██████████████▍                                     | 73.4M/265M [00:08<00:20, 9.28MB/s]pytorch_model.bin:  32%|████████████████▍                                   | 83.9M/265M [00:11<00:26, 6.79MB/s]pytorch_model.bin:  32%|████████████████▍                                   | 83.9M/265M [00:25<00:26, 6.79MB/s]pytorch_model.bin:  36%|██████████████████▍                                 | 94.4M/265M [00:37<02:31, 1.13MB/s]pytorch_model.bin:  39%|████████████████████▉                                | 105M/265M [00:49<02:32, 1.05MB/s]pytorch_model.bin:  43%|███████████████████████                              | 115M/265M [00:56<02:10, 1.15MB/s]pytorch_model.bin:  47%|█████████████████████████                            | 126M/265M [01:02<01:49, 1.28MB/s]pytorch_model.bin:  51%|███████████████████████████▏                         | 136M/265M [01:07<01:27, 1.47MB/s]pytorch_model.bin:  55%|█████████████████████████████▎                       | 147M/265M [01:10<01:06, 1.79MB/s]pytorch_model.bin:  59%|███████████████████████████████▍                     | 157M/265M [01:13<00:52, 2.05MB/s]pytorch_model.bin:  63%|█████████████████████████████████▍                   | 168M/265M [01:16<00:42, 2.32MB/s]pytorch_model.bin:  67%|███████████████████████████████████▌                 | 178M/265M [01:19<00:34, 2.55MB/s]pytorch_model.bin:  71%|█████████████████████████████████████▋               | 189M/265M [01:22<00:27, 2.79MB/s]pytorch_model.bin:  75%|███████████████████████████████████████▊             | 199M/265M [01:25<00:22, 2.97MB/s]pytorch_model.bin:  79%|█████████████████████████████████████████▊           | 210M/265M [01:28<00:17, 3.24MB/s]pytorch_model.bin:  83%|███████████████████████████████████████████▉         | 220M/265M [01:31<00:13, 3.34MB/s]pytorch_model.bin:  87%|██████████████████████████████████████████████       | 231M/265M [01:33<00:10, 3.47MB/s]pytorch_model.bin:  91%|████████████████████████████████████████████████▏    | 241M/265M [01:36<00:06, 3.64MB/s]pytorch_model.bin:  95%|██████████████████████████████████████████████████▏  | 252M/265M [01:38<00:03, 3.74MB/s]pytorch_model.bin:  99%|████████████████████████████████████████████████████▎| 262M/265M [01:41<00:00, 3.98MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 265M/265M [01:41<00:00, 4.08MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 265M/265M [01:41<00:00, 2.61MB/s]
sentence_bert_config.json:   0%|                                                     | 0.00/53.0 [00:00<?, ?B/s]sentence_bert_config.json: 100%|█████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 16.8kB/s]
special_tokens_map.json:   0%|                                                        | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|██████████████████████████████████████████████████| 112/112 [00:00<00:00, 127kB/s]
tokenizer.json:   0%|                                                                | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|█████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 520kB/s]tokenizer.json: 100%|█████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 520kB/s]
tokenizer_config.json:   0%|                                                          | 0.00/489 [00:00<?, ?B/s]tokenizer_config.json: 100%|████████████████████████████████████████████████████| 489/489 [00:00<00:00, 573kB/s]
vocab.txt:   0%|                                                                     | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|█████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 1.58MB/s]vocab.txt: 100%|█████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 1.58MB/s]
modules.json:   0%|                                                                   | 0.00/229 [00:00<?, ?B/s]modules.json: 100%|█████████████████████████████████████████████████████████████| 229/229 [00:00<00:00, 256kB/s]
Batches:   0%|                                                                            | 0/1 [00:00<?, ?it/s]Batches: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.07it/s]Batches: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.07it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  super()._check_params_vs_input(X, default_n_init=10)
