tokenizer_config.json:   0%|                                                          | 0.00/411 [00:00<?, ?B/s]tokenizer_config.json: 100%|████████████████████████████████████████████████████| 411/411 [00:00<00:00, 114kB/s]
vocab.txt:   0%|                                                                    | 0.00/5.22M [00:00<?, ?B/s]vocab.txt: 100%|███████████████████████████████████████████████████████████| 5.22M/5.22M [00:04<00:00, 1.30MB/s]vocab.txt: 100%|███████████████████████████████████████████████████████████| 5.22M/5.22M [00:04<00:00, 1.30MB/s]
tokenizer.json:   0%|                                                               | 0.00/9.62M [00:00<?, ?B/s]tokenizer.json: 100%|██████████████████████████████████████████████████████| 9.62M/9.62M [00:06<00:00, 1.43MB/s]tokenizer.json: 100%|██████████████████████████████████████████████████████| 9.62M/9.62M [00:06<00:00, 1.42MB/s]
special_tokens_map.json:   0%|                                                        | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|█████████████████████████████████████████████████| 112/112 [00:00<00:00, 36.7kB/s]
pytorch_model.bin:   0%|                                                            | 0.00/1.88G [00:00<?, ?B/s]pytorch_model.bin:   1%|▎                                                 | 10.5M/1.88G [00:20<1:00:45, 514kB/s]pytorch_model.bin:   1%|▎                                                 | 10.5M/1.88G [00:34<1:00:45, 514kB/s]pytorch_model.bin:   1%|▌                                                 | 21.0M/1.88G [00:46<1:10:17, 442kB/s]pytorch_model.bin:   1%|▌                                                 | 21.0M/1.88G [01:04<1:10:17, 442kB/s]pytorch_model.bin:   2%|▊                                                 | 31.5M/1.88G [01:06<1:04:43, 477kB/s]pytorch_model.bin:   2%|▊                                                 | 31.5M/1.88G [01:24<1:04:43, 477kB/s]pytorch_model.bin:   2%|█                                                 | 41.9M/1.88G [01:31<1:08:30, 448kB/s]pytorch_model.bin:   2%|█                                                 | 41.9M/1.88G [01:44<1:08:30, 448kB/s]pytorch_model.bin:   3%|█▍                                                | 52.4M/1.88G [01:50<1:02:55, 485kB/s]pytorch_model.bin:   3%|█▍                                                | 52.4M/1.88G [02:04<1:02:55, 485kB/s]pytorch_model.bin:   3%|█▋                                                | 62.9M/1.88G [02:10<1:01:10, 496kB/s]pytorch_model.bin:   3%|█▋                                                | 62.9M/1.88G [02:24<1:01:10, 496kB/s]pytorch_model.bin:   4%|█▉                                                | 73.4M/1.88G [02:31<1:00:37, 498kB/s]pytorch_model.bin:   4%|█▉                                                | 73.4M/1.88G [02:44<1:00:37, 498kB/s]pytorch_model.bin:   4%|██▏                                               | 83.9M/1.88G [02:55<1:03:17, 474kB/s]pytorch_model.bin:   5%|██▌                                                 | 94.4M/1.88G [03:11<57:22, 520kB/s]pytorch_model.bin:   5%|██▌                                                 | 94.4M/1.88G [03:24<57:22, 520kB/s]pytorch_model.bin:   6%|██▉                                                  | 105M/1.88G [03:34<59:31, 498kB/s]pytorch_model.bin:   6%|██▉                                                  | 105M/1.88G [03:54<59:31, 498kB/s]pytorch_model.bin:   6%|███                                                | 115M/1.88G [04:02<1:04:31, 457kB/s]pytorch_model.bin:   6%|███                                                | 115M/1.88G [04:14<1:04:31, 457kB/s]pytorch_model.bin:   7%|███▍                                               | 126M/1.88G [04:40<1:17:39, 377kB/s]pytorch_model.bin:   7%|███▍                                               | 126M/1.88G [04:54<1:17:39, 377kB/s]pytorch_model.bin:   7%|███▋                                               | 136M/1.88G [05:03<1:12:30, 402kB/s]pytorch_model.bin:   7%|███▋                                               | 136M/1.88G [05:14<1:12:30, 402kB/s]pytorch_model.bin:   8%|███▉                                               | 147M/1.88G [05:30<1:13:22, 395kB/s]pytorch_model.bin:   8%|███▉                                               | 147M/1.88G [05:44<1:13:22, 395kB/s]pytorch_model.bin:   8%|████▎                                              | 157M/1.88G [05:54<1:10:07, 410kB/s]pytorch_model.bin:   8%|████▎                                              | 157M/1.88G [06:04<1:10:07, 410kB/s]pytorch_model.bin:   9%|████▌                                              | 168M/1.88G [06:10<1:02:01, 461kB/s]pytorch_model.bin:   9%|████▌                                              | 168M/1.88G [06:24<1:02:01, 461kB/s]pytorch_model.bin:   9%|████▊                                              | 178M/1.88G [06:34<1:02:48, 453kB/s]pytorch_model.bin:   9%|████▊                                              | 178M/1.88G [06:54<1:02:48, 453kB/s]pytorch_model.bin:  10%|█████                                              | 189M/1.88G [06:55<1:00:53, 464kB/s]pytorch_model.bin:  10%|█████                                              | 189M/1.88G [07:14<1:00:53, 464kB/s]pytorch_model.bin:  11%|█████▍                                             | 199M/1.88G [07:20<1:02:40, 448kB/s]pytorch_model.bin:  11%|█████▍                                             | 199M/1.88G [07:34<1:02:40, 448kB/s]pytorch_model.bin:  11%|█████▋                                             | 210M/1.88G [07:48<1:05:50, 424kB/s]pytorch_model.bin:  11%|█████▋                                             | 210M/1.88G [08:04<1:05:50, 424kB/s]pytorch_model.bin:  12%|█████▉                                             | 220M/1.88G [08:18<1:09:11, 401kB/s]pytorch_model.bin:  12%|█████▉                                             | 220M/1.88G [08:34<1:09:11, 401kB/s]pytorch_model.bin:  12%|██████▏                                            | 231M/1.88G [08:56<1:18:07, 353kB/s]pytorch_model.bin:  12%|██████▏                                            | 231M/1.88G [09:14<1:18:07, 353kB/s]pytorch_model.bin:  13%|██████▌                                            | 241M/1.88G [09:28<1:19:54, 343kB/s]pytorch_model.bin:  13%|██████▌                                            | 241M/1.88G [09:44<1:19:54, 343kB/s]pytorch_model.bin:  13%|██████▊                                            | 252M/1.88G [10:06<1:24:45, 321kB/s]pytorch_model.bin:  13%|██████▊                                            | 252M/1.88G [10:24<1:24:45, 321kB/s]pytorch_model.bin:  14%|███████                                            | 262M/1.88G [10:37<1:22:37, 327kB/s]pytorch_model.bin:  14%|███████                                            | 262M/1.88G [10:54<1:22:37, 327kB/s]pytorch_model.bin:  14%|███████▍                                           | 273M/1.88G [10:58<1:13:41, 364kB/s]pytorch_model.bin:  14%|███████▍                                           | 273M/1.88G [11:14<1:13:41, 364kB/s]pytorch_model.bin:  15%|███████▋                                           | 283M/1.88G [11:22<1:09:43, 383kB/s]pytorch_model.bin:  15%|███████▋                                           | 283M/1.88G [11:34<1:09:43, 383kB/s]pytorch_model.bin:  16%|███████▉                                           | 294M/1.88G [11:52<1:11:15, 372kB/s]pytorch_model.bin:  16%|███████▉                                           | 294M/1.88G [12:04<1:11:15, 372kB/s]pytorch_model.bin:  16%|████████▏                                          | 304M/1.88G [12:43<1:28:12, 298kB/s]pytorch_model.bin:  16%|████████▏                                          | 304M/1.88G [12:54<1:28:12, 298kB/s]pytorch_model.bin:  16%|████████▏                                          | 304M/1.88G [15:58<1:23:00, 317kB/s]
Traceback (most recent call last):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 712, in _error_catcher
    yield
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 833, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
urllib3.exceptions.IncompleteRead: IncompleteRead(313616011 bytes read, 1570169958 more expected)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 934, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 905, in read
    data = self._raw_read(amt)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 833, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 729, in _error_catcher
    raise ProtocolError(f"Connection broken: {e!r}", e) from e
urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(313616011 bytes read, 1570169958 more expected)', IncompleteRead(313616011 bytes read, 1570169958 more expected))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./f00004_extract_sentence_embeddings.py", line 54, in <module>
    test_extract_sentence_embeddings()
  File "./f00004_extract_sentence_embeddings.py", line 41, in test_extract_sentence_embeddings
    embedding1 = extract_sentence_embeddings(sentence1)
  File "./f00004_extract_sentence_embeddings.py", line 19, in extract_sentence_embeddings
    model = AutoModel.from_pretrained('sentence-transformers/LaBSE')
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 566, in from_pretrained
    return model_class.from_pretrained(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3057, in from_pretrained
    resolved_archive_file = cached_file(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 430, in cached_file
    resolved_file = hf_hub_download(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1461, in hf_hub_download
    http_get(
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 541, in http_get
    for chunk in r.iter_content(chunk_size=DOWNLOAD_CHUNK_SIZE):
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/requests/models.py", line 818, in generate
    raise ChunkedEncodingError(e)
requests.exceptions.ChunkedEncodingError: ('Connection broken: IncompleteRead(313616011 bytes read, 1570169958 more expected)', IncompleteRead(313616011 bytes read, 1570169958 more expected))
