tokenizer_config.json:   0%|                                                          | 0.00/505 [00:00<?, ?B/s]tokenizer_config.json: 100%|███████████████████████████████████████████████████| 505/505 [00:00<00:00, 99.9kB/s]
config.json:   0%|                                                                    | 0.00/555 [00:00<?, ?B/s]config.json: 100%|█████████████████████████████████████████████████████████████| 555/555 [00:00<00:00, 56.9kB/s]
vocab.txt:   0%|                                                                     | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 295kB/s]vocab.txt: 100%|██████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 294kB/s]
tokenizer.json:   0%|                                                                | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 1.11MB/s]tokenizer.json: 100%|████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 1.11MB/s]
special_tokens_map.json:   0%|                                                        | 0.00/112 [00:00<?, ?B/s]special_tokens_map.json: 100%|██████████████████████████████████████████████████| 112/112 [00:00<00:00, 106kB/s]
pytorch_model.bin:   0%|                                                             | 0.00/265M [00:00<?, ?B/s]pytorch_model.bin:   4%|██                                                  | 10.5M/265M [00:05<02:12, 1.92MB/s]pytorch_model.bin:   8%|████                                                | 21.0M/265M [00:06<01:11, 3.44MB/s]pytorch_model.bin:  12%|██████▏                                             | 31.5M/265M [00:08<00:55, 4.23MB/s]pytorch_model.bin:  16%|████████▏                                           | 41.9M/265M [00:10<00:43, 5.10MB/s]pytorch_model.bin:  20%|██████████▎                                         | 52.4M/265M [00:11<00:36, 5.84MB/s]pytorch_model.bin:  24%|████████████▎                                       | 62.9M/265M [00:13<00:38, 5.25MB/s]pytorch_model.bin:  28%|██████████████▍                                     | 73.4M/265M [00:15<00:33, 5.73MB/s]pytorch_model.bin:  32%|████████████████▍                                   | 83.9M/265M [00:16<00:30, 5.90MB/s]pytorch_model.bin:  36%|██████████████████▍                                 | 94.4M/265M [00:18<00:28, 6.05MB/s]pytorch_model.bin:  39%|████████████████████▉                                | 105M/265M [00:20<00:26, 5.97MB/s]pytorch_model.bin:  43%|███████████████████████                              | 115M/265M [00:21<00:24, 6.19MB/s]pytorch_model.bin:  47%|█████████████████████████                            | 126M/265M [00:23<00:22, 6.26MB/s]pytorch_model.bin:  51%|███████████████████████████▏                         | 136M/265M [00:25<00:22, 5.86MB/s]pytorch_model.bin:  55%|█████████████████████████████▎                       | 147M/265M [00:27<00:19, 5.99MB/s]pytorch_model.bin:  59%|███████████████████████████████▍                     | 157M/265M [00:28<00:17, 6.27MB/s]pytorch_model.bin:  63%|█████████████████████████████████▍                   | 168M/265M [00:29<00:14, 6.78MB/s]pytorch_model.bin:  67%|███████████████████████████████████▌                 | 178M/265M [00:31<00:13, 6.57MB/s]pytorch_model.bin:  71%|█████████████████████████████████████▋               | 189M/265M [00:33<00:11, 6.78MB/s]pytorch_model.bin:  75%|███████████████████████████████████████▊             | 199M/265M [00:34<00:09, 7.18MB/s]pytorch_model.bin:  79%|█████████████████████████████████████████▊           | 210M/265M [00:35<00:07, 7.02MB/s]pytorch_model.bin:  83%|███████████████████████████████████████████▉         | 220M/265M [00:37<00:05, 7.60MB/s]pytorch_model.bin:  87%|██████████████████████████████████████████████       | 231M/265M [00:38<00:04, 7.42MB/s]pytorch_model.bin:  91%|████████████████████████████████████████████████▏    | 241M/265M [00:40<00:03, 7.02MB/s]pytorch_model.bin:  95%|██████████████████████████████████████████████████▏  | 252M/265M [00:41<00:02, 6.80MB/s]pytorch_model.bin:  99%|████████████████████████████████████████████████████▎| 262M/265M [00:43<00:00, 6.46MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 265M/265M [00:44<00:00, 5.68MB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████| 265M/265M [00:44<00:00, 5.92MB/s]
Traceback (most recent call last):
  File "./f00173_generate_sentence_embeddings.py", line 54, in <module>
    test_generate_sentence_embeddings()
  File "./f00173_generate_sentence_embeddings.py", line 46, in test_generate_sentence_embeddings
    embeddings = generate_sentence_embeddings(sentences)
  File "./f00173_generate_sentence_embeddings.py", line 32, in generate_sentence_embeddings
    output = model(tokenized_sentence)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py", line 582, in forward
    self.warn_if_padding_and_no_attention_mask(input_ids, attention_mask)
  File "/root/autodl-tmp/conda-envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 4116, in warn_if_padding_and_no_attention_mask
    if self.config.pad_token_id in input_ids[:, [-1, 0]]:
IndexError: too many indices for tensor of dimension 1
