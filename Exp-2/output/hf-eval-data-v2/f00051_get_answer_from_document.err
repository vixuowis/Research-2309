Downloading (…)lve/main/config.json:   0%|                                 | 0.00/729 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|███████████████████████████| 729/729 [00:00<00:00, 107kB/s]
Downloading model.safetensors:   0%|                                      | 0.00/496M [00:00<?, ?B/s]Downloading model.safetensors:   2%|▌                            | 10.5M/496M [00:01<01:31, 5.33MB/s]Downloading model.safetensors:   4%|█▏                           | 21.0M/496M [00:02<00:51, 9.19MB/s]Downloading model.safetensors:   6%|█▊                           | 31.5M/496M [00:03<00:39, 11.7MB/s]Downloading model.safetensors:   8%|██▍                          | 41.9M/496M [00:03<00:33, 13.5MB/s]Downloading model.safetensors:  11%|███                          | 52.4M/496M [00:04<00:31, 14.0MB/s]Downloading model.safetensors:  13%|███▋                         | 62.9M/496M [00:05<00:36, 11.8MB/s]Downloading model.safetensors:  15%|████▎                        | 73.4M/496M [00:06<00:34, 12.2MB/s]Downloading model.safetensors:  17%|████▉                        | 83.9M/496M [00:07<00:32, 12.6MB/s]Downloading model.safetensors:  19%|█████▌                       | 94.4M/496M [00:07<00:30, 13.3MB/s]Downloading model.safetensors:  21%|██████▎                       | 105M/496M [00:08<00:29, 13.4MB/s]Downloading model.safetensors:  23%|██████▉                       | 115M/496M [00:09<00:28, 13.2MB/s]Downloading model.safetensors:  25%|███████▌                      | 126M/496M [00:10<00:26, 14.0MB/s]Downloading model.safetensors:  27%|████████▏                     | 136M/496M [00:10<00:24, 14.5MB/s]Downloading model.safetensors:  30%|████████▊                     | 147M/496M [00:11<00:23, 14.9MB/s]Downloading model.safetensors:  32%|█████████▌                    | 157M/496M [00:12<00:22, 15.4MB/s]Downloading model.safetensors:  34%|██████████▏                   | 168M/496M [00:12<00:21, 15.5MB/s]Downloading model.safetensors:  36%|██████████▊                   | 178M/496M [00:13<00:20, 15.7MB/s]Downloading model.safetensors:  38%|███████████▍                  | 189M/496M [00:14<00:24, 12.4MB/s]Downloading model.safetensors:  40%|████████████                  | 199M/496M [00:15<00:22, 13.0MB/s]Downloading model.safetensors:  42%|████████████▋                 | 210M/496M [00:16<00:21, 13.6MB/s]Downloading model.safetensors:  44%|█████████████▎                | 220M/496M [00:17<00:22, 12.3MB/s]Downloading model.safetensors:  46%|█████████████▉                | 231M/496M [00:17<00:20, 12.8MB/s]Downloading model.safetensors:  49%|██████████████▌               | 241M/496M [00:19<00:25, 9.82MB/s]Downloading model.safetensors:  51%|███████████████▏              | 252M/496M [00:20<00:26, 9.35MB/s]Downloading model.safetensors:  53%|███████████████▊              | 262M/496M [00:21<00:22, 10.2MB/s]Downloading model.safetensors:  55%|████████████████▍             | 273M/496M [00:22<00:20, 10.8MB/s]Downloading model.safetensors:  57%|█████████████████             | 283M/496M [00:23<00:18, 11.3MB/s]Downloading model.safetensors:  59%|█████████████████▋            | 294M/496M [00:23<00:17, 11.8MB/s]Downloading model.safetensors:  61%|██████████████████▍           | 304M/496M [00:24<00:15, 12.3MB/s]Downloading model.safetensors:  63%|███████████████████           | 315M/496M [00:25<00:16, 11.3MB/s]Downloading model.safetensors:  66%|███████████████████▋          | 325M/496M [00:26<00:15, 11.3MB/s]Downloading model.safetensors:  68%|████████████████████▎         | 336M/496M [00:28<00:18, 8.54MB/s]Downloading model.safetensors:  70%|████████████████████▉         | 346M/496M [00:29<00:17, 8.76MB/s]Downloading model.safetensors:  72%|█████████████████████▌        | 357M/496M [00:30<00:15, 8.87MB/s]Downloading model.safetensors:  74%|██████████████████████▏       | 367M/496M [00:31<00:12, 10.1MB/s]Downloading model.safetensors:  76%|██████████████████████▊       | 377M/496M [00:33<00:12, 9.26MB/s]Downloading model.safetensors:  78%|███████████████████████▍      | 388M/496M [00:33<00:10, 10.5MB/s]Downloading model.safetensors:  80%|████████████████████████      | 398M/496M [00:34<00:08, 11.3MB/s]Downloading model.safetensors:  82%|████████████████████████▋     | 409M/496M [00:35<00:07, 11.4MB/s]Downloading model.safetensors:  85%|█████████████████████████▎    | 419M/496M [00:36<00:06, 11.7MB/s]Downloading model.safetensors:  87%|█████████████████████████▉    | 430M/496M [00:37<00:05, 11.6MB/s]Downloading model.safetensors:  89%|██████████████████████████▌   | 440M/496M [00:38<00:04, 11.7MB/s]Downloading model.safetensors:  91%|███████████████████████████▎  | 451M/496M [00:38<00:03, 12.1MB/s]Downloading model.safetensors:  93%|███████████████████████████▉  | 461M/496M [00:39<00:02, 12.6MB/s]Downloading model.safetensors:  95%|████████████████████████████▌ | 472M/496M [00:40<00:01, 13.1MB/s]Downloading model.safetensors:  97%|█████████████████████████████▏| 482M/496M [00:40<00:01, 13.6MB/s]Downloading model.safetensors:  99%|█████████████████████████████▊| 493M/496M [00:41<00:00, 14.2MB/s]Downloading model.safetensors: 100%|██████████████████████████████| 496M/496M [00:41<00:00, 14.4MB/s]Downloading model.safetensors: 100%|██████████████████████████████| 496M/496M [00:41<00:00, 11.9MB/s]
Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2-distilled and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00051_get_answer_from_document.py", line 38, in <module>
    test_get_answer_from_document()
  File "output/hf-eval-data-v2/f00051_get_answer_from_document.py", line 33, in test_get_answer_from_document
    answer = get_answer_from_document(context, question)
  File "output/hf-eval-data-v2/f00051_get_answer_from_document.py", line 20, in get_answer_from_document
    qa_pipeline = pipeline('question-answering', model=qa_model)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 904, in pipeline
    raise Exception(
Exception: Impossible to guess which tokenizer to use. Please provide a PreTrainedTokenizer class or a path/identifier to a pretrained tokenizer.
