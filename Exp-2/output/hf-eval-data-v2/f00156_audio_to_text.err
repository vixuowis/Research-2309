Downloading (…)rocessor_config.json:   0%|                                 | 0.00/159 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|██████████████████████████| 159/159 [00:00<00:00, 11.4kB/s]
Downloading (…)okenizer_config.json:   0%|                                 | 0.00/163 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|██████████████████████████| 163/163 [00:00<00:00, 42.5kB/s]
Downloading (…)lve/main/config.json:   0%|                               | 0.00/1.60k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|██████████████████████| 1.60k/1.60k [00:00<00:00, 2.15MB/s]
Downloading (…)olve/main/vocab.json:   0%|                                 | 0.00/291 [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|███████████████████████████| 291/291 [00:00<00:00, 468kB/s]
Downloading (…)cial_tokens_map.json:   0%|                                | 0.00/85.0 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|█████████████████████████| 85.0/85.0 [00:00<00:00, 139kB/s]
Downloading model.safetensors:   0%|                                      | 0.00/378M [00:00<?, ?B/s]Downloading model.safetensors:   3%|▊                             | 10.5M/378M [00:11<06:49, 896kB/s]Downloading model.safetensors:   3%|▊                             | 10.5M/378M [00:23<06:49, 896kB/s]Downloading model.safetensors:   6%|█▋                            | 21.0M/378M [01:08<21:31, 276kB/s]Downloading model.safetensors:   6%|█▋                            | 21.0M/378M [01:23<21:31, 276kB/s]Downloading model.safetensors:   8%|██▍                           | 31.5M/378M [03:21<44:49, 129kB/s]Downloading model.safetensors:   8%|██▍                           | 31.5M/378M [03:33<44:49, 129kB/s]Downloading model.safetensors:  11%|███▎                          | 41.9M/378M [05:35<54:39, 102kB/s]Downloading model.safetensors:  14%|████▏                         | 52.4M/378M [05:45<35:39, 152kB/s]Downloading model.safetensors:  17%|████▉                         | 62.9M/378M [05:51<23:46, 221kB/s]Downloading model.safetensors:  19%|█████▊                        | 73.4M/378M [05:57<16:21, 310kB/s]Downloading model.safetensors:  22%|██████▋                       | 83.9M/378M [06:04<11:49, 414kB/s]Downloading model.safetensors:  25%|███████▍                      | 94.4M/378M [06:07<08:21, 564kB/s]Downloading model.safetensors:  28%|████████▌                      | 105M/378M [06:16<06:43, 676kB/s]Downloading model.safetensors:  31%|█████████▍                     | 115M/378M [06:26<05:44, 762kB/s]Downloading model.safetensors:  33%|██████████▎                    | 126M/378M [06:34<04:48, 873kB/s]Downloading model.safetensors:  36%|███████████▏                   | 136M/378M [06:46<04:36, 872kB/s]Downloading model.safetensors:  39%|████████████                   | 147M/378M [06:54<04:00, 961kB/s]Downloading model.safetensors:  42%|████████████▍                 | 157M/378M [07:03<03:35, 1.02MB/s]Downloading model.safetensors:  44%|█████████████▎                | 168M/378M [07:12<03:15, 1.07MB/s]Downloading model.safetensors:  47%|██████████████▏               | 178M/378M [07:22<03:09, 1.05MB/s]Downloading model.safetensors:  47%|██████████████▏               | 178M/378M [07:33<03:09, 1.05MB/s]Downloading model.safetensors:  50%|███████████████▍               | 189M/378M [07:34<03:10, 991kB/s]Downloading model.safetensors:  53%|████████████████▎              | 199M/378M [07:46<03:06, 956kB/s]Downloading model.safetensors:  56%|████████████████▋             | 210M/378M [07:54<02:39, 1.05MB/s]Downloading model.safetensors:  58%|█████████████████▍            | 220M/378M [08:00<02:11, 1.20MB/s]Downloading model.safetensors:  61%|██████████████████▎           | 231M/378M [08:05<01:50, 1.33MB/s]Downloading model.safetensors:  64%|███████████████████▏          | 241M/378M [08:13<01:42, 1.33MB/s]Downloading model.safetensors:  67%|███████████████████▉          | 252M/378M [08:24<01:44, 1.20MB/s]Downloading model.safetensors:  69%|████████████████████▊         | 262M/378M [08:25<01:11, 1.61MB/s]Downloading model.safetensors:  72%|█████████████████████▋        | 273M/378M [08:26<00:48, 2.16MB/s]Downloading model.safetensors:  75%|██████████████████████▍       | 283M/378M [08:28<00:34, 2.71MB/s]Downloading model.safetensors:  78%|███████████████████████▎      | 294M/378M [08:30<00:26, 3.16MB/s]Downloading model.safetensors:  81%|████████████████████████▏     | 304M/378M [08:31<00:17, 4.16MB/s]Downloading model.safetensors:  83%|████████████████████████▉     | 315M/378M [08:31<00:11, 5.30MB/s]Downloading model.safetensors:  86%|█████████████████████████▊    | 325M/378M [08:32<00:08, 6.55MB/s]Downloading model.safetensors:  89%|██████████████████████████▋   | 336M/378M [08:33<00:05, 7.97MB/s]Downloading model.safetensors:  92%|███████████████████████████▍  | 346M/378M [08:33<00:03, 8.83MB/s]Downloading model.safetensors:  94%|████████████████████████████▎ | 357M/378M [08:34<00:02, 10.2MB/s]Downloading model.safetensors:  97%|█████████████████████████████▏| 367M/378M [08:35<00:00, 11.4MB/s]Downloading model.safetensors: 100%|█████████████████████████████▉| 377M/378M [08:36<00:00, 10.7MB/s]Downloading model.safetensors: 100%|███████████████████████████████| 378M/378M [08:36<00:00, 731kB/s]
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Downloading builder script:   0%|                                        | 0.00/5.16k [00:00<?, ?B/s]Downloading builder script: 100%|███████████████████████████████| 5.16k/5.16k [00:00<00:00, 9.53MB/s]
HF google storage unreachable. Downloading and preparing it from source
Downloading data files:   0%|                                                  | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 3360.82it/s]
Extracting data files:   0%|                                                   | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00, 1195.98it/s]
Generating validation split: 0 examples [00:00, ? examples/s]Generating validation split: 0 examples [00:00, ? examples/s]
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/audio.py", line 91, in encode_example
    import soundfile as sf  # soundfile is a dependency of librosa, needed to decode audio files.
ModuleNotFoundError: No module named 'soundfile'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1693, in _prepare_split_single
    example = self.info.features.encode_example(record) if self.info.features is not None else record
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1852, in encode_example
    return encode_nested_example(self, example)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1229, in encode_nested_example
    {
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1230, in <dictcomp>
    k: encode_nested_example(sub_schema, sub_obj, level=level + 1)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/features.py", line 1284, in encode_nested_example
    return schema.encode_example(obj) if obj is not None else None
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/features/audio.py", line 93, in encode_example
    raise ImportError("To support encoding audio data, please install 'soundfile'.") from err
ImportError: To support encoding audio data, please install 'soundfile'.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00156_audio_to_text.py", line 53, in <module>
    test_audio_to_text()
  File "output/hf-eval-data-v2/f00156_audio_to_text.py", line 46, in test_audio_to_text
    transcription = audio_to_text(sample_audio_file)
  File "output/hf-eval-data-v2/f00156_audio_to_text.py", line 24, in audio_to_text
    ds = load_dataset('patrickvonplaten/librispeech_asr_dummy', 'clean', split='validation')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/load.py", line 2153, in load_dataset
    builder_instance.download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 954, in download_and_prepare
    self._download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1717, in _download_and_prepare
    super()._download_and_prepare(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1049, in _download_and_prepare
    self._prepare_split(split_generator, **prepare_split_kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1555, in _prepare_split
    for job_id, done, content in self._prepare_split_single(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/datasets/builder.py", line 1712, in _prepare_split_single
    raise DatasetGenerationError("An error occurred while generating the dataset") from e
datasets.builder.DatasetGenerationError: An error occurred while generating the dataset
