/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Downloading (…)lve/main/config.json:   0%|                                 | 0.00/870 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|███████████████████████████| 870/870 [00:00<00:00, 167kB/s]
Downloading pytorch_model.bin:   0%|                                      | 0.00/268M [00:00<?, ?B/s]Downloading pytorch_model.bin:   4%|█▏                           | 10.5M/268M [00:01<00:42, 6.08MB/s]Downloading pytorch_model.bin:   8%|██▎                          | 21.0M/268M [00:02<00:24, 10.1MB/s]Downloading pytorch_model.bin:  12%|███▍                         | 31.5M/268M [00:03<00:20, 11.8MB/s]Downloading pytorch_model.bin:  16%|████▌                        | 41.9M/268M [00:03<00:17, 12.9MB/s]Downloading pytorch_model.bin:  20%|█████▋                       | 52.4M/268M [00:04<00:15, 14.1MB/s]Downloading pytorch_model.bin:  23%|██████▊                      | 62.9M/268M [00:05<00:14, 14.4MB/s]Downloading pytorch_model.bin:  27%|███████▉                     | 73.4M/268M [00:05<00:13, 14.5MB/s]Downloading pytorch_model.bin:  31%|█████████                    | 83.9M/268M [00:06<00:13, 14.0MB/s]Downloading pytorch_model.bin:  35%|██████████▏                  | 94.4M/268M [00:07<00:12, 13.9MB/s]Downloading pytorch_model.bin:  39%|███████████▋                  | 105M/268M [00:07<00:11, 14.7MB/s]Downloading pytorch_model.bin:  43%|████████████▉                 | 115M/268M [00:08<00:10, 14.4MB/s]Downloading pytorch_model.bin:  47%|██████████████                | 126M/268M [00:09<00:09, 15.0MB/s]Downloading pytorch_model.bin:  51%|███████████████▎              | 136M/268M [00:10<00:08, 14.8MB/s]Downloading pytorch_model.bin:  55%|████████████████▍             | 147M/268M [00:11<00:09, 13.0MB/s]Downloading pytorch_model.bin:  59%|█████████████████▌            | 157M/268M [00:13<00:12, 8.94MB/s]Downloading pytorch_model.bin:  63%|██████████████████▊           | 168M/268M [00:14<00:10, 9.23MB/s]Downloading pytorch_model.bin:  67%|███████████████████▉          | 178M/268M [00:15<00:09, 9.72MB/s]Downloading pytorch_model.bin:  70%|█████████████████████▏        | 189M/268M [00:16<00:09, 8.49MB/s]Downloading pytorch_model.bin:  74%|██████████████████████▎       | 199M/268M [00:18<00:08, 7.76MB/s]Downloading pytorch_model.bin:  78%|███████████████████████▍      | 210M/268M [00:19<00:07, 7.40MB/s]Downloading pytorch_model.bin:  82%|████████████████████████▋     | 220M/268M [00:21<00:06, 7.03MB/s]Downloading pytorch_model.bin:  86%|█████████████████████████▊    | 231M/268M [00:23<00:05, 7.03MB/s]Downloading pytorch_model.bin:  90%|███████████████████████████   | 241M/268M [00:24<00:03, 7.30MB/s]Downloading pytorch_model.bin:  94%|████████████████████████████▏ | 252M/268M [00:26<00:02, 6.86MB/s]Downloading pytorch_model.bin:  98%|█████████████████████████████▎| 262M/268M [00:27<00:00, 7.38MB/s]Downloading pytorch_model.bin: 100%|██████████████████████████████| 268M/268M [00:27<00:00, 7.65MB/s]Downloading pytorch_model.bin: 100%|██████████████████████████████| 268M/268M [00:27<00:00, 9.60MB/s]
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:640: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
Downloading (…)okenizer_config.json:   0%|                                 | 0.00/317 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|███████████████████████████| 317/317 [00:00<00:00, 274kB/s]
Downloading (…)solve/main/vocab.txt:   0%|                                | 0.00/232k [00:00<?, ?B/s]Downloading (…)solve/main/vocab.txt: 100%|█████████████████████████| 232k/232k [00:00<00:00, 424kB/s]Downloading (…)solve/main/vocab.txt: 100%|█████████████████████████| 232k/232k [00:00<00:00, 424kB/s]
Downloading (…)/main/tokenizer.json:   0%|                                | 0.00/466k [00:00<?, ?B/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████| 466k/466k [00:00<00:00, 1.28MB/s]Downloading (…)/main/tokenizer.json: 100%|████████████████████████| 466k/466k [00:00<00:00, 1.27MB/s]
Downloading (…)cial_tokens_map.json:   0%|                                 | 0.00/112 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|███████████████████████████| 112/112 [00:00<00:00, 120kB/s]
Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00292_detect_gibberish.py", line 34, in <module>
    test_detect_gibberish()
  File "output/hf-eval-data-v2/f00292_detect_gibberish.py", line 29, in test_detect_gibberish
    assert detect_gibberish('I love AutoNLP') == False
AssertionError
