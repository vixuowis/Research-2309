Downloading (…)lve/main/config.json:   0%|                                 | 0.00/473 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|███████████████████████████| 473/473 [00:00<00:00, 110kB/s]
Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00212_get_answer.py", line 36, in <module>
    test_get_answer()
  File "output/hf-eval-data-v2/f00212_get_answer.py", line 30, in test_get_answer
    answer = get_answer(context, question)
  File "output/hf-eval-data-v2/f00212_get_answer.py", line 18, in get_answer
    qa_pipeline = pipeline('question-answering', model='philschmid/distilbert-onnx')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 824, in pipeline
    framework, model = infer_framework_load_model(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 282, in infer_framework_load_model
    raise ValueError(
ValueError: Could not load model philschmid/distilbert-onnx with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForQuestionAnswering'>, <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForQuestionAnswering'>). See the original errors:

while loading with AutoModelForQuestionAnswering, an error is thrown:
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 269, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2834, in from_pretrained
    raise EnvironmentError(
OSError: philschmid/distilbert-onnx does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with DistilBertForQuestionAnswering, an error is thrown:
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 269, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2834, in from_pretrained
    raise EnvironmentError(
OSError: philschmid/distilbert-onnx does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



