Downloading (…)lve/main/config.json:   0%|                                 | 0.00/955 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|███████████████████████████| 955/955 [00:00<00:00, 208kB/s]
Downloading pytorch_model.bin:   0%|                                      | 0.00/245M [00:00<?, ?B/s]Downloading pytorch_model.bin:   4%|█▏                           | 10.5M/245M [00:09<03:22, 1.16MB/s]Downloading pytorch_model.bin:   9%|██▌                           | 21.0M/245M [00:23<04:25, 845kB/s]Downloading pytorch_model.bin:   9%|██▌                           | 21.0M/245M [00:36<04:25, 845kB/s]Downloading pytorch_model.bin:  13%|███▊                          | 31.5M/245M [00:43<05:22, 664kB/s]Downloading pytorch_model.bin:  13%|███▊                          | 31.5M/245M [00:56<05:22, 664kB/s]Downloading pytorch_model.bin:  17%|█████▏                        | 41.9M/245M [01:15<07:07, 475kB/s]Downloading pytorch_model.bin:  17%|█████▏                        | 41.9M/245M [01:26<07:07, 475kB/s]Downloading pytorch_model.bin:  21%|██████▍                       | 52.4M/245M [01:53<08:29, 378kB/s]Downloading pytorch_model.bin:  21%|██████▍                       | 52.4M/245M [02:06<08:29, 378kB/s]Downloading pytorch_model.bin:  26%|███████▋                      | 62.9M/245M [02:42<10:12, 298kB/s]Downloading pytorch_model.bin:  26%|███████▋                      | 62.9M/245M [02:56<10:12, 298kB/s]Downloading pytorch_model.bin:  26%|███████▋                      | 62.9M/245M [03:13<09:21, 324kB/s]
Downloading pytorch_model.bin:   0%|                                      | 0.00/245M [00:00<?, ?B/s]Downloading pytorch_model.bin:   4%|█▎                            | 10.5M/245M [00:34<12:53, 303kB/s]Downloading pytorch_model.bin:   4%|█▎                            | 10.5M/245M [00:45<12:53, 303kB/s]Downloading pytorch_model.bin:   4%|█▎                            | 10.5M/245M [01:06<24:55, 157kB/s]
Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00106_estimate_depth.py", line 42, in <module>
    test_estimate_depth()
  File "output/hf-eval-data-v2/f00106_estimate_depth.py", line 37, in test_estimate_depth
    result = estimate_depth(test_image_path)
  File "output/hf-eval-data-v2/f00106_estimate_depth.py", line 20, in estimate_depth
    depth_estimator = pipeline('depth-estimation', model='sayakpaul/glpn-nyu-finetuned-diode-221221-102136')
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 824, in pipeline
    framework, model = infer_framework_load_model(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 282, in infer_framework_load_model
    raise ValueError(
ValueError: Could not load model sayakpaul/glpn-nyu-finetuned-diode-221221-102136 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForDepthEstimation'>, <class 'transformers.models.glpn.modeling_glpn.GLPNForDepthEstimation'>). See the original errors:

while loading with AutoModelForDepthEstimation, an error is thrown:
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 710, in _error_catcher
    yield
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 835, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
urllib3.exceptions.IncompleteRead: IncompleteRead(68022884 bytes read, 177189509 more expected)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 940, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 911, in read
    data = self._raw_read(amt)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 835, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/root/miniconda3/envs/py38/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 727, in _error_catcher
    raise ProtocolError(f"Connection broken: {e!r}", e) from e
urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(68022884 bytes read, 177189509 more expected)', IncompleteRead(68022884 bytes read, 177189509 more expected))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 269, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2793, in from_pretrained
    resolved_archive_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1429, in hf_hub_download
    http_get(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 551, in http_get
    for chunk in r.iter_content(chunk_size=10 * 1024 * 1024):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 818, in generate
    raise ChunkedEncodingError(e)
requests.exceptions.ChunkedEncodingError: ('Connection broken: IncompleteRead(68022884 bytes read, 177189509 more expected)', IncompleteRead(68022884 bytes read, 177189509 more expected))

while loading with GLPNForDepthEstimation, an error is thrown:
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 710, in _error_catcher
    yield
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 814, in _raw_read
    data = self._fp_read(amt) if not fp_closed else b""
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 799, in _fp_read
    return self._fp.read(amt) if amt is not None else self._fp.read()
  File "/root/miniconda3/envs/py38/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/root/miniconda3/envs/py38/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/root/miniconda3/envs/py38/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/root/miniconda3/envs/py38/lib/python3.8/ssl.py", line 1274, in recv_into
    return self.read(nbytes, buffer)
  File "/root/miniconda3/envs/py38/lib/python3.8/ssl.py", line 1132, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 940, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 879, in read
    data = self._raw_read(amt)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 835, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/root/miniconda3/envs/py38/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/urllib3/response.py", line 715, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.") from e  # type: ignore[arg-type]
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 269, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2793, in from_pretrained
    resolved_archive_file = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1429, in hf_hub_download
    http_get(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 551, in http_get
    for chunk in r.iter_content(chunk_size=10 * 1024 * 1024):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/requests/models.py", line 822, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.



