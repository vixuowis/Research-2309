Downloading (…)lve/main/config.json:   0%|                                   | 0.00/31.3k [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|███████████████████████████| 31.3k/31.3k [00:00<00:00, 169kB/s]Downloading (…)lve/main/config.json: 100%|███████████████████████████| 31.3k/31.3k [00:00<00:00, 169kB/s]
Downloading pytorch_model.bin:   0%|                                          | 0.00/546M [00:00<?, ?B/s]Downloading pytorch_model.bin:   2%|▋                                 | 10.5M/546M [00:10<09:06, 980kB/s]Downloading pytorch_model.bin:   4%|█▎                                | 21.0M/546M [00:22<09:26, 927kB/s]Downloading pytorch_model.bin:   4%|█▎                                | 21.0M/546M [00:36<09:26, 927kB/s]Downloading pytorch_model.bin:   6%|█▉                                | 31.5M/546M [00:38<11:12, 765kB/s]Downloading pytorch_model.bin:   6%|█▉                                | 31.5M/546M [00:56<11:12, 765kB/s]Downloading pytorch_model.bin:   8%|██▌                               | 41.9M/546M [00:57<12:29, 673kB/s]Downloading pytorch_model.bin:  10%|███▎                              | 52.4M/546M [01:14<12:41, 648kB/s]Downloading pytorch_model.bin:  10%|███▎                              | 52.4M/546M [01:26<12:41, 648kB/s]Downloading pytorch_model.bin:  12%|███▉                              | 62.9M/546M [01:28<11:50, 680kB/s]Downloading pytorch_model.bin:  13%|████▌                             | 73.4M/546M [01:44<11:39, 675kB/s]Downloading pytorch_model.bin:  13%|████▌                             | 73.4M/546M [01:56<11:39, 675kB/s]Downloading pytorch_model.bin:  15%|█████▏                            | 83.9M/546M [02:00<11:36, 664kB/s]Downloading pytorch_model.bin:  15%|█████▏                            | 83.9M/546M [02:16<11:36, 664kB/s]Downloading pytorch_model.bin:  15%|█████▏                            | 83.9M/546M [02:33<14:06, 546kB/s]
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 4e74f585-bb74-4941-b4e7-28224d966a59)')' thrown while requesting HEAD https://huggingface.co/azwierzc/vilt-b32-finetuned-vqa-pl/resolve/main/config.json
Downloading pytorch_model.bin:   0%|                                          | 0.00/546M [00:00<?, ?B/s]Downloading pytorch_model.bin:   2%|▋                                | 10.5M/546M [00:07<06:35, 1.35MB/s]Downloading pytorch_model.bin:   4%|█▎                               | 21.0M/546M [00:15<06:34, 1.33MB/s]Downloading pytorch_model.bin:   6%|█▉                               | 31.5M/546M [00:19<04:43, 1.81MB/s]Downloading pytorch_model.bin:   8%|██▌                              | 41.9M/546M [00:20<03:20, 2.51MB/s]Downloading pytorch_model.bin:  10%|███▏                             | 52.4M/546M [00:21<02:25, 3.39MB/s]Downloading pytorch_model.bin:  12%|███▊                             | 62.9M/546M [00:22<01:50, 4.36MB/s]Downloading pytorch_model.bin:  13%|████▍                            | 73.4M/546M [00:23<01:25, 5.50MB/s]Downloading pytorch_model.bin:  15%|█████                            | 83.9M/546M [00:24<01:08, 6.76MB/s]Downloading pytorch_model.bin:  17%|█████▋                           | 94.4M/546M [00:25<00:55, 8.12MB/s]Downloading pytorch_model.bin:  19%|██████▌                           | 105M/546M [00:26<00:46, 9.48MB/s]Downloading pytorch_model.bin:  21%|███████▏                          | 115M/546M [00:26<00:42, 10.2MB/s]Downloading pytorch_model.bin:  23%|███████▊                          | 126M/546M [00:28<00:43, 9.74MB/s]Downloading pytorch_model.bin:  25%|████████▍                         | 136M/546M [00:28<00:37, 10.9MB/s]Downloading pytorch_model.bin:  27%|█████████▏                        | 147M/546M [00:29<00:33, 12.0MB/s]Downloading pytorch_model.bin:  29%|█████████▊                        | 157M/546M [00:30<00:30, 12.7MB/s]Downloading pytorch_model.bin:  31%|██████████▍                       | 168M/546M [00:30<00:28, 13.5MB/s]Downloading pytorch_model.bin:  33%|███████████                       | 178M/546M [00:31<00:28, 13.1MB/s]Downloading pytorch_model.bin:  35%|███████████▊                      | 189M/546M [00:32<00:25, 13.8MB/s]Downloading pytorch_model.bin:  37%|████████████▍                     | 199M/546M [00:33<00:24, 14.2MB/s]Downloading pytorch_model.bin:  38%|█████████████                     | 210M/546M [00:33<00:24, 13.6MB/s]Downloading pytorch_model.bin:  40%|█████████████▋                    | 220M/546M [00:34<00:22, 14.2MB/s]Downloading pytorch_model.bin:  42%|██████████████▎                   | 231M/546M [00:35<00:22, 13.9MB/s]Downloading pytorch_model.bin:  44%|███████████████                   | 241M/546M [00:36<00:23, 13.2MB/s]Downloading pytorch_model.bin:  46%|███████████████▋                  | 252M/546M [00:37<00:23, 12.7MB/s]Downloading pytorch_model.bin:  48%|████████████████▎                 | 262M/546M [00:38<00:26, 10.9MB/s]Downloading pytorch_model.bin:  50%|████████████████▉                 | 273M/546M [00:39<00:24, 11.0MB/s]Downloading pytorch_model.bin:  52%|█████████████████▋                | 283M/546M [00:44<00:58, 4.51MB/s]Downloading pytorch_model.bin:  54%|██████████████████▎               | 294M/546M [00:46<00:51, 4.88MB/s]Downloading pytorch_model.bin:  56%|██████████████████▉               | 304M/546M [00:48<00:44, 5.44MB/s]Downloading pytorch_model.bin:  58%|███████████████████▌              | 315M/546M [00:49<00:40, 5.65MB/s]Downloading pytorch_model.bin:  60%|████████████████████▎             | 325M/546M [00:51<00:37, 5.94MB/s]Downloading pytorch_model.bin:  61%|████████████████████▉             | 336M/546M [00:52<00:31, 6.57MB/s]Downloading pytorch_model.bin:  63%|█████████████████████▌            | 346M/546M [00:53<00:26, 7.43MB/s]Downloading pytorch_model.bin:  65%|██████████████████████▏           | 357M/546M [00:54<00:25, 7.53MB/s]Downloading pytorch_model.bin:  67%|██████████████████████▊           | 367M/546M [00:56<00:23, 7.50MB/s]Downloading pytorch_model.bin:  69%|███████████████████████▌          | 377M/546M [00:57<00:20, 8.05MB/s]Downloading pytorch_model.bin:  71%|████████████████████████▏         | 388M/546M [00:58<00:18, 8.33MB/s]Downloading pytorch_model.bin:  73%|████████████████████████▊         | 398M/546M [00:59<00:17, 8.48MB/s]Downloading pytorch_model.bin:  75%|█████████████████████████▍        | 409M/546M [01:01<00:17, 7.87MB/s]Downloading pytorch_model.bin:  77%|██████████████████████████▏       | 419M/546M [01:04<00:24, 5.19MB/s]Downloading pytorch_model.bin:  79%|██████████████████████████▊       | 430M/546M [01:13<00:44, 2.63MB/s]Downloading pytorch_model.bin:  81%|███████████████████████████▍      | 440M/546M [01:18<00:43, 2.43MB/s]Downloading pytorch_model.bin:  83%|████████████████████████████      | 451M/546M [01:22<00:37, 2.53MB/s]Downloading pytorch_model.bin:  85%|████████████████████████████▋     | 461M/546M [01:26<00:34, 2.45MB/s]Downloading pytorch_model.bin:  86%|█████████████████████████████▍    | 472M/546M [01:30<00:29, 2.54MB/s]Downloading pytorch_model.bin:  88%|██████████████████████████████    | 482M/546M [01:35<00:26, 2.43MB/s]Downloading pytorch_model.bin:  90%|██████████████████████████████▋   | 493M/546M [01:42<00:25, 2.07MB/s]Downloading pytorch_model.bin:  92%|███████████████████████████████▎  | 503M/546M [01:46<00:20, 2.11MB/s]Downloading pytorch_model.bin:  94%|████████████████████████████████  | 514M/546M [01:50<00:13, 2.33MB/s]Downloading pytorch_model.bin:  96%|████████████████████████████████▋ | 524M/546M [01:54<00:08, 2.43MB/s]Downloading pytorch_model.bin:  98%|█████████████████████████████████▎| 535M/546M [01:57<00:04, 2.52MB/s]Downloading pytorch_model.bin: 100%|█████████████████████████████████▉| 545M/546M [02:01<00:00, 2.65MB/s]Downloading pytorch_model.bin: 100%|██████████████████████████████████| 546M/546M [02:01<00:00, 2.67MB/s]Downloading pytorch_model.bin: 100%|██████████████████████████████████| 546M/546M [02:01<00:00, 4.49MB/s]
Downloading (…)okenizer_config.json:   0%|                                     | 0.00/581 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|███████████████████████████████| 581/581 [00:00<00:00, 533kB/s]
Downloading (…)solve/main/vocab.txt:   0%|                                    | 0.00/555k [00:00<?, ?B/s]Downloading (…)solve/main/vocab.txt: 100%|█████████████████████████████| 555k/555k [00:01<00:00, 494kB/s]Downloading (…)solve/main/vocab.txt: 100%|█████████████████████████████| 555k/555k [00:01<00:00, 494kB/s]
Downloading (…)cial_tokens_map.json:   0%|                                     | 0.00/112 [00:00<?, ?B/s]Downloading (…)cial_tokens_map.json: 100%|███████████████████████████████| 112/112 [00:00<00:00, 112kB/s]
Downloading (…)rocessor_config.json:   0%|                                     | 0.00/308 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|███████████████████████████████| 308/308 [00:00<00:00, 300kB/s]
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/image_utils.py", line 308, in load_image
    b64 = base64.b64decode(image, validate=True)
  File "/root/miniconda3/envs/py38/lib/python3.8/base64.py", line 86, in b64decode
    raise binascii.Error('Non-base64 digit found')
binascii.Error: Non-base64 digit found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "output/hf-eval-data-v2/f00013_analyze_food_image.py", line 36, in <module>
    test_analyze_food_image()
  File "output/hf-eval-data-v2/f00013_analyze_food_image.py", line 30, in test_analyze_food_image
    answer = analyze_food_image(image_path, question)
  File "output/hf-eval-data-v2/f00013_analyze_food_image.py", line 19, in analyze_food_image
    answer = vqa_model({'image': image_path, 'question': question})
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/visual_question_answering.py", line 114, in __call__
    results = super().__call__(inputs, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1140, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/base.py", line 1146, in run_single
    model_inputs = self.preprocess(inputs, **preprocess_params)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/pipelines/visual_question_answering.py", line 118, in preprocess
    image = load_image(inputs["image"], timeout=timeout)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/image_utils.py", line 311, in load_image
    raise ValueError(
ValueError: Incorrect image source. Must be a valid URL starting with `http://` or `https://`, a valid path to an image file, or a base64 encoded string. Got path_to_test_image. Failed with Non-base64 digit found
