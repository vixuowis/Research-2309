{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9894798c-cfc9-4f08-b5e1-2cceb980d30b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内容来自文件: output/hf-eval-data-v3-valid/f00002_extract_medical_term_relationships.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00004_extract_sentence_embeddings.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00016_load_graphormer_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00018_estimate_image_depth.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00020_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00035_sentiment_analysis.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00049_get_legal_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00051_get_answer_from_document.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00053_news_category_detection.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00058_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00059_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00060_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00069_compute_sentence_embeddings.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00071_get_sentence_embedding.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00075_transcribe_audio.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00082_detect_voice_segments.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00083_classify_wine_quality.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00088_calculate_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00089_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00111_detect_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00112_image_segmentation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00114_segment_city_layout.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00123_analyze_review_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00126_get_best_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00127_extract_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00128_extract_entities_from_email.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00130_table_question_answering.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00134_extract_non_compete_clause_info.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00135_get_game_day.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00138_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00139_summarize_news.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00141_generate_story.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00142_generate_conversation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00143_generate_code.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00146_translate_english_to_german.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00160_keyword_spotting.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00166_predict_housing_prices.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00173_generate_sentence_embeddings.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00178_text_to_video.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00181_visual_question_answering.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00184_estimate_depth.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00185_extract_invoice_info.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00187_estimate_depth.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00188_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00189_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00193_detect_shoplifters.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00194_detect_blood_cells.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00198_generate_minecraft_skin.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00199_generate_cat_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00204_analyze_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00205_image_geolocalization.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00208_detect_named_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00210_get_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00213_get_answer_from_book.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00215_classify_news_headlines.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00216_german_text_classification.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00217_determine_logical_relationship.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00219_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00221_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00223_dialogue_response_generation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00225_generate_dialogue.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00226_generate_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00228_korean_text_summarization.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00229_translate_english_to_french.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00238_separate_vocals.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00249_predict_house_prices.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00255_extract_positional_relations.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00258_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00259_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00283_generate_insect_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00290_identify_street_location.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00297_classify_spanish_article.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00299_translate_catalan_to_spanish.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00301_translate_french_to_spanish.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00307_generate_code.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00310_generate_query.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00313_generate_fill_in_the_blank_questions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00330_classify_movie_reviews.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00333_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00346_generate_image_from_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00349_generate_image_caption.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00350_identify_landmark.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00359_classify_computer_parts.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00364_detect_kitchen_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00365_segment_clothes.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00371_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00372_generate_human_face.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00375_load_and_classify_video.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00380_detect_gpt2_generated_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00385_identify_company_names.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00395_answer_question.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00399_detect_russian_sentence_contradiction.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00410_generate_queries.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00413_generate_embeddings.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00414_group_articles_by_topic.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00415_get_sentence_similarity.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00420_generate_telugu_audio.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00422_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00433_identify_speaker.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00436_predict_wine_quality.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00437_predict_customer_purchase.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00438_TF_Decision_Trees.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00510_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00442_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00443_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00445_predict_electricity_consumption.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00450_generate_hashtags.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00468_segment_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00469_segment_clothes.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00472_estimate_human_pose.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00474_transform_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00475_generate_car_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00476_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00487_classify_device_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00489_analyze_stock_forum_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00493_extract_named_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00496_extract_named_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00497_get_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00499_sentiment_analysis.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00500_translate_french_to_english.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00512_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00514_print_hello_world.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00518_generate_code_summary.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00540_load_voice_activity_detection_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00541_predict_survival.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00542_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00546_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00547_load_hubert_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00548_generate_image_from_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00553_get_image_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00554_detect_intruder.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00559_extract_invoice_info.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00563_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00566_image_segmentation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00567_create_artistic_variations.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00570_generate_slogan.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00575_location_recommendation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00637_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00576_analyze_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00577_detect_toxic_comment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00578_retrieve_relevant_documents.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00580_extract_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00584_identify_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00589_get_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00590_get_capital_of_germany.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00593_classify_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00596_classify_synopsis.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00605_translate_spanish_to_polish.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00606_generate_synonyms.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00609_encode_sentences.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00612_generate_audio_announcement.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00624_classify_audio.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00631_classify_co2_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00632_predict_pokemon_hp.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00635_extract_code_syntax_and_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00639_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00641_get_image_summary_and_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00642_extract_captions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00644_generate_video_from_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00653_detect_license_plate.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00656_image_segmentation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00663_generate_vintage_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00670_classify_product_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00672_find_relevant_passage.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00675_emotion_classifier.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00678_tokenize_chinese_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00686_classify_review.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00687_classify_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00694_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00696_chatbot_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00697_complete_sentence.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00700_translate_hindi_to_french.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00798_fill_mask.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00704_find_most_related_faq.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00705_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00706_convert_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00721_predict_wine_quality.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00725_predict_carbon_emission.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00727_load_decision_transformer_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00729_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00730_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00731_generate_anime_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00732_generate_image_description.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00737_estimate_depth.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00739_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00743_detect_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00745_detect_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00746_segment_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00747_urban_landscape_recognition.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00748_detect_pcb_defects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00749_detect_potholes.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00751_generate_image_variations.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00755_generate_butterfly_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00758_generate_butterfly_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00762_video_action_recognition.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00768_analyze_review_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00771_extract_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00772_predict_punctuation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00774_load_tapas_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00776_get_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00781_classify_news_article.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00782_german_news_classifier.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00789_generate_dialogue.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00791_generate_chatbot_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00793_generate_summary.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00794_complete_code.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00795_generate_marketing_content.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00796_summarize_diary.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00799_generate_interactive_sentence.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00800_find_most_suitable_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00804_convert_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00812_detect_voice_activity.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00823_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00824_analyze_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00825_generate_question_embedding.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00826_encode_sentences.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00827_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00834_extract_property_info.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00843_detect_csgo_players.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00845_detect_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00846_detect_blood_cells.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00847_detect_vehicles.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00854_generate_cat_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00857_classify_video.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00858_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00861_sentiment_analysis.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00862_rank_search_results.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00863_emotion_classification.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00869_extract_info_from_french_doc.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00872_get_answer_from_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00874_question_answering_tool.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00875_classify_article.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00876_analyze_review.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00884_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00885_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00886_generate_game_setting.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00890_translate_english_to_german.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00892_fill_mask_chinese.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00895_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00906_measure_noise_levels.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00911_predict_electricity_consumption.py\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'path': 'output/hf-eval-data-v3-valid/f00002_extract_medical_term_relationships.py',\n",
       "  'content': '# function_import --------------------\\n\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"\\n    tokenizer = AutoTokenizer.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n    model = AutoModel.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n\\n    inputs = tokenizer(medical_term, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n# test_function_code --------------------\\n\\ndef test_extract_medical_term_relationships():\\n    \"\"\"\\n    This function tests the \\'extract_medical_term_relationships\\' function with different medical terms.\\n    It asserts that the embeddings for different terms should not be the same.\\n    \"\"\"\\n    embedding1 = extract_medical_term_relationships(\\'Cancer\\')\\n    embedding2 = extract_medical_term_relationships(\\'Diabetes\\')\\n\\n    assert not torch.equal(embedding1, embedding2), \\'Embeddings for different terms should not be the same.\\'\\n\\n    embedding3 = extract_medical_term_relationships(\\'Hypertension\\')\\n    embedding4 = extract_medical_term_relationships(\\'Asthma\\')\\n\\n    assert not torch.equal(embedding3, embedding4), \\'Embeddings for different terms should not be the same.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n# call_test_function_code --------------------\\n\\ntest_extract_medical_term_relationships()'},\n",
       " 241)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据 load\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "valid_dir = \"output/hf-eval-data-v3-valid/\"\n",
    "\n",
    "def load_valid_data(dir_path):\n",
    "    data = []\n",
    "    file_pattern = \"*.py\"\n",
    "\n",
    "    # 使用 glob.glob 获取匹配的文件列表\n",
    "    python_files = glob.glob(dir_path + file_pattern)\n",
    "\n",
    "    for file_path in python_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                data.append({\n",
    "                    \"path\": file_path,\n",
    "                    \"content\": content,\n",
    "                })\n",
    "                print(f\"内容来自文件: {file_path}\\n\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"文件 {file_path} 未找到。\")\n",
    "        except Exception as e:\n",
    "            print(f\"发生错误：{e}\")\n",
    "            \n",
    "    return data\n",
    "\n",
    "valid_data = load_valid_data(valid_dir)\n",
    "valid_data[0], len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f5211cf-1552-46e0-8c74-877ea079cc62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'output/hf-eval-data-v3-valid/f00002_extract_medical_term_relationships.py',\n",
       " 'content': '# function_import --------------------\\n\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"\\n    tokenizer = AutoTokenizer.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n    model = AutoModel.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n\\n    inputs = tokenizer(medical_term, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n# test_function_code --------------------\\n\\ndef test_extract_medical_term_relationships():\\n    \"\"\"\\n    This function tests the \\'extract_medical_term_relationships\\' function with different medical terms.\\n    It asserts that the embeddings for different terms should not be the same.\\n    \"\"\"\\n    embedding1 = extract_medical_term_relationships(\\'Cancer\\')\\n    embedding2 = extract_medical_term_relationships(\\'Diabetes\\')\\n\\n    assert not torch.equal(embedding1, embedding2), \\'Embeddings for different terms should not be the same.\\'\\n\\n    embedding3 = extract_medical_term_relationships(\\'Hypertension\\')\\n    embedding4 = extract_medical_term_relationships(\\'Asthma\\')\\n\\n    assert not torch.equal(embedding3, embedding4), \\'Embeddings for different terms should not be the same.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n# call_test_function_code --------------------\\n\\ntest_extract_medical_term_relationships()',\n",
       " 'function_import': '# function_import --------------------\\n\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n',\n",
       " 'function_code': '# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"\\n    tokenizer = AutoTokenizer.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n    model = AutoModel.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n\\n    inputs = tokenizer(medical_term, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n',\n",
       " 'test_function_code': '# test_function_code --------------------\\n\\ndef test_extract_medical_term_relationships():\\n    \"\"\"\\n    This function tests the \\'extract_medical_term_relationships\\' function with different medical terms.\\n    It asserts that the embeddings for different terms should not be the same.\\n    \"\"\"\\n    embedding1 = extract_medical_term_relationships(\\'Cancer\\')\\n    embedding2 = extract_medical_term_relationships(\\'Diabetes\\')\\n\\n    assert not torch.equal(embedding1, embedding2), \\'Embeddings for different terms should not be the same.\\'\\n\\n    embedding3 = extract_medical_term_relationships(\\'Hypertension\\')\\n    embedding4 = extract_medical_term_relationships(\\'Asthma\\')\\n\\n    assert not torch.equal(embedding3, embedding4), \\'Embeddings for different terms should not be the same.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n',\n",
       " 'call_test_function_code': '# call_test_function_code --------------------\\n\\ntest_extract_medical_term_relationships()'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拆出 instruct / output / testing\n",
    "import re\n",
    "\n",
    "def extract_between_strings(input_string, start_string, end_string):\n",
    "    after = input_string.split(start_string)[1]\n",
    "    if end_string != \"\":\n",
    "        between = after.split(end_string)[0]\n",
    "        return start_string + between\n",
    "    \n",
    "    return start_string + after\n",
    "\n",
    "def extract_section(data):\n",
    "    content = data['content']\n",
    "    \n",
    "    s = \"# function_import --------------------\"\n",
    "    e = \"# function_code --------------------\"\n",
    "    function_import = extract_between_strings(content, s, e)\n",
    "    \n",
    "    s = \"# function_code --------------------\"\n",
    "    e = \"# test_function_code --------------------\"\n",
    "    function_code = extract_between_strings(content, s, e)\n",
    "    \n",
    "    s = \"# test_function_code --------------------\"\n",
    "    e = \"# call_test_function_code --------------------\"\n",
    "    test_function_code = extract_between_strings(content, s, e)\n",
    "    \n",
    "    s = \"# call_test_function_code --------------------\"\n",
    "    e = \"\"\n",
    "    call_test_function_code = extract_between_strings(content, s, e)\n",
    "    \n",
    "    data['function_import'] = function_import\n",
    "    data['function_code'] = function_code\n",
    "    data['test_function_code'] = test_function_code\n",
    "    data['call_test_function_code'] = call_test_function_code\n",
    "    \n",
    "    return data\n",
    "\n",
    "result = extract_section(valid_data[0])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "832c71e9-6c1c-46d1-b8c7-260ead1defd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241,\n",
       " {'path': 'output/hf-eval-data-v3-valid/f00002_extract_medical_term_relationships.py',\n",
       "  'content': '# function_import --------------------\\n\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"\\n    tokenizer = AutoTokenizer.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n    model = AutoModel.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n\\n    inputs = tokenizer(medical_term, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n# test_function_code --------------------\\n\\ndef test_extract_medical_term_relationships():\\n    \"\"\"\\n    This function tests the \\'extract_medical_term_relationships\\' function with different medical terms.\\n    It asserts that the embeddings for different terms should not be the same.\\n    \"\"\"\\n    embedding1 = extract_medical_term_relationships(\\'Cancer\\')\\n    embedding2 = extract_medical_term_relationships(\\'Diabetes\\')\\n\\n    assert not torch.equal(embedding1, embedding2), \\'Embeddings for different terms should not be the same.\\'\\n\\n    embedding3 = extract_medical_term_relationships(\\'Hypertension\\')\\n    embedding4 = extract_medical_term_relationships(\\'Asthma\\')\\n\\n    assert not torch.equal(embedding3, embedding4), \\'Embeddings for different terms should not be the same.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n# call_test_function_code --------------------\\n\\ntest_extract_medical_term_relationships()',\n",
       "  'function_import': '# function_import --------------------\\n\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n',\n",
       "  'function_code': '# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"\\n    tokenizer = AutoTokenizer.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n    model = AutoModel.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n\\n    inputs = tokenizer(medical_term, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n',\n",
       "  'test_function_code': '# test_function_code --------------------\\n\\ndef test_extract_medical_term_relationships():\\n    \"\"\"\\n    This function tests the \\'extract_medical_term_relationships\\' function with different medical terms.\\n    It asserts that the embeddings for different terms should not be the same.\\n    \"\"\"\\n    embedding1 = extract_medical_term_relationships(\\'Cancer\\')\\n    embedding2 = extract_medical_term_relationships(\\'Diabetes\\')\\n\\n    assert not torch.equal(embedding1, embedding2), \\'Embeddings for different terms should not be the same.\\'\\n\\n    embedding3 = extract_medical_term_relationships(\\'Hypertension\\')\\n    embedding4 = extract_medical_term_relationships(\\'Asthma\\')\\n\\n    assert not torch.equal(embedding3, embedding4), \\'Embeddings for different terms should not be the same.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n',\n",
       "  'call_test_function_code': '# call_test_function_code --------------------\\n\\ntest_extract_medical_term_relationships()',\n",
       "  'instruct': '# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"',\n",
       "  'answer': \"\\n    tokenizer = AutoTokenizer.from_pretrained('GanjinZero/UMLSBert_ENG')\\n    model = AutoModel.from_pretrained('GanjinZero/UMLSBert_ENG')\\n\\n    inputs = tokenizer(medical_term, return_tensors='pt')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n\"})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拆出注释、正文\n",
    "def extract_all_section(data):\n",
    "    result = extract_section(data)\n",
    "        \n",
    "    s = \"# function_code --------------------\"\n",
    "    e = \"'''\"\n",
    "    if e not in result['function_code']:\n",
    "        e = '\"\"\"'\n",
    "\n",
    "    def extract_instruct(input_string, start_string, end_string):\n",
    "        after = input_string.split(start_string)[1]\n",
    "        between = after.rsplit(end_string, 1)[0]\n",
    "        return start_string + between + end_string\n",
    "\n",
    "    def extract_answer(input_string, start_string):\n",
    "        after = input_string.split(start_string)[-1]\n",
    "        return after\n",
    "\n",
    "    instruct = extract_instruct(result['function_code'], s, e)\n",
    "    answer = extract_answer(result['function_code'], e)\n",
    "    \n",
    "    result['instruct'] = instruct\n",
    "    result['answer'] = answer\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "import traceback\n",
    "\n",
    "section_valid_data = []\n",
    "for d in valid_data:\n",
    "    try:\n",
    "        result = extract_all_section(d)\n",
    "        section_valid_data.append(result)\n",
    "    except Exception as e:\n",
    "        # Handle the exception and print the traceback\n",
    "        print(\"An exception occurred:\", e)\n",
    "        traceback.print_exc()\n",
    "    \n",
    "len(section_valid_data), section_valid_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "68e4e66d-e75e-4bc9-ae8e-1de0ae9775d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出到文件， alpaca format\n",
    "import json\n",
    "\n",
    "json_data = []\n",
    "\n",
    "for d in section_valid_data:\n",
    "    json_data.append({\n",
    "        \"instruction\": d['instruct'], \n",
    "        \"input\": \"\",\n",
    "        \"output\": d['answer'],\n",
    "        \"history\": [],\n",
    "    })\n",
    "\n",
    "with open(\"output/hf-eval-v3-240.json\", 'w') as f:\n",
    "    f.write(json.dumps(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15d3192-748a-4e5a-b655-5568a8efaf85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pprint\u001b[38;5;241m.\u001b[39mpp(\u001b[43mjson_data\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pp(json_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92dabd6c-9b6c-48bc-8def-0838da967751",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp output/hf-eval-v3-240.json /root/autodl-tmp/LLaMA-Factory/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0397238f-b355-4697-a420-873d8106a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "d = {}\n",
    "\n",
    "with open(\"/root/autodl-tmp/LLaMA-Factory/data/dataset_info.json\") as f:\n",
    "    d = json.loads(f.read())\n",
    "    d['hf_eval_v3_240'] = {\n",
    "        \"file_name\": \"hf-eval-v3-240.json\",\n",
    "        \"columns\": {\n",
    "          \"prompt\": \"instruction\",\n",
    "          \"query\": \"input\",\n",
    "          \"response\": \"output\",\n",
    "          \"history\": \"history\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "with open(\"/root/autodl-tmp/LLaMA-Factory/data/dataset_info.json\", 'w') as f:\n",
    "    f.write(json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "163835a6-1be5-4b7f-a816-96769a6e0468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '\\n    # Load the pretrained model\\n    model = AutoModel.from_pretra'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://q5oxc8tobsyka6kl.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "headers = {\n",
    "\t\"Authorization\": \"Bearer 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\",\n",
    "\t\"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": section_valid_data[0]['instruct'],\n",
    "})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5334ef-469c-4f7c-b97c-0d96b1441070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
