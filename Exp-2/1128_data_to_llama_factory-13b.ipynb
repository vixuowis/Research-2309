{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9894798c-cfc9-4f08-b5e1-2cceb980d30b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内容来自文件: output/hf-eval-data-v3-valid/f00002_extract_medical_term_relationships.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00004_extract_sentence_embeddings.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00016_load_graphormer_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00018_estimate_image_depth.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00020_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00035_sentiment_analysis.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00049_get_legal_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00051_get_answer_from_document.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00053_news_category_detection.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00058_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00059_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00060_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00069_compute_sentence_embeddings.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00071_get_sentence_embedding.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00075_transcribe_audio.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00082_detect_voice_segments.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00083_classify_wine_quality.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00088_calculate_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00089_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00111_detect_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00112_image_segmentation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00114_segment_city_layout.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00123_analyze_review_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00126_get_best_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00127_extract_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00128_extract_entities_from_email.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00130_table_question_answering.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00134_extract_non_compete_clause_info.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00135_get_game_day.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00138_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00139_summarize_news.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00141_generate_story.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00142_generate_conversation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00143_generate_code.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00146_translate_english_to_german.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00160_keyword_spotting.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00166_predict_housing_prices.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00173_generate_sentence_embeddings.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00178_text_to_video.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00181_visual_question_answering.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00184_estimate_depth.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00185_extract_invoice_info.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00187_estimate_depth.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00188_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00189_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00193_detect_shoplifters.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00194_detect_blood_cells.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00198_generate_minecraft_skin.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00199_generate_cat_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00204_analyze_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00205_image_geolocalization.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00208_detect_named_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00210_get_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00213_get_answer_from_book.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00215_classify_news_headlines.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00216_german_text_classification.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00217_determine_logical_relationship.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00219_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00221_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00223_dialogue_response_generation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00225_generate_dialogue.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00226_generate_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00228_korean_text_summarization.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00229_translate_english_to_french.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00238_separate_vocals.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00249_predict_house_prices.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00255_extract_positional_relations.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00258_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00259_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00283_generate_insect_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00290_identify_street_location.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00297_classify_spanish_article.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00299_translate_catalan_to_spanish.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00301_translate_french_to_spanish.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00307_generate_code.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00310_generate_query.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00313_generate_fill_in_the_blank_questions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00330_classify_movie_reviews.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00333_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00346_generate_image_from_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00349_generate_image_caption.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00350_identify_landmark.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00359_classify_computer_parts.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00364_detect_kitchen_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00365_segment_clothes.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00371_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00372_generate_human_face.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00375_load_and_classify_video.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00380_detect_gpt2_generated_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00385_identify_company_names.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00395_answer_question.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00399_detect_russian_sentence_contradiction.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00410_generate_queries.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00413_generate_embeddings.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00414_group_articles_by_topic.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00415_get_sentence_similarity.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00420_generate_telugu_audio.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00422_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00433_identify_speaker.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00436_predict_wine_quality.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00437_predict_customer_purchase.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00438_TF_Decision_Trees.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00510_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00442_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00443_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00445_predict_electricity_consumption.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00450_generate_hashtags.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00468_segment_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00469_segment_clothes.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00472_estimate_human_pose.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00474_transform_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00475_generate_car_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00476_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00487_classify_device_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00489_analyze_stock_forum_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00493_extract_named_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00496_extract_named_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00497_get_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00499_sentiment_analysis.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00500_translate_french_to_english.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00512_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00514_print_hello_world.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00518_generate_code_summary.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00540_load_voice_activity_detection_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00541_predict_survival.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00542_predict_carbon_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00546_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00547_load_hubert_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00548_generate_image_from_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00553_get_image_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00554_detect_intruder.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00559_extract_invoice_info.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00563_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00566_image_segmentation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00567_create_artistic_variations.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00570_generate_slogan.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00575_location_recommendation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00637_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00576_analyze_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00577_detect_toxic_comment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00578_retrieve_relevant_documents.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00580_extract_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00584_identify_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00589_get_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00590_get_capital_of_germany.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00593_classify_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00596_classify_synopsis.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00605_translate_spanish_to_polish.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00606_generate_synonyms.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00609_encode_sentences.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00612_generate_audio_announcement.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00624_classify_audio.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00631_classify_co2_emissions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00632_predict_pokemon_hp.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00635_extract_code_syntax_and_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00639_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00641_get_image_summary_and_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00642_extract_captions.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00644_generate_video_from_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00653_detect_license_plate.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00656_image_segmentation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00663_generate_vintage_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00670_classify_product_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00672_find_relevant_passage.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00675_emotion_classifier.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00678_tokenize_chinese_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00686_classify_review.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00687_classify_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00694_summarize_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00696_chatbot_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00697_complete_sentence.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00700_translate_hindi_to_french.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00798_fill_mask.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00704_find_most_related_faq.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00705_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00706_convert_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00721_predict_wine_quality.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00725_predict_carbon_emission.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00727_load_decision_transformer_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00729_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00730_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00731_generate_anime_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00732_generate_image_description.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00737_estimate_depth.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00739_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00743_detect_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00745_detect_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00746_segment_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00747_urban_landscape_recognition.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00748_detect_pcb_defects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00749_detect_potholes.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00751_generate_image_variations.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00755_generate_butterfly_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00758_generate_butterfly_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00762_video_action_recognition.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00768_analyze_review_sentiment.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00771_extract_entities.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00772_predict_punctuation.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00774_load_tapas_model.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00776_get_answer.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00781_classify_news_article.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00782_german_news_classifier.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00789_generate_dialogue.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00791_generate_chatbot_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00793_generate_summary.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00794_complete_code.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00795_generate_marketing_content.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00796_summarize_diary.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00799_generate_interactive_sentence.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00800_find_most_suitable_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00804_convert_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00812_detect_voice_activity.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00823_extract_features.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00824_analyze_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00825_generate_question_embedding.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00826_encode_sentences.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00827_generate_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00834_extract_property_info.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00843_detect_csgo_players.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00845_detect_objects.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00846_detect_blood_cells.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00847_detect_vehicles.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00854_generate_cat_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00857_classify_video.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00858_classify_image.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00861_sentiment_analysis.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00862_rank_search_results.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00863_emotion_classification.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00869_extract_info_from_french_doc.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00872_get_answer_from_text.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00874_question_answering_tool.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00875_classify_article.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00876_analyze_review.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00884_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00885_generate_response.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00886_generate_game_setting.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00890_translate_english_to_german.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00892_fill_mask_chinese.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00895_text_to_speech.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00906_measure_noise_levels.py\n",
      "\n",
      "内容来自文件: output/hf-eval-data-v3-valid/f00911_predict_electricity_consumption.py\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'path': 'output/hf-eval-data-v3-valid/f00002_extract_medical_term_relationships.py',\n",
       "  'content': '# function_import --------------------\\n\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"\\n    tokenizer = AutoTokenizer.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n    model = AutoModel.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n\\n    inputs = tokenizer(medical_term, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n# test_function_code --------------------\\n\\ndef test_extract_medical_term_relationships():\\n    \"\"\"\\n    This function tests the \\'extract_medical_term_relationships\\' function with different medical terms.\\n    It asserts that the embeddings for different terms should not be the same.\\n    \"\"\"\\n    embedding1 = extract_medical_term_relationships(\\'Cancer\\')\\n    embedding2 = extract_medical_term_relationships(\\'Diabetes\\')\\n\\n    assert not torch.equal(embedding1, embedding2), \\'Embeddings for different terms should not be the same.\\'\\n\\n    embedding3 = extract_medical_term_relationships(\\'Hypertension\\')\\n    embedding4 = extract_medical_term_relationships(\\'Asthma\\')\\n\\n    assert not torch.equal(embedding3, embedding4), \\'Embeddings for different terms should not be the same.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n# call_test_function_code --------------------\\n\\ntest_extract_medical_term_relationships()'},\n",
       " 241)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据 load\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "valid_dir = \"output/hf-eval-data-v3-valid/\"\n",
    "\n",
    "def load_valid_data(dir_path):\n",
    "    data = []\n",
    "    file_pattern = \"*.py\"\n",
    "\n",
    "    # 使用 glob.glob 获取匹配的文件列表\n",
    "    python_files = glob.glob(dir_path + file_pattern)\n",
    "\n",
    "    for file_path in python_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                data.append({\n",
    "                    \"path\": file_path,\n",
    "                    \"content\": content,\n",
    "                })\n",
    "                print(f\"内容来自文件: {file_path}\\n\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"文件 {file_path} 未找到。\")\n",
    "        except Exception as e:\n",
    "            print(f\"发生错误：{e}\")\n",
    "            \n",
    "    return data\n",
    "\n",
    "valid_data = load_valid_data(valid_dir)\n",
    "valid_data[0], len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5211cf-1552-46e0-8c74-877ea079cc62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'output/hf-eval-data-v3-valid/f00385_identify_company_names.py',\n",
       " 'content': '# function_import --------------------\\n\\nimport torch\\nfrom transformers import AutoModelForTokenClassification, AutoTokenizer\\n\\n# function_code --------------------\\n\\ndef identify_company_names(text):\\n    \"\"\"\\n    Identify company names from a given text using a pre-trained model from Hugging Face Transformers.\\n\\n    Args:\\n        text (str): The input text from which company names are to be identified.\\n\\n    Returns:\\n        outputs (torch.Tensor): The model outputs, which include the predicted token classifications.\\n\\n    Raises:\\n        ValueError: If the input text is not a string.\\n    \"\"\"\\n    if not isinstance(text, str):\\n        raise ValueError(\\'Input text must be a string.\\')\\n\\n    model = AutoModelForTokenClassification.from_pretrained(\\'ismail-lucifer011/autotrain-company_all-903429548\\')\\n    tokenizer = AutoTokenizer.from_pretrained(\\'ismail-lucifer011/autotrain-company_all-903429548\\')\\n\\n    inputs = tokenizer(text, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n\\n    return outputs\\n\\n# test_function_code --------------------\\n\\ndef test_identify_company_names():\\n    \"\"\"\\n    Test the identify_company_names function with various test cases.\\n    \"\"\"\\n    # Test with a simple text\\n    text = \\'Apple Inc. is an American multinational technology company.\\'\\n    outputs = identify_company_names(text)\\n    assert outputs is not None, \\'The output should not be None.\\'\\n\\n    # Test with a text that does not contain any company names\\n    text = \\'This is a test sentence without any company names.\\'\\n    outputs = identify_company_names(text)\\n    assert outputs is not None, \\'The output should not be None.\\'\\n\\n    # Test with a text that contains multiple company names\\n    text = \\'Apple and Microsoft are two of the biggest technology companies in the world.\\'\\n    outputs = identify_company_names(text)\\n    assert outputs is not None, \\'The output should not be None.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n# call_test_function_code --------------------\\n\\ntest_identify_company_names()',\n",
       " 'function_import': '# function_import --------------------\\n\\nimport torch\\nfrom transformers import AutoModelForTokenClassification, AutoTokenizer\\n\\n',\n",
       " 'function_code': '# function_code --------------------\\n\\ndef identify_company_names(text):\\n    \"\"\"\\n    Identify company names from a given text using a pre-trained model from Hugging Face Transformers.\\n\\n    Args:\\n        text (str): The input text from which company names are to be identified.\\n\\n    Returns:\\n        outputs (torch.Tensor): The model outputs, which include the predicted token classifications.\\n\\n    Raises:\\n        ValueError: If the input text is not a string.\\n    \"\"\"\\n    if not isinstance(text, str):\\n        raise ValueError(\\'Input text must be a string.\\')\\n\\n    model = AutoModelForTokenClassification.from_pretrained(\\'ismail-lucifer011/autotrain-company_all-903429548\\')\\n    tokenizer = AutoTokenizer.from_pretrained(\\'ismail-lucifer011/autotrain-company_all-903429548\\')\\n\\n    inputs = tokenizer(text, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n\\n    return outputs\\n\\n',\n",
       " 'test_function_code': '# test_function_code --------------------\\n\\ndef test_identify_company_names():\\n    \"\"\"\\n    Test the identify_company_names function with various test cases.\\n    \"\"\"\\n    # Test with a simple text\\n    text = \\'Apple Inc. is an American multinational technology company.\\'\\n    outputs = identify_company_names(text)\\n    assert outputs is not None, \\'The output should not be None.\\'\\n\\n    # Test with a text that does not contain any company names\\n    text = \\'This is a test sentence without any company names.\\'\\n    outputs = identify_company_names(text)\\n    assert outputs is not None, \\'The output should not be None.\\'\\n\\n    # Test with a text that contains multiple company names\\n    text = \\'Apple and Microsoft are two of the biggest technology companies in the world.\\'\\n    outputs = identify_company_names(text)\\n    assert outputs is not None, \\'The output should not be None.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n',\n",
       " 'call_test_function_code': '# call_test_function_code --------------------\\n\\ntest_identify_company_names()'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拆出 instruct / output / testing\n",
    "import re\n",
    "\n",
    "def extract_between_strings(input_string, start_string, end_string):\n",
    "    after = input_string.split(start_string)[1]\n",
    "    if end_string != \"\":\n",
    "        between = after.split(end_string)[0]\n",
    "        return start_string + between\n",
    "    \n",
    "    return start_string + after\n",
    "\n",
    "def extract_section(data):\n",
    "    content = data['content']\n",
    "    \n",
    "    s = \"# function_import --------------------\"\n",
    "    e = \"# function_code --------------------\"\n",
    "    function_import = extract_between_strings(content, s, e)\n",
    "    \n",
    "    s = \"# function_code --------------------\"\n",
    "    e = \"# test_function_code --------------------\"\n",
    "    function_code = extract_between_strings(content, s, e)\n",
    "    \n",
    "    s = \"# test_function_code --------------------\"\n",
    "    e = \"# call_test_function_code --------------------\"\n",
    "    test_function_code = extract_between_strings(content, s, e)\n",
    "    \n",
    "    s = \"# call_test_function_code --------------------\"\n",
    "    e = \"\"\n",
    "    call_test_function_code = extract_between_strings(content, s, e)\n",
    "    \n",
    "    data['function_import'] = function_import\n",
    "    data['function_code'] = function_code\n",
    "    data['test_function_code'] = test_function_code\n",
    "    data['call_test_function_code'] = call_test_function_code\n",
    "    \n",
    "    return data\n",
    "\n",
    "result = extract_section(valid_data[89])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832c71e9-6c1c-46d1-b8c7-260ead1defd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241,\n",
       " {'path': 'output/hf-eval-data-v3-valid/f00002_extract_medical_term_relationships.py',\n",
       "  'content': '# function_import --------------------\\n\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"\\n    tokenizer = AutoTokenizer.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n    model = AutoModel.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n\\n    inputs = tokenizer(medical_term, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n# test_function_code --------------------\\n\\ndef test_extract_medical_term_relationships():\\n    \"\"\"\\n    This function tests the \\'extract_medical_term_relationships\\' function with different medical terms.\\n    It asserts that the embeddings for different terms should not be the same.\\n    \"\"\"\\n    embedding1 = extract_medical_term_relationships(\\'Cancer\\')\\n    embedding2 = extract_medical_term_relationships(\\'Diabetes\\')\\n\\n    assert not torch.equal(embedding1, embedding2), \\'Embeddings for different terms should not be the same.\\'\\n\\n    embedding3 = extract_medical_term_relationships(\\'Hypertension\\')\\n    embedding4 = extract_medical_term_relationships(\\'Asthma\\')\\n\\n    assert not torch.equal(embedding3, embedding4), \\'Embeddings for different terms should not be the same.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n# call_test_function_code --------------------\\n\\ntest_extract_medical_term_relationships()',\n",
       "  'function_import': '# function_import --------------------\\n\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n',\n",
       "  'function_code': '# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"\\n    tokenizer = AutoTokenizer.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n    model = AutoModel.from_pretrained(\\'GanjinZero/UMLSBert_ENG\\')\\n\\n    inputs = tokenizer(medical_term, return_tensors=\\'pt\\')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n',\n",
       "  'test_function_code': '# test_function_code --------------------\\n\\ndef test_extract_medical_term_relationships():\\n    \"\"\"\\n    This function tests the \\'extract_medical_term_relationships\\' function with different medical terms.\\n    It asserts that the embeddings for different terms should not be the same.\\n    \"\"\"\\n    embedding1 = extract_medical_term_relationships(\\'Cancer\\')\\n    embedding2 = extract_medical_term_relationships(\\'Diabetes\\')\\n\\n    assert not torch.equal(embedding1, embedding2), \\'Embeddings for different terms should not be the same.\\'\\n\\n    embedding3 = extract_medical_term_relationships(\\'Hypertension\\')\\n    embedding4 = extract_medical_term_relationships(\\'Asthma\\')\\n\\n    assert not torch.equal(embedding3, embedding4), \\'Embeddings for different terms should not be the same.\\'\\n\\n    return \\'All Tests Passed\\'\\n\\n',\n",
       "  'call_test_function_code': '# call_test_function_code --------------------\\n\\ntest_extract_medical_term_relationships()',\n",
       "  'instruct': '# function_import --------------------\\n\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\n\\n# function_code --------------------\\n\\ndef extract_medical_term_relationships(medical_term):\\n    \"\"\"\\n    This function uses the pretrained model \\'GanjinZero/UMLSBert_ENG\\' from Hugging Face Transformers to find relationships between medical terms.\\n    It converts the medical terms into embeddings (dense vectors) which can be compared to find similarities and relationships.\\n\\n    Args:\\n        medical_term (str): The medical term to be converted into an embedding.\\n\\n    Returns:\\n        torch.Tensor: The embedding of the input medical term.\\n    \"\"\"',\n",
       "  'answer': \"\\n    tokenizer = AutoTokenizer.from_pretrained('GanjinZero/UMLSBert_ENG')\\n    model = AutoModel.from_pretrained('GanjinZero/UMLSBert_ENG')\\n\\n    inputs = tokenizer(medical_term, return_tensors='pt')\\n    outputs = model(**inputs)\\n    embeddings = outputs.last_hidden_state\\n\\n    return embeddings\\n\\n\"})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拆出注释、正文\n",
    "def extract_all_section(data):\n",
    "    result = extract_section(data)\n",
    "        \n",
    "    s = \"# function_code --------------------\"\n",
    "    e = \"'''\"\n",
    "    if e not in result['function_code']:\n",
    "        e = '\"\"\"'\n",
    "\n",
    "    def extract_instruct(input_string, start_string, end_string):\n",
    "        after = input_string.split(start_string)[1]\n",
    "        between = after.rsplit(end_string, 1)[0]\n",
    "        return start_string + between + end_string\n",
    "\n",
    "    def extract_answer(input_string, start_string):\n",
    "        after = input_string.split(start_string)[-1]\n",
    "        return after\n",
    "\n",
    "    instruct = extract_instruct(result['function_code'], s, e)\n",
    "    answer = extract_answer(result['function_code'], e)\n",
    "    \n",
    "    result['instruct'] = result['function_import'] + instruct\n",
    "    result['answer'] = answer\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "import traceback\n",
    "\n",
    "section_valid_data = []\n",
    "for d in valid_data:\n",
    "    try:\n",
    "        result = extract_all_section(d)\n",
    "        section_valid_data.append(result)\n",
    "    except Exception as e:\n",
    "        # Handle the exception and print the traceback\n",
    "        print(\"An exception occurred:\", e)\n",
    "        traceback.print_exc()\n",
    "    \n",
    "len(section_valid_data), section_valid_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68e4e66d-e75e-4bc9-ae8e-1de0ae9775d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出到文件\n",
    "import json\n",
    "\n",
    "with open(f\"output/hf-eval-data-v3-instruct.jsonl\", 'w') as f:\n",
    "    for d in section_valid_data:\n",
    "        f.write(json.dumps(d) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c15d3192-748a-4e5a-b655-5568a8efaf85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'output/hf-eval-data-v3-valid/f00002_extract_medical_term_relationships.py',\n",
      " 'content': '# function_import --------------------\\n'\n",
      "            '\\n'\n",
      "            'from transformers import AutoTokenizer, AutoModel\\n'\n",
      "            'import torch\\n'\n",
      "            '\\n'\n",
      "            '# function_code --------------------\\n'\n",
      "            '\\n'\n",
      "            'def extract_medical_term_relationships(medical_term):\\n'\n",
      "            '    \"\"\"\\n'\n",
      "            '    This function uses the pretrained model '\n",
      "            \"'GanjinZero/UMLSBert_ENG' from Hugging Face Transformers to find \"\n",
      "            'relationships between medical terms.\\n'\n",
      "            '    It converts the medical terms into embeddings (dense vectors) '\n",
      "            'which can be compared to find similarities and relationships.\\n'\n",
      "            '\\n'\n",
      "            '    Args:\\n'\n",
      "            '        medical_term (str): The medical term to be converted into '\n",
      "            'an embedding.\\n'\n",
      "            '\\n'\n",
      "            '    Returns:\\n'\n",
      "            '        torch.Tensor: The embedding of the input medical term.\\n'\n",
      "            '    \"\"\"\\n'\n",
      "            '    tokenizer = '\n",
      "            \"AutoTokenizer.from_pretrained('GanjinZero/UMLSBert_ENG')\\n\"\n",
      "            \"    model = AutoModel.from_pretrained('GanjinZero/UMLSBert_ENG')\\n\"\n",
      "            '\\n'\n",
      "            \"    inputs = tokenizer(medical_term, return_tensors='pt')\\n\"\n",
      "            '    outputs = model(**inputs)\\n'\n",
      "            '    embeddings = outputs.last_hidden_state\\n'\n",
      "            '\\n'\n",
      "            '    return embeddings\\n'\n",
      "            '\\n'\n",
      "            '# test_function_code --------------------\\n'\n",
      "            '\\n'\n",
      "            'def test_extract_medical_term_relationships():\\n'\n",
      "            '    \"\"\"\\n'\n",
      "            \"    This function tests the 'extract_medical_term_relationships' \"\n",
      "            'function with different medical terms.\\n'\n",
      "            '    It asserts that the embeddings for different terms should not '\n",
      "            'be the same.\\n'\n",
      "            '    \"\"\"\\n'\n",
      "            \"    embedding1 = extract_medical_term_relationships('Cancer')\\n\"\n",
      "            \"    embedding2 = extract_medical_term_relationships('Diabetes')\\n\"\n",
      "            '\\n'\n",
      "            \"    assert not torch.equal(embedding1, embedding2), 'Embeddings \"\n",
      "            \"for different terms should not be the same.'\\n\"\n",
      "            '\\n'\n",
      "            '    embedding3 = '\n",
      "            \"extract_medical_term_relationships('Hypertension')\\n\"\n",
      "            \"    embedding4 = extract_medical_term_relationships('Asthma')\\n\"\n",
      "            '\\n'\n",
      "            \"    assert not torch.equal(embedding3, embedding4), 'Embeddings \"\n",
      "            \"for different terms should not be the same.'\\n\"\n",
      "            '\\n'\n",
      "            \"    return 'All Tests Passed'\\n\"\n",
      "            '\\n'\n",
      "            '# call_test_function_code --------------------\\n'\n",
      "            '\\n'\n",
      "            'test_extract_medical_term_relationships()',\n",
      " 'function_import': '# function_import --------------------\\n'\n",
      "                    '\\n'\n",
      "                    'from transformers import AutoTokenizer, AutoModel\\n'\n",
      "                    'import torch\\n'\n",
      "                    '\\n',\n",
      " 'function_code': '# function_code --------------------\\n'\n",
      "                  '\\n'\n",
      "                  'def extract_medical_term_relationships(medical_term):\\n'\n",
      "                  '    \"\"\"\\n'\n",
      "                  '    This function uses the pretrained model '\n",
      "                  \"'GanjinZero/UMLSBert_ENG' from Hugging Face Transformers to \"\n",
      "                  'find relationships between medical terms.\\n'\n",
      "                  '    It converts the medical terms into embeddings (dense '\n",
      "                  'vectors) which can be compared to find similarities and '\n",
      "                  'relationships.\\n'\n",
      "                  '\\n'\n",
      "                  '    Args:\\n'\n",
      "                  '        medical_term (str): The medical term to be '\n",
      "                  'converted into an embedding.\\n'\n",
      "                  '\\n'\n",
      "                  '    Returns:\\n'\n",
      "                  '        torch.Tensor: The embedding of the input medical '\n",
      "                  'term.\\n'\n",
      "                  '    \"\"\"\\n'\n",
      "                  '    tokenizer = '\n",
      "                  \"AutoTokenizer.from_pretrained('GanjinZero/UMLSBert_ENG')\\n\"\n",
      "                  '    model = '\n",
      "                  \"AutoModel.from_pretrained('GanjinZero/UMLSBert_ENG')\\n\"\n",
      "                  '\\n'\n",
      "                  \"    inputs = tokenizer(medical_term, return_tensors='pt')\\n\"\n",
      "                  '    outputs = model(**inputs)\\n'\n",
      "                  '    embeddings = outputs.last_hidden_state\\n'\n",
      "                  '\\n'\n",
      "                  '    return embeddings\\n'\n",
      "                  '\\n',\n",
      " 'test_function_code': '# test_function_code --------------------\\n'\n",
      "                       '\\n'\n",
      "                       'def test_extract_medical_term_relationships():\\n'\n",
      "                       '    \"\"\"\\n'\n",
      "                       '    This function tests the '\n",
      "                       \"'extract_medical_term_relationships' function with \"\n",
      "                       'different medical terms.\\n'\n",
      "                       '    It asserts that the embeddings for different terms '\n",
      "                       'should not be the same.\\n'\n",
      "                       '    \"\"\"\\n'\n",
      "                       '    embedding1 = '\n",
      "                       \"extract_medical_term_relationships('Cancer')\\n\"\n",
      "                       '    embedding2 = '\n",
      "                       \"extract_medical_term_relationships('Diabetes')\\n\"\n",
      "                       '\\n'\n",
      "                       '    assert not torch.equal(embedding1, embedding2), '\n",
      "                       \"'Embeddings for different terms should not be the \"\n",
      "                       \"same.'\\n\"\n",
      "                       '\\n'\n",
      "                       '    embedding3 = '\n",
      "                       \"extract_medical_term_relationships('Hypertension')\\n\"\n",
      "                       '    embedding4 = '\n",
      "                       \"extract_medical_term_relationships('Asthma')\\n\"\n",
      "                       '\\n'\n",
      "                       '    assert not torch.equal(embedding3, embedding4), '\n",
      "                       \"'Embeddings for different terms should not be the \"\n",
      "                       \"same.'\\n\"\n",
      "                       '\\n'\n",
      "                       \"    return 'All Tests Passed'\\n\"\n",
      "                       '\\n',\n",
      " 'call_test_function_code': '# call_test_function_code --------------------\\n'\n",
      "                            '\\n'\n",
      "                            'test_extract_medical_term_relationships()',\n",
      " 'instruct': '# function_import --------------------\\n'\n",
      "             '\\n'\n",
      "             'from transformers import AutoTokenizer, AutoModel\\n'\n",
      "             'import torch\\n'\n",
      "             '\\n'\n",
      "             '# function_code --------------------\\n'\n",
      "             '\\n'\n",
      "             'def extract_medical_term_relationships(medical_term):\\n'\n",
      "             '    \"\"\"\\n'\n",
      "             '    This function uses the pretrained model '\n",
      "             \"'GanjinZero/UMLSBert_ENG' from Hugging Face Transformers to find \"\n",
      "             'relationships between medical terms.\\n'\n",
      "             '    It converts the medical terms into embeddings (dense '\n",
      "             'vectors) which can be compared to find similarities and '\n",
      "             'relationships.\\n'\n",
      "             '\\n'\n",
      "             '    Args:\\n'\n",
      "             '        medical_term (str): The medical term to be converted '\n",
      "             'into an embedding.\\n'\n",
      "             '\\n'\n",
      "             '    Returns:\\n'\n",
      "             '        torch.Tensor: The embedding of the input medical term.\\n'\n",
      "             '    \"\"\"',\n",
      " 'answer': '\\n'\n",
      "           '    tokenizer = '\n",
      "           \"AutoTokenizer.from_pretrained('GanjinZero/UMLSBert_ENG')\\n\"\n",
      "           \"    model = AutoModel.from_pretrained('GanjinZero/UMLSBert_ENG')\\n\"\n",
      "           '\\n'\n",
      "           \"    inputs = tokenizer(medical_term, return_tensors='pt')\\n\"\n",
      "           '    outputs = model(**inputs)\\n'\n",
      "           '    embeddings = outputs.last_hidden_state\\n'\n",
      "           '\\n'\n",
      "           '    return embeddings\\n'\n",
      "           '\\n'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pp(section_valid_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92dabd6c-9b6c-48bc-8def-0838da967751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cp output/hf-eval-v3-240.json /root/autodl-tmp/LLaMA-Factory/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0397238f-b355-4697-a420-873d8106a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# d = {}\n",
    "\n",
    "# with open(\"/root/autodl-tmp/LLaMA-Factory/data/dataset_info.json\") as f:\n",
    "#     d = json.loads(f.read())\n",
    "#     d['hf_eval_v3_240'] = {\n",
    "#         \"file_name\": \"hf-eval-v3-240.json\",\n",
    "#         \"columns\": {\n",
    "#           \"prompt\": \"instruction\",\n",
    "#           \"query\": \"input\",\n",
    "#           \"response\": \"output\",\n",
    "#           \"history\": \"history\"\n",
    "#         }\n",
    "#     }\n",
    "    \n",
    "# with open(\"/root/autodl-tmp/LLaMA-Factory/data/dataset_info.json\", 'w') as f:\n",
    "#     f.write(json.dumps(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44614582-988d-4bd1-9bef-fdaa45e285d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REPLICATE_API_TOKEN=r8_1YU2oz2exxBYZYIo9sZDngjFwBNvNQD0IiXjD\n"
     ]
    }
   ],
   "source": [
    "%env REPLICATE_API_TOKEN=r8_1YU2oz2exxBYZYIo9sZDngjFwBNvNQD0IiXjD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf0ac14-e74f-44a7-a6ae-446c94fe4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n",
    "def get_prediction(prompt, model=\"vixuowis/codellama-13b-python\"):\n",
    "    deployment = replicate.deployments.get(model)\n",
    "    prediction = deployment.predictions.create(\n",
    "      input={\"prompt\": prompt}\n",
    "    )\n",
    "    prediction.wait()\n",
    "    return \"\".join(prediction.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c0c6c0-6a2d-4996-b8be-cc978fb1408e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00001...00002...00003...00004...00005...00006...00007...00008...00009...00010...00011...00012...00013...00014...00015...00016...00017...00018...An exception occurred: Expecting value: line 1 column 1 (char 0)\n",
      "00019..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_4874/4280536160.py\", line 11, in <cell line: 4>\n",
      "    d['prediction'] = get_prediction(d['instruct'], \"vixuowis/codellama-13b-python\")\n",
      "  File \"/tmp/ipykernel_4874/4135852144.py\", line 8, in get_prediction\n",
      "    prediction.wait()\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/prediction.py\", line 126, in wait\n",
      "    self.reload()\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/prediction.py\", line 142, in reload\n",
      "    updated = self._client.predictions.get(self.id)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/prediction.py\", line 240, in get\n",
      "    resp = self._client._request(\"GET\", f\"/v1/predictions/{id}\")\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/client.py\", line 85, in _request\n",
      "    _raise_for_status(resp)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/client.py\", line 358, in _raise_for_status\n",
      "    raise ReplicateError(resp.json()[\"detail\"])\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/httpx/_models.py\", line 761, in json\n",
      "    return jsonlib.loads(self.content, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/root/miniconda3/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/root/miniconda3/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred: Expecting value: line 1 column 1 (char 0)\n",
      "00020..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_4874/4280536160.py\", line 11, in <cell line: 4>\n",
      "    d['prediction'] = get_prediction(d['instruct'], \"vixuowis/codellama-13b-python\")\n",
      "  File \"/tmp/ipykernel_4874/4135852144.py\", line 8, in get_prediction\n",
      "    prediction.wait()\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/prediction.py\", line 126, in wait\n",
      "    self.reload()\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/prediction.py\", line 142, in reload\n",
      "    updated = self._client.predictions.get(self.id)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/prediction.py\", line 240, in get\n",
      "    resp = self._client._request(\"GET\", f\"/v1/predictions/{id}\")\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/client.py\", line 85, in _request\n",
      "    _raise_for_status(resp)\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/replicate/client.py\", line 358, in _raise_for_status\n",
      "    raise ReplicateError(resp.json()[\"detail\"])\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/httpx/_models.py\", line 761, in json\n",
      "    return jsonlib.loads(self.content, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/root/miniconda3/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/root/miniconda3/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00021...00022...00023...00024...00025...00026...00027...00028...00029...00030...00031...00032...00033...00034...00035...00036...00037...00038...00039...00040...00041...00042...00043...00044...00045...00046...00047...00048...00049...00050...00051...00052...00053...00054...00055...00056...00057...00058...00059...00060...00061...00062...00063...00064...00065...00066...00067...00068...00069...00070...00071...00072...00073...00074...00075...00076...00077...00078...00079...00080...00081...00082...00083...00084...00085...00086...00087...00088...00089...00090...00091...00092...00093...00094...00095...00096...00097...00098...00099...00100...00101...00102...00103...00104...00105...00106...00107...00108...00109...00110...00111...00112...00113...00114...00115...00116...00117...00118...00119...00120...00121...00122...00123...00124...00125...00126...00127...00128...00129...00130...00131...00132...00133...00134...00135...00136...00137...00138...00139...00140...00141...00142...00143...00144...00145...00146...00147...00148...00149...00150...00151...00152...00153...00154...00155...00156...00157...00158...00159...00160...00161...00162...00163...00164...00165...00166...00167...00168...00169...00170...00171...00172...00173...00174...00175...00176...00177...00178...00179...00180...00181...00182...00183...00184...00185...00186...00187...00188...00189...00190...00191...00192...00193...00194...00195...00196...00197...00198...00199...00200...00201...00202...00203...00204...00205...00206...00207...00208...00209...00210...00211...00212...00213...00214...00215...00216...00217...00218...00219...00220...00221...00222...00223...00224...00225...00226...00227...00228...00229...00230...00231...00232...00233...00234...00235...00236...00237...00238...00239...00240...00241..."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import traceback\n",
    "\n",
    "with open(\"output/hf-eval-data-v3-instruct.jsonl\") as f:\n",
    "    for idx, l in enumerate(f):\n",
    "        d = json.loads(l)\n",
    "        idx_str = str(idx + 1).zfill(5)\n",
    "        with open(f\"output/hf-eval-data-v3-result-13b/result-{idx_str}.json\", 'w') as fw:\n",
    "            try:\n",
    "                print(idx_str, end=\"...\")\n",
    "                d['prediction'] = get_prediction(d['instruct'], \"vixuowis/codellama-13b-python\")\n",
    "                fw.write(json.dumps(d))\n",
    "            except Exception as e:\n",
    "                # Handle the exception and print the traceback\n",
    "                print(\"An exception occurred:\", e)\n",
    "                traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bb155-e924-430b-8411-571915fa189c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
