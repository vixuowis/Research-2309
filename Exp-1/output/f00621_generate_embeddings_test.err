Downloading (…)rocessor_config.json:   0%|                                                                       | 0.00/251 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|████████████████████████████████████████████████████████████████| 251/251 [00:00<00:00, 22.1kB/s]
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.
  warnings.warn(
Downloading (…)lve/main/config.json:   0%|                                                                       | 0.00/653 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████| 653/653 [00:00<00:00, 57.4kB/s]
You are using a model of type vilt to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.
Downloading pytorch_model.bin:   0%|                                                                            | 0.00/543M [00:00<?, ?B/s]Downloading pytorch_model.bin:   2%|█▎                                                                 | 10.5M/543M [00:01<01:30, 5.86MB/s]Downloading pytorch_model.bin:   4%|██▌                                                                | 21.0M/543M [00:02<00:56, 9.16MB/s]Downloading pytorch_model.bin:   6%|███▉                                                               | 31.5M/543M [00:03<00:44, 11.5MB/s]Downloading pytorch_model.bin:   8%|█████▏                                                             | 41.9M/543M [00:03<00:38, 12.9MB/s]Downloading pytorch_model.bin:  10%|██████▍                                                            | 52.4M/543M [00:04<00:35, 13.8MB/s]Downloading pytorch_model.bin:  12%|███████▊                                                           | 62.9M/543M [00:05<00:32, 14.6MB/s]Downloading pytorch_model.bin:  14%|█████████                                                          | 73.4M/543M [00:05<00:31, 15.0MB/s]Downloading pytorch_model.bin:  15%|██████████▎                                                        | 83.9M/543M [00:06<00:30, 15.2MB/s]Downloading pytorch_model.bin:  17%|███████████▋                                                       | 94.4M/543M [00:07<00:28, 15.6MB/s]Downloading pytorch_model.bin:  19%|█████████████▏                                                      | 105M/543M [00:07<00:27, 15.8MB/s]Downloading pytorch_model.bin:  21%|██████████████▍                                                     | 115M/543M [00:08<00:27, 15.7MB/s]Downloading pytorch_model.bin:  23%|███████████████▊                                                    | 126M/543M [00:09<00:26, 15.9MB/s]Downloading pytorch_model.bin:  25%|█████████████████                                                   | 136M/543M [00:09<00:25, 15.9MB/s]Downloading pytorch_model.bin:  27%|██████████████████▍                                                 | 147M/543M [00:10<00:24, 16.0MB/s]Downloading pytorch_model.bin:  29%|███████████████████▋                                                | 157M/543M [00:11<00:24, 15.8MB/s]Downloading pytorch_model.bin:  31%|█████████████████████                                               | 168M/543M [00:11<00:23, 16.2MB/s]Downloading pytorch_model.bin:  33%|██████████████████████▎                                             | 178M/543M [00:12<00:22, 15.9MB/s]Downloading pytorch_model.bin:  35%|███████████████████████▋                                            | 189M/543M [00:12<00:22, 16.0MB/s]Downloading pytorch_model.bin:  37%|████████████████████████▉                                           | 199M/543M [00:13<00:21, 15.8MB/s]Downloading pytorch_model.bin:  39%|██████████████████████████▎                                         | 210M/543M [00:14<00:20, 16.2MB/s]Downloading pytorch_model.bin:  41%|███████████████████████████▌                                        | 220M/543M [00:15<00:24, 13.2MB/s]Downloading pytorch_model.bin:  43%|████████████████████████████▉                                       | 231M/543M [00:16<00:22, 13.7MB/s]Downloading pytorch_model.bin:  44%|██████████████████████████████▏                                     | 241M/543M [00:16<00:22, 13.2MB/s]Downloading pytorch_model.bin:  46%|███████████████████████████████▌                                    | 252M/543M [00:17<00:21, 13.4MB/s]Downloading pytorch_model.bin:  48%|████████████████████████████████▊                                   | 262M/543M [00:18<00:20, 13.7MB/s]Downloading pytorch_model.bin:  50%|██████████████████████████████████▏                                 | 273M/543M [00:19<00:19, 13.8MB/s]Downloading pytorch_model.bin:  52%|███████████████████████████████████▍                                | 283M/543M [00:19<00:18, 13.7MB/s]Downloading pytorch_model.bin:  54%|████████████████████████████████████▊                               | 294M/543M [00:20<00:17, 13.9MB/s]Downloading pytorch_model.bin:  56%|██████████████████████████████████████                              | 304M/543M [00:21<00:17, 14.0MB/s]Downloading pytorch_model.bin:  58%|███████████████████████████████████████▍                            | 315M/543M [00:22<00:16, 13.8MB/s]Downloading pytorch_model.bin:  60%|████████████████████████████████████████▋                           | 325M/543M [00:22<00:15, 14.0MB/s]Downloading pytorch_model.bin:  62%|██████████████████████████████████████████                          | 336M/543M [00:23<00:14, 13.9MB/s]Downloading pytorch_model.bin:  64%|███████████████████████████████████████████▎                        | 346M/543M [00:24<00:14, 13.7MB/s]Downloading pytorch_model.bin:  66%|████████████████████████████████████████████▋                       | 357M/543M [00:25<00:13, 13.9MB/s]Downloading pytorch_model.bin:  68%|█████████████████████████████████████████████▉                      | 367M/543M [00:25<00:12, 13.8MB/s]Downloading pytorch_model.bin:  70%|███████████████████████████████████████████████▎                    | 377M/543M [00:27<00:14, 11.4MB/s]Downloading pytorch_model.bin:  71%|████████████████████████████████████████████████▌                   | 388M/543M [00:28<00:12, 12.0MB/s]Downloading pytorch_model.bin:  73%|█████████████████████████████████████████████████▉                  | 398M/543M [00:28<00:11, 12.6MB/s]Downloading pytorch_model.bin:  75%|███████████████████████████████████████████████████▏                | 409M/543M [00:29<00:10, 13.2MB/s]Downloading pytorch_model.bin:  77%|████████████████████████████████████████████████████▌               | 419M/543M [00:30<00:09, 13.3MB/s]Downloading pytorch_model.bin:  79%|█████████████████████████████████████████████████████▊              | 430M/543M [00:31<00:08, 13.5MB/s]Downloading pytorch_model.bin:  81%|███████████████████████████████████████████████████████▏            | 440M/543M [00:31<00:07, 13.3MB/s]Downloading pytorch_model.bin:  83%|████████████████████████████████████████████████████████▍           | 451M/543M [00:32<00:06, 13.7MB/s]Downloading pytorch_model.bin:  85%|█████████████████████████████████████████████████████████▊          | 461M/543M [00:33<00:05, 13.6MB/s]Downloading pytorch_model.bin:  87%|███████████████████████████████████████████████████████████         | 472M/543M [00:34<00:05, 12.9MB/s]Downloading pytorch_model.bin:  89%|████████████████████████████████████████████████████████████▍       | 482M/543M [00:35<00:05, 11.5MB/s]Downloading pytorch_model.bin:  91%|█████████████████████████████████████████████████████████████▋      | 493M/543M [00:36<00:04, 12.1MB/s]Downloading pytorch_model.bin:  93%|███████████████████████████████████████████████████████████████     | 503M/543M [00:36<00:03, 12.7MB/s]Downloading pytorch_model.bin:  95%|████████████████████████████████████████████████████████████████▍   | 514M/543M [00:37<00:02, 13.2MB/s]Downloading pytorch_model.bin:  97%|█████████████████████████████████████████████████████████████████▋  | 524M/543M [00:38<00:01, 13.5MB/s]Downloading pytorch_model.bin:  99%|███████████████████████████████████████████████████████████████████ | 535M/543M [00:39<00:00, 13.7MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████| 543M/543M [00:39<00:00, 13.9MB/s]Downloading pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████| 543M/543M [00:39<00:00, 13.7MB/s]
Some weights of ViTModel were not initialized from the model checkpoint at dandelin/vilt-b32-mlm and are newly initialized: ['encoder.layer.7.attention.attention.value.weight', 'encoder.layer.2.attention.attention.key.bias', 'encoder.layer.2.layernorm_before.bias', 'encoder.layer.3.layernorm_before.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.attention.value.weight', 'encoder.layer.6.attention.attention.query.bias', 'encoder.layer.10.layernorm_before.bias', 'encoder.layer.10.layernorm_after.weight', 'encoder.layer.9.attention.attention.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.8.attention.attention.value.bias', 'encoder.layer.8.layernorm_before.weight', 'encoder.layer.2.attention.attention.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.2.layernorm_after.weight', 'pooler.dense.weight', 'encoder.layer.5.layernorm_after.bias', 'encoder.layer.9.layernorm_after.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.attention.value.weight', 'encoder.layer.6.layernorm_before.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.2.attention.attention.value.weight', 'encoder.layer.2.attention.attention.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'layernorm.bias', 'encoder.layer.6.attention.attention.key.bias', 'embeddings.patch_embeddings.projection.bias', 'encoder.layer.9.attention.attention.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.attention.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.attention.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.attention.attention.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.8.attention.attention.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.attention.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.attention.attention.query.weight', 'encoder.layer.11.attention.attention.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.attention.attention.value.weight', 'encoder.layer.8.layernorm_before.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.attention.value.weight', 'encoder.layer.4.layernorm_before.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.8.attention.attention.key.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'embeddings.position_embeddings', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.layernorm_after.weight', 'encoder.layer.11.attention.attention.query.bias', 'encoder.layer.2.layernorm_after.bias', 'encoder.layer.4.layernorm_after.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.layernorm_after.bias', 'encoder.layer.7.layernorm_after.weight', 'encoder.layer.6.attention.attention.value.weight', 'encoder.layer.10.layernorm_after.bias', 'encoder.layer.4.attention.attention.query.bias', 'encoder.layer.0.attention.attention.key.weight', 'encoder.layer.3.attention.attention.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.8.layernorm_after.weight', 'embeddings.cls_token', 'encoder.layer.10.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.attention.attention.query.weight', 'encoder.layer.0.layernorm_before.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.layernorm_after.weight', 'encoder.layer.0.layernorm_before.weight', 'encoder.layer.7.layernorm_after.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.1.layernorm_before.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.attention.key.bias', 'encoder.layer.6.layernorm_before.bias', 'encoder.layer.1.attention.attention.query.weight', 'encoder.layer.11.layernorm_after.bias', 'encoder.layer.11.layernorm_before.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.attention.attention.query.bias', 'encoder.layer.10.attention.attention.key.weight', 'encoder.layer.7.layernorm_before.bias', 'embeddings.patch_embeddings.projection.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.attention.attention.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.3.attention.attention.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.6.layernorm_after.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.attention.attention.value.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.attention.attention.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.attention.attention.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.layernorm_before.bias', 'encoder.layer.1.attention.attention.key.bias', 'encoder.layer.2.attention.attention.value.bias', 'encoder.layer.9.layernorm_before.bias', 'encoder.layer.8.attention.attention.query.bias', 'encoder.layer.3.attention.attention.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.7.layernorm_before.weight', 'encoder.layer.1.layernorm_after.bias', 'encoder.layer.0.layernorm_after.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.10.attention.attention.key.bias', 'encoder.layer.4.attention.attention.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.attention.value.bias', 'encoder.layer.1.attention.attention.value.weight', 'encoder.layer.5.attention.attention.key.bias', 'encoder.layer.7.attention.attention.value.bias', 'layernorm.weight', 'encoder.layer.4.layernorm_before.bias', 'encoder.layer.3.attention.attention.query.bias', 'encoder.layer.5.layernorm_before.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.attention.attention.key.weight', 'encoder.layer.7.attention.attention.key.bias', 'encoder.layer.1.layernorm_after.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.7.attention.attention.query.bias', 'encoder.layer.3.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.5.attention.attention.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.layernorm_before.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.attention.query.weight', 'encoder.layer.10.attention.attention.query.weight', 'encoder.layer.11.attention.attention.value.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.attention.attention.value.bias', 'encoder.layer.1.layernorm_before.bias', 'encoder.layer.11.attention.attention.key.weight', 'encoder.layer.2.layernorm_before.weight', 'encoder.layer.2.attention.attention.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.attention.attention.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.1.attention.attention.key.weight', 'encoder.layer.6.attention.attention.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.7.attention.attention.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.4.attention.attention.query.weight', 'encoder.layer.10.layernorm_before.weight', 'encoder.layer.3.layernorm_before.weight', 'encoder.layer.3.layernorm_after.weight', 'encoder.layer.5.layernorm_before.weight', 'encoder.layer.6.layernorm_after.bias', 'encoder.layer.11.attention.attention.value.bias', 'encoder.layer.6.attention.attention.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.4.attention.attention.value.bias', 'encoder.layer.11.attention.attention.key.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.attention.attention.query.bias', 'encoder.layer.6.attention.attention.value.bias', 'encoder.layer.0.attention.attention.key.bias', 'encoder.layer.5.layernorm_after.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.layernorm_after.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.layernorm_after.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.attention.key.weight', 'encoder.layer.8.layernorm_after.bias', 'encoder.layer.10.attention.attention.query.bias', 'encoder.layer.10.attention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "output/f00621_generate_embeddings_test.py", line 10, in <module>
    embeddings = generate_embeddings(image_paths)
  File "/root/Experiments/output/f00621_generate_embeddings.py", line 20, in generate_embeddings
    image = Image.open(image_path)
NameError: name 'Image' is not defined
