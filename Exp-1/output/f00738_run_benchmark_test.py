from f00738_run_benchmark import *
def test_run_benchmark():
    assert run_benchmark() == "====================       INFERENCE - SPEED - RESULT       ====================\n--------------------------------------------------------------------------------\nModel Name             Batch Size     Seq Length     Time in s                  \n--------------------------------------------------------------------------------\nbert-base-uncased          8               8             0.006     \nbert-base-uncased          8               32            0.006     \nbert-base-uncased          8              128            0.018     \nbert-base-uncased          8              512            0.088     \n--------------------------------------------------------------------------------\n\n====================      INFERENCE - MEMORY - RESULT       ====================\n--------------------------------------------------------------------------------\nModel Name             Batch Size     Seq Length    Memory in MB \n--------------------------------------------------------------------------------\nbert-base-uncased          8               8             1227\nbert-base-uncased          8               32            1281\nbert-base-uncased          8              128            1307\nbert-base-uncased          8              512            1539\n--------------------------------------------------------------------------------\n\n====================        ENVIRONMENT INFORMATION         ====================\n\n- transformers_version: 2.11.0\n- framework: PyTorch\n- use_torchscript: False\n- framework_version: 1.4.0\n- python_version: 3.6.10\n- system: Linux\n- cpu: x86_64\n- architecture: 64bit\n- date: 2020-06-29\n- time: 08:58:43.371351\n- fp16: False\n- use_multiprocessing: True\n- only_pretrain_model: False\n- cpu_ram_mb: 32088\n- use_gpu: True\n- num_gpus: 1\n- gpu: TITAN RTX\n- gpu_ram_mb: 24217\n- gpu_power_watts: 280.0\n- gpu_performance_state: 2\n- use_tpu: False"


def run_benchmark():
    results = benchmark.run()
    print(results)

def test_run_benchmark():
    assert run_benchmark() == "====================       INFERENCE - SPEED - RESULT       ====================\n--------------------------------------------------------------------------------\nModel Name             Batch Size     Seq Length     Time in s                  \n--------------------------------------------------------------------------------\nbert-base-uncased          8               8             0.006     \nbert-base-uncased          8               32            0.006     \nbert-base-uncased          8              128            0.018     \nbert-base-uncased          8              512            0.088     \n--------------------------------------------------------------------------------\n\n====================      INFERENCE - MEMORY - RESULT       ====================\n--------------------------------------------------------------------------------\nModel Name             Batch Size     Seq Length    Memory in MB \n--------------------------------------------------------------------------------\nbert-base-uncased          8               8             1227\nbert-base-uncased          8               32            1281\nbert-base-uncased          8              128            1307\nbert-base-uncased          8              512            1539\n--------------------------------------------------------------------------------\n\n====================        ENVIRONMENT INFORMATION         ====================\n\n- transformers_version: 2.11.0\n- framework: PyTorch\n- use_torchscript: False\n- framework_version: 1.4.0\n- python_version: 3.6.10\n- system: Linux\n- cpu: x86_64\n- architecture: 64bit\n- date: 2020-06-29\n- time: 08:58:43.371351\n- fp16: False\n- use_multiprocessing: True\n- only_pretrain_model: False\n- cpu_ram_mb: 32088\n- use_gpu: True\n- num_gpus: 1\n- gpu: TITAN RTX\n- gpu_ram_mb: 24217\n- gpu_power_watts: 280.0\n- gpu_performance_state: 2\n- use_tpu: False"
