Downloading (…)rocessor_config.json:   0%|                                                                       | 0.00/254 [00:00<?, ?B/s]Downloading (…)rocessor_config.json: 100%|████████████████████████████████████████████████████████████████| 254/254 [00:00<00:00, 24.4kB/s]
Downloading (…)okenizer_config.json:   0%|                                                                       | 0.00/397 [00:00<?, ?B/s]Downloading (…)okenizer_config.json: 100%|████████████████████████████████████████████████████████████████| 397/397 [00:00<00:00, 31.8kB/s]
Downloading (…)olve/main/vocab.json:   0%|                                                                     | 0.00/1.34M [00:00<?, ?B/s]Downloading (…)olve/main/vocab.json: 100%|████████████████████████████████████████████████████████████| 1.34M/1.34M [00:00<00:00, 1.35MB/s]Downloading (…)olve/main/vocab.json: 100%|████████████████████████████████████████████████████████████| 1.34M/1.34M [00:00<00:00, 1.35MB/s]
/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:53: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: 
  warnings.warn(
Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1648, in _chmod_and_replace
    tmp_file.touch()
  File "/root/miniconda3/envs/py38/lib/python3.8/pathlib.py", line 1278, in touch
    fd = self._raw_open(flags, mode)
  File "/root/miniconda3/envs/py38/lib/python3.8/pathlib.py", line 1087, in _raw_open
    return self._accessor.open(self, flags, mode)
OSError: [Errno 122] Disk quota exceeded: '/root/autodl-tmp/.cache/huggingface/hub/models--facebook--mms-1b-all/tmp_899ed11e-c504-4ff4-9739-23be0157df9b'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 51, in from_pretrained
    return super().from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/processing_utils.py", line 226, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/processing_utils.py", line 270, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 736, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 1813, in from_pretrained
    resolved_vocab_files[file_id] = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1440, in hf_hub_download
    _chmod_and_replace(temp_file.name, blob_path)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1652, in _chmod_and_replace
    tmp_file.unlink()
  File "/root/miniconda3/envs/py38/lib/python3.8/pathlib.py", line 1325, in unlink
    self._accessor.unlink(self)
FileNotFoundError: [Errno 2] No such file or directory: '/root/autodl-tmp/.cache/huggingface/hub/models--facebook--mms-1b-all/tmp_899ed11e-c504-4ff4-9739-23be0157df9b'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "output/f00873_load_model_and_processor_test.py", line 12, in <module>
    test_load_model_and_processor()
  File "output/f00873_load_model_and_processor_test.py", line 4, in test_load_model_and_processor
    processor, model = load_model_and_processor(model_id)
  File "/root/Experiments/output/f00873_load_model_and_processor.py", line 6, in load_model_and_processor
    processor = AutoProcessor.from_pretrained(model_id)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/processing_auto.py", line 287, in from_pretrained
    return processor_class.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py", line 63, in from_pretrained
    tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 1813, in from_pretrained
    resolved_vocab_files[file_id] = cached_file(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1417, in hf_hub_download
    with temp_file_manager() as temp_file:
  File "/root/miniconda3/envs/py38/lib/python3.8/tempfile.py", line 540, in NamedTemporaryFile
    (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)
  File "/root/miniconda3/envs/py38/lib/python3.8/tempfile.py", line 250, in _mkstemp_inner
    fd = _os.open(file, flags, 0o600)
OSError: [Errno 122] Disk quota exceeded: '/root/autodl-tmp/.cache/huggingface/hub/tmptash_rwu'
