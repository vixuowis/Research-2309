Downloading (…)lve/main/config.json:   0%|                                                                       | 0.00/693 [00:00<?, ?B/s]Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████| 693/693 [00:00<00:00, 61.5kB/s]
Traceback (most recent call last):
  File "output/f00792_load_model_with_memory_test.py", line 11, in <module>
    test_load_model_with_memory()
  File "output/f00792_load_model_with_memory_test.py", line 7, in test_load_model_with_memory
    model = load_model_with_memory(model_name, device_map, load_in_4bit, max_memory_mapping)
  File "/root/Experiments/output/f00792_load_model_with_memory.py", line 19, in load_model_with_memory
    model = AutoModelForCausalLM.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/root/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2482, in from_pretrained
    raise ImportError(
ImportError: Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` 
